{
    "1809.09060": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cortes-Ciriano",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Isidro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bender",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Confidence: A Computationally Efficient Framework for Calculating\n  Reliable Errors for Deep Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI q-bio.QM stat.ML",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1021/acs.jcim.8b00542",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep learning architectures have proved versatile in a number of drug\ndiscovery applications, including the modelling of in vitro compound activity.\nWhile controlling for prediction confidence is essential to increase the trust,\ninterpretability and usefulness of virtual screening models in drug discovery,\ntechniques to estimate the reliability of the predictions generated with deep\nlearning networks remain largely underexplored. Here, we present Deep\nConfidence, a framework to compute valid and efficient confidence intervals for\nindividual predictions using the deep learning technique Snapshot Ensembling\nand conformal prediction. Specifically, Deep Confidence generates an ensemble\nof deep neural networks by recording the network parameters throughout the\nlocal minima visited during the optimization phase of a single neural network.\nThis approach serves to derive a set of base learners (i.e., snapshots) with\ncomparable predictive power on average, that will however generate slightly\ndifferent predictions for a given instance. The variability across base\nlearners and the validation residuals are in turn harnessed to compute\nconfidence intervals using the conformal prediction framework. Using a set of\n24 diverse IC50 data sets from ChEMBL 23, we show that Snapshot Ensembles\nperform on par with Random Forest (RF) and ensembles of independently trained\ndeep neural networks. In addition, we find that the confidence regions\npredicted using the Deep Confidence framework span a narrower set of values.\nOverall, Deep Confidence represents a highly versatile error prediction\nframework that can be applied to any deep learning-based application at no\nextra computational cost."
    },
    "1806.00050": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cotter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Heinrich"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Muller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Narayan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Taman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serena"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tao"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Set Functions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose learning flexible but interpretable functions that aggregate a\nvariable-length set of permutation-invariant feature vectors to predict a\nlabel. We use a deep lattice network model so we can architect the model\nstructure to enhance interpretability, and add monotonicity constraints between\ninputs-and-outputs. We then use the proposed set function to automate the\nengineering of dense, interpretable features from sparse categorical features,\nwhich we call semantic feature engine. Experiments on real-world data show the\nachieved accuracy is similar to deep sets or deep neural networks, and is\neasier to debug and understand."
    },
    "1811.01012": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhiraj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raghu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dinesh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pandey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gaurav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Joshi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sachindra"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unsupervised Learning of Interpretable Dialog Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recently several deep learning based models have been proposed for end-to-end\nlearning of dialogs. While these models can be trained from data without the\nneed for any additional annotations, it is hard to interpret them. On the other\nhand, there exist traditional state based dialog systems, where the states of\nthe dialog are discrete and hence easy to interpret. However these states need\nto be handcrafted and annotated in the data. To achieve the best of both\nworlds, we propose Latent State Tracking Network (LSTN) using which we learn an\ninterpretable model in unsupervised manner. The model defines a discrete latent\nvariable at each turn of the conversation which can take a finite set of\nvalues. Since these discrete variables are not present in the training data, we\nuse EM algorithm to train our model in unsupervised manner. In the experiments,\nwe show that LSTN can help achieve interpretability in dialog models without\nmuch decrease in performance compared to end-to-end approaches."
    },
    "1401.3860": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-01-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tobias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Toussaint",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marc"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Planning with Noisy Probabilistic Relational Rules",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 39, pages\n  1-49, 2010",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.3093",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Noisy probabilistic relational rules are a promising world model\nrepresentation for several reasons. They are compact and generalize over world\ninstantiations. They are usually interpretable and they can be learned\neffectively from the action experiences in complex worlds. We investigate\nreasoning with such rules in grounded relational domains. Our algorithms\nexploit the compactness of rules for efficient and flexible decision-theoretic\nplanning. As a first approach, we combine these rules with the Upper Confidence\nBounds applied to Trees (UCT) algorithm based on look-ahead trees. Our second\napproach converts these rules into a structured dynamic Bayesian network\nrepresentation and predicts the effects of action sequences using approximate\ninference and beliefs over world states. We evaluate the effectiveness of our\napproaches for planning in a simulated complex 3D robot manipulation scenario\nwith an articulated manipulator and realistic physics and in domains of the\nprobabilistic planning competition. Empirical results show that our methods can\nsolve problems where existing methods fail."
    },
    "1708.06551": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Steckelmacher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Denis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Roijers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diederik M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harutyunyan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vrancx",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Plisnier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "H\u00e9l\u00e8ne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Now\u00e9",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ann"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Reinforcement Learning in POMDPs with Memoryless Options and\n  Option-Observation Initiation Sets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many real-world reinforcement learning problems have a hierarchical nature,\nand often exhibit some degree of partial observability. While hierarchy and\npartial observability are usually tackled separately (for instance by combining\nrecurrent neural networks and options), we show that addressing both problems\nsimultaneously is simpler and more efficient in many cases. More specifically,\nwe make the initiation set of options conditional on the previously-executed\noption, and show that options with such Option-Observation Initiation Sets\n(OOIs) are at least as expressive as Finite State Controllers (FSCs), a\nstate-of-the-art approach for learning in POMDPs. OOIs are easy to design based\non an intuitive description of the task, lead to explainable policies and keep\nthe top-level and option policies memoryless. Our experiments show that OOIs\nallow agents to learn optimal policies in challenging POMDPs, while being much\nmore sample-efficient than a recurrent neural network over options."
    },
    "1708.03246": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bogdanova",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dasha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yazdani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Majid"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "SESA: Supervised Explicit Semantic Analysis",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent years supervised representation learning has provided state of the\nart or close to the state of the art results in semantic analysis tasks\nincluding ranking and information retrieval. The core idea is to learn how to\nembed items into a latent space such that they optimize a supervised objective\nin that latent space. The dimensions of the latent space have no clear\nsemantics, and this reduces the interpretability of the system. For example, in\npersonalization models, it is hard to explain why a particular item is ranked\nhigh for a given user profile. We propose a novel model of representation\nlearning called Supervised Explicit Semantic Analysis (SESA) that is trained in\na supervised fashion to embed items to a set of dimensions with explicit\nsemantics. The model learns to compare two objects by representing them in this\nexplicit space, where each dimension corresponds to a concept from a knowledge\nbase. This work extends Explicit Semantic Analysis (ESA) with a supervised\nmodel for ranking problems. We apply this model to the task of Job-Profile\nrelevance in LinkedIn in which a set of skills defines our explicit dimensions\nof the space. Every profile and job are encoded to this set of skills their\nsimilarity is calculated in this space. We use RNNs to embed text input into\nthis space. In addition to interpretability, our model makes use of the\nweb-scale collaborative skills data that is provided by users for each LinkedIn\nprofile. Our model provides state of the art result while it remains\ninterpretable."
    },
    "1810.02338": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kexin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiajun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chuang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Torralba",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua B."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Neural-Symbolic VQA: Disentangling Reasoning from Vision and Language\n  Understanding",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "NIPS 2018 (spotlight). The first two authors contributed equally to\n  this work. Project page: http://nsvqa.csail.mit.edu",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We marry two powerful ideas: deep representation learning for visual\nrecognition and language understanding, and symbolic program execution for\nreasoning. Our neural-symbolic visual question answering (NS-VQA) system first\nrecovers a structural scene representation from the image and a program trace\nfrom the question. It then executes the program on the scene representation to\nobtain an answer. Incorporating symbolic structure as prior knowledge offers\nthree unique advantages. First, executing programs on a symbolic space is more\nrobust to long program traces; our model can solve complex reasoning tasks\nbetter, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model\nis more data- and memory-efficient: it performs well after learning on a small\nnumber of training data; it can also encode an image into a compact\nrepresentation, requiring less storage than existing methods for offline\nquestion answering. Third, symbolic program execution offers full transparency\nto the reasoning process; we are thus able to interpret and diagnose each\nexecution step."
    },
    "1705.07874": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lundberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Scott"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Su-In"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Unified Approach to Interpreting Model Predictions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Understanding why a model makes a certain prediction can be as crucial as the\nprediction's accuracy in many applications. However, the highest accuracy for\nlarge modern datasets is often achieved by complex models that even experts\nstruggle to interpret, such as ensemble or deep learning models, creating a\ntension between accuracy and interpretability. In response, various methods\nhave recently been proposed to help users interpret the predictions of complex\nmodels, but it is often unclear how these methods are related and when one\nmethod is preferable over another. To address this problem, we present a\nunified framework for interpreting predictions, SHAP (SHapley Additive\nexPlanations). SHAP assigns each feature an importance value for a particular\nprediction. Its novel components include: (1) the identification of a new class\nof additive feature importance measures, and (2) theoretical results showing\nthere is a unique solution in this class with a set of desirable properties.\nThe new class unifies six existing methods, notable because several recent\nmethods in the class lack the proposed desirable properties. Based on insights\nfrom this unification, we present new methods that show improved computational\nperformance and/or better consistency with human intuition than previous\napproaches."
    },
    "1805.02408": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ding",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boyang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Quan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Li"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving Knowledge Graph Embedding Using Simple Constraints",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in ACL 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of\ncurrent research. Early works performed this task via simple models developed\nover KG triples. Recent attempts focused on either designing more complicated\ntriple scoring models, or incorporating extra information beyond triples. This\npaper, by contrast, investigates the potential of using very simple constraints\nto improve KG embedding. We examine non-negativity constraints on entity\nrepresentations and approximate entailment constraints on relation\nrepresentations. The former help to learn compact and interpretable\nrepresentations for entities. The latter further encode regularities of logical\nentailment between relations into their distributed representations. These\nconstraints impose prior beliefs upon the structure of the embedding space,\nwithout negative impacts on efficiency or scalability. Evaluation on WordNet,\nFreebase, and DBpedia shows that our approach is simple yet surprisingly\neffective, significantly and consistently outperforming competitive baselines.\nThe constraints imposed indeed improve model interpretability, leading to a\nsubstantially increased structuring of the embedding space. Code and data are\navailable at https://github.com/iieir-km/ComplEx-NNE_AER."
    },
    "1707.05654": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Toffano",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zeno",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "L2S"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dubois",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fran\u00e7ois",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "LM-Orsay"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Eigenlogic: Interpretable Quantum Observables with applications to Fuzzy\n  Behavior of Vehicular Robots",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "ccsd",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This work proposes a formulation of propositional logic, named Eigenlogic,\nusing quantum observables as propositions. The eigenvalues of these operators\nare the truth-values and the associated eigenvectors the interpretations of the\npropositional system. Fuzzy logic arises naturally when considering vectors\noutside the eigensystem, the fuzzy membership function is obtained by the Born\nrule of the logical observable.This approach is then applied in the context of\nquantum robots using simple behavioral agents represented by Braitenberg\nvehicles. Processing with non-classical logic such as multivalued logic, fuzzy\nlogic and the quantum Eigenlogic permits to enlarge the behavior possibilities\nand the associated decisions of these simple agents."
    },
    "1605.00241": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "El-Barashy",
                "http://arxiv.org/OAI/arXiv/:forenames": "Basem G."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Common-Description Learning: A Framework for Learning Algorithms and\n  Generating Subproblems from Few Examples",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "32 pages, 13 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Current learning algorithms face many difficulties in learning simple\npatterns and using them to learn more complex ones. They also require more\nexamples than humans do to learn the same pattern, assuming no prior knowledge.\nIn this paper, a new learning framework is introduced that is called\ncommon-description learning (CDL). This framework has been tested on 32 small\nmulti-task datasets, and the results show that it was able to learn complex\nalgorithms from a few number of examples. The final model is perfectly\ninterpretable and its depth depends on the question. What is meant by depth\nhere is that whenever needed, the model learns to break down the problem into\nsimpler subproblems and solves them using previously learned models. Finally,\nwe explain the capabilities of our framework in discovering complex relations\nin data and how it can help in improving language understanding in machines."
    },
    "1806.03492": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bertram",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Deterministic MDPs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Work in progress",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a method for a certain class of Markov Decision Processes (MDPs)\nthat can relate the optimal policy back to one or more reward sources in the\nenvironment. For a given initial state, without fully computing the value\nfunction, q-value function, or the optimal policy the algorithm can determine\nwhich rewards will and will not be collected, whether a given reward will be\ncollected only once or continuously, and which local maximum within the value\nfunction the initial state will ultimately lead to. We demonstrate that the\nmethod can be used to map the state space to identify regions that are\ndominated by one reward source and can fully analyze the state space to explain\nall actions. We provide a mathematical framework to show how all of this is\npossible without first computing the optimal policy or value function."
    },
    "1802.03052": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jansen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wainwright",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Elizabeth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marmorstein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steven"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Morrison",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Clayton T."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "WorldTree: A Corpus of Explanation Graphs for Elementary Science\n  Questions supporting Multi-Hop Inference",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at the Language Resource and Evaluation Conference (LREC)\n  2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Developing methods of automated inference that are able to provide users with\ncompelling human-readable justifications for why the answer to a question is\ncorrect is critical for domains such as science and medicine, where user trust\nand detecting costly errors are limiting factors to adoption. One of the\ncentral barriers to training question answering models on explainable inference\ntasks is the lack of gold explanations to serve as training data. In this paper\nwe present a corpus of explanations for standardized science exams, a recent\nchallenge task for question answering. We manually construct a corpus of\ndetailed explanations for nearly all publicly available standardized elementary\nscience question (approximately 1,680 3rd through 5th grade questions) and\nrepresent these as \"explanation graphs\" -- sets of lexically overlapping\nsentences that describe how to arrive at the correct answer to a question\nthrough a combination of domain and world knowledge. We also provide an\nexplanation-centered tablestore, a collection of semi-structured tables that\ncontain the knowledge to construct these elementary science explanations.\nTogether, these two knowledge resources map out a substantial portion of the\nknowledge required for answering and explaining elementary science exams, and\nprovide both structured and free-text training data for the explainable\ninference task."
    },
    "1803.07540": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Edwards",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lilian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Enslaving the Algorithm: From a \"Right to an Explanation\" to a \"Right to\n  Better Decisions\"?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 0 figures, forthcoming in IEEE Security and Privacy, 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As concerns about unfairness and discrimination in \"black box\" machine\nlearning systems rise, a legal \"right to an explanation\" has emerged as a\ncompellingly attractive approach for challenge and redress. We outline recent\ndebates on the limited provisions in European data protection law, and\nintroduce and analyze newer explanation rights in French administrative law and\nthe draft modernized Council of Europe Convention 108. While individual rights\ncan be useful, in privacy law they have historically unreasonably burdened the\naverage data subject. \"Meaningful information\" about algorithmic logics is more\ntechnically possible than commonly thought, but this exacerbates a new\n\"transparency fallacy\"---an illusion of remedy rather than anything\nsubstantively helpful. While rights-based approaches deserve a firm place in\nthe toolbox, other forms of governance, such as impact assessments, \"soft law,\"\njudicial review, and model repositories deserve more attention, alongside\ncatalyzing agencies acting for users to control algorithmic system design."
    },
    "1609.01926": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-09-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Carmantini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giovanni Sirio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Graben",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter beim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Desroches",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathieu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rodrigues",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serafim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A modular architecture for transparent computation in Recurrent Neural\n  Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.CL cs.FL cs.SC",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.neunet.2016.09.001",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Computation is classically studied in terms of automata, formal languages and\nalgorithms; yet, the relation between neural dynamics and symbolic\nrepresentations and operations is still unclear in traditional eliminative\nconnectionism. Therefore, we suggest a unique perspective on this central\nissue, to which we would like to refer as to transparent connectionism, by\nproposing accounts of how symbolic computation can be implemented in neural\nsubstrates. In this study we first introduce a new model of dynamics on a\nsymbolic space, the versatile shift, showing that it supports the real-time\nsimulation of a range of automata. We then show that the Goedelization of\nversatile shifts defines nonlinear dynamical automata, dynamical systems\nevolving on a vectorial space. Finally, we present a mapping between nonlinear\ndynamical automata and recurrent artificial neural networks. The mapping\ndefines an architecture characterized by its granular modularity, where data,\nsymbolic operations and their control are not only distinguishable in\nactivation space, but also spatially localizable in the network itself, while\nmaintaining a distributed encoding of symbolic representations. The resulting\nnetworks simulate automata in real-time and are programmed directly, in absence\nof network training. To discuss the unique characteristics of the architecture\nand their consequences, we present two examples: i) the design of a Central\nPattern Generator from a finite-state locomotive controller, and ii) the\ncreation of a network simulating a system of interactive automata that supports\nthe parsing of garden-path sentences as investigated in psycholinguistics\nexperiments."
    },
    "1804.09502": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zejian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongchuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "He",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongxing"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unsupervised Disentangled Representation Learning with Analogical\n  Relations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Learning the disentangled representation of interpretable generative factors\nof data is one of the foundations to allow artificial intelligence to think\nlike people. In this paper, we propose the analogical training strategy for the\nunsupervised disentangled representation learning in generative models. The\nanalogy is one of the typical cognitive processes, and our proposed strategy is\nbased on the observation that sample pairs in which one is different from the\nother in one specific generative factor show the same analogical relation.\nThus, the generator is trained to generate sample pairs from which a designed\nclassifier can identify the underlying analogical relation. In addition, we\npropose a disentanglement metric called the subspace score, which is inspired\nby subspace learning methods and does not require supervised information.\nExperiments show that our proposed training strategy allows the generative\nmodels to find the disentangled factors, and that our methods can give\ncompetitive performances as compared with the state-of-the-art methods."
    },
    "1803.07517": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ras",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gabrielle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van Gerven",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Haselager",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, 1 figure, This article will appear as a chapter in\n  Explainable and Interpretable Models in Computer Vision and Machine Learning\n  Springer series on Challenges in Machine Learning",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68-02",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes."
    },
    "1804.08597": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garcez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Artur d'Avila"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dutra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aimore Resende Riquetti"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Alonso",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eduardo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Symbolic Reinforcement Learning with Common Sense",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 13 figures, 26 references",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep Reinforcement Learning (deep RL) has made several breakthroughs in\nrecent years in applications ranging from complex control tasks in unmanned\nvehicles to game playing. Despite their success, deep RL still lacks several\nimportant capacities of human intelligence, such as transfer learning,\nabstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)\nseeks to incorporate such capacities to deep Q-networks (DQN) by learning a\nrelevant symbolic representation prior to using Q-learning. In this paper, we\npropose a novel extension of DSRL, which we call Symbolic Reinforcement\nLearning with Common Sense (SRL+CS), offering a better balance between\ngeneralization and specialization, inspired by principles of common sense when\nassigning rewards and aggregating Q-values. Experiments reported in this paper\nshow that SRL+CS learns consistently faster than Q-learning and DSRL, achieving\nalso a higher accuracy. In the hardest case, where agents were trained in a\ndeterministic environment and tested in a random environment, SRL+CS achieves\nnearly 100% average accuracy compared to DSRL's 70% and DQN's 50% accuracy. To\nthe best of our knowledge, this is the first case of near perfect zero-shot\ntransfer learning using Reinforcement Learning."
    },
    "1811.08120": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Weiyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yanyan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yanmin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Linpeng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explaining Latent Factor Models for Recommendation with Influence\n  Functions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.IR stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Latent factor models (LFMs) such as matrix factorization achieve the\nstate-of-the-art performance among various Collaborative Filtering (CF)\napproaches for recommendation. Despite the high recommendation accuracy of\nLFMs, a critical issue to be resolved is the lack of explainability. Extensive\nefforts have been made in the literature to incorporate explainability into\nLFMs. However, they either rely on auxiliary information which may not be\navailable in practice, or fail to provide easy-to-understand explanations. In\nthis paper, we propose a fast influence analysis method named FIA, which\nsuccessfully enforces explicit neighbor-style explanations to LFMs with the\ntechnique of influence functions stemmed from robust statistics. We first\ndescribe how to employ influence functions to LFMs to deliver neighbor-style\nexplanations. Then we develop a novel influence computation algorithm for\nmatrix factorization with high efficiency. We further extend it to the more\ngeneral neural collaborative filtering and introduce an approximation algorithm\nto accelerate influence analysis over neural network models. Experimental\nresults on real datasets demonstrate the correctness, efficiency and usefulness\nof our proposed method."
    },
    "1809.08098": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shiqi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kexin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Whitehouse",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Justin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Junfeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suman"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficient Formal Safety Analysis of Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.LO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to NIPS'18",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neural networks are increasingly deployed in real-world safety-critical\ndomains such as autonomous driving, aircraft collision avoidance, and malware\ndetection. However, these networks have been shown to often mispredict on\ninputs with minor adversarial or even accidental perturbations. Consequences of\nsuch errors can be disastrous and even potentially fatal as shown by the recent\nTesla autopilot crash. Thus, there is an urgent need for formal analysis\nsystems that can rigorously check neural networks for violations of different\nsafety properties such as robustness against adversarial perturbations within a\ncertain $L$-norm of a given image. An effective safety analysis system for a\nneural network must be able to either ensure that a safety property is\nsatisfied by the network or find a counterexample, i.e., an input for which the\nnetwork will violate the property. Unfortunately, most existing techniques for\nperforming such analysis struggle to scale beyond very small networks and the\nones that can scale to larger networks suffer from high false positives and\ncannot produce concrete counterexamples in case of a property violation. In\nthis paper, we present a new efficient approach for rigorously checking\ndifferent safety properties of neural networks that significantly outperforms\nexisting approaches by multiple orders of magnitude. Our approach can check\ndifferent safety properties and find concrete counterexamples for networks that\nare 10$\\times$ larger than the ones supported by existing analysis techniques.\nWe believe that our approach to estimating tight output bounds of a network for\na given input range can also help improve the explainability of neural networks\nand guide the training process of more robust neural networks."
    },
    "1711.07414": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Herman",
                "http://arxiv.org/OAI/arXiv/:forenames": "Bernease"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Promise and Peril of Human Evaluation for Model Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Transparency, user trust, and human comprehension are popular ethical\nmotivations for interpretable machine learning. In support of these goals,\nresearchers evaluate model explanation performance using humans and real world\napplications. This alone presents a challenge in many areas of artificial\nintelligence. In this position paper, we propose a distinction between\ndescriptive and persuasive explanations. We discuss reasoning suggesting that\nfunctional interpretability may be correlated with cognitive function and user\npreferences. If this is indeed the case, evaluation and optimization using\nfunctional metrics could perpetuate implicit cognitive bias in explanations\nthat threaten transparency. Finally, we propose two potential research\ndirections to disambiguate cognitive function and explanation models, retaining\ncontrol over the tradeoff between accuracy and interpretability."
    },
    "1408.5246": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-08-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nguyen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Duc-Hien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Le",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manh-Thanh"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving the Interpretability of Support Vector Machines-based Fuzzy\n  Rules",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68U35",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Support vector machines (SVMs) and fuzzy rule systems are functionally\nequivalent under some conditions. Therefore, the learning algorithms developed\nin the field of support vector machines can be used to adapt the parameters of\nfuzzy systems. Extracting fuzzy models from support vector machines has the\ninherent advantage that the model does not need to determine the number of\nrules in advance. However, after the support vector machine learning, the\ncomplexity is usually high, and interpretability is also impaired. This paper\nnot only proposes a complete framework for extracting interpretable SVM-based\nfuzzy modeling, but also provides optimization issues of the models.\nSimulations examples are given to embody the idea of this paper."
    },
    "1608.07398": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "G\u00f6ssler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gregor",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "INRIA, France"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sokolsky",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oleg"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Proceedings First Workshop on Causal Reasoning for Embedded and\n  safety-critical Systems Technologies",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LO cs.AI cs.SE",
        "http://arxiv.org/OAI/arXiv/:proxy": "EPTCS",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "EPTCS 224, 2016",
        "http://arxiv.org/OAI/arXiv/:doi": "10.4204/EPTCS.224",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Formal approaches for automated causality analysis, fault localization,\nexplanation of events, accountability and blaming have been proposed\nindependently by several communities --- in particular, AI, concurrency,\nmodel-based diagnosis, formal methods. Work on these topics has significantly\ngained speed during the last years. The goals of CREST are to bring together\nand foster exchange between researchers from the different communities, and to\npresent and discuss recent advances and new ideas in the field.\n  The workshop program consisted of a set of invited and contributed\npresentations that illustrate different techniques for, and applications of,\ncausality analysis and fault localization.\n  The program was anchored by two keynote talks. The keynote by Hana Chockler\n(King's College) provided a broad perspective on the application of causal\nreasoning based on Halpern and Pearl's definitions of actual causality to a\nvariety of application domains ranging from formal verification to legal\nreasoning. The keynote by Chao Wang (Virginia Tech) concentrated on\nconstraint-based analysis techniques for debugging and verifying concurrent\nprograms.\n  Workshop papers deal with compositional causality analysis and a wide\nspectrum of application for causal reasoning, such as debugging of\nprobabilistic models, accountability and responsibility, hazard analysis in\npractice based on Lewis' counterfactuals, and fault localization and repair."
    },
    "1707.01154": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lakkaraju",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Himabindu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kamar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ece"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Caruana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rich"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Leskovec",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jure"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable & Explorable Approximations of Black Box Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose Black Box Explanations through Transparent Approximations (BETA),\na novel model agnostic framework for explaining the behavior of any black-box\nclassifier by simultaneously optimizing for fidelity to the original model and\ninterpretability of the explanation. To this end, we develop a novel objective\nfunction which allows us to learn (with optimality guarantees), a small number\nof compact decision sets each of which explains the behavior of the black box\nmodel in unambiguous, well-defined regions of feature space. Furthermore, our\nframework also is capable of accepting user input when generating these\napproximations, thus allowing users to interactively explore how the black-box\nmodel behaves in different subspaces that are of interest to the user. To the\nbest of our knowledge, this is the first approach which can produce global\nexplanations of the behavior of any given black box model through joint\noptimization of unambiguity, fidelity, and interpretability, while also\nallowing users to explore model behavior based on their preferences.\nExperimental evaluation with real-world datasets and user studies demonstrates\nthat our approach can generate highly compact, easy-to-understand, yet accurate\napproximations of various kinds of predictive models compared to\nstate-of-the-art baselines."
    },
    "1810.11580": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guanhong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shiqing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yingqi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiangyu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Attacks Meet Interpretability: Attribute-steered Detection of\n  Adversarial Samples",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CR stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to NIPS 2018 Spotlight",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors.\nRecent research has demonstrated the widespread presence and the devastating\nconsequences of such attacks. Existing defense techniques either assume prior\nknowledge of specific attacks or may not work well on complex models due to\ntheir underlying assumptions. We argue that adversarial sample attacks are\ndeeply entangled with interpretability of DNN models: while classification\nresults on benign inputs can be reasoned based on the human perceptible\nfeatures/attributes, results on adversarial samples can hardly be explained.\nTherefore, we propose a novel adversarial sample detection technique for face\nrecognition models, based on interpretability. It features a novel\nbi-directional correspondence inference between attributes and internal neurons\nto identify neurons critical for individual attributes. The activation values\nof critical neurons are enhanced to amplify the reasoning part of the\ncomputation and the values of other neurons are weakened to suppress the\nuninterpretable part. The classification results after such transformation are\ncompared with those of the original model to detect adversaries. Results show\nthat our technique can achieve 94% detection accuracy for 7 different kinds of\nattacks with 9.91% false positives on benign inputs. In contrast, a\nstate-of-the-art feature squeezing technique can only achieve 55% accuracy with\n23.3% false positives."
    },
    "1712.00576": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shaoting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Metaxas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dimitris"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interactive Reinforcement Learning for Object Grounding via Self-Talking",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "NIPS 2017 - Visually-Grounded Interaction and Language (ViGIL)\n  Workshop",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Humans are able to identify a referred visual object in a complex scene via a\nfew rounds of natural language communications. Success communication requires\nboth parties to engage and learn to adapt for each other. In this paper, we\nintroduce an interactive training method to improve the natural language\nconversation system for a visual grounding task. During interactive training,\nboth agents are reinforced by the guidance from a common reward function. The\nparametrized reward function also cooperatively updates itself via\ninteractions, and contribute to accomplishing the task. We evaluate the method\non GuessWhat?! visual grounding task, and significantly improve the task\nsuccess rate. However, we observe language drifting problem during training and\npropose to use reward engineering to improve the interpretability for the\ngenerated conversations. Our result also indicates evaluating goal-ended visual\nconversation tasks require semantic relevant metrics beyond task success rate."
    },
    "1811.01439": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mittelstadt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Russell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wachter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sandra"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explaining Explanations in AI",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "FAT* 2019 Proceedings",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3287560.3287574",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent work on interpretability in machine learning and AI has focused on the\nbuilding of simplified models that approximate the true criteria used to make\ndecisions. These models are a useful pedagogical device for teaching trained\nprofessionals how to predict what decisions will be made by the complex system,\nand most importantly how the system might break. However, when considering any\nsuch model it's important to remember Box's maxim that \"All models are wrong\nbut some are useful.\" We focus on the distinction between these models and\nexplanations in philosophy and sociology. These models can be understood as a\n\"do it yourself kit\" for explanations, allowing a practitioner to directly\nanswer \"what if questions\" or generate contrastive explanations without\nexternal assistance. Although a valuable ability, giving these models as\nexplanations appears more difficult than necessary, and other forms of\nexplanation may not have the same trade-offs. We contrast the different schools\nof thought on what makes an explanation, and suggest that machine learning\nmight benefit from viewing the problem more broadly."
    },
    "1810.11187": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Das",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhishek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gervet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Th\u00e9ophile"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Romoff",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rabbat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pineau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joelle"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "TarMAC: Targeted Multi-Agent Communication",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.MA stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 4 figures, 4 tables",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We explore a collaborative multi-agent reinforcement learning setting where a\nteam of agents attempts to solve cooperative tasks in partially-observable\nenvironments. In this scenario, learning an effective communication protocol is\nkey. We propose a communication architecture that allows for targeted\ncommunication, where agents learn both what messages to send and who to send\nthem to, solely from downstream task-specific reward without any communication\nsupervision. Additionally, we introduce a multi-stage communication approach\nwhere the agents co-ordinate via multiple rounds of communication before taking\nactions in the environment. We evaluate our approach on a diverse set of\ncooperative multi-agent tasks, of varying difficulties, with varying number of\nagents, in a variety of environments ranging from 2D grid layouts of shapes and\nsimulated traffic junctions to complex 3D indoor environments. We demonstrate\nthe benefits of targeted as well as multi-stage communication. Moreover, we\nshow that the targeted communication strategies learned by agents are both\ninterpretable and intuitive."
    },
    "1611.07478": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-12-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lundberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Scott"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Su-In"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An unexpected unity among methods for interpreting model predictions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Understanding why a model made a certain prediction is crucial in many data\nscience fields. Interpretable predictions engender appropriate trust and\nprovide insight into how the model may be improved. However, with large modern\ndatasets the best accuracy is often achieved by complex models even experts\nstruggle to interpret, which creates a tension between accuracy and\ninterpretability. Recently, several methods have been proposed for interpreting\npredictions from complex models by estimating the importance of input features.\nHere, we present how a model-agnostic additive representation of the importance\nof input features unifies current methods. This representation is optimal, in\nthe sense that it is the only set of additive values that satisfies important\nproperties. We show how we can leverage these properties to create novel visual\nexplanations of model predictions. The thread of unity that this representation\nweaves through the literature indicates that there are common principles to be\nlearned about the interpretation of model predictions that apply in many\nscenarios."
    },
    "1709.09480": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Depeweg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tokic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Udluft",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steffen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hentschel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Runkler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sterzing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Volkmar"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Benchmark Environment Motivated by Industrial Control Problems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG cs.SY",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "2017 IEEE Symposium Series on Computational Intelligence (SSCI)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/SSCI.2017.8280935",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the research area of reinforcement learning (RL), frequently novel and\npromising methods are developed and introduced to the RL community. However,\nalthough many researchers are keen to apply their methods on real-world\nproblems, implementing such methods in real industry environments often is a\nfrustrating and tedious process. Generally, academic research groups have only\nlimited access to real industrial data and applications. For this reason, new\nmethods are usually developed, evaluated and compared by using artificial\nsoftware benchmarks. On one hand, these benchmarks are designed to provide\ninterpretable RL training scenarios and detailed insight into the learning\nprocess of the method on hand. On the other hand, they usually do not share\nmuch similarity with industrial real-world applications. For this reason we\nused our industry experience to design a benchmark which bridges the gap\nbetween freely available, documented, and motivated artificial benchmarks and\nproperties of real industrial problems. The resulting industrial benchmark (IB)\nhas been made publicly available to the RL community by publishing its Java and\nPython code, including an OpenAI Gym wrapper, on Github. In this paper we\nmotivate and describe in detail the IB's dynamics and identify prototypic\nexperimental settings that capture common situations in real-world industry\ncontrol problems."
    },
    "1806.07371": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guangxiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chongjie"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Object-Oriented Dynamics Predictor",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to NIPS 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Generalization has been one of the major challenges for learning dynamics\nmodels in model-based reinforcement learning. However, previous work on\naction-conditioned dynamics prediction focuses on learning the pixel-level\nmotion and thus does not generalize well to novel environments with different\nobject layouts. In this paper, we present a novel object-oriented framework,\ncalled object-oriented dynamics predictor (OODP), which decomposes the\nenvironment into objects and predicts the dynamics of objects conditioned on\nboth actions and object-to-object relations. It is an end-to-end neural network\nand can be trained in an unsupervised manner. To enable the generalization\nability of dynamics learning, we design a novel CNN-based relation mechanism\nthat is class-specific (rather than object-specific) and exploits the locality\nprinciple. Empirical results show that OODP significantly outperforms previous\nmethods in terms of generalization over novel environments with various object\nlayouts. OODP is able to learn from very few environments and accurately\npredict dynamics in a large number of unseen environments. In addition, OODP\nlearns semantically and visually interpretable dynamics models."
    },
    "1605.09304": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-11-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nguyen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dosovitskiy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yosinski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jason"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brox",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Clune",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeff"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Synthesizing the preferred inputs for neurons in neural networks via\n  deep generator networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "29 pages, 35 figures, NIPS camera-ready",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks (DNNs) have demonstrated state-of-the-art results on\nmany pattern recognition tasks, especially vision classification problems.\nUnderstanding the inner workings of such computational brains is both\nfascinating basic science that is interesting in its own right - similar to why\nwe study the human brain - and will enable researchers to further improve DNNs.\nOne path to understanding how a neural network functions internally is to study\nwhat each of its neurons has learned to detect. One such method is called\nactivation maximization (AM), which synthesizes an input (e.g. an image) that\nhighly activates a neuron. Here we dramatically improve the qualitative state\nof the art of activation maximization by harnessing a powerful, learned prior:\na deep generator network (DGN). The algorithm (1) generates qualitatively\nstate-of-the-art synthetic images that look almost real, (2) reveals the\nfeatures learned by each neuron in an interpretable way, (3) generalizes well\nto new datasets and somewhat well to different network architectures without\nrequiring the prior to be relearned, and (4) can be considered as a\nhigh-quality generative method (in this case, by generating novel, creative,\ninteresting, recognizable images)."
    },
    "1111.6191": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-11-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bringmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bj\u00f6rn"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nijssen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siegfried"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zimmermann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Albrecht"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Pattern-Based Classification: A Unifying Perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The use of patterns in predictive models is a topic that has received a lot\nof attention in recent years. Pattern mining can help to obtain models for\nstructured domains, such as graphs and sequences, and has been proposed as a\nmeans to obtain more accurate and more interpretable models. Despite the large\namount of publications devoted to this topic, we believe however that an\noverview of what has been accomplished in this area is missing. This paper\npresents our perspective on this evolving area. We identify the principles of\npattern mining that are important when mining patterns for models and provide\nan overview of pattern-based classification methods. We categorize these\nmethods along the following dimensions: (1) whether they post-process a\npre-computed set of patterns or iteratively execute pattern mining algorithms;\n(2) whether they select patterns model-independently or whether the pattern\nselection is guided by a model. We summarize the results that have been\nobtained for each of these methods."
    },
    "cs_0504066": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2005-04-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schetinin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vitaly"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fieldsend",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Partridge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krzanowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wojtek J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Everson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bailey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Trevor C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adolfo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Comparison of the Bayesian and Randomised Decision Tree Ensembles within\n  an Uncertainty Envelope Technique",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Mathematical Modelling and Algorithms, 2005",
        "http://arxiv.org/OAI/arXiv/:abstract": "Multiple Classifier Systems (MCSs) allow evaluation of the uncertainty of\nclassification outcomes that is of crucial importance for safety critical\napplications. The uncertainty of classification is determined by a trade-off\nbetween the amount of data available for training, the classifier diversity and\nthe required performance. The interpretability of MCSs can also give useful\ninformation for experts responsible for making reliable classifications. For\nthis reason Decision Trees (DTs) seem to be attractive classification models\nfor experts. The required diversity of MCSs exploiting such classification\nmodels can be achieved by using two techniques, the Bayesian model averaging\nand the randomised DT ensemble. Both techniques have revealed promising results\nwhen applied to real-world problems. In this paper we experimentally compare\nthe classification uncertainty of the Bayesian model averaging with a\nrestarting strategy and the randomised DT ensemble on a synthetic dataset and\nsome domain problems commonly used in the machine learning community. To make\nthe Bayesian DT averaging feasible, we use a Markov Chain Monte Carlo\ntechnique. The classification uncertainty is evaluated within an Uncertainty\nEnvelope technique dealing with the class posterior distribution and a given\nconfidence probability. Exploring a full posterior distribution, this technique\nproduces realistic estimates which can be easily interpreted in statistical\nterms. In our experiments we found out that the Bayesian DTs are superior to\nthe randomised DT ensembles within the Uncertainty Envelope technique."
    },
    "1803.02627": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hinz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tobias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wermter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Inferencing Based on Unsupervised Learning of Disentangled\n  Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted as a conference paper at the European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning\n  (ESANN) 2018, 6 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Combining Generative Adversarial Networks (GANs) with encoders that learn to\nencode data points has shown promising results in learning data representations\nin an unsupervised way. We propose a framework that combines an encoder and a\ngenerator to learn disentangled representations which encode meaningful\ninformation about the data distribution without the need for any labels. While\ncurrent approaches focus mostly on the generative aspects of GANs, our\nframework can be used to perform inference on both real and generated data\npoints. Experiments on several data sets show that the encoder learns\ninterpretable, disentangled representations which encode descriptive properties\nand can be used to sample images that exhibit specific characteristics."
    },
    "1810.09352": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guidotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ruggieri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Salvatore"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Assessing the Stability of Interpretable Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process,\nwhich, in particular, comprises data collection and filtering. Selection bias\nin data collection or in data pre-processing may affect the model learned.\nAlthough model induction algorithms are designed to learn to generalize, they\npursue optimization of predictive accuracy. It remains unclear how\ninterpretability is instead impacted. We conduct an experimental analysis to\ninvestigate whether interpretable models are able to cope with data selection\nbias as far as interpretability is concerned."
    },
    "1802.01274": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Spratt",
                "http://arxiv.org/OAI/arXiv/:forenames": "Emily L."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Dream Formulations and Deep Neural Networks: Humanistic Themes in the\n  Iconology of the Machine-Learned Image",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "29 pages, 8 Figures, This paper was originally presented as Dream\n  Formulations and Image Recognition: Algorithms for the Study of Renaissance\n  Art, at Critical Approaches to Digital Art History, The Villa I Tatti, The\n  Harvard University Center for Italian Renaissance Studies and The Newberry\n  Center for Renaissance Studies, Renaissance Society of America Annual\n  Meeting, Chicago, 31 March 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper addresses the interpretability of deep learning-enabled image\nrecognition processes in computer vision science in relation to theories in art\nhistory and cognitive psychology on the vision-related perceptual capabilities\nof humans. Examination of what is determinable about the machine-learned image\nin comparison to humanistic theories of visual perception, particularly in\nregard to art historian Erwin Panofsky's methodology for image analysis and\npsychologist Eleanor Rosch's theory of graded categorization according to\nprototypes, finds that there are surprising similarities between the two that\nsuggest that researchers in the arts and the sciences would have much to\nbenefit from closer collaborations. Utilizing the examples of Google's\nDeepDream and the Machine Learning and Perception Lab at Georgia Tech's\nGrad-CAM: Gradient-weighted Class Activation Mapping programs, this study\nsuggests that a revival of art historical research in iconography and formalism\nin the age of AI is essential for shaping the future navigation and\ninterpretation of all machine-learned images, given the rapid developments in\nimage recognition technologies."
    },
    "1705.11040": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rockt\u00e4schel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riedel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "End-to-End Differentiable Proving",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "NIPS 2017 camera-ready, NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce neural networks for end-to-end differentiable proving of queries\nto knowledge bases by operating on dense vector representations of symbols.\nThese neural networks are constructed recursively by taking inspiration from\nthe backward chaining algorithm as used in Prolog. Specifically, we replace\nsymbolic unification with a differentiable computation on vector\nrepresentations of symbols using a radial basis function kernel, thereby\ncombining symbolic reasoning with learning subsymbolic vector representations.\nBy using gradient descent, the resulting neural network can be trained to infer\nfacts from a given incomplete knowledge base. It learns to (i) place\nrepresentations of similar symbols in close proximity in a vector space, (ii)\nmake use of such similarities to prove queries, (iii) induce logical rules, and\n(iv) use provided and induced logical rules for multi-hop reasoning. We\ndemonstrate that this architecture outperforms ComplEx, a state-of-the-art\nneural link prediction model, on three out of four benchmark knowledge bases\nwhile at the same time inducing interpretable function-free first-order logic\nrules."
    },
    "1510.05911": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-10-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-04-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Baoxu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weninger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Discriminative Predicate Path Mining for Fact Checking in Knowledge\n  Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI cs.IR cs.SI",
        "http://arxiv.org/OAI/arXiv/:comments": "17 pages, 4 Figures. To Appear in Knowledge Based Systems",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.4, H.2.8",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.knosys.2016.04.015",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Traditional fact checking by experts and analysts cannot keep pace with the\nvolume of newly created information. It is important and necessary, therefore,\nto enhance our ability to computationally determine whether some statement of\nfact is true or false. We view this problem as a link-prediction task in a\nknowledge graph, and present a discriminative path-based method for fact\nchecking in knowledge graphs that incorporates connectivity, type information,\nand predicate interactions. Given a statement S of the form (subject,\npredicate, object), for example, (Chicago, capitalOf, Illinois), our approach\nmines discriminative paths that alternatively define the generalized statement\n(U.S. city, predicate, U.S. state) and uses the mined rules to evaluate the\nveracity of statement S. We evaluate our approach by examining thousands of\nclaims related to history, geography, biology, and politics using a public,\nmillion node knowledge graph extracted from Wikipedia and PubMedDB. Not only\ndoes our approach significantly outperform related models, we also find that\nthe discriminative predicate path model is easily interpretable and provides\nsensible reasons for the final determination."
    },
    "1607.03611": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-10-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Weishan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Renjie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Changsheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lanjun"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Characterizing Driving Styles with Deep Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Characterizing driving styles of human drivers using vehicle sensor data,\ne.g., GPS, is an interesting research problem and an important real-world\nrequirement from automotive industries. A good representation of driving\nfeatures can be highly valuable for autonomous driving, auto insurance, and\nmany other application scenarios. However, traditional methods mainly rely on\nhandcrafted features, which limit machine learning algorithms to achieve a\nbetter performance. In this paper, we propose a novel deep learning solution to\nthis problem, which could be the first attempt of extending deep learning to\ndriving behavior analysis based on GPS data. The proposed approach can\neffectively extract high level and interpretable features describing complex\ndriving patterns. It also requires significantly less human experience and\nwork. The power of the learned driving style representations are validated\nthrough the driver identification problem using a large real dataset."
    },
    "1611.07100": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-11-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hammerschmidt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian Albert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verwer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sicco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "State",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpreting Finite Automata for Sequential Data",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automaton models are often seen as interpretable models. Interpretability\nitself is not well defined: it remains unclear what interpretability means\nwithout first explicitly specifying objectives or desired attributes. In this\npaper, we identify the key properties used to interpret automata and propose a\nmodification of a state-merging approach to learn variants of finite state\nautomata. We apply the approach to problems beyond typical grammar inference\ntasks. Additionally, we cover several use-cases for prediction, classification,\nand clustering on sequential data in both supervised and unsupervised scenarios\nto show how the identified key properties are applicable in a wide range of\ncontexts."
    },
    "1804.05741": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jatinder"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cobbe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jennifer"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Norval",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Decision Provenance: Capturing data flow for accountable systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Demand is growing for more accountability in the technological systems that\nincreasingly occupy our world. However, the complexity of many of these systems\n- often systems of systems - poses accountability challenges. This is because\nthe details and nature of the data flows that interconnect and drive systems,\nwhich often occur across technical and organisational boundaries, tend to be\nopaque. This paper argues that data provenance methods show much promise as a\ntechnical means for increasing the transparency of these interconnected\nsystems. Given concerns with the ever-increasing levels of automated and\nalgorithmic decision-making, we make the case for decision provenance. This\ninvolves exposing the 'decision pipeline' by tracking the chain of inputs to,\nand flow-on effects from, the decisions and actions taken within these systems.\nThis paper proposes decision provenance as a means to assist in raising levels\nof accountability, discusses relevant legal conceptions, and indicates some\npractical considerations for moving forward."
    },
    "cs_0106025": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2001-06-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dimopoulos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yannis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kakas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonis"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Information Integration and Computational Logic",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "53 Pages",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.2.m;I.2.m",
        "http://arxiv.org/OAI/arXiv/:abstract": "Information Integration is a young and exciting field with enormous research\nand commercial significance in the new world of the Information Society. It\nstands at the crossroad of Databases and Artificial Intelligence requiring\nnovel techniques that bring together different methods from these fields.\nInformation from disparate heterogeneous sources often with no a-priori common\nschema needs to be synthesized in a flexible, transparent and intelligent way\nin order to respond to the demands of a query thus enabling a more informed\ndecision by the user or application program. The field although relatively\nyoung has already found many practical applications particularly for\nintegrating information over the World Wide Web. This paper gives a brief\nintroduction of the field highlighting some of the main current and future\nresearch issues and application areas. It attempts to evaluate the current and\npotential role of Computational Logic in this and suggests some of the problems\nwhere logic-based techniques could be used."
    },
    "1704.03296": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-11",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ruth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vedaldi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Explanations of Black Boxes by Meaningful Perturbation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Final camera-ready paper published at ICCV 2017 (Supplementary\n  materials:\n  http://openaccess.thecvf.com/content_ICCV_2017/supplemental/Fong_Interpretable_Explanations_of_ICCV_2017_supplemental.pdf)",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 2017 IEEE International Conference on Computer\n  Vision (ICCV)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ICCV.2017.371",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As machine learning algorithms are increasingly applied to high impact yet\nhigh risk tasks, such as medical diagnosis or autonomous driving, it is\ncritical that researchers can explain how such algorithms arrived at their\npredictions. In recent years, a number of image saliency methods have been\ndeveloped to summarize where highly complex neural networks \"look\" in an image\nfor evidence for their predictions. However, these techniques are limited by\ntheir heuristic nature and architectural constraints. In this paper, we make\ntwo main contributions: First, we propose a general framework for learning\ndifferent kinds of explanations for any black box algorithm. Second, we\nspecialise the framework to find the part of an image most responsible for a\nclassifier decision. Unlike previous works, our method is model-agnostic and\ntestable because it is grounded in explicit and interpretable image\nperturbations."
    },
    "1608.08974": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-09-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goyal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yash"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mohapatra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Akrit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Transparent AI Systems: Interpreting Visual Question Answering\n  Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks have shown striking progress and obtained\nstate-of-the-art results in many AI research fields in the recent years.\nHowever, it is often unsatisfying to not know why they predict what they do. In\nthis paper, we address the problem of interpreting Visual Question Answering\n(VQA) models. Specifically, we are interested in finding what part of the input\n(pixels in images or words in questions) the VQA model focuses on while\nanswering the question. To tackle this problem, we use two visualization\ntechniques -- guided backpropagation and occlusion -- to find important words\nin the question and important regions in the image. We then present qualitative\nand quantitative analyses of these importance maps. We found that even without\nexplicit attention mechanisms, VQA models may sometimes be implicitly attending\nto relevant regions in the image, and often to appropriate words in the\nquestion."
    },
    "1811.05437": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "\u010cyras",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kristijonas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Letsios",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dimitrios"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Misener",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ruth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Toni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Argumentation for Explainable Scheduling (Full Paper with Proofs)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Full version (including proofs) of the paper published at AAAI-19",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Mathematical optimization offers highly-effective tools for finding solutions\nfor problems with well-defined goals, notably scheduling. However, optimization\nsolvers are often unexplainable black boxes whose solutions are inaccessible to\nusers and which users cannot interact with. We define a novel paradigm using\nargumentation to empower the interaction between optimization solvers and\nusers, supported by tractable explanations which certify or refute solutions. A\nsolution can be from a solver or of interest to a user (in the context of\n'what-if' scenarios). Specifically, we define argumentative and natural\nlanguage explanations for why a schedule is (not) feasible, (not) efficient or\n(not) satisfying fixed user decisions, based on models of the fundamental\nmakespan scheduling problem in terms of abstract argumentation frameworks\n(AFs). We define three types of AFs, whose stable extensions are in one-to-one\ncorrespondence with schedules that are feasible, efficient and satisfying fixed\ndecisions, respectively. We extract the argumentative explanations from these\nAFs and the natural language explanations from the argumentative ones."
    },
    "cs_0605120": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2006-05-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kryssanov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "V. V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tamaki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kitamura",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Understanding Design Fundamentals: How Synthesis and Analysis Drive\n  Creativity, Resulting in Emergence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CE cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "33pages, 4 figures. Preprint completed in 2000",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "AI in Engineering. 2001, Vol.15/4, 329-342",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper presents results of an ongoing interdisciplinary study to develop\na computational theory of creativity for engineering design. Human design\nactivities are surveyed, and popular computer-aided design methodologies are\nexamined. It is argued that semiotics has the potential to merge and unite\nvarious design approaches into one fundamental theory that is naturally\ninterpretable and so comprehensible in terms of computer use. Reviewing related\nwork in philosophy, psychology, and cognitive science provides a general and\nencompassing vision of the creativity phenomenon. Basic notions of algebraic\nsemiotics are given and explained in terms of design. This is to define a model\nof the design creative process, which is seen as a process of semiosis, where\nconcepts and their attributes represented as signs organized into systems are\nevolved, blended, and analyzed, resulting in the development of new concepts.\nThe model allows us to formally describe and investigate essential properties\nof the design process, namely its dynamics and non-determinism inherent in\ncreative thinking. A stable pattern of creative thought - analogical and\nmetaphorical reasoning - is specified to demonstrate the expressive power of\nthe modeling approach; illustrative examples are given. The developed theory is\napplied to clarify the nature of emergence in design: it is shown that while\nemergent properties of a product may influence its creative value, emergence\ncan simply be seen as a by-product of the creative process. Concluding remarks\nsummarize the research, point to some unresolved issues, and outline directions\nfor future work."
    },
    "1805.07780": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jameson"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poupart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pascal"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unsupervised Video Object Segmentation for Deep Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a new technique for deep reinforcement learning that automatically\ndetects moving objects and uses the relevant information for action selection.\nThe detection of moving objects is done in an unsupervised way by exploiting\nstructure from motion. Instead of directly learning a policy from raw images,\nthe agent first learns to detect and segment moving objects by exploiting flow\ninformation in video sequences. The learned representation is then used to\nfocus the policy of the agent on the moving objects. Over time, the agent\nidentifies which objects are critical for decision making and gradually builds\na policy based on relevant moving objects. This approach, which we call\nMotion-Oriented REinforcement Learning (MOREL), is demonstrated on a suite of\nAtari games where the ability to detect moving objects reduces the amount of\ninteraction needed with the environment to obtain a good policy. Furthermore,\nthe resulting policy is more interpretable than policies that directly map\nimages to actions or values with a black box neural network. We can gain\ninsight into the policy by inspecting the segmentation and motion of each\nobject detected by the agent. This allows practitioners to confirm whether a\npolicy is making decisions based on sensible information."
    },
    "1806.03563": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hao Henry"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunyang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vikas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Building Bayesian Neural Networks with Blocks: On Structure,\n  Interpretability and Uncertainty",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We provide simple schemes to build Bayesian Neural Networks (BNNs), block by\nblock, inspired by a recent idea of computation skeletons. We show how by\nadjusting the types of blocks that are used within the computation skeleton, we\ncan identify interesting relationships with Deep Gaussian Processes (DGPs),\ndeep kernel learning (DKL), random features type approximation and other\ntopics. We give strategies to approximate the posterior via doubly stochastic\nvariational inference for such models which yield uncertainty estimates. We\ngive a detailed theoretical analysis and point out extensions that may be of\nindependent interest. As a special case, we instantiate our procedure to define\na Bayesian {\\em additive} Neural network -- a promising strategy to identify\nstatistical interactions and has direct benefits for obtaining interpretable\nmodels."
    },
    "1803.09010": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gebru",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timnit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Morgenstern",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jamie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vecchione",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Briana"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vaughan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jennifer Wortman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wallach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hanna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Daume\u00e9",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hal",
                    "http://arxiv.org/OAI/arXiv/:suffix": "III"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Crawford",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kate"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Datasheets for Datasets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Working Paper, comments are encouraged",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Currently there is no standard way to identify how a dataset was created, and\nwhat characteristics, motivations, and potential skews it represents. To begin\nto address this issue, we propose the concept of a datasheet for datasets, a\nshort document to accompany public datasets, commercial APIs, and pretrained\nmodels. The goal of this proposal is to enable better communication between\ndataset creators and users, and help the AI community move toward greater\ntransparency and accountability. By analogy, in computer hardware, it has\nbecome industry standard to accompany everything from the simplest components\n(e.g., resistors), to the most complex microprocessor chips, with datasheets\ndetailing standard operating characteristics, test results, recommended usage,\nand other information. We outline some of the questions a datasheet for\ndatasets should answer. These questions focus on when, where, and how the\ntraining data was gathered, its recommended use cases, and, in the case of\nhuman-centric datasets, information regarding the subjects' demographics and\nconsent as applicable. We develop prototypes of datasheets for two well-known\ndatasets: Labeled Faces in The Wild~\\cite{lfw} and the Pang \\& Lee Polarity\nDataset~\\cite{polarity}."
    },
    "1710.10675": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devinder"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Taylor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Graham W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Discovery Radiomics with CLEAR-DR: Interpretable Computer Aided\n  Diagnosis of Diabetic Retinopathy",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Objective: Radiomics-driven Computer Aided Diagnosis (CAD) has shown\nconsiderable promise in recent years as a potential tool for improving clinical\ndecision support in medical oncology, particularly those based around the\nconcept of Discovery Radiomics, where radiomic sequencers are discovered\nthrough the analysis of medical imaging data. One of the main limitations with\ncurrent CAD approaches is that it is very difficult to gain insight or\nrationale as to how decisions are made, thus limiting their utility to\nclinicians. Methods: In this study, we propose CLEAR-DR, a novel interpretable\nCAD system based on the notion of CLass-Enhanced Attentive Response Discovery\nRadiomics for the purpose of clinical decision support for diabetic\nretinopathy. Results: In addition to disease grading via the discovered deep\nradiomic sequencer, the CLEAR-DR system also produces a visual interpretation\nof the decision-making process to provide better insight and understanding into\nthe decision-making process of the system. Conclusion: We demonstrate the\neffectiveness and utility of the proposed CLEAR-DR system of enhancing the\ninterpretability of diagnostic grading results for the application of diabetic\nretinopathy grading. Significance: CLEAR-DR can act as a potential powerful\ntool to address the uninterpretability issue of current CAD systems, thus\nimproving their utility to clinicians."
    },
    "1801.04346": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kleiman-Weiner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Max"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abeliuk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andres"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Awad",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edmond"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dsouza",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sohan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rahwan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iyad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Computational Model of Commonsense Moral Decision Making",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce a new computational model of moral decision making, drawing on a\nrecent theory of commonsense moral learning via social dynamics. Our model\ndescribes moral dilemmas as a utility function that computes trade-offs in\nvalues over abstract moral dimensions, which provide interpretable parameter\nvalues when implemented in machine-led ethical decision-making. Moreover,\ncharacterizing the social structures of individuals and groups as a\nhierarchical Bayesian model, we show that a useful description of an\nindividual's moral values - as well as a group's shared values - can be\ninferred from a limited amount of observed data. Finally, we apply and evaluate\nour approach to data from the Moral Machine, a web application that collects\nhuman judgments on moral dilemmas involving autonomous vehicles."
    },
    "1402.2300": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-02-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Karper",
                "http://arxiv.org/OAI/arXiv/:forenames": "Aaron"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Feature and Variable Selection in Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Part of master seminar in document analysis held by Marcus\n  Eichenberger-Liwicki",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/publicdomain/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The amount of information in the form of features and variables avail- able\nto machine learning algorithms is ever increasing. This can lead to classifiers\nthat are prone to overfitting in high dimensions, high di- mensional models do\nnot lend themselves to interpretable results, and the CPU and memory resources\nnecessary to run on high-dimensional datasets severly limit the applications of\nthe approaches. Variable and feature selection aim to remedy this by finding a\nsubset of features that in some way captures the information provided best. In\nthis paper we present the general methodology and highlight some specific\napproaches."
    },
    "1709.08878": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kelvin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hashimoto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tatsunori B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Oren",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yonatan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Percy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generating Sentences by Editing Prototypes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies."
    },
    "1712.07745": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mazumder",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sahisnu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bing"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Context-aware Path Ranking for Knowledge Base Completion",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Published in IJCAI 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.24963/ijcai.2017/166",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Knowledge base (KB) completion aims to infer missing facts from existing ones\nin a KB. Among various approaches, path ranking (PR) algorithms have received\nincreasing attention in recent years. PR algorithms enumerate paths between\nentity pairs in a KB and use those paths as features to train a model for\nmissing fact prediction. Due to their good performances and high model\ninterpretability, several methods have been proposed. However, most existing\nmethods suffer from scalability (high RAM consumption) and feature explosion\n(trains on an exponentially large number of features) problems. This paper\nproposes a Context-aware Path Ranking (C-PR) algorithm to solve these problems\nby introducing a selective path exploration strategy. C-PR learns global\nsemantics of entities in the KB using word embedding and leverages the\nknowledge of entity semantics to enumerate contextually relevant paths using\nbidirectional random walk. Experimental results on three large KBs show that\nthe path features (fewer in number) discovered by C-PR not only improve\npredictive performance but also are more interpretable than existing baselines."
    },
    "1610.02995": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Martius",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Georg"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lampert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph H."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Extrapolation and learning equations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "13 pages, 8 figures, 4 tables",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68T05, 68T30, 68T40, 62J02, 65D15",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6; I.2.8",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In classical machine learning, regression is treated as a black box process\nof identifying a suitable function from a hypothesis set without attempting to\ngain insight into the mechanism connecting inputs and outputs. In the natural\nsciences, however, finding an interpretable function for a phenomenon is the\nprime goal as it allows to understand and generalize results. This paper\nproposes a novel type of function learning network, called equation learner\n(EQL), that can learn analytical expressions and is able to extrapolate to\nunseen domains. It is implemented as an end-to-end differentiable feed-forward\nnetwork and allows for efficient gradient based training. Due to sparsity\nregularization concise interpretable expressions can be obtained. Often the\ntrue underlying source expression is identified."
    },
    "1706.00536": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grimm",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Arumugam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dilip"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Karamcheti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siddharth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lawson L. S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Littman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael L."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling Latent Attention Within Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks are able to solve tasks across a variety of domains and\nmodalities of data. Despite many empirical successes, we lack the ability to\nclearly understand and interpret the learned internal mechanisms that\ncontribute to such effective behaviors or, more critically, failure modes. In\nthis work, we present a general method for visualizing an arbitrary neural\nnetwork's inner mechanisms and their power and limitations. Our dataset-centric\nmethod produces visualizations of how a trained network attends to components\nof its inputs. The computed \"attention masks\" support improved interpretability\nby highlighting which input attributes are critical in determining output. We\ndemonstrate the effectiveness of our framework on a variety of deep neural\nnetwork architectures in domains from computer vision, natural language\nprocessing, and reinforcement learning. The primary contribution of our\napproach is an interpretable visualization of attention that provides unique\ninsights into the network's underlying decision-making process irrespective of\nthe data modality."
    },
    "1806.03934": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ella M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Martin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bowers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeffrey S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "When and where do feed-forward neural networks learn localist\n  representations?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.ET cs.LG",
        "http://arxiv.org/OAI/arXiv/:msc-class": "92b20",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "According to parallel distributed processing (PDP) theory in psychology,\nneural networks (NN) learn distributed rather than interpretable localist\nrepresentations. This view has been held so strongly that few researchers have\nanalysed single units to determine if this assumption is correct. However,\nrecent results from psychology, neuroscience and computer science have shown\nthe occasional existence of local codes emerging in artificial and biological\nneural networks. In this paper, we undertake the first systematic survey of\nwhen local codes emerge in a feed-forward neural network, using generated input\nand output data with known qualities. We find that the number of local codes\nthat emerge from a NN follows a well-defined distribution across the number of\nhidden layer neurons, with a peak determined by the size of input data, number\nof examples presented and the sparsity of input data. Using a 1-hot output code\ndrastically decreases the number of local codes on the hidden layer. The number\nof emergent local codes increases with the percentage of dropout applied to the\nhidden layer, suggesting that the localist encoding may offer a resilience to\nnoisy networks. This data suggests that localist coding can emerge from\nfeed-forward PDP networks and suggests some of the conditions that may lead to\ninterpretable localist representations in the cortex. The findings highlight\nhow local codes should not be dismissed out of hand."
    },
    "1705.09558": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saatchi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Gordon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian GAN",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Updated to the version that appears at Advances in Neural Information\n  Processing Systems 30 (NIPS), 2017",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Generative adversarial networks (GANs) can implicitly learn rich\ndistributions over images, audio, and data which are hard to model with an\nexplicit likelihood. We present a practical Bayesian formulation for\nunsupervised and semi-supervised learning with GANs. Within this framework, we\nuse stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of\nthe generator and discriminator networks. The resulting approach is\nstraightforward and obtains good performance without any standard interventions\nsuch as feature matching, or mini-batch discrimination. By exploring an\nexpressive posterior over the parameters of the generator, the Bayesian GAN\navoids mode-collapse, produces interpretable and diverse candidate samples, and\nprovides state-of-the-art quantitative results for semi-supervised learning on\nbenchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN,\nWasserstein GANs, and DCGAN ensembles."
    },
    "1401.0943": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-01-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Akanbi",
                "http://arxiv.org/OAI/arXiv/:forenames": "Adeyinka K"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "LB2CO: A Semantic Ontology Framework for B2C eCommerce Transaction on\n  the Internet",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "9 Pages, 7 figures, Research Paper",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Research in Computer Science, 4 (1): pp.\n  1-9, January 2014",
        "http://arxiv.org/OAI/arXiv/:doi": "10.7815/ijorcs.41.2014.075",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Business ontology can enhance the successful development of complex\nenterprise system; this is being achieved through knowledge sharing and the\nease of communication between every entity in the domain. Through human\nsemantic interaction with the web resources, machines to interpret the data\npublished in a machine interpretable form under web. However, the theoretical\npractice of business ontology in eCommerce domain is quite a few especially in\nthe section of electronic transaction, and the various techniques used to\nobtain efficient communication across spheres are error prone and are not\nalways guaranteed to be efficient in obtaining desired result due to poor\nsemantic integration between entities. To overcome the poor semantic\nintegration this research focuses on proposed ontology called LB2CO, which\ncombines the framework of IDEF5 & SNAP as an analysis tool, for automated\nrecommendation of product and services and create effective ontological\nframework for B2C transaction & communication across different business domains\nthat facilitates the interoperability & integration of B2C transactions over\nthe web."
    },
    "1010.3796": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-10-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brescia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Longo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "G."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pasian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "F."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mining Knowledge in Astrophysical Massive Data Sets",
        "http://arxiv.org/OAI/arXiv/:categories": "astro-ph.IM cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Pages 845-849 1rs International Conference on Frontiers in\n  Diagnostics Technologies",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Elsevier, Nuclear Instruments and Methods in Physics Research\n  Section A: Accelerators, Spectrometers, Detectors and Associated Equipment\n  Volume 623, Issue 2, 11 November 2010",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.nima.2010.02.002",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Modern scientific data mainly consist of huge datasets gathered by a very\nlarge number of techniques and stored in very diversified and often\nincompatible data repositories. More in general, in the e-science environment,\nit is considered as a critical and urgent requirement to integrate services\nacross distributed, heterogeneous, dynamic \"virtual organizations\" formed by\ndifferent resources within a single enterprise. In the last decade, Astronomy\nhas become an immensely data rich field due to the evolution of detectors\n(plates to digital to mosaics), telescopes and space instruments. The Virtual\nObservatory approach consists into the federation under common standards of all\nastronomical archives available worldwide, as well as data analysis, data\nmining and data exploration applications. The main drive behind such effort\nbeing that once the infrastructure will be completed, it will allow a new type\nof multi-wavelength, multi-epoch science which can only be barely imagined.\nData Mining, or Knowledge Discovery in Databases, while being the main\nmethodology to extract the scientific information contained in such MDS\n(Massive Data Sets), poses crucial problems since it has to orchestrate complex\nproblems posed by transparent access to different computing environments,\nscalability of algorithms, reusability of resources, etc. In the present paper\nwe summarize the present status of the MDS in the Virtual Observatory and what\nis currently done and planned to bring advanced Data Mining methodologies in\nthe case of the DAME (DAta Mining & Exploration) project."
    },
    "1804.10850": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tengfei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiayu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Drug Similarity Integration Through Attentive Multi-view Graph\n  Auto-Encoders",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "IJCAI 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Drug similarity has been studied to support downstream clinical tasks such as\ninferring novel properties of drugs (e.g. side effects, indications,\ninteractions) from known properties. The growing availability of new types of\ndrug features brings the opportunity of learning a more comprehensive and\naccurate drug similarity that represents the full spectrum of underlying drug\nrelations. However, it is challenging to integrate these heterogeneous, noisy,\nnonlinear-related information to learn accurate similarity measures especially\nwhen labels are scarce. Moreover, there is a trade-off between accuracy and\ninterpretability. In this paper, we propose to learn accurate and interpretable\nsimilarity measures from multiple types of drug features. In particular, we\nmodel the integration using multi-view graph auto-encoders, and add attentive\nmechanism to determine the weights for each view with respect to corresponding\ntasks and features for better interpretability. Our model has flexible design\nfor both semi-supervised and unsupervised settings. Experimental results\ndemonstrated significant predictive accuracy improvement. Case studies also\nshowed better model capacity (e.g. embed node features) and interpretability."
    },
    "1703.09845": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kenthapadi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Krishnaram"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ambler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stuart"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Liang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Deepak"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bringing Salary Transparency to the World: Computing Robust Compensation\n  Insights via LinkedIn Salary",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI cs.IR",
        "http://arxiv.org/OAI/arXiv/:comments": "Conference information: ACM International Conference on Information\n  and Knowledge Management (CIKM 2017)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3132847.3132863",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The recently launched LinkedIn Salary product has been designed with the goal\nof providing compensation insights to the world's professionals and thereby\nhelping them optimize their earning potential. We describe the overall design\nand architecture of the statistical modeling system underlying this product. We\nfocus on the unique data mining challenges while designing and implementing the\nsystem, and describe the modeling components such as Bayesian hierarchical\nsmoothing that help to compute and present robust compensation insights to\nusers. We report on extensive evaluation with nearly one year of de-identified\ncompensation data collected from over one million LinkedIn users, thereby\ndemonstrating the efficacy of the statistical models. We also highlight the\nlessons learned through the deployment of our system at LinkedIn."
    },
    "1808.08497": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaolin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mengying"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qibing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chaochao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yanchao"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "FinBrain: When Finance Meets AI 2.0",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Frontiers of Information Technology & Electronic Engineering 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence (AI) is the core technology of technological\nrevolution and industrial transformation. As one of the new intelligent needs\nin the AI 2.0 era, financial intelligence has elicited much attention from the\nacademia and industry. In our current dynamic capital market, financial\nintelligence demonstrates a fast and accurate machine learning capability to\nhandle complex data and has gradually acquired the potential to become a\n\"financial brain\". In this work, we survey existing studies on financial\nintelligence. First, we describe the concept of financial intelligence and\nelaborate on its position in the financial technology field. Second, we\nintroduce the development of financial intelligence and review state-of-the-art\ntechniques in wealth management, risk management, financial security, financial\nconsulting, and blockchain. Finally, we propose a research framework called\nFinBrain and summarize four open issues, namely, explainable financial agents\nand causality, perception and prediction under uncertainty, risk-sensitive and\nrobust decision making, and multi-agent game and mechanism design. We believe\nthat these research directions can lay the foundation for the development of AI\n2.0 in the finance field."
    },
    "1808.07261": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hind",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mehta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameep"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mojsilovic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aleksandra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nair",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ravi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthikeyan Natesan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Olteanu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexandra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kush R."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Increasing Trust in AI Services through Supplier's Declarations of\n  Conformity",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The accuracy and reliability of machine learning algorithms are an important\nconcern for suppliers of artificial intelligence (AI) services, but\nconsiderations beyond accuracy, such as safety, security, and provenance, are\nalso critical elements to engender consumers' trust in a service. In this\npaper, we propose a supplier's declaration of conformity (SDoC) for AI services\nto help increase trust in AI services. An SDoC is a transparent, standardized,\nbut often not legally required, document used in many industries and sectors to\ndescribe the lineage of a product along with the safety and performance testing\nit has undergone. We envision an SDoC for AI services to contain purpose,\nperformance, safety, security, and provenance information to be completed and\nvoluntarily released by AI service providers for examination by consumers.\nImportantly, it conveys product-level rather than component-level functional\ntesting. We suggest a set of declaration items tailored to AI and provide\nexamples for two fictitious AI services."
    },
    "1808.00265": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yundong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Niebles",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Juan Carlos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Soto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alvaro"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Visual Question Answering by Visual Grounding from\n  Attention Supervision Mining",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 4 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A key aspect of VQA models that are interpretable is their ability to ground\ntheir answers to relevant regions in the image. Current approaches with this\ncapability rely on supervised learning and human annotated groundings to train\nattention mechanisms inside the VQA architecture. Unfortunately, obtaining\nhuman annotations specific for visual grounding is difficult and expensive. In\nthis work, we demonstrate that we can effectively train a VQA architecture with\ngrounding supervision that can be automatically obtained from available region\ndescriptions and object annotations. We also show that our model trained with\nthis mined supervision generates visual groundings that achieve a higher\ncorrelation with respect to manually-annotated groundings, meanwhile achieving\nstate-of-the-art VQA accuracy."
    },
    "1811.06471": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Modarres",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ceena"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ibrahim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Louie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Melissa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paisley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Explainable Deep Learning for Credit Lending: A Case Study",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted NIPS 2018 FEAP",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep learning adoption in the financial services industry has been limited\ndue to a lack of model interpretability. However, several techniques have been\nproposed to explain predictions made by a neural network. We provide an initial\ninvestigation into these techniques for the assessment of credit risk with\nneural networks."
    },
    "1804.02969": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kliegr",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom\u00e1\u0161"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bahn\u00edk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "\u0160t\u011bp\u00e1n"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "F\u00fcrnkranz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Johannes"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A review of possible effects of cognitive biases on interpretation of\n  rule-based machine learning models",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper investigates to what extent do cognitive biases affect human\nunderstanding of interpretable machine learning models, in particular of rules\ndiscovered from data. Twenty cognitive biases (illusions, effects) are covered,\nas are possibly effective debiasing techniques that can be adopted by designers\nof machine learning algorithms and software. While there seems no universal\napproach for eliminating all the identified cognitive biases, it follows from\nour analysis that the effect of most biases can be ameliorated by making\nrule-based models more concise. Due to lack of previous research, our review\ntransfers general results obtained in cognitive psychology to the domain of\nmachine learning. It needs to be succeeded by empirical studies specifically\naimed at the machine learning domain."
    },
    "1801.01807": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "de Franca",
                "http://arxiv.org/OAI/arXiv/:forenames": "Fabricio Olivetti"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Greedy Search Tree Heuristic for Symbolic Regression",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages, 7 figures, 3 tables, submitted to Information Science on\n  12/2016",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.ins.2018.02.040",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Symbolic Regression tries to find a mathematical expression that describes\nthe relationship of a set of explanatory variables to a measured variable. The\nmain objective is to find a model that minimizes the error and, optionally,\nthat also minimizes the expression size. A smaller expression can be seen as an\ninterpretable model considered a reliable decision model. This is often\nperformed with Genetic Programming which represents their solution as\nexpression trees. The shortcoming of this algorithm lies on this representation\nthat defines a rugged search space and contains expressions of any size and\ndifficulty. These pose as a challenge to find the optimal solution under\ncomputational constraints. This paper introduces a new data structure, called\nInteraction-Transformation (IT), that constrains the search space in order to\nexclude a region of larger and more complicated expressions. In order to test\nthis data structure, it was also introduced an heuristic called SymTree. The\nobtained results show evidence that SymTree are capable of obtaining the\noptimal solution whenever the target function is within the search space of the\nIT data structure and competitive results when it is not. Overall, the\nalgorithm found a good compromise between accuracy and simplicity for all the\ngenerated models."
    },
    "1602.05012": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-02-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-11-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fowkes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jaroslav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sutton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Subsequence Interleaving Model for Sequential Pattern Mining",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages in KDD 2016: Proceedings of the 22nd ACM SIGKDD\n  International Conference on Knowledge Discovery and Data Mining",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/2939672.2939787",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent sequential pattern mining methods have used the minimum description\nlength (MDL) principle to define an encoding scheme which describes an\nalgorithm for mining the most compressing patterns in a database. We present a\nnovel subsequence interleaving model based on a probabilistic model of the\nsequence database, which allows us to search for the most compressing set of\npatterns without designing a specific encoding scheme. Our proposed algorithm\nis able to efficiently mine the most relevant sequential patterns and rank them\nusing an associated measure of interestingness. The efficient inference in our\nmodel is a direct result of our use of a structural expectation-maximization\nframework, in which the expectation-step takes the form of a submodular\noptimization problem subject to a coverage constraint. We show on both\nsynthetic and real world datasets that our model mines a set of sequential\npatterns with low spuriousness and redundancy, high interpretability and\nusefulness in real-world applications. Furthermore, we demonstrate that the\nquality of the patterns from our approach is comparable to, if not better than,\nexisting state of the art sequential pattern mining algorithms."
    },
    "1710.10967": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Igami",
                "http://arxiv.org/OAI/arXiv/:forenames": "Mitsuru"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Artificial Intelligence as Structural Estimation: Economic\n  Interpretations of Deep Blue, Bonanza, and AlphaGo",
        "http://arxiv.org/OAI/arXiv/:categories": "econ.EM cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence (AI) has achieved superhuman performance in a growing\nnumber of tasks, but understanding and explaining AI remain challenging. This\npaper clarifies the connections between machine-learning algorithms to develop\nAIs and the econometrics of dynamic structural models through the case studies\nof three famous game AIs. Chess-playing Deep Blue is a calibrated value\nfunction, whereas shogi-playing Bonanza is an estimated value function via\nRust's (1987) nested fixed-point method. AlphaGo's \"supervised-learning policy\nnetwork\" is a deep neural network implementation of Hotz and Miller's (1993)\nconditional choice probability estimation; its \"reinforcement-learning value\nnetwork\" is equivalent to Hotz, Miller, Sanders, and Smith's (1994) conditional\nchoice simulation method. Relaxing these AIs' implicit econometric assumptions\nwould improve their structural interpretability."
    },
    "1712.10280": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Jia",
                "http://arxiv.org/OAI/arXiv/:forenames": "Hongbo"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "First Draft on the xInf Model for Universal Physical Computation and\n  Reverse Engineering of Natural Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.NC cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "32 pages, 4 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Turing Machines are universal computing machines in theory. It has been a\nlong debate whether Turing Machines can simulate the consciousness mind\nbehaviors in the materialistic universe. Three different hypotheses come out of\nsuch debate, in short:(A) Can; (B) Cannot; (C) Super-Turing machines can.\nBecause Turing Machines or other kinds of theoretical computing models are\nabstract objects while behaviors are real observables, this debate involves at\nleast three distinct fields of science and technology: physics, computer\nengineering, and experimental neuroscience. However, the languages used in\nthese different fields are highly heterogeneous and not easily interpretable\nfor each other, making it very difficult to reach partial agreements regarding\nthis debate, Therefore, the main goal of this manuscript is to establish a\nproper language that can translate among those different fields. First, I\npropose a theoretical model for analyzing how theoretical computing machines\nwould physically run in physical time. This model, termed as the xInf, is at\nfirst place Turing-complete in theory, and depending on the properties of\nphysical time, it can be either Turing-equivalent or Super-Turing in the\nphysical universe. The xInf Model is demonstrated to be a suitable universal\nlanguage to translate among physics, computer engineering, and neuroscience.\nFinally, I propose a conjecture that there exists a Minimal Complete Set of\nrules in the xInf Model that enables the construction of a physical machine\nusing inorganic materials that can pass the Turing Test in physical time. I\ncannot demonstrate whether such a conjecture to be testified or falsified on\npaper using finite-order logic, my only solution is physical time itself, i.e.\nan evolutionary competition will eventually tell the conclusion."
    },
    "1807.03418": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Becker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S\u00f6ren"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ackermann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lapuschkin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "M\u00fcller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Klaus-Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Samek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wojciech"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpreting and Explaining Deep Neural Networks for Classification of\n  Audio Signals",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SD cs.AI cs.LG eess.AS",
        "http://arxiv.org/OAI/arXiv/:comments": "6 pages, 4 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Interpretability of deep neural networks is a recently emerging area of\nmachine learning research targeting a better understanding of how models\nperform feature selection and derive their classification decisions. In this\npaper, two neural network architectures are trained on spectrogram and raw\nwaveform data for audio classification tasks on a newly created audio dataset\nand layer-wise relevance propagation (LRP), a previously proposed\ninterpretability method, is applied to investigate the models' feature\nselection and decision making. It is demonstrated that the networks are highly\nreliant on feature marked as relevant by LRP through systematic manipulation of\nthe input data. Our results show that by making deep audio classifiers\ninterpretable, one can analyze and compare the properties and strategies of\ndifferent models beyond classification accuracy, which potentially opens up new\nways for model improvements."
    },
    "1806.02308": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Geffner",
                "http://arxiv.org/OAI/arXiv/:forenames": "Hector"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Model-free, Model-based, and General Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Invited talk. IJCAI 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "During the 60s and 70s, AI researchers explored intuitions about intelligence\nby writing programs that displayed intelligent behavior. Many good ideas came\nout from this work but programs written by hand were not robust or general.\nAfter the 80s, research increasingly shifted to the development of learners\ncapable of inferring behavior and functions from experience and data, and\nsolvers capable of tackling well-defined but intractable models like SAT,\nclassical planning, Bayesian networks, and POMDPs. The learning approach has\nachieved considerable success but results in black boxes that do not have the\nflexibility, transparency, and generality of their model-based counterparts.\nModel-based approaches, on the other hand, require models and scalable\nalgorithms. Model-free learners and model-based solvers have close parallels\nwith Systems 1 and 2 in current theories of the human mind: the first, a fast,\nopaque, and inflexible intuitive mind; the second, a slow, transparent, and\nflexible analytical mind. In this paper, I review developments in AI and draw\non these theories to discuss the gap between model-free learners and\nmodel-based solvers, a gap that needs to be bridged in order to have\nintelligent systems that are robust and general."
    },
    "1811.03433": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qiao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Delingette",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Herv\u00e9"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ayache",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicholas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable cardiac pathology classification on cine MRI with motion\n  characterization by semi-supervised learning of apparent flow",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a method to classify cardiac pathology based on a novel approach\nto extract image derived features to characterize the shape and motion of the\nheart. An original semi-supervised learning procedure, which makes efficient\nuse of a large amount of non-segmented images and a small amount of images\nsegmented manually by experts, is developed to generate pixel-wise apparent\nflow between two time points of a 2D+t cine MRI image sequence. Combining the\napparent flow maps and cardiac segmentation masks, we obtain a local apparent\nflow corresponding to the 2D motion of myocardium and ventricular cavities.\nThis leads to the generation of time series of the radius and thickness of\nmyocardial segments to represent cardiac motion. These time series of motion\nfeatures are reliable and explainable characteristics of pathological cardiac\nmotion. Furthermore, they are combined with shape-related features to classify\ncardiac pathologies. Using only nine feature values as input, we propose an\nexplainable, simple and flexible model for pathology classification. On ACDC\ntraining set and testing set, the model achieves 95% and 94% respectively as\nclassification accuracy. Its performance is hence comparable to that of the\nstate-of-the-art. Comparison with various other models is performed to outline\nsome advantages of our model."
    },
    "1404.3659": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Konigsberg",
                "http://arxiv.org/OAI/arXiv/:forenames": "Amir"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Avoiding Undesired Choices Using Intelligent Adaptive Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol. 5, No. 2, March 2014",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a number of heuristics that can be used for identifying when\nintransitive choice behaviour is likely to occur in choice situations. We also\nsuggest two methods for avoiding undesired choice behaviour, namely transparent\ncommunication and adaptive choice-set generation. We believe that these two\nways can contribute to the avoidance of decision biases in choice situations\nthat may often be regretted."
    },
    "1802.00560": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoguang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Matwin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Deep Convolutional Neural Networks via Meta-learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 9 figures, submitted to the 2018 International Joint\n  Conference on Neural Networks",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Model interpretability is a requirement in many applications in which crucial\ndecisions are made by users relying on a model's outputs. The recent movement\nfor \"algorithmic fairness\" also stipulates explainability, and therefore\ninterpretability of learning models. And yet the most successful contemporary\nMachine Learning approaches, the Deep Neural Networks, produce models that are\nhighly non-interpretable. We attempt to address this challenge by proposing a\ntechnique called CNN-INTE to interpret deep Convolutional Neural Networks (CNN)\nvia meta-learning. In this work, we interpret a specific hidden layer of the\ndeep CNN model on the MNIST image dataset. We use a clustering algorithm in a\ntwo-level structure to find the meta-level training data and Random Forest as\nbase learning algorithms to generate the meta-level test data. The\ninterpretation results are displayed visually via diagrams, which clearly\nindicates how a specific test instance is classified. Our method achieves\nglobal interpretation for all the test instances without sacrificing the\naccuracy obtained by the original deep CNN model. This means our model is\nfaithful to the deep CNN model, which leads to reliable interpretations."
    },
    "1808.00033": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Du",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mengnan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ninghao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Techniques for Interpretable Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Interpretable machine learning tackles the important problem that humans\ncannot understand the behaviors of complex machine learning models and how\nthese classifiers arrive at a particular decision. Although many approaches\nhave been proposed, a comprehensive understanding of the achievements and\nchallenges is still lacking. This paper provides a survey covering existing\ntechniques and methods to increase the interpretability of machine learning\nmodels and also discusses the crucial issues to consider in future work such as\ninterpretation design principles and evaluation metrics in order to push\nforward the area of interpretable machine learning."
    },
    "1712.06657": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Holzinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Malle",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernd"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kieseberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Roth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "M\u00fcller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Heimo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Reihs",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zatloukal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kurt"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards the Augmented Pathologist: Challenges of Explainable-AI in\n  Digital Pathology",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Digital pathology is not only one of the most promising fields of diagnostic\nmedicine, but at the same time a hot topic for fundamental research. Digital\npathology is not just the transfer of histopathological slides into digital\nrepresentations. The combination of different data sources (images, patient\nrecords, and *omics data) together with current advances in artificial\nintelligence/machine learning enable to make novel information accessible and\nquantifiable to a human expert, which is not yet available and not exploited in\ncurrent medical settings. The grand goal is to reach a level of usable\nintelligence to understand the data in the context of an application task,\nthereby making machine decisions transparent, interpretable and explainable.\nThe foundation of such an \"augmented pathologist\" needs an integrated approach:\nWhile machine learning algorithms require many thousands of training examples,\na human expert is often confronted with only a few data points. Interestingly,\nhumans can learn from such few examples and are able to instantly interpret\ncomplex patterns. Consequently, the grand goal is to combine the possibilities\nof artificial intelligence with human intelligence and to find a well-suited\nbalance between them to enable what neither of them could do on their own. This\ncan raise the quality of education, diagnosis, prognosis and prediction of\ncancer and other diseases. In this paper we describe some (incomplete) research\nissues which we believe should be addressed in an integrated and concerted\neffort for paving the way towards the augmented pathologist."
    },
    "1810.12698": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Selvakumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Muru"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamoorthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suriyadeepan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Archana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vaidheeswaran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sankarasubbu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Malaikannan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Compositional Attention Networks for Interpretability in Natural\n  Language Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages,10 figures, 1 table",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "MAC Net is a compositional attention network designed for Visual Question\nAnswering. We propose a modified MAC net architecture for Natural Language\nQuestion Answering. Question Answering typically requires Language\nUnderstanding and multi-step Reasoning. MAC net's unique architecture - the\nseparation between memory and control, facilitates data-driven iterative\nreasoning. This makes it an ideal candidate for solving tasks that involve\nlogical reasoning. Our experiments with 20 bAbI tasks demonstrate the value of\nMAC net as a data-efficient and interpretable architecture for Natural Language\nQuestion Answering. The transparent nature of MAC net provides a highly\ngranular view of the reasoning steps taken by the network in answering a query."
    },
    "1806.09769": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zheming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiqiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jenkins",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Odest Chadwicke"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Plenoptic Monte Carlo Object Localization for Robot Grasping under\n  Layered Translucency",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "1. Modify the result representation and corresponding figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order to fully function in human environments, robot perception will need\nto account for the uncertainty caused by translucent materials. Translucency\nposes several open challenges in the form of transparent objects (e.g.,\ndrinking glasses), refractive media (e.g., water), and diffuse partial\nocclusions (e.g., objects behind stained glass panels). This paper presents\nPlenoptic Monte Carlo Localization (PMCL) as a method for localizing object\nposes in the presence of translucency using plenoptic (light-field)\nobservations. We propose a new depth descriptor, the Depth Likelihood Volume\n(DLV), and its use within a Monte Carlo object localization algorithm. We\npresent results of localizing and manipulating objects with translucent\nmaterials and objects occluded by layers of translucency. Our PMCL\nimplementation uses observations from a Lytro first generation light field\ncamera to allow a Michigan Progress Fetch robot to perform grasping."
    },
    "1802.05312": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ridgeway",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karl"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mozer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael C."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Deep Disentangled Embeddings with the F-Statistic Loss",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep-embedding methods aim to discover representations of a domain that make\nexplicit the domain's class structure and thereby support few-shot learning.\nDisentangling methods aim to make explicit compositional or factorial\nstructure. We combine these two active but independent lines of research and\npropose a new paradigm suitable for both goals. We propose and evaluate a novel\nloss function based on the $F$ statistic, which describes the separation of two\nor more distributions. By ensuring that distinct classes are well separated on\na subset of embedding dimensions, we obtain embeddings that are useful for\nfew-shot learning. By not requiring separation on all dimensions, we encourage\nthe discovery of disentangled representations. Our embedding method matches or\nbeats state-of-the-art, as evaluated by performance on recall@$k$ and few-shot\nlearning tasks. Our method also obtains performance superior to a variety of\nalternatives on disentangling, as evaluated by two key properties of a\ndisentangled representation: modularity and explicitness. The goal of our work\nis to obtain more interpretable, manipulable, and generalizable deep\nrepresentations of concepts and categories."
    },
    "1606.07461": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Strobelt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hendrik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gehrmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pfister",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hanspeter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rush",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander M."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in\n  Recurrent Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "InfoVis 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recurrent neural networks, and in particular long short-term memory (LSTM)\nnetworks, are a remarkably effective tool for sequence modeling that learn a\ndense black-box hidden representation of their sequential input. Researchers\ninterested in better understanding these models have studied the changes in\nhidden state representations over time and noticed some interpretable patterns\nbut also significant noise. In this work, we present LSTMVIS, a visual analysis\ntool for recurrent neural networks with a focus on understanding these hidden\nstate dynamics. The tool allows users to select a hypothesis input range to\nfocus on local state changes, to match these states changes to similar patterns\nin a large data set, and to align these results with structural annotations\nfrom their domain. We show several use cases of the tool for analyzing specific\nhidden state properties on dataset containing nesting, phrase structure, and\nchord progressions, and demonstrate how the tool can be used to isolate\npatterns for further statistical analysis. We characterize the domain, the\ndifferent stakeholders, and their goals and tasks."
    },
    "1710.06169": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sarah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Caruana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rich"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hooker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Auditing Black-Box Models Using Transparent Model Distillation With Side\n  Information",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Previously titled \"Detecting Bias in Black-Box Models Using\n  Transparent Model Distillation\". A short version was presented at NIPS 2017\n  Symposium on Interpretable Machine Learning and AIES 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Black-box risk scoring models permeate our lives, yet are typically\nproprietary or opaque. We propose a transparent model distillation approach to\naudit such models. Model distillation was first introduced to transfer\nknowledge from a large, complex teacher model to a faster, simpler student\nmodel without significant loss in prediction accuracy. To this we add a third\ncriterion - transparency. To gain insight into black-box models, we treat them\nas teachers, training transparent student models to mimic the risk scores\nassigned by the teacher. Moreover, we use side information in the form of the\nactual outcomes the teacher scoring model was intended to predict in the first\nplace. By training a second transparent model on the outcomes, we can compare\nthe two models to each other. When comparing models trained on risk scores to\nmodels trained on outcomes, we show that it is necessary to calibrate the\nrisk-scoring model's predictions to remove distortion that may have been added\nto the black-box risk-scoring model during or after its training process. We\nalso show how to compute confidence intervals for the particular class of\ntransparent student models we use - tree-based additive models with pairwise\ninteractions (GA2Ms) - to support comparison of the two transparent models. We\ndemonstrate the methods on four public datasets: COMPAS, Lending Club,\nStop-and-Frisk, and Chicago Police."
    },
    "1110.0214": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Iqbal",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ridwan Al"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Eclectic Extraction of Propositional Rules from Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "ICCIT 2011, Dhaka, Bangladesh",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial Neural Network is among the most popular algorithm for supervised\nlearning. However, Neural Networks have a well-known drawback of being a \"Black\nBox\" learner that is not comprehensible to the Users. This lack of transparency\nmakes it unsuitable for many high risk tasks such as medical diagnosis that\nrequires a rational justification for making a decision. Rule Extraction\nmethods attempt to curb this limitation by extracting comprehensible rules from\na trained Network. Many such extraction algorithms have been developed over the\nyears with their respective strengths and weaknesses. They have been broadly\ncategorized into three types based on their approach to use internal model of\nthe Network. Eclectic Methods are hybrid algorithms that combine the other\napproaches to attain more performance. In this paper, we present an Eclectic\nmethod called HERETIC. Our algorithm uses Inductive Decision Tree learning\ncombined with information of the neural network structure for extracting\nlogical rules. Experiments and theoretical analysis show HERETIC to be better\nin terms of speed and performance."
    },
    "1606.03475": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dernoncourt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franck"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ji Young"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Uzuner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ozlem"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Szolovits",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "De-identification of Patient Notes with Recurrent Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering."
    },
    "1804.02477": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhinav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Murali",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vijayaraghavan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rishabh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chaudhuri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Swarat"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Programmatically Interpretable Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.PL stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study the problem of generating interpretable and verifiable policies\nthrough reinforcement learning. Unlike the popular Deep Reinforcement Learning\n(DRL) paradigm, in which the policy is represented by a neural network, the aim\nin Programmatically Interpretable Reinforcement Learning is to find a policy\nthat can be represented in a high-level programming language. Such programmatic\npolicies have the benefits of being more easily interpreted than neural\nnetworks, and being amenable to verification by symbolic methods. We propose a\nnew method, called Neurally Directed Program Search (NDPS), for solving the\nchallenging nonsmooth optimization problem of finding a programmatic policy\nwith maxima reward. NDPS works by first learning a neural policy network using\nDRL, and then performing a local search over programmatic policies that seeks\nto minimize a distance from this neural \"oracle\". We evaluate NDPS on the task\nof learning to drive a simulated car in the TORCS car-racing environment. We\ndemonstrate that NDPS is able to discover human-readable policies that pass\nsome significant performance bars. We also find that a well-designed policy\nlanguage can serve as a regularizer, and result in the discovery of policies\nthat lead to smoother trajectories and are more easily transferred to\nenvironments not encountered during training."
    },
    "1806.02056": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khawar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Farhan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nevin L."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Hierarchical Item Categories from Implicit Feedback Data for\n  Efficient Recommendations and Browsing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Searching, browsing, and recommendations are common ways in which the \"choice\noverload\" faced by users in the online marketplace can be mitigated. In this\npaper we propose the use of hierarchical item categories, obtained from\nimplicit feedback data, to enable efficient browsing and recommendations. We\npresent a method of creating hierarchical item categories from implicit\nfeedback data only i.e., without any other information on the items like name,\ngenre etc. Categories created in this fashion are based on users'\nco-consumption of items. Thus, they can be more useful for users in finding\ninteresting and relevant items while they are browsing through the hierarchy.\nWe also show that this item hierarchy can be useful in making category based\nrecommendations, which makes the recommendations more explainable and increases\nthe diversity of the recommendations without compromising much on the accuracy.\nItem hierarchy can also be useful in the creation of an automatic item taxonomy\nskeleton by bypassing manual labeling and annotation. This can especially be\nuseful for small vendors. Our data-driven hierarchical categories are based on\nhierarchical latent tree analysis (HLTA) which has been previously used for\ntext analysis. We present a scaled up learning algorithm \\emph{HLTA-Forest} so\nthat HLTA can be applied to implicit feedback data."
    },
    "1805.09843": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dinghan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guoyin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wenlin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Min",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin Renqiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qinliang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yizhe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chunyuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Henao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ricardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Carin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lawrence"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n  Associated Pooling Mechanisms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear at ACL 2018 (code: https://github.com/dinghanshen/SWEM)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many deep learning architectures have been proposed to model the\ncompositionality in text sequences, requiring a substantial number of\nparameters and expensive computations. However, there has not been a rigorous\nevaluation regarding the added value of sophisticated compositional functions.\nIn this paper, we conduct a point-by-point comparative study between Simple\nWord-Embedding-based Models (SWEMs), consisting of parameter-free pooling\noperations, relative to word-embedding-based RNN/CNN models. Surprisingly,\nSWEMs exhibit comparable or even superior performance in the majority of cases\nconsidered. Based upon this understanding, we propose two additional pooling\nstrategies over learned word embeddings: (i) a max-pooling operation for\nimproved interpretability; and (ii) a hierarchical pooling operation, which\npreserves spatial (n-gram) information within text sequences. We present\nexperiments on 17 datasets encompassing three tasks: (i) (long) document\nclassification; (ii) text sequence matching; and (iii) short text tasks,\nincluding classification and tagging. The source code and datasets can be\nobtained from https:// github.com/dinghanshen/SWEM."
    },
    "1806.00712": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shiwen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon X."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aberle",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Denise R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex A. T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hsu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Willliam"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Interpretable Deep Hierarchical Semantic Convolutional Neural Network\n  for Lung Nodule Malignancy Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While deep learning methods are increasingly being applied to tasks such as\ncomputer-aided diagnosis, these models are difficult to interpret, do not\nincorporate prior domain knowledge, and are often considered as a \"black-box.\"\nThe lack of model interpretability hinders them from being fully understood by\ntarget users such as radiologists. In this paper, we present a novel\ninterpretable deep hierarchical semantic convolutional neural network (HSCNN)\nto predict whether a given pulmonary nodule observed on a computed tomography\n(CT) scan is malignant. Our network provides two levels of output: 1) low-level\nradiologist semantic features, and 2) a high-level malignancy prediction score.\nThe low-level semantic outputs quantify the diagnostic features used by\nradiologists and serve to explain how the model interprets the images in an\nexpert-driven manner. The information from these low-level tasks, along with\nthe representations learned by the convolutional layers, are then combined and\nused to infer the high-level task of predicting nodule malignancy. This unified\narchitecture is trained by optimizing a global loss function including both\nlow- and high-level tasks, thereby learning all the parameters within a joint\nframework. Our experimental results using the Lung Image Database Consortium\n(LIDC) show that the proposed method not only produces interpretable lung\ncancer predictions but also achieves significantly better results compared to\ncommon 3D CNN approaches."
    },
    "1004.3260": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-04-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mohemad",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rosmayati"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamdan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abdul Razak"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Othman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zulaiha Ali"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Noor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Noor Maizura Mohamad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Decision Support Systems (DSS) in Construction Tendering Processes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "International Journal of Computer Science Issues online at\n  http://ijcsi.org/articles/Decision-Support-Systems-DSS-in-Construction-Tendering-Processes.php",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IJCSI, Volume 7, Issue 2, March 2010",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The successful execution of a construction project is heavily impacted by\nmaking the right decision during tendering processes. Managing tender\nprocedures is very complex and uncertain involving coordination of many tasks\nand individuals with different priorities and objectives. Bias and inconsistent\ndecision are inevitable if the decision-making process is totally depends on\nintuition, subjective judgement or emotion. In making transparent decision and\nhealthy competition tendering, there exists a need for flexible guidance tool\nfor decision support. Aim of this paper is to give a review on current\npractices of Decision Support Systems (DSS) technology in construction\ntendering processes. Current practices of general tendering processes as\napplied to the most countries in different regions such as United States,\nEurope, Middle East and Asia are comprehensively discussed. Applications of\nWeb-based tendering processes is also summarised in terms of its properties.\nBesides that, a summary of Decision Support System (DSS) components is included\nin the next section. Furthermore, prior researches on implementation of DSS\napproaches in tendering processes are discussed in details. Current issues\narise from both of paper-based and Web-based tendering processes are outlined.\nFinally, conclusion is included at the end of this paper."
    },
    "1301.5488": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-01-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Melo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francisco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lopes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manuel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multi-class Generalized Binary Search for Active Inverse Reinforcement\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper addresses the problem of learning a task from demonstration. We\nadopt the framework of inverse reinforcement learning, where tasks are\nrepresented in the form of a reward function. Our contribution is a novel\nactive learning algorithm that enables the learning agent to query the expert\nfor more informative demonstrations, thus leading to more sample-efficient\nlearning. For this novel algorithm (Generalized Binary Search for Inverse\nReinforcement Learning, or GBS-IRL), we provide a theoretical bound on sample\ncomplexity and illustrate its applicability on several different tasks. To our\nknowledge, GBS-IRL is the first active IRL algorithm with provable sample\ncomplexity bounds. We also discuss our method in light of other existing\nmethods in the literature and its general applicability in multi-class\nclassification problems. Finally, motivated by recent work on learning from\ndemonstration in robots, we also discuss how different forms of human feedback\ncan be integrated in a transparent manner in our learning framework."
    },
    "1809.03051": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghaeini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Reza"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fern",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoli Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tadepalli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prasad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Attentional Multi-Reading Sarcasm Detection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recognizing sarcasm often requires a deep understanding of multiple sources\nof information, including the utterance, the conversational context, and real\nworld facts. Most of the current sarcasm detection systems consider only the\nutterance in isolation. There are some limited attempts toward taking into\naccount the conversational context. In this paper, we propose an interpretable\nend-to-end model that combines information from both the utterance and the\nconversational context to detect sarcasm, and demonstrate its effectiveness\nthrough empirical evaluations. We also study the behavior of the proposed model\nto provide explanations for the model's decisions. Importantly, our model is\ncapable of determining the impact of utterance and conversational context on\nthe model's decisions. Finally, we provide an ablation study to illustrate the\nimpact of different components of the proposed model."
    },
    "0705.0761": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2007-05-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2007-08-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marwala",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tshilidzi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Crossingham",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bodie"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian Approach to Neuro-Rough Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages, 5 figures, 1 table",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper proposes a neuro-rough model based on multi-layered perceptron and\nrough set. The neuro-rough model is then tested on modelling the risk of HIV\nfrom demographic data. The model is formulated using Bayesian framework and\ntrained using Monte Carlo method and Metropolis criterion. When the model was\ntested to estimate the risk of HIV infection given the demographic data it was\nfound to give the accuracy of 62%. The proposed model is able to combine the\naccuracy of the Bayesian MLP model and the transparency of Bayesian rough set\nmodel."
    },
    "1801.05075": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mohseni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ragan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric D."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Human-Grounded Evaluation Benchmark for Local Explanations of Machine\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Benchmark Available online at\n  https://github.com/SinaMohseni/ML-Interpretability-Evaluation-Benchmark",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order for people to be able to trust and take advantage of the results of\nadvanced machine learning and artificial intelligence solutions for real\ndecision making, people need to be able to understand the machine rationale for\ngiven output. Research in explain artificial intelligence (XAI) addresses the\naim, but there is a need for evaluation of human relevance and\nunderstandability of explanations. Our work contributes a novel methodology for\nevaluating the quality or human interpretability of explanations for machine\nlearning models. We present an evaluation benchmark for instance explanations\nfrom text and image classifiers. The explanation meta-data in this benchmark is\ngenerated from user annotations of image and text samples. We describe the\nbenchmark and demonstrate its utility by a quantitative evaluation on\nexplanations generated from a recent machine learning algorithm. This research\ndemonstrates how human-grounded evaluation could be used as a measure to\nqualify local machine-learning explanations."
    },
    "1806.00047": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blukis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Valts"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brukhim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nataly"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bennett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Knepper",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ross A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Artzi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoav"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Following High-level Navigation Instructions on a Simulated Quadcopter\n  with Imitation Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CV cs.LG cs.RO",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Robotics: Science and Systems (RSS), 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce a method for following high-level navigation instructions by\nmapping directly from images, instructions and pose estimates to continuous\nlow-level velocity commands for real-time control. The Grounded Semantic\nMapping Network (GSMN) is a fully-differentiable neural network architecture\nthat builds an explicit semantic map in the world reference frame by\nincorporating a pinhole camera projection model within the network. The\ninformation stored in the map is learned from experience, while the\nlocal-to-world transformation is computed explicitly. We train the model using\nDAggerFM, a modified variant of DAgger that trades tabular convergence\nguarantees for improved training speed and memory use. We test GSMN in virtual\nenvironments on a realistic quadcopter simulator and show that incorporating an\nexplicit mapping and grounding modules allows GSMN to outperform strong neural\nbaselines and almost reach an expert policy performance. Finally, we analyze\nthe learned map representations and show that using an explicit map leads to an\ninterpretable instruction-following model."
    },
    "1801.09810": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Al-Shedivat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maruan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dubey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Avinava"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Personalized Survival Prediction with Contextual Explanation Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Machine Learning for Healthcare Workshop, NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Accurate and transparent prediction of cancer survival times on the level of\nindividual patients can inform and improve patient care and treatment\npractices. In this paper, we design a model that concurrently learns to\naccurately predict patient-specific survival distributions and to explain its\npredictions in terms of patient attributes such as clinical tests or\nassessments. Our model is flexible and based on a recurrent network, can handle\nvarious modalities of data including temporal measurements, and yet constructs\nand uses simple explanations in the form of patient- and time-specific linear\nregression. For analysis, we use two publicly available datasets and show that\nour networks outperform a number of baselines in prediction while providing a\nway to inspect the reasons behind each prediction."
    },
    "1312.2798": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-12-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shao Fen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scott",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Donia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stevens",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rector",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "OntoVerbal: a Generic Tool and Practical Application to SNOMED CT",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Ontology development is a non-trivial task requiring expertise in the chosen\nontological language. We propose a method for making the content of ontologies\nmore transparent by presenting, through the use of natural language generation,\nnaturalistic descriptions of ontology classes as textual paragraphs. The method\nhas been implemented in a proof-of- concept system, OntoVerbal, that\nautomatically generates paragraph-sized textual descriptions of ontological\nclasses expressed in OWL. OntoVerbal has been applied to ontologies that can be\nloaded into Prot\\'eg\\'e and been evaluated with SNOMED CT, showing that it\nprovides coherent, well-structured and accurate textual descriptions of\nontology classes."
    },
    "1708.00754": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zliobaite",
                "http://arxiv.org/OAI/arXiv/:forenames": "Indre"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness-aware machine learning: a perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Algorithms learned from data are increasingly used for deciding many aspects\nin our life: from movies we see, to prices we pay, or medicine we get. Yet\nthere is growing evidence that decision making by inappropriately trained\nalgorithms may unintentionally discriminate people. For example, in automated\nmatching of candidate CVs with job descriptions, algorithms may capture and\npropagate ethnicity related biases. Several repairs for selected algorithms\nhave already been proposed, but the underlying mechanisms how such\ndiscrimination happens from the computational perspective are not yet\nscientifically understood. We need to develop theoretical understanding how\nalgorithms may become discriminatory, and establish fundamental machine\nlearning principles for prevention. We need to analyze machine learning process\nas a whole to systematically explain the roots of discrimination occurrence,\nwhich will allow to devise global machine learning optimization criteria for\nguaranteed prevention, as opposed to pushing empirical constraints into\nexisting algorithms case-by-case. As a result, the state-of-the-art will\nadvance from heuristic repairing, to proactive and theoretically supported\nprevention. This is needed not only because law requires to protect vulnerable\npeople. Penetration of big data initiatives will only increase, and computer\nscience needs to provide solid explanations and accountability to the public,\nbefore public concerns lead to unnecessarily restrictive regulations against\nmachine learning."
    },
    "1811.04179": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blukis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Valts"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Misra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dipendra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Knepper",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ross A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Artzi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoav"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mapping Navigation Instructions to Continuous Control Actions with\n  Position-Visitation Prediction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI cs.CL cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Appeared in Conference on Robot Learning 2018",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "In Conference on Robot Learning (pp. 505-518) (2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an approach for mapping natural language instructions and raw\nobservations to continuous control of a quadcopter drone. Our model predicts\ninterpretable position-visitation distributions indicating where the agent\nshould go during execution and where it should stop, and uses the predicted\ndistributions to select the actions to execute. This two-step model\ndecomposition allows for simple and efficient training using a combination of\nsupervised learning and imitation learning. We evaluate our approach with a\nrealistic drone simulator, and demonstrate absolute task-completion accuracy\nimprovements of 16.85% over two state-of-the-art instruction-following methods."
    },
    "1811.00090": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lyu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daoming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fangkai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gustafson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steven"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "SDRL: Interpretable and Data-efficient Deep Reinforcement\n  LearningLeveraging Symbolic Planning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep reinforcement learning (DRL) has gained great success by learning\ndirectly from high-dimensional sensory inputs, yet is notorious for the lack of\ninterpretability. Interpretability of the subtasks is critical in hierarchical\ndecision-making as it increases the transparency of black-box-style DRL\napproach and helps the RL practitioners to understand the high-level behavior\nof the system better. In this paper, we introduce symbolic planning into DRL\nand propose a framework of Symbolic Deep Reinforcement Learning (SDRL) that can\nhandle both high-dimensional sensory inputs and symbolic planning. The\ntask-level interpretability is enabled by relating symbolic actions to\noptions.This framework features a planner -- controller -- meta-controller\narchitecture, which takes charge of subtask scheduling, data-driven subtask\nlearning, and subtask evaluation, respectively. The three components\ncross-fertilize each other and eventually converge to an optimal symbolic plan\nalong with the learned subtasks, bringing together the advantages of long-term\nplanning capability with symbolic knowledge and end-to-end reinforcement\nlearning directly from a high-dimensional sensory input. Experimental results\nvalidate the interpretability of subtasks, along with improved data efficiency\ncompared with state-of-the-art approaches."
    },
    "1502.06626": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Magdon-Ismail",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Malik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boutsidis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Optimal Sparse Linear Auto-Encoders and Sparse PCA",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.IT math.IT stat.CO stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Principal components analysis (PCA) is the optimal linear auto-encoder of\ndata, and it is often used to construct features. Enforcing sparsity on the\nprincipal components can promote better generalization, while improving the\ninterpretability of the features. We study the problem of constructing optimal\nsparse linear auto-encoders. Two natural questions in such a setting are: i)\nGiven a level of sparsity, what is the best approximation to PCA that can be\nachieved? ii) Are there low-order polynomial-time algorithms which can\nasymptotically achieve this optimal tradeoff between the sparsity and the\napproximation quality?\n  In this work, we answer both questions by giving efficient low-order\npolynomial-time algorithms for constructing asymptotically \\emph{optimal}\nlinear auto-encoders (in particular, sparse features with near-PCA\nreconstruction error) and demonstrate the performance of our algorithms on real\ndata."
    },
    "1704.05908": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qizhe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuezhe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zihang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hovy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eduard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Interpretable Knowledge Transfer Model for Knowledge Base Completion",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted by ACL 2017. Minor update",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Knowledge bases are important resources for a variety of natural language\nprocessing tasks but suffer from incompleteness. We propose a novel embedding\nmodel, \\emph{ITransF}, to perform knowledge base completion. Equipped with a\nsparse attention mechanism, ITransF discovers hidden concepts of relations and\ntransfer statistical strength through the sharing of concepts. Moreover, the\nlearned associations between relations and concepts, which are represented by\nsparse attention vectors, can be interpreted easily. We evaluate ITransF on two\nbenchmark datasets---WN18 and FB15k for knowledge base completion and obtains\nimprovements on both the mean rank and Hits@10 metrics, over all baselines that\ndo not use additional information."
    },
    "1209.0911": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-09-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Junming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xue-Qi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hua-Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaolong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Conquering the rating bound problem in neighborhood-based collaborative\n  filtering: a function recovery approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 4 figures",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.3.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As an important tool for information filtering in the era of socialized web,\nrecommender systems have witnessed rapid development in the last decade. As\nbenefited from the better interpretability, neighborhood-based collaborative\nfiltering techniques, such as item-based collaborative filtering adopted by\nAmazon, have gained a great success in many practical recommender systems.\nHowever, the neighborhood-based collaborative filtering method suffers from the\nrating bound problem, i.e., the rating on a target item that this method\nestimates is bounded by the observed ratings of its all neighboring items.\nTherefore, it cannot accurately estimate the unobserved rating on a target\nitem, if its ground truth rating is actually higher (lower) than the highest\n(lowest) rating over all items in its neighborhood. In this paper, we address\nthis problem by formalizing rating estimation as a task of recovering a scalar\nrating function. With a linearity assumption, we infer all the ratings by\noptimizing the low-order norm, e.g., the $l_1/2$-norm, of the second derivative\nof the target scalar function, while remaining its observed ratings unchanged.\nExperimental results on three real datasets, namely Douban, Goodreads and\nMovieLens, demonstrate that the proposed approach can well overcome the rating\nbound problem. Particularly, it can significantly improve the accuracy of\nrating estimation by 37% than the conventional neighborhood-based methods."
    },
    "1708.01104": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Holzinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Plass",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Markus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Holzinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Katharina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Crisan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gloria Cerasela"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pintea",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Camelia-M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Palade",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vasile"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A glass-box interactive machine learning approach for solving NP-hard\n  problems with the human-in-the-loop",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "26 pages, 5 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The goal of Machine Learning to automatically learn from data, extract\nknowledge and to make decisions without any human intervention. Such automatic\n(aML) approaches show impressive success. Recent results even demonstrate\nintriguingly that deep learning applied for automatic classification of skin\nlesions is on par with the performance of dermatologists, yet outperforms the\naverage. As human perception is inherently limited, such approaches can\ndiscover patterns, e.g. that two objects are similar, in arbitrarily\nhigh-dimensional spaces what no human is able to do. Humans can deal only with\nlimited amounts of data, whilst big data is beneficial for aML; however, in\nhealth informatics, we are often confronted with a small number of data sets,\nwhere aML suffer of insufficient training samples and many problems are\ncomputationally hard. Here, interactive machine learning (iML) may be of help,\nwhere a human-in-the-loop contributes to reduce the complexity of NP-hard\nproblems. A further motivation for iML is that standard black-box approaches\nlack transparency, hence do not foster trust and acceptance of ML among\nend-users. Rising legal and privacy aspects, e.g. with the new European General\nData Protection Regulations, make black-box approaches difficult to use,\nbecause they often are not able to explain why a decision has been made. In\nthis paper, we present some experiments to demonstrate the effectiveness of the\nhuman-in-the-loop approach, particularly in opening the black-box to a\nglass-box and thus enabling a human directly to interact with an learning\nalgorithm. We selected the Ant Colony Optimization framework, and applied it on\nthe Traveling Salesman Problem, which is a good example, due to its relevance\nfor health informatics, e.g. for the study of protein folding. From studies of\nhow humans extract so much from so little data, fundamental ML-research also\nmay benefit."
    },
    "0911.0460": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-11-03",
        "http://arxiv.org/OAI/arXiv/:updated": "2009-11-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sill",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joseph"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Takacs",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gabor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mackey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lester"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Feature-Weighted Linear Stacking",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "17 pages, 1 figure, 2 tables",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Ensemble methods, such as stacking, are designed to boost predictive accuracy\nby blending the predictions of multiple machine learning models. Recent work\nhas shown that the use of meta-features, additional inputs describing each\nexample in a dataset, can boost the performance of ensemble methods, but the\ngreatest reported gains have come from nonlinear procedures requiring\nsignificant tuning and training time. Here, we present a linear technique,\nFeature-Weighted Linear Stacking (FWLS), that incorporates meta-features for\nimproved accuracy while retaining the well-known virtues of linear regression\nregarding speed, stability, and interpretability. FWLS combines model\npredictions linearly using coefficients that are themselves linear functions of\nmeta-features. This technique was a key facet of the solution of the second\nplace team in the recently concluded Netflix Prize competition. Significant\nincreases in accuracy over standard linear stacking are demonstrated on the\nNetflix Prize collaborative filtering dataset."
    },
    "1703.03130": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhouhan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Minwei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Santos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cicero Nogueira dos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bowen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Structured Self-attentive Sentence Embedding",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages with appendix, 7 figures, 4 tables. Conference paper in 5th\n  International Conference on Learning Representations (ICLR 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks."
    },
    "1705.05785": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Duman\u010di\u0107",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastijan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blockeel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hendrik"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Demystifying Relational Latent Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "12 pages, 8 figures; accepted to ILP 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Latent features learned by deep learning approaches have proven to be a\npowerful tool for machine learning. They serve as a data abstraction that makes\nlearning easier by capturing regularities in data explicitly. Their benefits\nmotivated their adaptation to relational learning context. In our previous\nwork, we introduce an approach that learns relational latent features by means\nof clustering instances and their relations. The major drawback of latent\nrepresentations is that they are often black-box and difficult to interpret.\nThis work addresses these issues and shows that (1) latent features created by\nclustering are interpretable and capture interesting properties of data; (2)\nthey identify local regions of instances that match well with the label, which\npartially explains their benefit; and (3) although the number of latent\nfeatures generated by this approach is large, often many of them are highly\nredundant and can be removed without hurting performance much."
    },
    "1809.07424": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nushi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Besmira"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kamar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ece"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Horvitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Accountable AI: Hybrid Human-Machine Analyses for Characterizing\n  System Failure",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.HC stat.ML",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "AAAI Conference on Human Computation and Crowdsourcing 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As machine learning systems move from computer-science laboratories into the\nopen world, their accountability becomes a high priority problem.\nAccountability requires deep understanding of system behavior and its failures.\nCurrent evaluation methods such as single-score error metrics and confusion\nmatrices provide aggregate views of system performance that hide important\nshortcomings. Understanding details about failures is important for identifying\npathways for refinement, communicating the reliability of systems in different\nsettings, and for specifying appropriate human oversight and engagement.\nCharacterization of failures and shortcomings is particularly complex for\nsystems composed of multiple machine learned components. For such systems,\nexisting evaluation methods have limited expressiveness in describing and\nexplaining the relationship among input content, the internal states of system\ncomponents, and final output quality. We present Pandora, a set of hybrid\nhuman-machine methods and tools for describing and explaining system failures.\nPandora leverages both human and system-generated observations to summarize\nconditions of system malfunction with respect to the input content and system\narchitecture. We share results of a case study with a machine learning pipeline\nfor image captioning that show how detailed performance views can be beneficial\nfor analysis and debugging."
    },
    "1704.05796": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bolei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khosla",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aditya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Oliva",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aude"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Torralba",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Network Dissection: Quantifying Interpretability of Deep Visual\n  Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "First two authors contributed equally. Oral presentation at CVPR 2017",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.10",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a general framework called Network Dissection for quantifying the\ninterpretability of latent representations of CNNs by evaluating the alignment\nbetween individual hidden units and a set of semantic concepts. Given any CNN\nmodel, the proposed method draws on a broad data set of visual concepts to\nscore the semantics of hidden units at each intermediate convolutional layer.\nThe units with semantics are given labels across a range of objects, parts,\nscenes, textures, materials, and colors. We use the proposed method to test the\nhypothesis that interpretability of units is equivalent to random linear\ncombinations of units, then we apply our method to compare the latent\nrepresentations of various networks when trained to solve different supervised\nand self-supervised training tasks. We further analyze the effect of training\niterations, compare networks trained with different initializations, examine\nthe impact of network depth and width, and measure the effect of dropout and\nbatch normalization on the interpretability of deep visual representations. We\ndemonstrate that the proposed method can shed light on characteristics of CNN\nmodels and training methods that go beyond measurements of their discriminative\npower."
    },
    "1604.02336": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-05-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Karklin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bojian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ekanadham",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chaitanya"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Back to the Basics: Bayesian extensions of IRT outperform neural\n  networks for proficiency estimation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "6 pages, 2 figures, Educational Data Mining 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Estimating student proficiency is an important task for computer based\nlearning systems. We compare a family of IRT-based proficiency estimation\nmethods to Deep Knowledge Tracing (DKT), a recently proposed recurrent neural\nnetwork model with promising initial results. We evaluate how well each model\npredicts a student's future response given previous responses using two\npublicly available and one proprietary data set. We find that IRT-based methods\nconsistently matched or outperformed DKT across all data sets at the finest\nlevel of content granularity that was tractable for them to be trained on. A\nhierarchical extension of IRT that captured item grouping structure performed\nbest overall. When data sets included non-trivial autocorrelations in student\nresponse patterns, a temporal extension of IRT improved performance over\nstandard IRT while the RNN-based method did not. We conclude that IRT-based\nmodels provide a simpler, better-performing alternative to existing RNN-based\nmodels of student interaction data while also affording more interpretability\nand guarantees due to their formulation as Bayesian probabilistic models."
    },
    "1803.09702": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Deiss",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Olivier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Biswal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siddharth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haoqi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Westover",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M. Brandon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jimeng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "HAMLET: Interpretable Human And Machine co-LEarning Technique",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Reference update to published version of an article",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Efficient label acquisition processes are key to obtaining robust\nclassifiers. However, data labeling is often challenging and subject to high\nlevels of label noise. This can arise even when classification targets are well\ndefined, if instances to be labeled are more difficult than the prototypes used\nto define the class, leading to disagreements among the expert community. Here,\nwe enable efficient training of deep neural networks. From low-confidence\nlabels, we iteratively improve their quality by simultaneous learning of\nmachines and experts. We call it Human And Machine co-LEarning Technique\n(HAMLET). Throughout the process, experts become more consistent, while the\nalgorithm provides them with explainable feedback for confirmation. HAMLET uses\na neural embedding function and a memory module filled with diverse reference\nembeddings from different classes. Its output includes classification labels\nand highly relevant reference embeddings as explanation. We took the study of\nbrain monitoring at intensive care unit (ICU) as an application of HAMLET on\ncontinuous electroencephalography (cEEG) data. Although cEEG monitoring yields\nlarge volumes of data, labeling costs and difficulty make it hard to build a\nclassifier. Additionally, while experts agree on the labels of clear-cut\nexamples of cEEG patterns, labeling many real-world cEEG data can be extremely\nchallenging. Thus, a large minority of sequences might be mislabeled. HAMLET\nhas shown significant performance gain against deep learning and other\nbaselines, increasing accuracy from 7.03% to 68.75% on challenging inputs.\nBesides improved performance, clinical experts confirmed the interpretability\nof those reference embeddings in helping explaining the classification results\nby HAMLET."
    },
    "1704.00717": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-03",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chandrasekaran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yadav",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Deshraj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chattopadhyay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prithvijit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Prabhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Viraj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "It Takes Two to Tango: Towards Theory of AI's Mind",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Theory of Mind is the ability to attribute mental states (beliefs, intents,\nknowledge, perspectives, etc.) to others and recognize that these mental states\nmay differ from one's own. Theory of Mind is critical to effective\ncommunication and to teams demonstrating higher collective performance. To\neffectively leverage the progress in Artificial Intelligence (AI) to make our\nlives more productive, it is important for humans and AI to work well together\nin a team. Traditionally, there has been much emphasis on research to make AI\nmore accurate, and (to a lesser extent) on having it better understand human\nintentions, tendencies, beliefs, and contexts. The latter involves making AI\nmore human-like and having it develop a theory of our minds. In this work, we\nargue that for human-AI teams to be effective, humans must also develop a\ntheory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs,\nand quirks. We instantiate these ideas within the domain of Visual Question\nAnswering (VQA). We find that using just a few examples (50), lay people can be\ntrained to better predict responses and oncoming failures of a complex VQA\nmodel. We further evaluate the role existing explanation (or interpretability)\nmodalities play in helping humans build ToAIM. Explainable AI has received\nconsiderable scientific and popular attention in recent times. Surprisingly, we\nfind that having access to the model's internal states - its confidence in its\ntop-k predictions, explicit or implicit attention maps which highlight regions\nin the image (and words in the question) the model is looking at (and listening\nto) while answering a question about an image - do not help people better\npredict its behavior."
    },
    "1803.11261": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                "http://arxiv.org/OAI/arXiv/:forenames": "Kush R."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "How an Electrical Engineer Became an Artificial Intelligence Researcher,\n  a Multiphase Active Contours Analysis",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.IT math.IT stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This essay examines how what is considered to be artificial intelligence (AI)\nhas changed over time and come to intersect with the expertise of the author.\nInitially, AI developed on a separate trajectory, both topically and\ninstitutionally, from pattern recognition, neural information processing,\ndecision and control systems, and allied topics by focusing on symbolic systems\nwithin computer science departments rather than on continuous systems in\nelectrical engineering departments. The separate evolutions continued\nthroughout the author's lifetime, with some crossover in reinforcement learning\nand graphical models, but were shocked into converging by the virality of deep\nlearning, thus making an electrical engineer into an AI researcher. Now that\nthis convergence has happened, opportunity exists to pursue an agenda that\ncombines learning and reasoning bridged by interpretable machine learning\nmodels."
    },
    "1809.10436": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Forssell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Henrik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kindermann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lupp",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sattler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Uli"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Thorstensen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Evgenij"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generating Ontologies from Templates: A Rule-Based Approach for\n  Capturing Regularity",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Technical report, extended version of paper accepted to DL Workshop\n  2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a second-order language that can be used to succinctly specify\nontologies in a consistent and transparent manner. This language is based on\nontology templates (OTTR), a framework for capturing recurring patterns of\naxioms in ontological modelling. The language and our results are independent\nof any specific DL. We define the language and its semantics, including the\ncase of negation-as-failure, investigate reasoning over ontologies specified\nusing our language, and show results about the decidability of useful reasoning\ntasks about the language itself. We also state and discuss some open problems\nthat we believe to be of interest."
    },
    "1801.00102": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luu Anh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siu Cheung"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Compare-Propagate Architecture with Alignment Factorization for\n  Natural Language Inference",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper presents a new deep learning architecture for Natural Language\nInference (NLI). Firstly, we introduce a new compare-propagate architecture\nwhere alignments pairs are compared and then propagated to upper layers for\nenhanced representation learning. Secondly, we adopt novel factorization layers\nfor efficient compression of alignment vectors into scalar valued features,\nwhich are then be used to augment the base word representations. The design of\nour approach is aimed to be conceptually simple, compact and yet powerful. We\nconduct experiments on three popular benchmarks, SNLI, MultiNLI and SciTail,\nachieving state-of-the-art performance on all. A lightweight parameterization\nof our model enjoys a $\\approx 300\\%$ reduction in parameter size compared to\nthe ESIM and DIIN, while maintaining competitive performance. Visual analysis\nshows that our propagated features are highly interpretable, opening new\navenues to explainability in neural NLI models."
    },
    "1808.01664": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-05",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kaidi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sijia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pin-Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Huan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Quanfu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Erdogmus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Deniz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yanzhi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xue"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Structured Adversarial Attack: Towards General Implementation and Better\n  Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "When generating adversarial examples to attack deep neural networks (DNNs),\nLp norm of the added perturbation is usually used to measure the similarity\nbetween original image and adversarial example. However, such adversarial\nattacks perturbing the raw input spaces may fail to capture structural\ninformation hidden in the input. This work develops a more general attack\nmodel, i.e., the structured attack (StrAttack), which explores group sparsity\nin adversarial perturbations by sliding a mask through images aiming for\nextracting key spatial structures. An ADMM (alternating direction method of\nmultipliers)-based framework is proposed that can split the original problem\ninto a sequence of analytically solvable subproblems and can be generalized to\nimplement other attacking methods. Strong group sparsity is achieved in\nadversarial perturbations even with the same level of Lp norm distortion as the\nstate-of-the-art attacks. We demonstrate the effectiveness of StrAttack by\nextensive experimental results onMNIST, CIFAR-10, and ImageNet. We also show\nthat StrAttack provides better interpretability (i.e., better correspondence\nwith discriminative image regions)through adversarial saliency map (Papernot et\nal., 2016b) and class activation map(Zhou et al., 2016)."
    },
    "1803.03067": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hudson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Drew A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Manning",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher D."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Compositional Attention Networks for Machine Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Published as a conference paper at ICLR 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present the MAC network, a novel fully differentiable neural network\narchitecture, designed to facilitate explicit and expressive reasoning. MAC\nmoves away from monolithic black-box neural architectures towards a design that\nencourages both transparency and versatility. The model approaches problems by\ndecomposing them into a series of attention-based reasoning steps, each\nperformed by a novel recurrent Memory, Attention, and Composition (MAC) cell\nthat maintains a separation between control and memory. By stringing the cells\ntogether and imposing structural constraints that regulate their interaction,\nMAC effectively learns to perform iterative reasoning processes that are\ndirectly inferred from the data in an end-to-end approach. We demonstrate the\nmodel's strength, robustness and interpretability on the challenging CLEVR\ndataset for visual reasoning, achieving a new state-of-the-art 98.9% accuracy,\nhalving the error rate of the previous best model. More importantly, we show\nthat the model is computationally-efficient and data-efficient, in particular\nrequiring 5x less data than existing models to achieve strong results."
    },
    "1511.06191": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-11-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Borchmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ganter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Abstract Attribute Exploration with Partial Object Descriptions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Attribute exploration has been investigated in several studies, with\nparticular emphasis on the algorithmic aspects of this knowledge acquisition\nmethod. In its basic version the method itself is rather simple and\ntransparent. But when background knowledge and partially described\ncounter-examples are admitted, it gets more difficult. Here we discuss this\ncase in an abstract, somewhat \"axiomatic\" setting, providing a terminology that\nclarifies the abstract strategy of the method rather than its algorithmic\nimplementation."
    },
    "1611.08070": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jung-Su"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Choi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Han-Lim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multiscale Inverse Reinforcement Learning using Diffusion Wavelets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This work presents a multiscale framework to solve an inverse reinforcement\nlearning (IRL) problem for continuous-time/state stochastic systems. We take\nadvantage of a diffusion wavelet representation of the associated Markov chain\nto abstract the state space. This not only allows for effectively handling the\nlarge (and geometrically complex) decision space but also provides more\ninterpretable representations of the demonstrated state trajectories and also\nof the resulting policy of IRL. In the proposed framework, the problem is\ndivided into the global and local IRL, where the global approximation of the\noptimal value functions are obtained using coarse features and the local\ndetails are quantified using fine local features. An illustrative numerical\nexample on robot path control in a complex environment is presented to verify\nthe proposed method."
    },
    "1710.05426": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Rule Sets for Identifying Subgroups with Enhanced Treatment\n  Effect",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce a novel generative model for interpretable subgroup analysis for\ncausal inference applications, Causal Rule Sets (CRS). A CRS model uses a small\nset of short rules to capture a subgroup where the average treatment effect is\nelevated compared to the entire population. We present a Bayesian framework for\nlearning a causal rule set. The Bayesian framework consists of a prior that\nfavors simpler models and a Bayesian logistic regression that characterizes the\nrelation between outcomes, attributes and subgroup membership. We find maximum\na posteriori models using discrete Monte Carlo steps in the joint solution\nspace of rules sets and parameters. We provide theoretically grounded\nheuristics and bounding strategies to improve search efficiency. Experiments\nshow that the search algorithm can efficiently recover a true underlying\nsubgroup and CRS shows consistently competitive performance compared to other\nstate-of-the-art baseline methods."
    },
    "1610.00054": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-09-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuan-Hong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Silva",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arlei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ambuj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Swami",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ananthram"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Basu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prithwish"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Outlier Detection from Network Data with Subnetwork Interpretation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Detecting a small number of outliers from a set of data observations is\nalways challenging. This problem is more difficult in the setting of multiple\nnetwork samples, where computing the anomalous degree of a network sample is\ngenerally not sufficient. In fact, explaining why the network is exceptional,\nexpressed in the form of subnetwork, is also equally important. In this paper,\nwe develop a novel algorithm to address these two key problems. We treat each\nnetwork sample as a potential outlier and identify subnetworks that mostly\ndiscriminate it from nearby regular samples. The algorithm is developed in the\nframework of network regression combined with the constraints on both network\ntopology and L1-norm shrinkage to perform subnetwork discovery. Our method thus\ngoes beyond subspace/subgraph discovery and we show that it converges to a\nglobal optimum. Evaluation on various real-world network datasets demonstrates\nthat our algorithm not only outperforms baselines in both network and high\ndimensional setting, but also discovers highly relevant and interpretable local\nsubnetworks, further enhancing our understanding of anomalous networks."
    },
    "1711.01134": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-03",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Doshi-Velez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Finale"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kortz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mason"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Budish",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bavitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gershman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "O'Brien",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schieber",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stuart"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Waldo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weinberger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wood",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexandra"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Accountability of AI Under the Law: The Role of Explanation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The ubiquity of systems using artificial intelligence or \"AI\" has brought\nincreasing attention to how those systems should be regulated. The choice of\nhow to regulate AI systems will require care. AI systems have the potential to\nsynthesize large amounts of data, allowing for greater levels of\npersonalization and precision than ever before---applications range from\nclinical decision support to autonomous driving and predictive policing. That\nsaid, there exist legitimate concerns about the intentional and unintentional\nnegative consequences of AI systems. There are many ways to hold AI systems\naccountable. In this work, we focus on one: explanation. Questions about a\nlegal right to explanation from AI systems was recently debated in the EU\nGeneral Data Protection Regulation, and thus thinking carefully about when and\nhow explanation from AI systems might improve accountability is timely. In this\nwork, we review contexts in which explanation is currently required under the\nlaw, and then list the technical considerations that must be considered if we\ndesired AI systems that could provide kinds of explanations that are currently\nrequired of humans."
    },
    "1107.4570": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-07-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2011-10-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Manna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ricca",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Terracina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giorgio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Consistent Query Answering via ASP from Different Perspectives: Theory\n  and Practice",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68P15 (Primary), 68T27 (Secondary)",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.2.4; I.2.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A data integration system provides transparent access to different data\nsources by suitably combining their data, and providing the user with a unified\nview of them, called global schema. However, source data are generally not\nunder the control of the data integration process, thus integrated data may\nviolate global integrity constraints even in presence of locally-consistent\ndata sources. In this scenario, it may be anyway interesting to retrieve as\nmuch consistent information as possible. The process of answering user queries\nunder global constraint violations is called consistent query answering (CQA).\nSeveral notions of CQA have been proposed, e.g., depending on whether\nintegrated information is assumed to be sound, complete, exact or a variant of\nthem. This paper provides a contribution in this setting: it uniforms solutions\ncoming from different perspectives under a common ASP-based core, and provides\nquery-driven optimizations designed for isolating and eliminating\ninefficiencies of the general approach for computing consistent answers.\nMoreover, the paper introduces some new theoretical results enriching existing\nknowledge on decidability and complexity of the considered problems. The\neffectiveness of the approach is evidenced by experimental results.\n  To appear in Theory and Practice of Logic Programming (TPLP)."
    },
    "1801.05394": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei-Han"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ortiz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jorge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ko",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bongjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ruby"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Time Series Segmentation through Automatic Feature Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Internet of things (IoT) applications have become increasingly popular in\nrecent years, with applications ranging from building energy monitoring to\npersonal health tracking and activity recognition. In order to leverage these\ndata, automatic knowledge extraction - whereby we map from observations to\ninterpretable states and transitions - must be done at scale. As such, we have\nseen many recent IoT data sets include annotations with a human expert\nspecifying states, recorded as a set of boundaries and associated labels in a\ndata sequence. These data can be used to build automatic labeling algorithms\nthat produce labels as an expert would. Here, we refer to human-specified\nboundaries as breakpoints. Traditional changepoint detection methods only look\nfor statistically-detectable boundaries that are defined as abrupt variations\nin the generative parameters of a data sequence. However, we observe that\nbreakpoints occur on more subtle boundaries that are non-trivial to detect with\nthese statistical methods. In this work, we propose a new unsupervised\napproach, based on deep learning, that outperforms existing techniques and\nlearns the more subtle, breakpoint boundaries with a high accuracy. Through\nextensive experiments on various real-world data sets - including\nhuman-activity sensing data, speech signals, and electroencephalogram (EEG)\nactivity traces - we demonstrate the effectiveness of our algorithm for\npractical applications. Furthermore, we show that our approach achieves\nsignificantly better performance than previous methods."
    },
    "1810.08744": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamilton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raghunathan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sudarshan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Matiach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ilya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schonhoffer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anand"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barzilay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eli"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Thigpen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Minsoo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rajendran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mahajan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Janhavi Suresh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cochrane",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Courtney"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Eswaran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhiram"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Green",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ari"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "MMLSpark: Unifying Machine Learning Ecosystems at Massive Scales",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.DC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to the NIPS SysML Workshop 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce Microsoft Machine Learning for Apache Spark (MMLSpark), an\necosystem of enhancements that expand the Apache Spark distributed computing\nlibrary to tackle problems in Deep Learning, Micro-Service Orchestration,\nGradient Boosting, Model Interpretability, and other areas of modern\ncomputation. Furthermore, we present a novel system called Spark Serving that\nallows users to run any Apache Spark program as a distributed, sub-millisecond\nlatency web service backed by their existing Spark Cluster. All MMLSpark\ncontributions have the same API to enable simple composition across frameworks\nand usage across batch, streaming, and RESTful web serving scenarios on static,\nelastic, or serverless clusters. We showcase MMLSpark by creating a method for\ndeep object detection capable of learning without human labeled data and\ndemonstrate its effectiveness for Snow Leopard conservation."
    },
    "1606.01855": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aaron"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mingyuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wallach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hanna"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian Poisson Tucker Decomposition for Learning the Structure of\n  International Relations",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG cs.SI stat.AP",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Proceedings of the 33rd International Conference on\n  Machine Learning (ICML 2016)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce Bayesian Poisson Tucker decomposition (BPTD) for modeling\ncountry--country interaction event data. These data consist of interaction\nevents of the form \"country $i$ took action $a$ toward country $j$ at time\n$t$.\" BPTD discovers overlapping country--community memberships, including the\nnumber of latent communities. In addition, it discovers directed\ncommunity--community interaction networks that are specific to \"topics\" of\naction types and temporal \"regimes.\" We show that BPTD yields an efficient MCMC\ninference algorithm and achieves better predictive performance than related\nmodels. We also demonstrate that it discovers interpretable latent structure\nthat agrees with our knowledge of international relations."
    },
    "1603.07810": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-03-24",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veit",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Belongie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Karaletsos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Theofanis"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Conditional Similarity Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "CVPR 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "What makes images similar? To measure the similarity between images, they are\ntypically embedded in a feature-vector space, in which their distance preserve\nthe relative dissimilarity. However, when learning such similarity embeddings\nthe simplifying assumption is commonly made that images are only compared to\none unique measure of similarity. A main reason for this is that contradicting\nnotions of similarities cannot be captured in a single space. To address this\nshortcoming, we propose Conditional Similarity Networks (CSNs) that learn\nembeddings differentiated into semantically distinct subspaces that capture the\ndifferent notions of similarities. CSNs jointly learn a disentangled embedding\nwhere features for different similarities are encoded in separate dimensions as\nwell as masks that select and reweight relevant dimensions to induce a subspace\nthat encodes a specific similarity notion. We show that our approach learns\ninterpretable image representations with visually relevant semantic subspaces.\nFurther, when evaluating on triplet questions from multiple similarity notions\nour model even outperforms the accuracy obtained by training individual\nspecialized networks for each notion separately."
    },
    "1506.03493": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-06-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aaron"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paisley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wallach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hanna"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian Poisson Tensor Factorization for Inferring Multilateral\n  Relations from Sparse Dyadic Event Counts",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG cs.SI stat.AP",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Proceedings of the 21st ACM SIGKDD Conference of\n  Knowledge Discovery and Data Mining (KDD 2015)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a Bayesian tensor factorization model for inferring latent group\nstructures from dynamic pairwise interaction patterns. For decades, political\nscientists have collected and analyzed records of the form \"country $i$ took\naction $a$ toward country $j$ at time $t$\"---known as dyadic events---in order\nto form and test theories of international relations. We represent these event\ndata as a tensor of counts and develop Bayesian Poisson tensor factorization to\ninfer a low-dimensional, interpretable representation of their salient\npatterns. We demonstrate that our model's predictive performance is better than\nthat of standard non-negative tensor factorization methods. We also provide a\ncomparison of our variational updates to their maximum likelihood counterparts.\nIn doing so, we identify a better way to form point estimates of the latent\nfactors than that typically used in Bayesian Poisson matrix factorization.\nFinally, we showcase our model as an exploratory analysis tool for political\nscientists. We show that the inferred latent factor matrices capture\ninterpretable multilateral relations that both conform to and inform our\nknowledge of international affairs."
    },
    "1806.10758": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hooker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sara"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Erhan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dumitru"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kindermans",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pieter-Jan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Been"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evaluating Feature Importance Estimates",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockholm, Sweden",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Estimating the influence of a given feature to a model prediction is\nchallenging. We introduce ROAR, RemOve And Retrain, a benchmark to evaluate the\naccuracy of interpretability methods that estimate input feature importance in\ndeep neural networks. We remove a fraction of input features deemed to be most\nimportant according to each estimator and measure the change to the model\naccuracy upon retraining. The most accurate estimator will identify inputs as\nimportant whose removal causes the most damage to model performance relative to\nall other estimators. This evaluation produces thought-provoking results -- we\nfind that several estimators are less accurate than a random assignment of\nfeature importance. However, averaging a set of squared noisy estimators (a\nvariant of a technique proposed by Smilkov et al. (2017)), leads to significant\ngains in accuracy for each method considered and far outperforms such a random\nguess."
    },
    "1803.08631": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiawei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Limeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gouza",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fisher B."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "SEGEN: Sample-Ensemble Genetic Evolutional Network Model",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "12 pages, 5 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep learning, a rebranding of deep neural network research works, has\nachieved a remarkable success in recent years. With multiple hidden layers,\ndeep learning models aim at computing the hierarchical feature representations\nof the observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning costs and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutionary Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutionary learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"narrower\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning efforts, but has sound theoretic\ninterpretability of the learning process and results. Extensive experiments\nhave been done on several different real-world benchmark datasets, and the\nexperimental results obtained by SEGEN have demonstrated its advantages over\nthe state-of-the-art representation learning models."
    },
    "1810.01729": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Besse",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philippe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Castets-Renard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Celine"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garivier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aurelien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Loubes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jean-Michel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Can everyday AI be ethical. Fairness of Machine Learning Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.OT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "in French. L'IA du quotidien peut-elle \\^etre \\'ethique. Loyaut\\'e\n  des Algorithmes d'apprentissage automatique",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Combining big data and machine learning algorithms, the power of automatic\ndecision tools induces as much hope as fear. Many recently enacted European\nlegislation (GDPR) and French laws attempt to regulate the use of these tools.\nLeaving aside the well-identified problems of data confidentiality and\nimpediments to competition, we focus on the risks of discrimination, the\nproblems of transparency and the quality of algorithmic decisions. The detailed\nperspective of the legal texts, faced with the complexity and opacity of the\nlearning algorithms, reveals the need for important technological disruptions\nfor the detection or reduction of the discrimination risk, and for addressing\nthe right to obtain an explanation of the auto- matic decision. Since trust of\nthe developers and above all of the users (citizens, litigants, customers) is\nessential, algorithms exploiting personal data must be deployed in a strict\nethical framework. In conclusion, to answer this need, we list some ways of\ncontrols to be developed: institutional control, ethical charter, external\naudit attached to the issue of a label."
    },
    "1804.08378": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weber",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schmidt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Florian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Niepert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huici",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Felipe"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First\n  Parallelism",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DC cs.AI cs.CV cs.NE cs.PF",
        "http://arxiv.org/OAI/arXiv/:comments": "Technical Report, 13 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neural network frameworks such as PyTorch and TensorFlow are the workhorses\nof numerous machine learning applications ranging from object recognition to\nmachine translation. While these frameworks are versatile and straightforward\nto use, the training of and inference in deep neural networks is resource\n(energy, compute, and memory) intensive. In contrast to recent works focusing\non algorithmic enhancements, we introduce BrainSlug, a framework that\ntransparently accelerates neural network workloads by changing the default\nlayer-by-layer processing to a depth-first approach, reducing the amount of\ndata required by the computations and thus improving the performance of the\navailable hardware caches. BrainSlug achieves performance improvements of up to\n41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the\nuser as they do not require hardware changes and only need tiny adjustments to\nthe software."
    },
    "1805.06549": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madhyastha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranava"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josiah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Specia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lucia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Defoiling Foiled Image Captions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address the task of detecting foiled image captions, i.e. identifying\nwhether a caption contains a word that has been deliberately replaced by a\nsemantically similar word, thus rendering it inaccurate with respect to the\nimage being described. Solving this problem should in principle require a\nfine-grained understanding of images to detect linguistically valid\nperturbations in captions. In such contexts, encoding sufficiently descriptive\nimage information becomes a key challenge. In this paper, we demonstrate that\nit is possible to solve this task using simple, interpretable yet powerful\nrepresentations based on explicit object information. Our models achieve\nstate-of-the-art performance on a standard dataset, with scores exceeding those\nachieved by humans on the task. We also measure the upper-bound performance of\nour models using gold standard annotations. Our analysis reveals that the\nsimpler model performs well even without image information, suggesting that the\ndataset contains strong linguistic bias."
    },
    "1612.02741": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-06-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lili"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhengdong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Coupling Distributed and Symbolic Execution for Natural Language Queries",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL cs.NE cs.SE",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted by ICML-17; also presented at ICLR-17 Workshop",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Building neural networks to query a knowledge base (a table) with natural\nlanguage is an emerging research topic in deep learning. An executor for table\nquerying typically requires multiple steps of execution because queries may\nhave complicated structures. In previous studies, researchers have developed\neither fully distributed executors or symbolic executors for table querying. A\ndistributed executor can be trained in an end-to-end fashion, but is weak in\nterms of execution efficiency and explicit interpretability. A symbolic\nexecutor is efficient in execution, but is very difficult to train especially\nat initial stages. In this paper, we propose to couple distributed and symbolic\nexecution for natural language queries, where the symbolic executor is\npretrained with the distributed executor's intermediate execution results in a\nstep-by-step fashion. Experiments show that our approach significantly\noutperforms both distributed and symbolic executors, exhibiting high accuracy,\nhigh learning efficiency, high execution efficiency, and high interpretability."
    },
    "1806.00778": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luu Anh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siu Cheung"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multi-Cast Attention Networks for Retrieval-based Question Answering and\n  Response Prediction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to KDD 2018 (Paper titled only \"Multi-Cast Attention\n  Networks\" in KDD version)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Attention is typically used to select informative sub-phrases that are used\nfor prediction. This paper investigates the novel use of attention as a form of\nfeature augmentation, i.e, casted attention. We propose Multi-Cast Attention\nNetworks (MCAN), a new attention mechanism and general model architecture for a\npotpourri of ranking tasks in the conversational modeling and question\nanswering domains. Our approach performs a series of soft attention operations,\neach time casting a scalar feature upon the inner word embeddings. The key idea\nis to provide a real-valued hint (feature) to a subsequent encoder layer and is\ntargeted at improving the representation learning process. There are several\nadvantages to this design, e.g., it allows an arbitrary number of attention\nmechanisms to be casted, allowing for multiple attention types (e.g.,\nco-attention, intra-attention) and attention variants (e.g., alignment-pooling,\nmax-pooling, mean-pooling) to be executed simultaneously. This not only\neliminates the costly need to tune the nature of the co-attention layer, but\nalso provides greater extents of explainability to practitioners. Via extensive\nexperiments on four well-known benchmark datasets, we show that MCAN achieves\nstate-of-the-art performance. On the Ubuntu Dialogue Corpus, MCAN outperforms\nexisting state-of-the-art models by $9\\%$. MCAN also achieves the best\nperforming score to date on the well-studied TrecQA dataset."
    },
    "1705.09207": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lapata",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mirella"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Structured Text Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "change to one-based indexing, published in Transactions of the\n  Association for Computational Linguistics (TACL),\n  https://transacl.org/ojs/index.php/tacl/article/view/1185/280",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we focus on learning structure-aware document representations\nfrom data without recourse to a discourse parser or additional annotations.\nDrawing inspiration from recent efforts to empower neural networks with a\nstructural bias, we propose a model that can encode a document while\nautomatically inducing rich structural dependencies. Specifically, we embed a\ndifferentiable non-projective parsing algorithm into a neural model and use\nattention mechanisms to incorporate the structural biases. Experimental\nevaluation across different tasks and datasets shows that the proposed model\nachieves state-of-the-art results on document modeling tasks while inducing\nintermediate structures which are both interpretable and meaningful."
    },
    "1711.02368": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Asahara",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Masato"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fujimaki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryohei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Distributed Bayesian Piecewise Sparse Linear Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DC cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Short version of this paper will be published in IEEE BigData 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The importance of interpretability of machine learning models has been\nincreasing due to emerging enterprise predictive analytics, threat of data\nprivacy, accountability of artificial intelligence in society, and so on.\nPiecewise linear models have been actively studied to achieve both accuracy and\ninterpretability. They often produce competitive accuracy against\nstate-of-the-art non-linear methods. In addition, their representations (i.e.,\nrule-based segmentation plus sparse linear formula) are often preferred by\ndomain experts. A disadvantage of such models, however, is high computational\ncost for simultaneous determinations of the number of \"pieces\" and cardinality\nof each linear predictor, which has restricted their applicability to\nmiddle-scale data sets. This paper proposes a distributed factorized asymptotic\nBayesian (FAB) inference of learning piece-wise sparse linear models on\ndistributed memory architectures. The distributed FAB inference solves the\nsimultaneous model selection issue without communicating $O(N)$ data where N is\nthe number of training samples and achieves linear scale-out against the number\nof CPU cores. Experimental results demonstrate that the distributed FAB\ninference achieves high prediction accuracy and performance scalability with\nboth synthetic and benchmark data."
    },
    "1705.02518": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mukherjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subhabrata"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Popat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kashyap"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weikum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Exploring Latent Semantic Factors to Find Useful Product Reviews",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.IR cs.SI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Online reviews provided by consumers are a valuable asset for e-Commerce\nplatforms, influencing potential consumers in making purchasing decisions.\nHowever, these reviews are of varying quality, with the useful ones buried deep\nwithin a heap of non-informative reviews. In this work, we attempt to\nautomatically identify review quality in terms of its helpfulness to the end\nconsumers. In contrast to previous works in this domain exploiting a variety of\nsyntactic and community-level features, we delve deep into the semantics of\nreviews as to what makes them useful, providing interpretable explanation for\nthe same. We identify a set of consistency and semantic factors, all from the\ntext, ratings, and timestamps of user-generated reviews, making our approach\ngeneralizable across all communities and domains. We explore review semantics\nin terms of several latent factors like the expertise of its author, his\njudgment about the fine-grained facets of the underlying product, and his\nwriting style. These are cast into a Hidden Markov Model -- Latent Dirichlet\nAllocation (HMM-LDA) based model to jointly infer: (i) reviewer expertise, (ii)\nitem facets, and (iii) review helpfulness. Large-scale experiments on five\nreal-world datasets from Amazon show significant improvement over\nstate-of-the-art baselines in predicting and ranking useful reviews."
    },
    "1807.10511": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agibetov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Asan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Samwald",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthias"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Global and local evaluation of link prediction tasks with neural\n  embeddings",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to 4th Semantic Deep Learning (SemDeep-4) Workshop at the\n  ISWC 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We focus our attention on the link prediction problem for knowledge graphs,\nwhich is treated herein as a binary classification task on neural embeddings of\nthe entities. By comparing, combining and extending different methodologies for\nlink prediction on graph-based data coming from different domains, we formalize\na unified methodology for the quality evaluation benchmark of neural embeddings\nfor knowledge graphs. This benchmark is then used to empirically investigate\nthe potential of training neural embeddings globally for the entire graph, as\nopposed to the usual way of training embeddings locally for a specific\nrelation. This new way of testing the quality of the embeddings evaluates the\nperformance of binary classifiers for scalable link prediction with limited\ndata. Our evaluation pipeline is made open source, and with this we aim to draw\nmore attention of the community towards an important issue of transparency and\nreproducibility of the neural embeddings evaluations."
    },
    "1811.04345": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jindal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ishan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Qin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiwei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuewen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nokleby",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ye",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jieping"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Optimizing Taxi Carpool Policies via Reinforcement Learning and\n  Spatio-Temporal Mining",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at IEEE International Conference on Big Data 2018. arXiv\n  admin note: text overlap with arXiv:1710.04350",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we develop a reinforcement learning (RL) based system to learn\nan effective policy for carpooling that maximizes transportation efficiency so\nthat fewer cars are required to fulfill the given amount of trip demand. For\nthis purpose, first, we develop a deep neural network model, called ST-NN\n(Spatio-Temporal Neural Network), to predict taxi trip time from the raw GPS\ntrip data. Secondly, we develop a carpooling simulation environment for RL\ntraining, with the output of ST-NN and using the NYC taxi trip dataset. In\norder to maximize transportation efficiency and minimize traffic congestion, we\nchoose the effective distance covered by the driver on a carpool trip as the\nreward. Therefore, the more effective distance a driver achieves over a trip\n(i.e. to satisfy more trip demand) the higher the efficiency and the less will\nbe the traffic congestion. We compared the performance of RL learned policy to\na fixed policy (which always accepts carpool) as a baseline and obtained\npromising results that are interpretable and demonstrate the advantage of our\nRL approach. We also compare the performance of ST-NN to that of\nstate-of-the-art travel time estimation methods and observe that ST-NN\nsignificantly improves the prediction performance and is more robust to\noutliers."
    },
    "1607.08186": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yerima",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suleiman Y."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sezer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sakir"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Muttik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Igor"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Android Malware Detection Using Parallel Machine Learning Classifiers",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CR cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8th International Conference on Next Generation Mobile Applications,\n  Services and Technologies, (NGMAST), 10-14 Sept., 2014, Oxford, United\n  Kingdom",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/NGMAST.2014.23",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Mobile malware has continued to grow at an alarming rate despite on-going\nefforts towards mitigating the problem. This has been particularly noticeable\non Android due to its being an open platform that has subsequently overtaken\nother platforms in the share of the mobile smart devices market. Hence,\nincentivizing a new wave of emerging Android malware sophisticated enough to\nevade most common detection methods. This paper proposes and investigates a\nparallel machine learning based classification approach for early detection of\nAndroid malware. Using real malware samples and benign applications, a\ncomposite classification model is developed from parallel combination of\nheterogeneous classifiers. The empirical evaluation of the model under\ndifferent combination schemes demonstrates its efficacy and potential to\nimprove detection accuracy. More importantly, by utilizing several classifiers\nwith diverse characteristics, their strengths can be harnessed not only for\nenhanced Android malware detection but also quicker white box analysis by means\nof the more interpretable constituent classifiers."
    },
    "1710.01691": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kun Ho"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mac Aodha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oisin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perona",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pietro"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Context Embedding Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "CVPR 2018 spotlight",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches."
    },
    "1810.05357": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kuo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chia-Tung"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Davidson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On The Equivalence of Tries and Dendrograms - Efficient Hierarchical\n  Clustering of Traffic Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The widespread use of GPS-enabled devices generates voluminous and continuous\namounts of traffic data but analyzing such data for interpretable and\nactionable insights poses challenges. A hierarchical clustering of the trips\nhas many uses such as discovering shortest paths, common routes and often\ntraversed areas. However, hierarchical clustering typically has time complexity\nof $O(n^2 \\log n)$ where $n$ is the number of instances, and is difficult to\nscale to large data sets associated with GPS data. Furthermore, incremental\nhierarchical clustering is still a developing area. Prefix trees (also called\ntries) can be efficiently constructed and updated in linear time (in $n$). We\nshow how a specially constructed trie can compactly store the trips and further\nshow this trie is equivalent to a dendrogram that would have been built by\nclassic agglomerative hierarchical algorithms using a specific distance metric.\nThis allows creating hierarchical clusterings of GPS trip data and updating\nthis hierarchy in linear time. %we can extract a meaningful kernel and can also\ninterpret the structure as clusterings of differing granularity as one\nprogresses down the tree. We demonstrate the usefulness of our proposed\napproach on a real world data set of half a million taxis' GPS traces, well\nbeyond the capabilities of agglomerative clustering methods. Our work is not\nlimited to trip data and can be used with other data with a string\nrepresentation."
    },
    "1810.12492": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Almukaynizi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammed"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ericsson"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nunes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shakarian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paulo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Simari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerardo I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kapoor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dipsy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Siedlecki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timothy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "DARKMENTION: A Deployed System to Predict Enterprise-Targeted External\n  Cyberattacks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CR cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent incidents of data breaches call for organizations to proactively\nidentify cyber attacks on their systems. Darkweb/Deepweb (D2web) forums and\nmarketplaces provide environments where hackers anonymously discuss existing\nvulnerabilities and commercialize malicious software to exploit those\nvulnerabilities. These platforms offer security practitioners a threat\nintelligence environment that allows to mine for patterns related to\norganization-targeted cyber attacks. In this paper, we describe a system\n(called DARKMENTION) that learns association rules correlating indicators of\nattacks from D2web to real-world cyber incidents. Using the learned rules,\nDARKMENTION generates and submits warnings to a Security Operations Center\n(SOC) prior to attacks. Our goal was to design a system that automatically\ngenerates enterprise-targeted warnings that are timely, actionable, accurate,\nand transparent. We show that DARKMENTION meets our goal. In particular, we\nshow that it outperforms baseline systems that attempt to generate warnings of\ncyber attacks related to two enterprises with an average increase in F1 score\nof about 45% and 57%. Additionally, DARKMENTION was deployed as part of a\nlarger system that is built under a contract with the IARPA Cyber-attack\nAutomated Unconventional Sensor Environment (CAUSE) program. It is actively\nproducing warnings that precede attacks by an average of 3 days."
    },
    "1712.08443": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Laugel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thibault"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lesot",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marie-Jeanne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marsala",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christophe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Renard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xavier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Detyniecki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Inverse Classification for Comparison-based Interpretability in Machine\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "preprint",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the context of post-hoc interpretability, this paper addresses the task of\nexplaining the prediction of a classifier, considering the case where no\ninformation is available, neither on the classifier itself, nor on the\nprocessed data (neither the training nor the test data). It proposes an\ninstance-based approach whose principle consists in determining the minimal\nchanges needed to alter a prediction: given a data point whose classification\nmust be explained, the proposed method consists in identifying a close\nneighbour classified differently, where the closeness definition integrates a\nsparsity constraint. This principle is implemented using observation generation\nin the Growing Spheres algorithm. Experimental results on two datasets\nillustrate the relevance of the proposed approach that can be used to gain\nknowledge about the classifier."
    },
    "1809.03406": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peterson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erik J"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "M\u00fcyesser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Necati Alp"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verstynen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timothy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dunovan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kyle"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Keep it stupid simple",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep reinforcement learning can match and exceed human performance, but if\neven minor changes are introduced to the environment artificial networks often\ncan't adapt. Humans meanwhile are quite adaptable. We hypothesize that this is\npartly because of how humans use heuristics, and partly because humans can\nimagine new and more challenging environments to learn from. We've developed a\nmodel of hierarchical reinforcement learning that combines both these elements\ninto a stumbler-strategist network. We test transfer performance of this\nnetwork using Wythoff's game, a gridworld environment with a known optimal\nstrategy. We show that combining imagined play with a heuristic--labeling each\nposition as \"good\" or \"bad\"'--both accelerates learning and promotes transfer\nto novel games, while also improving model interpretability."
    },
    "cs_0204047": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2002-04-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2002-04-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramakrishnan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Naren"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bailey-Kellogg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Sampling Strategies for Mining in Data-Scarce Domains",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CE cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "D.2.6; G.1.2; G.1.3; G.3; I.2.10; I.5; H.2.8",
        "http://arxiv.org/OAI/arXiv/:abstract": "Data mining has traditionally focused on the task of drawing inferences from\nlarge datasets. However, many scientific and engineering domains, such as fluid\ndynamics and aircraft design, are characterized by scarce data, due to the\nexpense and complexity of associated experiments and simulations. In such\ndata-scarce domains, it is advantageous to focus the data collection effort on\nonly those regions deemed most important to support a particular data mining\nobjective. This paper describes a mechanism that interleaves bottom-up data\nmining, to uncover multi-level structures in spatial data, with top-down\nsampling, to clarify difficult decisions in the mining process. The mechanism\nexploits relevant physical properties, such as continuity, correspondence, and\nlocality, in a unified framework. This leads to effective mining and sampling\ndecisions that are explainable in terms of domain knowledge and data\ncharacteristics. This approach is demonstrated in two diverse applications --\nmining pockets in spatial data, and qualitative determination of Jordan forms\nof matrices."
    },
    "1808.10393": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mehta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Subramanian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adithya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Subramanian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anbumani"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning End-to-end Autonomous Driving using Guided Auxiliary\n  Supervision",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "12 pages, 5 figures, 1 table",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Learning to drive faithfully in highly stochastic urban settings remains an\nopen problem. To that end, we propose a Multi-task Learning from Demonstration\n(MT-LfD) framework which uses supervised auxiliary task prediction to guide the\nmain task of predicting the driving commands. Our framework involves an\nend-to-end trainable network for imitating the expert demonstrator's driving\ncommands. The network intermediately predicts visual affordances and action\nprimitives through direct supervision which provide the aforementioned\nauxiliary supervised guidance. We demonstrate that such joint learning and\nsupervised guidance facilitates hierarchical task decomposition, assisting the\nagent to learn faster, achieve better driving performance and increases\ntransparency of the otherwise black-box end-to-end network. We run our\nexperiments to validate the MT-LfD framework in CARLA, an open-source urban\ndriving simulator. We introduce multiple non-player agents in CARLA and induce\ntemporal noise in them for realistic stochasticity."
    },
    "1610.06972": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lakkaraju",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Himabindu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Cost-Effective Treatment Regimes using Markov Decision\n  Processes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Decision makers, such as doctors and judges, make crucial decisions such as\nrecommending treatments to patients, and granting bails to defendants on a\ndaily basis. Such decisions typically involve weighting the potential benefits\nof taking an action against the costs involved. In this work, we aim to\nautomate this task of learning \\emph{cost-effective, interpretable and\nactionable treatment regimes}. We formulate this as a problem of learning a\ndecision list -- a sequence of if-then-else rules -- which maps characteristics\nof subjects (eg., diagnostic test results of patients) to treatments. We\npropose a novel objective to construct a decision list which maximizes outcomes\nfor the population, and minimizes overall costs. We model the problem of\nlearning such a list as a Markov Decision Process (MDP) and employ a variant of\nthe Upper Confidence Bound for Trees (UCT) strategy which leverages customized\nchecks for pruning the search space effectively. Experimental results on real\nworld observational data capturing judicial bail decisions and treatment\nrecommendations for asthma patients demonstrate the effectiveness of our\napproach."
    },
    "1805.09901": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dash",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanjeeb"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "G\u00fcnl\u00fck",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oktay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dennis"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Boolean Decision Rules via Column Generation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper considers the learning of Boolean rules in either disjunctive\nnormal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive\nnormal form (CNF, AND-of-ORs) as an interpretable model for classification. An\ninteger program is formulated to optimally trade classification accuracy for\nrule simplicity. Column generation (CG) is used to efficiently search over an\nexponential number of candidate clauses (conjunctions or disjunctions) without\nthe need for heuristic rule mining. This approach also bounds the gap between\nthe selected rule set and the best possible rule set on the training data. To\nhandle large datasets, we propose an approximate CG algorithm using\nrandomization. Compared to three recently proposed alternatives, the CG\nalgorithm dominates the accuracy-simplicity trade-off in 7 out of 15 datasets.\nWhen maximized for accuracy, CG is competitive with rule learners designed for\nthis purpose, sometimes finding significantly simpler solutions that are no\nless accurate."
    },
    "1712.08697": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Trott",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Caiming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Socher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Counting for Visual Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "ICLR 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Questions that require counting a variety of objects in images remain a major\nchallenge in visual question answering (VQA). The most common approaches to VQA\ninvolve either classifying answers based on fixed length representations of\nboth the image and question or summing fractional counts estimated from each\nsection of the image. In contrast, we treat counting as a sequential decision\nprocess and force our model to make discrete choices of what to count.\nSpecifically, the model sequentially selects from detected objects and learns\ninteractions between objects that influence subsequent selections. A\ndistinction of our approach is its intuitive and interpretable output, as\ndiscrete counts are automatically grounded in the image. Furthermore, our\nmethod outperforms the state of the art architecture for VQA on multiple\nmetrics that evaluate counting."
    },
    "1708.06039": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fernandez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Delia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Woodward",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alejandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Campos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Giro-i-Nieto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xavier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brendan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shih-Fu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "More cat than cute? Interpretable Prediction of Adjective-Noun Pairs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.MM",
        "http://arxiv.org/OAI/arXiv/:comments": "Oral paper at ACM Multimedia 2017 Workshop on Multimodal\n  Understanding of Social, Affective and Subjective Attributes (MUSA2)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3132515.3132520",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The increasing availability of affect-rich multimedia resources has bolstered\ninterest in understanding sentiment and emotions in and from visual content.\nAdjective-noun pairs (ANP) are a popular mid-level semantic construct for\ncapturing affect via visually detectable concepts such as \"cute dog\" or\n\"beautiful landscape\". Current state-of-the-art methods approach ANP prediction\nby considering each of these compound concepts as individual tokens, ignoring\nthe underlying relationships in ANPs. This work aims at disentangling the\ncontributions of the `adjectives' and `nouns' in the visual prediction of ANPs.\nTwo specialised classifiers, one trained for detecting adjectives and another\nfor nouns, are fused to predict 553 different ANPs. The resulting ANP\nprediction model is more interpretable as it allows us to study contributions\nof the adjective and noun components. Source code and models are available at\nhttps://imatge-upc.github.io/affective-2017-musa2/ ."
    },
    "1802.07810": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poursabzi-Sangdeh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Forough"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goldstein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel G."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hofman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jake M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vaughan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jennifer Wortman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wallach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hanna"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Manipulating and Measuring Model Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Despite a growing body of research focused on creating interpretable machine\nlearning methods, there have been few empirical studies verifying whether\ninterpretable methods achieve their intended effects on end users. We present a\nframework for assessing the effects of model interpretability on users via\npre-registered experiments in which participants are shown functionally\nidentical models that vary in factors thought to influence interpretability.\nUsing this framework, we ran a sequence of large-scale randomized experiments,\nvarying two putative drivers of interpretability: the number of features and\nthe model transparency (clear or black-box). We measured how these factors\nimpact trust in model predictions, the ability to simulate a model, and the\nability to detect a model's mistakes. We found that participants who were shown\na clear model with a small number of features were better able to simulate the\nmodel's predictions. However, we found no difference in multiple measures of\ntrust and found that clear models did not improve the ability to correct\nmistakes. These findings suggest that interpretability research could benefit\nfrom more emphasis on empirically verifying that interpretable models achieve\nall their intended effects."
    },
    "1710.05257": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multi-Value Rule Sets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DS",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present the Multi-vAlue Rule Set (MARS) model for interpretable\nclassification with feature efficient presentations. MARS introduces a more\ngeneralized form of association rules that allows multiple values in a\ncondition. Rules of this form are more concise than traditional single-valued\nrules in capturing and describing patterns in data. MARS mitigates the problem\nof dealing with continuous features and high-cardinality categorical features\nfaced by rule-based models. Our formulation also pursues a higher efficiency of\nfeature utilization, which reduces the cognitive load to understand the\ndecision process. We propose an efficient inference method for learning a\nmaximum a posteriori model, incorporating theoretically grounded bounds to\niteratively reduce the search space to improve search efficiency. Experiments\nwith synthetic and real-world data demonstrate that MARS models have\nsignificantly smaller complexity and fewer features, providing better\ninterpretability while being competitive in predictive accuracy. We conducted a\nusability study with human subjects and results show that MARS is the easiest\nto use compared with other competing rule-based models, in terms of the correct\nrate and response time. Overall, MARS introduces a new approach to rule-based\nmodels that balance accuracy and interpretability with feature-efficient\nrepresentations."
    },
    "1703.03055": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Liang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaohui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiashi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shuicheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Structure-Evolving LSTM",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in CVPR 2017 as a spotlight paper",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper develops a general framework for learning interpretable data\nrepresentation via Long Short-Term Memory (LSTM) recurrent neural networks over\nhierarchal graph structures. Instead of learning LSTM models over the pre-fixed\nstructures, we propose to further learn the intermediate interpretable\nmulti-level graph structures in a progressive and stochastic way from data\nduring the LSTM network optimization. We thus call this model the\nstructure-evolving LSTM. In particular, starting with an initial element-level\ngraph representation where each node is a small data element, the\nstructure-evolving LSTM gradually evolves the multi-level graph representations\nby stochastically merging the graph nodes with high compatibilities along the\nstacked LSTM layers. In each LSTM layer, we estimate the compatibility of two\nconnected nodes from their corresponding LSTM gate outputs, which is used to\ngenerate a merging probability. The candidate graph structures are accordingly\ngenerated where the nodes are grouped into cliques with their merging\nprobabilities. We then produce the new graph structure with a\nMetropolis-Hasting algorithm, which alleviates the risk of getting stuck in\nlocal optimums by stochastic sampling with an acceptance probability. Once a\ngraph structure is accepted, a higher-level graph is then constructed by taking\nthe partitioned cliques as its nodes. During the evolving process,\nrepresentation becomes more abstracted in higher-levels where redundant\ninformation is filtered out, allowing more efficient propagation of long-range\ndata dependencies. We evaluate the effectiveness of structure-evolving LSTM in\nthe application of semantic object parsing and demonstrate its advantage over\nstate-of-the-art LSTM models on standard benchmarks."
    },
    "1710.00794": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Doran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schulz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sarah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Besold",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tarek R."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "What Does Explainable AI Really Mean? A New Conceptualization of\n  Perspectives",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We characterize three notions of explainable AI that cut across research\nfields: opaque systems that offer no insight into its algo- rithmic mechanisms;\ninterpretable systems where users can mathemat- ically analyze its algorithmic\nmechanisms; and comprehensible systems that emit symbols enabling user-driven\nexplanations of how a conclusion is reached. The paper is motivated by a corpus\nanalysis of NIPS, ACL, COGSCI, and ICCV/ECCV paper titles showing differences\nin how work on explainable AI is positioned in various fields. We close by\nintroducing a fourth notion: truly explainable systems, where automated\nreasoning is central to output crafted explanations without requiring human\npost processing as final step of the generative process."
    },
    "1809.04506": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fran\u00e7ois-Lavet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vincent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Precup",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Doina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pineau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joelle"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Combined Reinforcement Learning via Abstract Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the quest for efficient and robust reinforcement learning methods, both\nmodel-free and model-based approaches offer advantages. In this paper we\npropose a new way of explicitly bridging both approaches via a shared\nlow-dimensional learned encoding of the environment, meant to capture\nsummarizing abstractions. We show that the modularity brought by this approach\nleads to good generalization while being computationally efficient, with\nplanning happening in a smaller latent state space. In addition, this approach\nrecovers a sufficient low-dimensional representation of the environment, which\nopens up new strategies for interpretable AI, exploration and transfer\nlearning."
    },
    "1807.03215": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-04",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fenglei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ge"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fuzzy Logic Interpretation of Artificial Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages and 9 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Over past several years, deep learning has achieved huge successes in various\napplications. However, such a data-driven approach is often criticized for lack\nof interpretability. Recently, we proposed artificial quadratic neural networks\nconsisting of second-order neurons in potentially many layers. In each\nsecond-order neuron, a quadratic function is used in the place of the inner\nproduct in a traditional neuron, and then undergoes a nonlinear activation.\nWith a single second-order neuron, any fuzzy logic operation, such as XOR, can\nbe implemented. In this sense, any deep network constructed with quadratic\nneurons can be interpreted as a deep fuzzy logic system. Since traditional\nneural networks and second-order counterparts can represent each other and\nfuzzy logic operations are naturally implemented in second-order neural\nnetworks, it is plausible to explain how a deep neural network works with a\nsecond-order network as the system model. In this paper, we generalize and\ncategorize fuzzy logic operations implementable with individual second-order\nneurons, and then perform statistical/information theoretic analyses of\nexemplary quadratic neural networks."
    },
    "1710.04806": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oscar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chaofan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Learning for Case-Based Reasoning through Prototypes: A Neural\n  Network that Explains Its Predictions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "The first two authors contributed equally, 8 pages, accepted in AAAI\n  2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks are widely used for classification. These deep models\noften suffer from a lack of interpretability -- they are particularly difficult\nto understand because of their non-linear nature. As a result, neural networks\nare often treated as \"black box\" models, and in the past, have been trained\npurely to optimize the accuracy of predictions. In this work, we create a novel\nnetwork architecture for deep learning that naturally explains its own\nreasoning for each prediction. This architecture contains an autoencoder and a\nspecial prototype layer, where each unit of that layer stores a weight vector\nthat resembles an encoded training input. The encoder of the autoencoder allows\nus to do comparisons within the latent space, while the decoder allows us to\nvisualize the learned prototypes. The training objective has four terms: an\naccuracy term, a term that encourages every prototype to be similar to at least\none encoded input, a term that encourages every encoded input to be close to at\nleast one prototype, and a term that encourages faithful reconstruction by the\nautoencoder. The distances computed in the prototype layer are used as part of\nthe classification process. Since the prototypes are learned during training,\nthe learned network naturally comes with explanations for each prediction, and\nthe explanations are loyal to what the network actually computes."
    },
    "1711.00694": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Milli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Smitha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abbeel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pieter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mordatch",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Igor"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable and Pedagogical Examples",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Teachers intentionally pick the most informative examples to show their\nstudents. However, if the teacher and student are neural networks, the examples\nthat the teacher network learns to give, although effective at teaching the\nstudent, are typically uninterpretable. We show that training the student and\nteacher iteratively, rather than jointly, can produce interpretable teaching\nstrategies. We evaluate interpretability by (1) measuring the similarity of the\nteacher's emergent strategies to intuitive strategies in each domain and (2)\nconducting human experiments to evaluate how effective the teacher's strategies\nare at teaching humans. We show that the teacher network learns to select or\ngenerate interpretable, pedagogical examples to teach rule-based,\nprobabilistic, boolean, and hierarchical concepts."
    },
    "1202.3711": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Claassen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heskes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Logical Characterization of Constraint-Based Causal Discovery",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2011-PG-135-144",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a novel approach to constraint-based causal discovery, that takes\nthe form of straightforward logical inference, applied to a list of simple,\nlogical statements about causal relations that are derived directly from\nobserved (in)dependencies. It is both sound and complete, in the sense that all\ninvariant features of the corresponding partial ancestral graph (PAG) are\nidentified, even in the presence of latent variables and selection bias. The\napproach shows that every identifiable causal relation corresponds to one of\njust two fundamental forms. More importantly, as the basic building blocks of\nthe method do not rely on the detailed (graphical) structure of the\ncorresponding PAG, it opens up a range of new opportunities, including more\nrobust inference, detailed accountability, and application to large models."
    },
    "q-bio_0511046": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2005-11-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Stockwell",
                "http://arxiv.org/OAI/arXiv/:forenames": "David R. B."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving ecological niche models by data mining large environmental\n  datasets for surrogate models",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.QM cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages, 4 figures, to appear in Ecological Modelling",
        "http://arxiv.org/OAI/arXiv/:abstract": "WhyWhere is a new ecological niche modeling (ENM) algorithm for mapping and\nexplaining the distribution of species. The algorithm uses image processing\nmethods to efficiently sift through large amounts of data to find the few\nvariables that best predict species occurrence. The purpose of this paper is to\ndescribe and justify the main parameterizations and to show preliminary success\nat rapidly providing accurate, scalable, and simple ENMs. Preliminary results\nfor 6 species of plants and animals in different regions indicate a significant\n(p<0.01) 14% increase in accuracy over the GARP algorithm using models with\nfew, typically two, variables. The increase is attributed to access to\nadditional data, particularly monthly vs. annual climate averages. WhyWhere is\nalso 6 times faster than GARP on large data sets. A data mining based approach\nwith transparent access to remote data archives is a new paradigm for ENM,\nparticularly suited to finding correlates in large databases of fine resolution\nsurfaces. Software for WhyWhere is freely available, both as a service and in a\ndesktop downloadable form from the web site http://biodi.sdsc.edu/ww_home.html."
    },
    "1602.08610": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-02-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-04-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hongyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Seltzer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Margo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Scalable Bayesian Rule Lists",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "31 pages, 19 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present an algorithm for building probabilistic rule lists that is two\norders of magnitude faster than previous work. Rule list algorithms are\ncompetitors for decision tree algorithms. They are associative classifiers, in\nthat they are built from pre-mined association rules. They have a logical\nstructure that is a sequence of IF-THEN rules, identical to a decision list or\none-sided decision tree. Instead of using greedy splitting and pruning like\ndecision tree algorithms, we fully optimize over rule lists, striking a\npractical balance between accuracy, interpretability, and computational speed.\nThe algorithm presented here uses a mixture of theoretical bounds (tight enough\nto have practical implications as a screening or bounding procedure),\ncomputational reuse, and highly tuned language libraries to achieve\ncomputational efficiency. Currently, for many practical problems, this method\nachieves better accuracy and sparsity than decision trees; further, in many\ncases, the computational time is practical and often less than that of decision\ntrees. The result is a probabilistic classifier (which estimates P(y = 1|x) for\neach x) that optimizes the posterior of a Bayesian hierarchical model over rule\nlists."
    },
    "1707.07341": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hughes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weiner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hope",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gabriel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "McCoy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas H.",
                    "http://arxiv.org/OAI/arXiv/:suffix": "Jr."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perlis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roy H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sudderth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erik B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Doshi-Velez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Finale"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Prediction-Constrained Training for Semi-Supervised Mixture and Topic\n  Models",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Supervisory signals have the potential to make low-dimensional data\nrepresentations, like those learned by mixture and topic models, more\ninterpretable and useful. We propose a framework for training latent variable\nmodels that explicitly balances two goals: recovery of faithful generative\nexplanations of high-dimensional data, and accurate prediction of associated\nsemantic labels. Existing approaches fail to achieve these goals due to an\nincomplete treatment of a fundamental asymmetry: the intended application is\nalways predicting labels from data, not data from labels. Our\nprediction-constrained objective for training generative models coherently\nintegrates loss-based supervisory signals while enabling effective\nsemi-supervised learning from partially labeled data. We derive learning\nalgorithms for semi-supervised mixture and topic models using stochastic\ngradient descent with automatic differentiation. We demonstrate improved\nprediction quality compared to several previous supervised topic models,\nachieving predictions competitive with high-dimensional logistic regression on\ntext sentiment analysis and electronic health records tasks while\nsimultaneously learning interpretable topics."
    },
    "1711.03846": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Israelsen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brett W"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ahmed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nisar R"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "\"Dave...I can assure you...that it's going to be all right...\" -- A\n  definition, case for, and survey of algorithmic assurances in human-autonomy\n  trust relationships",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.HC cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "page count reduction. arXiv admin note: substantial text overlap with\n  arXiv:1708.00495",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As technology becomes more advanced, those who design, use and are otherwise\naffected by it want to know that it will perform correctly, and understand why\nit does what it does, and how to use it appropriately. In essence they want to\nbe able to trust the systems that are being designed. In this survey we present\nassurances that are the method by which users can understand how to trust\nautonomous systems. Trust between humans and autonomy is reviewed, and the\nimplications for the design of assurances are highlighted. A survey of existing\nresearch related to assurances is presented. Much of the surveyed research\noriginates from fields such as interpretable, comprehensible, transparent, and\nexplainable machine learning, as well as human-computer interaction,\nhuman-robot interaction, and e-commerce. Several key ideas are extracted from\nthis work in order to refine the definition of assurances. The design of\nassurances is found to be highly dependent not only on the capabilities of the\nautonomous system, but on the characteristics of the human user, and the\nappropriate trust-related behaviors. Several directions for future research are\nidentified and discussed."
    },
    "1810.04793": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jinghe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kowsari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kamran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harrison",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lobo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jennifer M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barnes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Laura E."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Patient2Vec: A Personalized Interpretable Deep Representation of the\n  Longitudinal Electronic Health Record",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.QM cs.AI cs.IR cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted by IEEE Access",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ACCESS.2018.2875677",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The wide implementation of electronic health record (EHR) systems facilitates\nthe collection of large-scale health data from real clinical settings. Despite\nthe significant increase in adoption of EHR systems, this data remains largely\nunexplored, but presents a rich data source for knowledge discovery from\npatient health histories in tasks such as understanding disease correlations\nand predicting health outcomes. However, the heterogeneity, sparsity, noise,\nand bias in this data present many complex challenges. This complexity makes it\ndifficult to translate potentially relevant information into machine learning\nalgorithms. In this paper, we propose a computational framework, Patient2Vec,\nto learn an interpretable deep representation of longitudinal EHR data which is\npersonalized for each patient. To evaluate this approach, we apply it to the\nprediction of future hospitalizations using real EHR data and compare its\npredictive performance with baseline methods. Patient2Vec produces a vector\nspace with meaningful structure and it achieves an AUC around 0.799\noutperforming baseline methods. In the end, the learned feature importance can\nbe visualized and interpreted at both the individual and population levels to\nbring clinical insights."
    },
    "1806.03568": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hongning"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yiling"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yue"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Recommendation via Multi-Task Learning in Opinionated Text\n  Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, SIGIR 2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3209978.3210010",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Explaining automatically generated recommendations allows users to make more\ninformed and accurate decisions about which results to utilize, and therefore\nimproves their satisfaction. In this work, we develop a multi-task learning\nsolution for explainable recommendation. Two companion learning tasks of user\npreference modeling for recommendation} and \\textit{opinionated content\nmodeling for explanation are integrated via a joint tensor factorization. As a\nresult, the algorithm predicts not only a user's preference over a list of\nitems, i.e., recommendation, but also how the user would appreciate a\nparticular item at the feature level, i.e., opinionated textual explanation.\nExtensive experiments on two large collections of Amazon and Yelp reviews\nconfirmed the effectiveness of our solution in both recommendation and\nexplanation tasks, compared with several existing recommendation algorithms.\nAnd our extensive user study clearly demonstrates the practical value of the\nexplainable recommendations generated by our algorithm."
    },
    "1807.04178": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vigan\u00f2",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Magazzeni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniele"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Security",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CR cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "1 figure, IJCAI/ECAI 2018 Workshop on Explainable Artificial\n  Intelligence (XAI)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The Defense Advanced Research Projects Agency (DARPA) recently launched the\nExplainable Artificial Intelligence (XAI) program that aims to create a suite\nof new AI techniques that enable end users to understand, appropriately trust,\nand effectively manage the emerging generation of AI systems.\n  In this paper, inspired by DARPA's XAI program, we propose a new paradigm in\nsecurity research: Explainable Security (XSec). We discuss the ``Six Ws'' of\nXSec (Who? What? Where? When? Why? and How?) and argue that XSec has unique and\ncomplex characteristics: XSec involves several different stakeholders (i.e.,\nthe system's developers, analysts, users and attackers) and is multi-faceted by\nnature (as it requires reasoning about system model, threat model and\nproperties of security, privacy and trust as well as about concrete attacks,\nvulnerabilities and countermeasures). We define a roadmap for XSec that\nidentifies several possible research directions."
    },
    "1512.02406": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-12-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-12-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi-Chun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wheeler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim Allan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kochenderfer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mykel John"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Discrete Bayesian Networks from Continuous Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "This work has been submitted to Machine Learning (Springer journal)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Real data often contains a mixture of discrete and continuous variables, but\nmany Bayesian network structure learning and inference algorithms assume all\nrandom variables are discrete. Continuous variables are often discretized, but\nthe choice of discretization policy has significant impact on the accuracy,\nspeed, and interpretability of the resulting models. This paper introduces a\nprincipled Bayesian discretization method for continuous variables in Bayesian\nnetworks with quadratic complexity instead of the cubic complexity of other\nstandard techniques. Empirical demonstrations show that the proposed method is\nsuperior to the state of the art. In addition, this paper shows how to\nincorporate existing methods into the structure learning process to discretize\nall continuous variables and simultaneously learn Bayesian network structures."
    },
    "1807.06978": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ouyang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sixun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lawlor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aonghus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Costa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Felipe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dolog",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving Explainable Recommendations with Synthetic Reviews",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "Recsys DLRS 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "An important task for a recommender system to provide interpretable\nexplanations for the user. This is important for the credibility of the system.\nCurrent interpretable recommender systems tend to focus on certain features\nknown to be important to the user and offer their explanations in a structured\nform. It is well known that user generated reviews and feedback from reviewers\nhave strong leverage over the users' decisions. On the other hand, recent text\ngeneration works have been shown to generate text of similar quality to human\nwritten text, and we aim to show that generated text can be successfully used\nto explain recommendations.\n  In this paper, we propose a framework consisting of popular review-oriented\ngeneration models aiming to create personalised explanations for\nrecommendations. The interpretations are generated at both character and word\nlevels. We build a dataset containing reviewers' feedback from the Amazon books\nreview dataset. Our cross-domain experiments are designed to bridge from\nnatural language processing to the recommender system domain. Besides language\nmodel evaluation methods, we employ DeepCoNN, a novel review-oriented\nrecommender system using a deep neural network, to evaluate the recommendation\nperformance of generated reviews by root mean square error (RMSE). We\ndemonstrate that the synthetic personalised reviews have better recommendation\nperformance than human written reviews. To our knowledge, this presents the\nfirst machine-generated natural language explanations for rating prediction."
    },
    "1712.02034": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-05",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Garrett B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hodas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nathan O."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Siegel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vishnu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhinav"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for\n  Predicting Chemical Properties",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to SIGKDD 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Chemical databases store information in text representations, and the SMILES\nformat is a universal standard used in many cheminformatics software. Encoded\nin each SMILES string is structural information that can be used to predict\ncomplex chemical properties. In this work, we develop SMILES2vec, a deep RNN\nthat automatically learns features from SMILES to predict chemical properties,\nwithout the need for additional explicit feature engineering. Using Bayesian\noptimization methods to tune the network architecture, we show that an\noptimized SMILES2vec model can serve as a general-purpose neural network for\npredicting distinct chemical properties including toxicity, activity,\nsolubility and solvation energy, while also outperforming contemporary MLP\nneural networks that uses engineered features. Furthermore, we demonstrate\nproof-of-concept of interpretability by developing an explanation mask that\nlocalizes on the most important characters used in making a prediction. When\ntested on the solubility dataset, it identified specific parts of a chemical\nthat is consistent with established first-principles knowledge with an accuracy\nof 88%. Our work demonstrates that neural networks can learn technically\naccurate chemical concept and provide state-of-the-art accuracy, making\ninterpretable deep neural networks a useful tool of relevance to the chemical\nindustry."
    },
    "1712.00377": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agrawal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aishwarya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kembhavi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniruddha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 10 figures. To appear in IEEE Conference on Computer Vision\n  and Pattern Recognition (CVPR), 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models."
    },
    "0808.2984": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2008-08-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Destercke",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S\u00e9bastien",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "IRSN, IRIT"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guillaume",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serge",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "ITAP"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Charnomordic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brigitte",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "ASB"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Building an interpretable fuzzy rule base from data using Orthogonal\n  Least Squares Application to a depollution problem",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "pre-print of final version published in Fuzzy Sets and Systems",
        "http://arxiv.org/OAI/arXiv/:proxy": "ccsd irsn-00311750",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Fuzzy Sets and Systems 158, 18 (2007) 2078-2094",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.fss.2007.04.026",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In many fields where human understanding plays a crucial role, such as\nbioprocesses, the capacity of extracting knowledge from data is of critical\nimportance. Within this framework, fuzzy learning methods, if properly used,\ncan greatly help human experts. Amongst these methods, the aim of orthogonal\ntransformations, which have been proven to be mathematically robust, is to\nbuild rules from a set of training data and to select the most important ones\nby linear regression or rank revealing techniques. The OLS algorithm is a good\nrepresentative of those methods. However, it was originally designed so that it\nonly cared about numerical performance. Thus, we propose some modifications of\nthe original method to take interpretability into account. After recalling the\noriginal algorithm, this paper presents the changes made to the original\nmethod, then discusses some results obtained from benchmark problems. Finally,\nthe algorithm is applied to a real-world fault detection depollution problem."
    },
    "1804.10437": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gebser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Obermeier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philipp"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ratsch-Heitmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Runge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mario"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schaub",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Torsten"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Routing Driverless Transport Vehicles in Car Assembly with Answer Set\n  Programming",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018; 15 pages,\n  LaTeX, 3 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automated storage and retrieval systems are principal components of modern\nproduction and warehouse facilities. In particular, automated guided vehicles\nnowadays substitute human-operated pallet trucks in transporting production\nmaterials between storage locations and assembly stations. While low-level\ncontrol systems take care of navigating such driverless vehicles along\nprogrammed routes and avoid collisions even under unforeseen circumstances, in\nthe common case of multiple vehicles sharing the same operation area, the\nproblem remains how to set up routes such that a collection of transport tasks\nis accomplished most effectively. We address this prevalent problem in the\ncontext of car assembly at Mercedes-Benz Ludwigsfelde GmbH, a large-scale\nproducer of commercial vehicles, where routes for automated guided vehicles\nused in the production process have traditionally been hand-coded by human\nengineers. Such ad-hoc methods may suffice as long as a running production\nprocess remains in place, while any change in the factory layout or production\ntargets necessitates tedious manual reconfiguration, not to mention the missing\nportability between different production plants. Unlike this, we propose a\ndeclarative approach based on Answer Set Programming to optimize the routes\ntaken by automated guided vehicles for accomplishing transport tasks. The\nadvantages include a transparent and executable problem formalization, provable\noptimality of routes relative to objective criteria, as well as elaboration\ntolerance towards particular factory layouts and production targets. Moreover,\nwe demonstrate that our approach is efficient enough to deal with the transport\ntasks evolving in realistic production processes at the car factory of\nMercedes-Benz Ludwigsfelde GmbH."
    },
    "cs_0206041": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2002-06-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2003-02-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Laaksolahti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jarmo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Magnus"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Anticipatory Guidance of Plot",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "19 pages, 5 figures",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.11; I.6.3; I.6.5",
        "http://arxiv.org/OAI/arXiv/:abstract": "An anticipatory system for guiding plot development in interactive narratives\nis described. The executable model is a finite automaton that provides the\nimplemented system with a look-ahead. The identification of undesirable future\nstates in the model is used to guide the player, in a transparent manner. In\nthis way, too radical twists of the plot can be avoided. Since the player\nparticipates in the development of the plot, such guidance can have many forms,\ndepending on the environment of the player, on the behavior of the other\nplayers, and on the means of player interaction. We present a design method for\ninteractive narratives which produces designs suitable for the implementation\nof anticipatory mechanisms. Use of the method is illustrated by application to\nour interactive computer game Kaktus."
    },
    "1811.07600": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agrawal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Parag"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Suri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anshuman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Menon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tulasi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Trustworthy, Responsible and Interpretable System to Handle Chit-Chat\n  in Conversational Bots",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, 5 figures, The Second AAAI Workshop on Reasoning and\n  Learning for Human-Machine Dialogues (DEEP-DIAL 2019)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Most often, chat-bots are built to solve the purpose of a search engine or a\nhuman assistant: Their primary goal is to provide information to the user or\nhelp them complete a task. However, these chat-bots are incapable of responding\nto unscripted queries like \"Hi, what's up\", \"What's your favourite food\". Human\nevaluation judgments show that 4 humans come to a consensus on the intent of a\ngiven query which is from chat domain only 77% of the time, thus making it\nevident how non-trivial this task is. In our work, we show why it is difficult\nto break the chitchat space into clearly defined intents. We propose a system\nto handle this task in chat-bots, keeping in mind scalability,\ninterpretability, appropriateness, trustworthiness, relevance and coverage. Our\nwork introduces a pipeline for query understanding in chitchat using\nhierarchical intents as well as a way to use seq-seq auto-generation models in\nprofessional bots. We explore an interpretable model for chat domain detection\nand also show how various components such as adult/offensive classification,\ngrammars/regex patterns, curated personality based responses, generic guided\nevasive responses and response generation models can be combined in a scalable\nway to solve this problem."
    },
    "1809.01816": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kottur",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Satwik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moura",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jos\u00e9 M. F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rohrbach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcus"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Visual Coreference Resolution in Visual Dialog using Neural Module\n  Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "ECCV 2018 + results on VisDial v1.0 dataset",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Visual dialog entails answering a series of questions grounded in an image,\nusing dialog history as context. In addition to the challenges found in visual\nquestion answering (VQA), which can be seen as one-round dialog, visual dialog\nencompasses several more. We focus on one such problem called visual\ncoreference resolution that involves determining which words, typically noun\nphrases and pronouns, co-refer to the same entity/object instance in an image.\nThis is crucial, especially for pronouns (e.g., `it'), as the dialog agent must\nfirst link it to a previous coreference (e.g., `boat'), and only then can rely\non the visual grounding of the coreference `boat' to reason about the pronoun\n`it'. Prior work (in visual dialog) models visual coreference resolution either\n(a) implicitly via a memory network over history, or (b) at a coarse level for\nthe entire question; and not explicitly at a phrase level of granularity. In\nthis work, we propose a neural module network architecture for visual dialog by\nintroducing two novel modules - Refer and Exclude - that perform explicit,\ngrounded, coreference resolution at a finer word level. We demonstrate the\neffectiveness of our model on MNIST Dialog, a visually simple yet\ncoreference-wise complex dataset, by achieving near perfect accuracy, and on\nVisDial, a large and challenging visual dialog dataset on real images, where\nour model outperforms other approaches, and is more interpretable, grounded,\nand consistent qualitatively."
    },
    "1507.08717": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-07-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Benzm\u00fcller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Freie Universit\u00e4t Berlin, Germany"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Claus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maximilian",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Freie Universit\u00e4t Berlin, Germany"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sultana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nik",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Cambridge University, UK"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Systematic Verification of the Modal Logic Cube in Isabelle/HOL",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LO cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings PxTP 2015, arXiv:1507.08375",
        "http://arxiv.org/OAI/arXiv/:proxy": "EPTCS",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.3; I.2.4; F.4.1",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "EPTCS 186, 2015, pp. 27-41",
        "http://arxiv.org/OAI/arXiv/:doi": "10.4204/EPTCS.186.5",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present an automated verification of the well-known modal logic cube in\nIsabelle/HOL, in which we prove the inclusion relations between the cube's\nlogics using automated reasoning tools. Prior work addresses this problem but\nwithout restriction to the modal logic cube, and using encodings in first-order\nlogic in combination with first-order automated theorem provers. In contrast,\nour solution is more elegant, transparent and effective. It employs an\nembedding of quantified modal logic in classical higher-order logic. Automated\nreasoning tools, such as Sledgehammer with LEO-II, Satallax and CVC4, Metis and\nNitpick, are employed to achieve full automation. Though successful, the\nexperiments also motivate some technical improvements in the Isabelle/HOL tool."
    },
    "1804.01508": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-04",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Granmo",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ole-Christoffer"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal\n  Pattern Recognition with Propositional Logic",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages, 12 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Although simple individually, artificial neurons provide state-of-the-art\nperformance when interconnected in deep networks. Unknown to many, there exists\nan arguably even simpler and more versatile learning mechanism, namely, the\nTsetlin Automaton. Merely by means of a single integer as memory, it learns the\noptimal action in stochastic environments. In this paper, we introduce the\nTsetlin Machine, which solves complex pattern recognition problems with\neasy-to-interpret propositional formulas, composed by a collective of Tsetlin\nAutomata. To eliminate the longstanding problem of vanishing signal-to-noise\nratio, the Tsetlin Machine orchestrates the automata using a novel game. Our\ntheoretical analysis establishes that the Nash equilibria of the game are\naligned with the propositional formulas that provide optimal pattern\nrecognition accuracy. This translates to learning without local optima, only\nglobal ones. We argue that the Tsetlin Machine finds the propositional formula\nthat provides optimal accuracy, with probability arbitrarily close to unity. In\nfour distinct benchmarks, the Tsetlin Machine outperforms both Neural Networks,\nSVMs, Random Forests, the Naive Bayes Classifier and Logistic Regression. It\nfurther turns out that the accuracy advantage of the Tsetlin Machine increases\nwith lack of data. The Tsetlin Machine has a significant computational\nperformance advantage since both inputs, patterns, and outputs are expressed as\nbits, while recognition of patterns relies on bit manipulation. The combination\nof accuracy, interpretability, and computational simplicity makes the Tsetlin\nMachine a promising tool for a wide range of domains, including safety-critical\nmedicine. Being the first of its kind, we believe the Tsetlin Machine will\nkick-start completely new paths of research, with a potentially significant\nimpact on the AI field and the applications of AI."
    },
    "1702.04595": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zintgraf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luisa M"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cohen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Taco S"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Adel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tameem"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Welling",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Max"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Visualizing Deep Neural Network Decisions: Prediction Difference\n  Analysis",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "ICLR2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This article presents the prediction difference analysis method for\nvisualizing the response of a deep neural network to a specific input. When\nclassifying images, the method highlights areas in a given input image that\nprovide evidence for or against a certain class. It overcomes several\nshortcoming of previous methods and provides great additional insight into the\ndecision making process of classifiers. Making neural network decisions\ninterpretable through visualization is important both to improve models and to\naccelerate the adoption of black-box classifiers in application areas such as\nmedicine. We illustrate the method in experiments on natural images (ImageNet\ndata), as well as medical images (MRI brain scans)."
    },
    "1802.09911": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Frank Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cambria",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Malandri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lorenzo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vercellis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Discovering Bayesian Market Views for Intelligent Asset Allocation",
        "http://arxiv.org/OAI/arXiv/:categories": "q-fin.CP cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Along with the advance of opinion mining techniques, public mood has been\nfound to be a key element for stock market prediction. However, in what manner\nthe market participants are affected by public mood has been rarely discussed.\nAs a result, there has been little progress in leveraging public mood for the\nasset allocation problem, as the application is preferred in a trusted and\ninterpretable way. In order to address the issue of incorporating public mood\nanalyzed from social media, we propose to formalize it into market views that\ncan be integrated into the modern portfolio theory. In this framework, the\noptimal market views will maximize returns in each period with a Bayesian asset\nallocation model. We train two neural models to generate the market views, and\nbenchmark the performance of our model using market views on other popular\nasset allocation strategies. Our experimental results suggest that the\nformalization of market views significantly increases the profitability (5% to\n10%) of the simulated portfolio at a given risk level."
    },
    "1509.08535": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-09-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-02-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ravanbakhsh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siamak"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poczos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Barnabas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Greiner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Russell"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Boolean Matrix Factorization and Noisy Completion via Message Passing",
        "http://arxiv.org/OAI/arXiv/:categories": "math.ST cs.AI cs.DM stat.ML stat.TH",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Boolean matrix factorization and Boolean matrix completion from noisy\nobservations are desirable unsupervised data-analysis methods due to their\ninterpretability, but hard to perform due to their NP-hardness. We treat these\nproblems as maximum a posteriori inference problems in a graphical model and\npresent a message passing approach that scales linearly with the number of\nobservations and factors. Our empirical study demonstrates that message passing\nis able to recover low-rank Boolean matrices, in the boundaries of\ntheoretically possible recovery and compares favorably with state-of-the-art in\nreal-world applications, such collaborative filtering with large-scale Boolean\ndata."
    },
    "1711.06035": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "van Otterlo",
                "http://arxiv.org/OAI/arXiv/:forenames": "Martijn"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "From Algorithmic Black Boxes to Adaptive White Boxes: Declarative\n  Decision-Theoretic Ethical Programs as Codes of Ethics",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, 1 figure, submitted",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Ethics of algorithms is an emerging topic in various disciplines such as\nsocial science, law, and philosophy, but also artificial intelligence (AI). The\nvalue alignment problem expresses the challenge of (machine) learning values\nthat are, in some way, aligned with human requirements or values. In this paper\nI argue for looking at how humans have formalized and communicated values, in\nprofessional codes of ethics, and for exploring declarative decision-theoretic\nethical programs (DDTEP) to formalize codes of ethics. This renders machine\nethical reasoning and decision-making, as well as learning, more transparent\nand hopefully more accountable. The paper includes proof-of-concept examples of\nknown toy dilemmas and gatekeeping domains such as archives and libraries."
    },
    "1806.01261": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Battaglia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamrick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jessica B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bapst",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sanchez-Gonzalez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alvaro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zambaldi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vinicius"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Malinowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mateusz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tacchetti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raposo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Santoro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Faulkner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gulcehre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Caglar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ballard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gilmer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Justin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dahl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "George"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vaswani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Allen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kelsey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nash",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Langston",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victoria"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dyer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heess",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wierstra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Botvinick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matt"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vinyals",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oriol"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yujia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pascanu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Razvan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Relational inductive biases, deep learning, and graph networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence (AI) has undergone a renaissance recently, making\nmajor progress in key domains such as vision, language, control, and\ndecision-making. This has been due, in part, to cheap data and cheap compute\nresources, which have fit the natural strengths of deep learning. However, many\ndefining characteristics of human intelligence, which developed under much\ndifferent pressures, remain out of reach for current approaches. In particular,\ngeneralizing beyond one's experiences--a hallmark of human intelligence from\ninfancy--remains a formidable challenge for modern AI.\n  The following is part position paper, part review, and part unification. We\nargue that combinatorial generalization must be a top priority for AI to\nachieve human-like abilities, and that structured representations and\ncomputations are key to realizing this objective. Just as biology uses nature\nand nurture cooperatively, we reject the false choice between\n\"hand-engineering\" and \"end-to-end\" learning, and instead advocate for an\napproach which benefits from their complementary strengths. We explore how\nusing relational inductive biases within deep learning architectures can\nfacilitate learning about entities, relations, and rules for composing them. We\npresent a new building block for the AI toolkit with a strong relational\ninductive bias--the graph network--which generalizes and extends various\napproaches for neural networks that operate on graphs, and provides a\nstraightforward interface for manipulating structured knowledge and producing\nstructured behaviors. We discuss how graph networks can support relational\nreasoning and combinatorial generalization, laying the foundation for more\nsophisticated, interpretable, and flexible patterns of reasoning."
    },
    "1606.03490": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Lipton",
                "http://arxiv.org/OAI/arXiv/:forenames": "Zachary C."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Mythos of Model Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at 2016 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2016), New York, NY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Supervised machine learning models boast remarkable predictive capabilities.\nBut can you trust your model? Will it work in deployment? What else can it tell\nyou about the world? We want models to be not only good, but interpretable. And\nyet the task of interpretation appears underspecified. Papers provide diverse\nand sometimes non-overlapping motivations for interpretability, and offer\nmyriad notions of what attributes render models interpretable. Despite this\nambiguity, many papers proclaim interpretability axiomatically, absent further\nexplanation. In this paper, we seek to refine the discourse on\ninterpretability. First, we examine the motivations underlying interest in\ninterpretability, finding them to be diverse and occasionally discordant. Then,\nwe address model properties and techniques thought to confer interpretability,\nidentifying transparency to humans and post-hoc explanations as competing\nnotions. Throughout, we discuss the feasibility and desirability of different\nnotions, and question the oft-made assertions that linear models are\ninterpretable and that deep neural networks are not."
    },
    "1809.08343": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Noothigattu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ritesh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bouneffouf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Djallel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mattei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicholas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chandra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rachita"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Piyush"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kush"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Campbell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Murray"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moninder"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rossi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Multi-Objective Reinforcement Learning through Policy\n  Orchestration",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 3 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Autonomous cyber-physical agents and systems play an increasingly large role\nin our lives. To ensure that agents behave in ways aligned with the values of\nthe societies in which they operate, we must develop techniques that allow\nthese agents to not only maximize their reward in an environment, but also to\nlearn and follow the implicit constraints of society. These constraints and\nnorms can come from any number of sources including regulations, business\nprocess guidelines, laws, ethical principles, social norms, and moral values.\nWe detail a novel approach that uses inverse reinforcement learning to learn a\nset of unspecified constraints from demonstrations of the task, and\nreinforcement learning to learn to maximize the environment rewards. More\nprecisely, we assume that an agent can observe traces of behavior of members of\nthe society but has no access to the explicit set of constraints that give rise\nto the observed behavior. Inverse reinforcement learning is used to learn such\nconstraints, that are then combined with a possibly orthogonal value function\nthrough the use of a contextual bandit-based orchestrator that picks a\ncontextually-appropriate choice between the two policies (constraint-based and\nenvironment reward-based) when taking actions. The contextual bandit\norchestrator allows the agent to mix policies in novel ways, taking the best\nactions from either a reward maximizing or constrained policy. In addition, the\norchestrator is transparent on which policy is being employed at each time\nstep. We test our algorithms using a Pac-Man domain and show that the agent is\nable to learn to act optimally, act within the demonstrated constraints, and\nmix these two functions in complex ways."
    },
    "1803.04263": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weld",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bansal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gagan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Intelligible Artificial Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: text overlap with arXiv:1603.08507 by other authors",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Since Artificial Intelligence (AI) software uses techniques like deep\nlookahead search and stochastic optimization of huge neural networks to fit\nmammoth datasets, it often results in complex behavior that is difficult for\npeople to understand. Yet organizations are deploying AI algorithms in many\nmission-critical settings. In order to trust their behavior, we must make it\nintelligible --- either by using inherently interpretable models or by\ndeveloping methods for explaining otherwise overwhelmingly complex decisions by\nlocal approximation, vocabulary alignment, and interactive dialog."
    },
    "1804.00293": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Do",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Truyen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nguyen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Venkatesh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Svetha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Attentional Multilabel Learning over Graphs: A Message Passing Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address a largely open problem of multilabel classification over graphs.\nUnlike traditional vector input, a graph has rich variable-size substructures\nwhich are related to the labels in some ways. We believe that uncovering these\nrelations might hold the key to classification performance and explainability.\nWe introduce GAML (Graph Attentional Multi-Label learning), a novel graph\nneural network that can handle this problem effectively. GAML regards labels as\nauxiliary nodes and models them in conjunction with the input graph. By\napplying message passing and attention mechanisms to both the label nodes and\nthe input nodes iteratively, GAML can capture the relations between the labels\nand the input subgraphs at various resolution scales. Moreover, our model can\ntake advantage of explicit label dependencies. It also scales linearly with the\nnumber of labels and graph size thanks to our proposed hierarchical attention.\nWe evaluate GAML on an extensive set of experiments with both graph-structured\ninputs and classical unstructured inputs. The results show that GAML\nsignificantly outperforms other competing methods. Importantly, GAML enables\nintuitive visualizations for better understanding of the label-substructure\nrelations and explanation of the model behaviors."
    },
    "1705.01968": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-04",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krause",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dasgupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aritra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Swartz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jordan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aphinyanaphongs",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yindalon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bertini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Enrico"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Workflow for Visual Diagnostics of Binary Classifiers using\n  Instance-Level Explanations",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at IEEE Conference on Visual Analytics Science and\n  Technology (IEEE VAST 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Human-in-the-loop data analysis applications necessitate greater transparency\nin machine learning models for experts to understand and trust their decisions.\nTo this end, we propose a visual analytics workflow to help data scientists and\ndomain experts explore, diagnose, and understand the decisions made by a binary\nclassifier. The approach leverages \"instance-level explanations\", measures of\nlocal feature relevance that explain single instances, and uses them to build a\nset of visual representations that guide the users in their investigation. The\nworkflow is based on three main visual representations and steps: one based on\naggregate statistics to see how data distributes across correct / incorrect\ndecisions; one based on explanations to understand which features are used to\nmake these decisions; and one based on raw data, to derive insights on\npotential root causes for the observed patterns. The workflow is derived from a\nlong-term collaboration with a group of machine learning and healthcare\nprofessionals who used our method to make sense of machine learning models they\ndeveloped. The case study from this collaboration demonstrates that the\nproposed workflow helps experts derive useful knowledge about the model and the\nphenomena it describes, thus experts can generate useful hypotheses on how a\nmodel can be improved."
    },
    "1704.03012": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Florensa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Duan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abbeel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pieter"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Stochastic Neural Networks for Hierarchical Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG cs.NE cs.RO",
        "http://arxiv.org/OAI/arXiv/:comments": "Published as a conference paper at ICLR 2017",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Conference on Learning Representations 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep reinforcement learning has achieved many impressive results in recent\nyears. However, tasks with sparse rewards or long horizons continue to pose\nsignificant challenges. To tackle these important problems, we propose a\ngeneral framework that first learns useful skills in a pre-training\nenvironment, and then leverages the acquired skills for learning faster in\ndownstream tasks. Our approach brings together some of the strengths of\nintrinsic motivation and hierarchical methods: the learning of useful skill is\nguided by a single proxy reward, the design of which requires very minimal\ndomain knowledge about the downstream tasks. Then a high-level policy is\ntrained on top of these skills, providing a significant improvement of the\nexploration and allowing to tackle sparse rewards in the downstream tasks. To\nefficiently pre-train a large span of skills, we use Stochastic Neural Networks\ncombined with an information-theoretic regularizer. Our experiments show that\nthis combination is effective in learning a wide span of interpretable skills\nin a sample-efficient way, and can significantly boost the learning performance\nuniformly across a wide range of downstream tasks."
    },
    "1806.10574": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chaofan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oscar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barnett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "This looks like that: deep learning for interpretable image recognition",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, including the supplementary material",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "When we are faced with challenging image classification tasks, we often\nexplain our reasoning by dissecting the image, and pointing out prototypical\naspects of one class or another. The mounting evidence for each of the classes\nhelps us make our final decision. In this work, we introduce a deep network\narchitecture that reasons in a similar way: the network dissects the image by\nfinding prototypical parts, and combines evidence from the prototypes to make a\nfinal classification. The algorithm thus reasons in a way that is qualitatively\nsimilar to the way ornithologists, physicians, geologists, architects, and\nothers would explain to people on how to solve challenging image classification\ntasks. The network uses only image-level labels for training, meaning that\nthere are no labels for parts of images. We demonstrate the method on the\nCIFAR-10 dataset and 10 classes from the CUB-200-2011 dataset."
    },
    "1803.02088": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garcia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francisco J. Chiyah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Robb",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xingkun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Laskov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Atanas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Patron",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pedro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hastie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Helen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explain Yourself: A Natural Language Interface for Scrutable Autonomous\n  Robots",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "2 pages. Peer reviewed position paper accepted in the Explainable\n  Robotic Systems Workshop, ACM Human-Robot Interaction conference, March 2018,\n  Chicago, IL USA",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.7; H.5.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Autonomous systems in remote locations have a high degree of autonomy and\nthere is a need to explain what they are doing and why in order to increase\ntransparency and maintain trust. Here, we describe a natural language chat\ninterface that enables vehicle behaviour to be queried by the user. We obtain\nan interpretable model of autonomy through having an expert 'speak out-loud'\nand provide explanations during a mission. This approach is agnostic to the\ntype of autonomy model and as expert and operator are from the same user-group,\nwe predict that these explanations will align well with the operator's mental\nmodel, increase transparency and assist with operator training."
    },
    "1809.03260": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lohia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nagar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seema"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kuntal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diptikalyan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automated Test Generation to Detect Individual Discrimination in AI\n  Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Dependability on AI models is of utmost importance to ensure full acceptance\nof the AI systems. One of the key aspects of the dependable AI system is to\nensure that all its decisions are fair and not biased towards any individual.\nIn this paper, we address the problem of detecting whether a model has an\nindividual discrimination. Such a discrimination exists when two individuals\nwho differ only in the values of their protected attributes (such as,\ngender/race) while the values of their non-protected ones are exactly the same,\nget different decisions. Measuring individual discrimination requires an\nexhaustive testing, which is infeasible for a non-trivial system. In this\npaper, we present an automated technique to generate test inputs, which is\ngeared towards finding individual discrimination. Our technique combines the\nwell-known technique called symbolic execution along with the local\nexplainability for generation of effective test cases. Our experimental results\nclearly demonstrate that our technique produces 3.72 times more successful test\ncases than the existing state-of-the-art across all our chosen benchmarks."
    },
    "1806.02322": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghauch",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hadi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Skoglund",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mikael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shokri-Ghadikolaei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hossein"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fischione",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sayed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ali H."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Kolmogorov Models for Binary Random Variables",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, accecpted to ICML 2018: Workshop on Nonconvex Optimization",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We summarize our recent findings, where we proposed a framework for learning\na Kolmogorov model, for a collection of binary random variables. More\nspecifically, we derive conditions that link outcomes of specific random\nvariables, and extract valuable relations from the data. We also propose an\nalgorithm for computing the model and show its first-order optimality, despite\nthe combinatorial nature of the learning problem. We apply the proposed\nalgorithm to recommendation systems, although it is applicable to other\nscenarios. We believe that the work is a significant step toward interpretable\nmachine learning."
    },
    "1802.04289": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-12",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kudugunta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sneha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ferrara",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emilio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Neural Networks for Bot Detection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.SI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The problem of detecting bots, automated social media accounts governed by\nsoftware but disguising as human users, has strong implications. For example,\nbots have been used to sway political elections by distorting online discourse,\nto manipulate the stock market, or to push anti-vaccine conspiracy theories\nthat caused health epidemics. Most techniques proposed to date detect bots at\nthe account level, by processing large amount of social media posts, and\nleveraging information from network structure, temporal dynamics, sentiment\nanalysis, etc.\n  In this paper, we propose a deep neural network based on contextual long\nshort-term memory (LSTM) architecture that exploits both content and metadata\nto detect bots at the tweet level: contextual features are extracted from user\nmetadata and fed as auxiliary input to LSTM deep nets processing the tweet\ntext.\n  Another contribution that we make is proposing a technique based on synthetic\nminority oversampling to generate a large labeled dataset, suitable for deep\nnets training, from a minimal amount of labeled data (roughly 3,000 examples of\nsophisticated Twitter bots). We demonstrate that, from just one single tweet,\nour architecture can achieve high classification accuracy (AUC > 96%) in\nseparating bots from humans.\n  We apply the same architecture to account-level bot detection, achieving\nnearly perfect classification accuracy (AUC > 99%). Our system outperforms\nprevious state of the art while leveraging a small and interpretable set of\nfeatures yet requiring minimal training data."
    },
    "1809.04423": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hasani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramin M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lechner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniela"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grosu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Re-purposing Compact Neuronal Circuit Policies to Govern Reinforcement\n  Learning Tasks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: substantial text overlap with arXiv:1803.08554",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an effective method for creating interpretable control agents, by\n\\textit{re-purposing} the function of a biological neural circuit model, to\ngovern simulated and real world reinforcement learning (RL) test-beds. Inspired\nby the structure of the nervous system of the soil-worm, \\emph{C. elegans}, we\nintroduce \\emph{Neuronal Circuit Policies} (NCPs) as a novel recurrent neural\nnetwork instance with liquid time-constants, universal approximation\ncapabilities and interpretable dynamics. We theoretically show that they can\napproximate any finite simulation time of a given continuous n-dimensional\ndynamical system, with $n$ output units and some hidden units. We model\ninstances of the policies and learn their synaptic and neuronal parameters to\ncontrol standard RL tasks and demonstrate its application for autonomous\nparking of a real rover robot on a pre-defined trajectory. For reconfiguration\nof the \\emph{purpose} of the neural circuit, we adopt a search-based RL\nalgorithm. We show that our neuronal circuit policies perform as good as deep\nneural network policies with the advantage of realizing interpretable dynamics\nat the cell-level. We theoretically find bounds for the time-varying dynamics\nof the circuits, and introduce a novel way to reason about networks' dynamics."
    },
    "1704.05017": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Galtier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathieu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Camille"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Morpheo: Traceable Machine Learning on Hidden data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CR cs.DC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "whitepaper, 9 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Morpheo is a transparent and secure machine learning platform collecting and\nanalysing large datasets. It aims at building state-of-the art prediction\nmodels in various fields where data are sensitive. Indeed, it offers strong\nprivacy of data and algorithm, by preventing anyone to read the data, apart\nfrom the owner and the chosen algorithms. Computations in Morpheo are\norchestrated by a blockchain infrastructure, thus offering total traceability\nof operations. Morpheo aims at building an attractive economic ecosystem around\ndata prediction by channelling crypto-money from prediction requests to useful\ndata and algorithms providers. Morpheo is designed to handle multiple data\nsources in a transfer learning approach in order to mutualize knowledge\nacquired from large datasets for applications with smaller but similar\ndatasets."
    },
    "1708.04988": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Assya",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Trofimov"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sebastien",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lemieux"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Claude",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Perreault"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Warp: a method for neural network interpretability applied to gene\n  expression profiles",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.GN cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 3 figures, NIPS2016, Machine Learning in Computational\n  Biology workshop",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We show a proof of principle for warping, a method to interpret the inner\nworking of neural networks in the context of gene expression analysis. Warping\nis an efficient way to gain insight to the inner workings of neural nets and\nmake them more interpretable. We demonstrate the ability of warping to recover\nmeaningful information for a given class on a samplespecific individual basis.\nWe found warping works well in both linearly and nonlinearly separable\ndatasets. These encouraging results show that warping has a potential to be the\nanswer to neural networks interpretability in computational biology."
    },
    "1703.08100": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiongqian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jacobs",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiankai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parthasarathy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Srinivasan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semi-supervised Embedding in Attributed Networks with Outliers",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "in Proceedings of SIAM International Conference on Data Mining\n  (SDM'18)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we propose a novel framework, called Semi-supervised Embedding\nin Attributed Networks with Outliers (SEANO), to learn a low-dimensional vector\nrepresentation that systematically captures the topological proximity,\nattribute affinity and label similarity of vertices in a partially labeled\nattributed network (PLAN). Our method is designed to work in both transductive\nand inductive settings while explicitly alleviating noise effects from\noutliers. Experimental results on various datasets drawn from the web, text and\nimage domains demonstrate the advantages of SEANO over state-of-the-art methods\nin semi-supervised classification under transductive as well as inductive\nsettings. We also show that a subset of parameters in SEANO is interpretable as\noutlier score and can significantly outperform baseline methods when applied\nfor detecting network outliers. Finally, we present the use of SEANO in a\nchallenging real-world setting -- flood mapping of satellite images and show\nthat it is able to outperform modern remote sensing algorithms for this task."
    },
    "1712.00547": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Miller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Howe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Piers"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sonenberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Liz"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to\n  Stop Worrying and Love the Social and Behavioural Sciences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "IJCAI 2017 Workshop on Explainable Artificial Intelligence (XAI)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In his seminal book `The Inmates are Running the Asylum: Why High-Tech\nProducts Drive Us Crazy And How To Restore The Sanity' [2004, Sams\nIndianapolis, IN, USA], Alan Cooper argues that a major reason why software is\noften poorly designed (from a user perspective) is that programmers are in\ncharge of design decisions, rather than interaction designers. As a result,\nprogrammers design software for themselves, rather than for their target\naudience, a phenomenon he refers to as the `inmates running the asylum'. This\npaper argues that explainable AI risks a similar fate. While the re-emergence\nof explainable AI is positive, this paper argues most of us as AI researchers\nare building explanatory agents for ourselves, rather than for the intended\nusers. But explainable AI is more likely to succeed if researchers and\npractitioners understand, adopt, implement, and improve models from the vast\nand valuable bodies of research in philosophy, psychology, and cognitive\nscience, and if evaluation of these models is focused more on people than on\ntechnology. From a light scan of literature, we demonstrate that there is\nconsiderable scope to infuse more results from the social and behavioural\nsciences into explainable AI, and present some key results from these fields\nthat are relevant to explainable AI."
    },
    "1803.08554": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lechner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hasani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramin M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grosu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Neuronal Circuit Policies",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.NC cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an effective way to create interpretable control agents, by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real world reinforcement learning (RL) test-beds. We model the\ntap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit\nresponsible for the worm's reflexive response to external mechanical touch\nstimulations, and learn its synaptic and neuronal parameters as a policy for\ncontrolling basic RL tasks. We also autonomously park a real rover robot on a\npre-defined trajectory, by deploying such neuronal circuit policies learned in\na simulated environment. For reconfiguration of the purpose of the TW neural\ncircuit, we adopt a search-based RL algorithm. We show that our neuronal\npolicies perform as good as deep neural network policies with the advantage of\nrealizing interpretable dynamics at the cell level."
    },
    "1801.08175": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gallagher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Colm V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Leahy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "O'Donovan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bruton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ken"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "O'Sullivan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dominic T. J."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Development and application of a machine learning supported methodology\n  for measurement and verification (M&V) 2.0",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "17 pages. Pre-print submitted to Energy and Buildings. This\n  manuscript version is made available under the CC-BY-NC-ND 4.0 licence",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The foundations of all methodologies for the measurement and verification\n(M&V) of energy savings are based on the same five key principles: accuracy,\ncompleteness, conservatism, consistency and transparency. The most widely\naccepted methodologies tend to generalise M&V so as to ensure applicability\nacross the spectrum of energy conservation measures (ECM's). These do not\nprovide a rigid calculation procedure to follow. This paper aims to bridge the\ngap between high-level methodologies and the practical application of modelling\nalgorithms, with a focus on the industrial buildings sector. This is achieved\nwith the development of a novel, machine learning supported methodology for M&V\n2.0 which enables accurate quantification of savings.\n  A novel and computationally efficient feature selection algorithm and\npowerful machine learning regression algorithms are employed to maximise the\neffectiveness of available data. The baseline period energy consumption is\nmodelled using artificial neural networks, support vector machines, k-nearest\nneighbours and multiple ordinary least squares regression. Improved knowledge\ndiscovery and an expanded boundary of analysis allow more complex energy\nsystems be analysed, thus increasing the applicability of M&V. A case study in\na large biomedical manufacturing facility is used to demonstrate the\nmethodology's ability to accurately quantify the savings under real-world\nconditions. The ECM was found to result in 604,527 kWh of energy savings with\n57% uncertainty at a confidence interval of 68%. 20 baseline energy models are\ndeveloped using an exhaustive approach with the optimal model being used to\nquantify savings. The range of savings estimated with each model are presented\nand the acceptability of uncertainty is reviewed. The case study demonstrates\nthe ability of the methodology to perform M&V to an acceptable standard in\nchallenging circumstances."
    },
    "1712.07294": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianmin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Caiming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Socher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Hierarchical and Interpretable Skill Acquisition in Multi-task\n  Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Learning policies for complex tasks that require multiple different skills is\na major challenge in reinforcement learning (RL). It is also a requirement for\nits deployment in real-world scenarios. This paper proposes a novel framework\nfor efficient multi-task reinforcement learning. Our framework trains agents to\nemploy hierarchical policies that decide when to use a previously learned\npolicy and when to learn a new skill. This enables agents to continually\nacquire new skills during different stages of training. Each learned task\ncorresponds to a human language description. Because agents can only access\npreviously learned skills through these descriptions, the agent can always\nprovide a human-interpretable description of its choices. In order to help the\nagent learn the complex temporal dependencies necessary for the hierarchical\npolicy, we provide it with a stochastic temporal grammar that modulates when to\nrely on previously learned skills and when to execute new skills. We validate\nour approach on Minecraft games designed to explicitly test the ability to\nreuse previously learned skills while simultaneously learning new skills."
    },
    "1710.03875": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vazquez-Chanlatte",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcell"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Susmit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tiwari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Seshia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanjit A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Specification Inference from Demonstrations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.LO",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Learning from expert demonstrations has received a lot of attention in\nartificial intelligence and machine learning. The goal is to infer the\nunderlying reward function that an agent is optimizing given a set of\nobservations of the agent's behavior over time in a variety of circumstances,\nthe system state trajectories, and a plant model specifying the evolution of\nthe system state for different agent's actions. The system is often modeled as\na Markov decision process, that is, the next state depends only on the current\nstate and agent's action, and the the agent's choice of action depends only on\nthe current state. While the former is a Markovian assumption on the evolution\nof system state, the later assumes that the target reward function is itself\nMarkovian. In this work, we explore learning a class of non-Markovian reward\nfunctions, known in the formal methods literature as specifications. These\nspecifications offer better composition, transferability, and interpretability.\nWe then show that inferring the specification can be done efficiently without\nunrolling the transition system. We demonstrate on a 2-d grid world example."
    },
    "1806.07376": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Suchan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jakob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bhatt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mehul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vardarajan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Srikrishna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amirshahi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seyed Ali"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stella"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semantic Analysis of (Reflectional) Visual Symmetry: A Human-Centred\n  Computational Model for Declarative Explainability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "Preprint of accepted article / Journal: Advances in Cognitive\n  Systems. ( http://www.cogsys.org/journal )",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Advances in Cognitive Systems. (http://www.cogsys.org/journal),\n  2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a computational model for the semantic interpretation of symmetry\nin naturalistic scenes. Key features include a human-centred representation,\nand a declarative, explainable interpretation model supporting deep semantic\nquestion-answering founded on an integration of methods in knowledge\nrepresentation and deep learning based computer vision. In the backdrop of the\nvisual arts, we showcase the framework's capability to generate human-centred,\nqueryable, relational structures, also evaluating the framework with an\nempirical study on the human perception of visual symmetry. Our framework\nrepresents and is driven by the application of foundational, integrated Vision\nand Knowledge Representation and Reasoning methods for applications in the\narts, and the psychological and social sciences."
    },
    "1807.03633": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-07-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Allareddy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Veerajalandhar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rampa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sankeerth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Allareddy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Veerasathpurush"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Patient Mortality Prediction with Multi-value Rule Sets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: text overlap with arXiv:1710.05257",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a Multi-vAlue Rule Set (MRS) model for in-hospital predicting\npatient mortality. Compared to rule sets built from single-valued rules, MRS\nadopts a more generalized form of association rules that allows multiple values\nin a condition. Rules of this form are more concise than classical\nsingle-valued rules in capturing and describing patterns in data. Our\nformulation also pursues a higher efficiency of feature utilization, which\nreduces possible cost in data collection and storage. We propose a Bayesian\nframework for formulating a MRS model and propose an efficient inference method\nfor learning a maximum \\emph{a posteriori}, incorporating theoretically\ngrounded bounds to iteratively reduce the search space and improve the search\nefficiency. Experiments show that our model was able to achieve better\nperformance than baseline method including the current system used by the\nhospital."
    },
    "1608.05745": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-02-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Choi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bahadori",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad Taha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kulas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schuetz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stewart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Walter F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jimeng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "RETAIN: An Interpretable Predictive Model for Healthcare using Reverse\n  Time Attention Mechanism",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Neural Information Processing Systems (NIPS) 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Accuracy and interpretability are two dominant features of successful\npredictive models. Typically, a choice must be made in favor of complex black\nbox models such as recurrent neural networks (RNN) for accuracy versus less\naccurate but more interpretable traditional models such as logistic regression.\nThis tradeoff poses challenges in medicine where both accuracy and\ninterpretability are important. We addressed this challenge by developing the\nREverse Time AttentIoN model (RETAIN) for application to Electronic Health\nRecords (EHR) data. RETAIN achieves high accuracy while remaining clinically\ninterpretable and is based on a two-level neural attention model that detects\ninfluential past visits and significant clinical variables within those visits\n(e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR\ndata in a reverse time order so that recent clinical visits are likely to\nreceive higher attention. RETAIN was tested on a large health system EHR\ndataset with 14 million visits completed by 263K patients over an 8 year period\nand demonstrated predictive accuracy and computational scalability comparable\nto state-of-the-art methods such as RNN, and ease of interpretability\ncomparable to traditional models."
    },
    "1703.08705": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gehrmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dernoncourt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franck"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yeran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Carlson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joy T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Welt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Foote",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John",
                    "http://arxiv.org/OAI/arXiv/:suffix": "Jr."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moseley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grant",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tyler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Patrick D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Celi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leo Anthony"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes."
    },
    "1804.00506": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Du",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mengnan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ninghao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qingquan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Explanation of DNN-based Prediction with Guided Feature\n  Inversion",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While deep neural networks (DNN) have become an effective computational tool,\nthe prediction results are often criticized by the lack of interpretability,\nwhich is essential in many real-world applications such as health informatics.\nExisting attempts based on local interpretations aim to identify relevant\nfeatures contributing the most to the prediction of DNN by monitoring the\nneighborhood of a given input. They usually simply ignore the intermediate\nlayers of the DNN that might contain rich information for interpretation. To\nbridge the gap, in this paper, we propose to investigate a guided feature\ninversion framework for taking advantage of the deep architectures towards\neffective interpretation. The proposed framework not only determines the\ncontribution of each feature in the input but also provides insights into the\ndecision-making process of DNN models. By further interacting with the neuron\nof the target category at the output layer of the DNN, we enforce the\ninterpretation result to be class-discriminative. We apply the proposed\ninterpretation model to different CNN architectures to provide explanations for\nimage data and conduct extensive experiments on ImageNet and PASCAL VOC07\ndatasets. The interpretation results demonstrate the effectiveness of our\nproposed framework in providing class-discriminative interpretation for\nDNN-based prediction."
    },
    "1608.07685": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Han"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Minlie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoyan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "KSR: A Semantic Representation of Knowledge Graph within a Novel\n  Unsupervised Paradigm",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "submitting to IJCAI 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Knowledge representation is a long-history topic in AI, which is very\nimportant. A variety of models have been proposed for knowledge graph\nembedding, which projects symbolic entities and relations into continuous\nvector space. However, most related methods merely focus on the data-fitting of\nknowledge graph, and ignore the interpretable semantic expression. Thus,\ntraditional embedding methods are not friendly for applications that require\nsemantic analysis, such as question answering and entity retrieval. To this\nend, this paper proposes a semantic representation method for knowledge graph\n\\textbf{(KSR)}, which imposes a two-level hierarchical generative process that\nglobally extracts many aspects and then locally assigns a specific category in\neach aspect for every triple. Since both aspects and categories are\nsemantics-relevant, the collection of categories in each aspect is treated as\nthe semantic representation of this triple. Extensive experiments show that our\nmodel outperforms other state-of-the-art baselines substantially."
    },
    "1803.06174": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Binns",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Reuben"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Van Kleek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Max"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Some HCI Priorities for GDPR-Compliant Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 0 figures, The General Data Protection Regulation: An\n  Opportunity for the CHI Community? (CHI-GDPR 2018), Workshop at ACM CHI'18,\n  22 April 2018, Montreal, Canada",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this short paper, we consider the roles of HCI in enabling the better\ngovernance of consequential machine learning systems using the rights and\nobligations laid out in the recent 2016 EU General Data Protection Regulation\n(GDPR)---a law which involves heavy interaction with people and systems.\nFocussing on those areas that relate to algorithmic systems in society, we\npropose roles for HCI in legal contexts in relation to fairness, bias and\ndiscrimination; data protection by design; data protection impact assessments;\ntransparency and explanations; the mitigation and understanding of automation\nbias; and the communication of envisaged consequences of processing."
    },
    "1711.06431": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Babiker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Housam Khalifa Bashier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goebel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Randy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Using KL-divergence to focus Deep Visual Explanation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a method for explaining the image classification predictions of\ndeep convolution neural networks, by highlighting the pixels in the image which\ninfluence the final class prediction. Our method requires the identification of\na heuristic method to select parameters hypothesized to be most relevant in\nthis prediction, and here we use Kullback-Leibler divergence to provide this\nfocus. Overall, our approach helps in understanding and interpreting deep\nnetwork predictions and we hope contributes to a foundation for such\nunderstanding of deep learning networks. In this brief paper, our experiments\nevaluate the performance of two popular networks in this context of\ninterpretability."
    },
    "1802.01933": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guidotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Monreale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Turini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedreschi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dino"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Giannotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fosca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Survey Of Methods For Explaining Black Box Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "This work is currently under review on an international journal",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the last years many accurate decision support systems have been\nconstructed as black boxes, that is as systems that hide their internal logic\nto the user. This lack of explanation constitutes both a practical and an\nethical issue. The literature reports many approaches aimed at overcoming this\ncrucial weakness sometimes at the cost of scarifying accuracy for\ninterpretability. The applications in which black box decision systems can be\nused are various, and each approach is typically developed to provide a\nsolution for a specific problem and, as a consequence, delineating explicitly\nor implicitly its own definition of interpretability and explanation. The aim\nof this paper is to provide a classification of the main problems addressed in\nthe literature with respect to the notion of explanation and the type of black\nbox system. Given a problem definition, a black box type, and a desired\nexplanation this survey should help the researcher to find the proposals more\nuseful for his own work. The proposed classification of approaches to open\nblack box models should also be useful for putting the many research open\nquestions in perspective."
    },
    "1708.00376": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Penkov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Svetlin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamoorthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subramanian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Using Program Induction to Interpret Transition System Dynamics",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at 2017 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2017), Sydney, NSW, Australia. arXiv admin note: substantial\n  text overlap with arXiv:1705.08320",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Explaining and reasoning about processes which underlie observed black-box\nphenomena enables the discovery of causal mechanisms, derivation of suitable\nabstract representations and the formulation of more robust predictions. We\npropose to learn high level functional programs in order to represent abstract\nmodels which capture the invariant structure in the observed data. We introduce\nthe $\\pi$-machine (program-induction machine) -- an architecture able to induce\ninterpretable LISP-like programs from observed data traces. We propose an\noptimisation procedure for program learning based on backpropagation, gradient\ndescent and A* search. We apply the proposed method to two problems: system\nidentification of dynamical systems and explaining the behaviour of a DQN\nagent. Our results show that the $\\pi$-machine can efficiently induce\ninterpretable programs from individual data traces."
    },
    "1705.06715": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Feng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yerima",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suleiman Y."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "BooJoong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sezer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sakir"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Continuous Implicit Authentication for Mobile Devices based on Adaptive\n  Neuro-Fuzzy Inference System",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CR cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "International Conference on Cyber Security and Protection of Digital\n  Services (Cyber Security 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As mobile devices have become indispensable in modern life, mobile security\nis becoming much more important. Traditional password or PIN-like\npoint-of-entry security measures score low on usability and are vulnerable to\nbrute force and other types of attacks. In order to improve mobile security, an\nadaptive neuro-fuzzy inference system(ANFIS)-based implicit authentication\nsystem is proposed in this paper to provide authentication in a continuous and\ntransparent manner.To illustrate the applicability and capability of ANFIS in\nour implicit authentication system, experiments were conducted on behavioural\ndata collected for up to 12 weeks from different Android users. The ability of\nthe ANFIS-based system to detect an adversary is also tested with scenarios\ninvolving an attacker with varying levels of knowledge. The results demonstrate\nthat ANFIS is a feasible and efficient approach for implicit authentication\nwith an average of 95% user recognition rate. Moreover, the use of ANFIS-based\nsystem for implicit authentication significantly reduces manual tuning and\nconfiguration tasks due to its selflearning capability."
    },
    "1806.08055": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madumal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prashan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Miller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vetere",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Frank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sonenberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Liz"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards a Grounded Dialog Model for Explainable Artificial Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, First international workshop on socio-cognitive systems at\n  Federated AI Meeting (FAIM) 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "To generate trust with their users, Explainable Artificial Intelligence (XAI)\nsystems need to include an explanation model that can communicate the internal\ndecisions, behaviours and actions to the interacting humans. Successful\nexplanation involves both cognitive and social processes. In this paper we\nfocus on the challenge of meaningful interaction between an explainer and an\nexplainee and investigate the structural aspects of an explanation in order to\npropose a human explanation dialog model. We follow a bottom-up approach to\nderive the model by analysing transcripts of 398 different explanation dialog\ntypes. We use grounded theory to code and identify key components of which an\nexplanation dialog consists. We carry out further analysis to identify the\nrelationships between components and sequences and cycles that occur in a\ndialog. We present a generalized state model obtained by the analysis and\ncompare it with an existing conceptual dialog model of explanation."
    },
    "1705.07368": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Foulds",
                "http://arxiv.org/OAI/arXiv/:forenames": "James"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mixed Membership Word Embeddings for Computational Social Science",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Word embeddings improve the performance of NLP systems by revealing the\nhidden structural relationships between words. Despite their success in many\napplications, word embeddings have seen very little use in computational social\nscience NLP tasks, presumably due to their reliance on big data, and to a lack\nof interpretability. I propose a probabilistic model-based word embedding\nmethod which can recover interpretable embeddings, without big data. The key\ninsight is to leverage mixed membership modeling, in which global\nrepresentations are shared, but individual entities (i.e. dictionary words) are\nfree to use these representations to uniquely differing degrees. I show how to\ntrain the model using a combination of state-of-the-art training techniques for\nword embeddings and topic models. The experimental results show an improvement\nin predictive language modeling of up to 63% in MRR over the skip-gram, and\ndemonstrate that the representations are beneficial for supervised learning. I\nillustrate the interpretability of the models with computational social science\ncase studies on State of the Union addresses and NIPS articles."
    },
    "1801.05457": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wolff",
                "http://arxiv.org/OAI/arXiv/:forenames": "J Gerard"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Solutions to problems with deep learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Despite the several successes of deep learning systems, there are concerns\nabout their limitations, discussed most recently by Gary Marcus. This paper\ndiscusses Marcus's concerns and some others, together with solutions to several\nof these problems provided by the \"P theory of intelligence\" and its\nrealisation in the \"SP computer model\". The main advantages of the SP system\nare: relatively small requirements for data and the ability to learn from a\nsingle experience; the ability to model both hierarchical and non-hierarchical\nstructures; strengths in several kinds of reasoning, including `commonsense'\nreasoning; transparency in the representation of knowledge, and the provision\nof an audit trail for all processing; the likelihood that the SP system could\nnot be fooled into bizarre or eccentric recognition of stimuli, as deep\nlearning systems can be; the SP system provides a robust solution to the\nproblem of `catastrophic forgetting' in deep learning systems; the SP system\nprovides a theoretically-coherent solution to the problems of correcting over-\nand under-generalisations in learning, and learning correct structures despite\nerrors in data; unlike most research on deep learning, the SP programme of\nresearch draws extensively on research on human learning, perception, and\ncognition; and the SP programme of research has an overarching theory,\nsupported by evidence, something that is largely missing from research on deep\nlearning. In general, the SP system provides a much firmer foundation than deep\nlearning for the development of artificial general intelligence."
    },
    "1709.01574": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devinder"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Taylor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Graham W"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced\n  Attentive Response Approach for Explaining and Visualizing Deep\n  Learning-Driven Stock Market Prediction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep learning has been shown to outperform traditional machine learning\nalgorithms across a wide range of problem domains. However, current deep\nlearning algorithms have been criticized as uninterpretable \"black-boxes\" which\ncannot explain their decision making processes. This is a major shortcoming\nthat prevents the widespread application of deep learning to domains with\nregulatory processes such as finance. As such, industries such as finance have\nto rely on traditional models like decision trees that are much more\ninterpretable but less effective than deep learning for complex problems. In\nthis paper, we propose CLEAR-Trade, a novel financial AI visualization\nframework for deep learning-driven stock market prediction that mitigates the\ninterpretability issue of deep learning methods. In particular, CLEAR-Trade\nprovides a effective way to visualize and explain decisions made by deep stock\nmarket prediction models. We show the efficacy of CLEAR-Trade in enhancing the\ninterpretability of stock market prediction by conducting experiments based on\nS&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can\nprovide significant insight into the decision-making process of deep\nlearning-driven financial models, particularly for regulatory processes, thus\nimproving their potential uptake in the financial industry."
    },
    "1612.08544": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Karpatne",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anuj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Atluri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gowtham"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Faghmous",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Steinbach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Banerjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arindam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ganguly",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Auroop"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shekhar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shashi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Samatova",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nagiza"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vipin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Theory-guided Data Science: A New Paradigm for Scientific Discovery from\n  Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 29(10),\n  pp.2318-2331. 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/TKDE.2017.2720168",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Data science models, although successful in a number of commercial domains,\nhave had limited applicability in scientific problems involving complex\nphysical phenomena. Theory-guided data science (TGDS) is an emerging paradigm\nthat aims to leverage the wealth of scientific knowledge for improving the\neffectiveness of data science models in enabling scientific discovery. The\noverarching vision of TGDS is to introduce scientific consistency as an\nessential component for learning generalizable models. Further, by producing\nscientifically interpretable models, TGDS aims to advance our scientific\nunderstanding by discovering novel domain insights. Indeed, the paradigm of\nTGDS has started to gain prominence in a number of scientific disciplines such\nas turbulence modeling, material discovery, quantum chemistry, bio-medical\nscience, bio-marker discovery, climate science, and hydrology. In this paper,\nwe formally conceptualize the paradigm of TGDS and present a taxonomy of\nresearch themes in TGDS. We describe several approaches for integrating domain\nknowledge in different research themes using illustrative examples from\ndifferent disciplines. We also highlight some of the promising avenues of novel\nresearch for realizing the full potential of theory-guided data science."
    },
    "1705.02668": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mukherjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subhabrata"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dutta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sourav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weikum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Credible Review Detection with Limited Information using Consistency\n  Analysis",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.IR cs.SI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Online reviews provide viewpoints on the strengths and shortcomings of\nproducts/services, influencing potential customers' purchasing decisions.\nHowever, the proliferation of non-credible reviews -- either fake (promoting/\ndemoting an item), incompetent (involving irrelevant aspects), or biased --\nentails the problem of identifying credible reviews. Prior works involve\nclassifiers harnessing rich information about items/users -- which might not be\nreadily available in several domains -- that provide only limited\ninterpretability as to why a review is deemed non-credible. This paper presents\na novel approach to address the above issues. We utilize latent topic models\nleveraging review texts, item ratings, and timestamps to derive consistency\nfeatures without relying on item/user histories, unavailable for \"long-tail\"\nitems/users. We develop models, for computing review credibility scores to\nprovide interpretable evidence for non-credible reviews, that are also\ntransferable to other domains -- addressing the scarcity of labeled data.\nExperiments on real-world datasets demonstrate improvements over\nstate-of-the-art baselines."
    },
    "1705.08320": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Penkov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Svetlin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamoorthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subramanian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explaining Transition Systems through Program Induction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "submitted to Neural Information Processing Systems 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Explaining and reasoning about processes which underlie observed black-box\nphenomena enables the discovery of causal mechanisms, derivation of suitable\nabstract representations and the formulation of more robust predictions. We\npropose to learn high level functional programs in order to represent abstract\nmodels which capture the invariant structure in the observed data. We introduce\nthe $\\pi$-machine (program-induction machine) -- an architecture able to induce\ninterpretable LISP-like programs from observed data traces. We propose an\noptimisation procedure for program learning based on backpropagation, gradient\ndescent and A* search. We apply the proposed method to three problems: system\nidentification of dynamical systems, explaining the behaviour of a DQN agent\nand learning by demonstration in a human-robot interaction scenario. Our\nexperimental results show that the $\\pi$-machine can efficiently induce\ninterpretable programs from individual data traces."
    },
    "1605.08803": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-02-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dinh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Laurent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sohl-Dickstein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jascha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Samy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Density estimation using Real NVP",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages of main content, 3 pages of bibliography, 18 pages of\n  appendix. Accepted at ICLR 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Unsupervised learning of probabilistic models is a central yet challenging\nproblem in machine learning. Specifically, designing models with tractable\nlearning, sampling, inference and evaluation is crucial in solving this task.\nWe extend the space of such models using real-valued non-volume preserving\n(real NVP) transformations, a set of powerful invertible and learnable\ntransformations, resulting in an unsupervised learning algorithm with exact\nlog-likelihood computation, exact sampling, exact inference of latent\nvariables, and an interpretable latent space. We demonstrate its ability to\nmodel natural images on four datasets through sampling, log-likelihood\nevaluation and latent variable manipulations."
    },
    "1703.07022": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chuang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Recurrent Topic-Transition GAN for Visual Paragraph Generation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A natural image usually conveys rich semantic content and can be viewed from\ndifferent angles. Existing image description methods are largely restricted by\nsmall sets of biased visual paragraph annotations, and fail to cover rich\nunderlying semantics. In this paper, we investigate a semi-supervised paragraph\ngenerative framework that is able to synthesize diverse and semantically\ncoherent paragraph descriptions by reasoning over local semantic regions and\nexploiting linguistic knowledge. The proposed Recurrent Topic-Transition\nGenerative Adversarial Network (RTT-GAN) builds an adversarial framework\nbetween a structured paragraph generator and multi-level paragraph\ndiscriminators. The paragraph generator generates sentences recurrently by\nincorporating region-based visual and language attention mechanisms at each\nstep. The quality of generated paragraph sentences is assessed by multi-level\nadversarial discriminators from two aspects, namely, plausibility at sentence\nlevel and topic-transition coherence at paragraph level. The joint adversarial\ntraining of RTT-GAN drives the model to generate realistic paragraphs with\nsmooth logical transition between sentence topics. Extensive quantitative\nexperiments on image and video paragraph datasets demonstrate the effectiveness\nof our RTT-GAN in both supervised and semi-supervised settings. Qualitative\nresults on telling diverse stories for an image also verify the\ninterpretability of RTT-GAN."
    },
    "1607.00279": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Condry",
                "http://arxiv.org/OAI/arXiv/:forenames": "Nick"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Meaningful Models: Utilizing Conceptual Structure to Improve Machine\n  Learning Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 3 figures, presented at 2016 ICML Workshop on Human\n  Interpretability in Machine Learning (WHI 2016), New York, NY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The last decade has seen huge progress in the development of advanced machine\nlearning models; however, those models are powerless unless human users can\ninterpret them. Here we show how the mind's construction of concepts and\nmeaning can be used to create more interpretable machine learning models. By\nproposing a novel method of classifying concepts, in terms of 'form' and\n'function', we elucidate the nature of meaning and offer proposals to improve\nmodel understandability. As machine learning begins to permeate daily life,\ninterpretable models may serve as a bridge between domain-expert authors and\nnon-expert users."
    },
    "1810.00177": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hiraoka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Takuya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Onishi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Takashi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Imagawa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Takahisa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsuruoka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshimasa"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Refining Manually-Designed Symbol Grounding and High-Level Planning by\n  Policy Gradients",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at the IJCAI-ICAI 2018 workshop on Learning & Reasoning\n  (L&R 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Hierarchical planners that produce interpretable and appropriate plans are\ndesired, especially in its application to supporting human decision making. In\nthe typical development of the hierarchical planners, higher-level planners and\nsymbol grounding functions are manually created, and this manual creation\nrequires much human effort. In this paper, we propose a framework that can\nautomatically refine symbol grounding functions and a high-level planner to\nreduce human effort for designing these modules. In our framework, symbol\ngrounding and high-level planning, which are based on manually-designed\nknowledge bases, are modeled with semi-Markov decision processes. A policy\ngradient method is then applied to refine the modules, in which two terms for\nupdating the modules are considered. The first term, called a reinforcement\nterm, contributes to updating the modules to improve the overall performance of\na hierarchical planner to produce appropriate plans. The second term, called a\npenalty term, contributes to keeping refined modules consistent with the\nmanually-designed original modules. Namely, it keeps the planner, which uses\nthe refined modules, producing interpretable plans. We perform preliminary\nexperiments to solve the Mountain car problem, and its results show that a\nmanually-designed high-level planner and symbol grounding function were\nsuccessfully refined by our framework."
    },
    "1508.04087": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-08-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-03-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wolff",
                "http://arxiv.org/OAI/arXiv/:forenames": "J. G."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The SP theory of intelligence: distinctive features and advantages",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IEEE Access, 4, 216-246, 2016",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ACCESS.2015.2513822",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper highlights distinctive features of the \"SP theory of intelligence\"\nand its apparent advantages compared with some AI-related alternatives.\nDistinctive features and advantages are: simplification and integration of\nobservations and concepts; simplification and integration of structures and\nprocesses in computing systems; the theory is itself a theory of computing; it\ncan be the basis for new architectures for computers; information compression\nvia the matching and unification of patterns and, more specifically, via\nmultiple alignment, is fundamental; transparency in the representation and\nprocessing of knowledge; the discovery of 'natural' structures via information\ncompression (DONSVIC); interpretations of mathematics; interpretations in human\nperception and cognition; and realisation of abstract concepts in terms of\nneurons and their inter-connections (\"SP-neural\"). These things relate to\nAI-related alternatives: minimum length encoding and related concepts; deep\nlearning in neural networks; unified theories of cognition and related\nresearch; universal search; Bayesian networks and more; pattern recognition and\nvision; the analysis, production, and translation of natural language;\nUnsupervised learning of natural language; exact and inexact forms of\nreasoning; representation and processing of diverse forms of knowledge; IBM's\nWatson; software engineering; solving problems associated with big data, and in\nthe development of intelligence in autonomous robots. In conclusion, the SP\nsystem can provide a firm foundation for the long-term development of AI, with\nmany potential benefits and applications. It may also deliver useful results on\nrelatively short timescales. A high-parallel, open-source version of the SP\nmachine, derived from the SP computer model, would be a means for researchers\neverywhere to explore what can be done with the system, and to create new\nversions of it."
    },
    "1810.00024": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garcia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Washington"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Choi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joseph I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Adari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suman K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Somesh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Butler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin R. B."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Black-Box Attacks Against Model-based Authentication",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CR stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Establishing unique identities for both humans and end systems has been an\nactive research problem in the security community, giving rise to innovative\nmachine learning-based authentication techniques. Although such techniques\noffer an automated method to establish identity, they have not been vetted\nagainst sophisticated attacks that target their core machine learning\ntechnique. This paper demonstrates that mimicking the unique signatures\ngenerated by host fingerprinting and biometric authentication systems is\npossible. We expose the ineffectiveness of underlying machine learning\nclassification models by constructing a blind attack based around the query\nsynthesis framework and utilizing Explainable-AI (XAI) techniques. We launch an\nattack in under 130 queries on a state-of-the-art face authentication system,\nand under 100 queries on a host authentication system. We examine how these\nattacks can be defended against and explore their limitations. XAI provides an\neffective means for adversaries to infer decision boundaries and provides a new\nway forward in constructing attacks against systems using machine learning\nmodels for authentication."
    },
    "1712.03779": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumbier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karl"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Artificial Intelligence and Statistics",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence (AI) is intrinsically data-driven. It calls for the\napplication of statistical concepts through human-machine collaboration during\ngeneration of data, development of algorithms, and evaluation of results. This\npaper discusses how such human-machine collaboration can be approached through\nthe statistical concepts of population, question of interest,\nrepresentativeness of training data, and scrutiny of results (PQRS). The PQRS\nworkflow provides a conceptual framework for integrating statistical ideas with\nhuman input into AI products and research. These ideas include experimental\ndesign principles of randomization and local control as well as the principle\nof stability to gain reproducibility and interpretability of algorithms and\ndata results. We discuss the use of these principles in the contexts of\nself-driving cars, automated medical diagnoses, and examples from the authors'\ncollaborative research."
    },
    "1811.06747": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scantamburlo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Teresa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Charlesworth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cristianini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nello"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Machine Decisions and Human Consequences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As we increasingly delegate decision-making to algorithms, whether directly\nor indirectly, important questions emerge in circumstances where those\ndecisions have direct consequences for individual rights and personal\nopportunities, as well as for the collective good. A key problem for\npolicymakers is that the social implications of these new methods can only be\ngrasped if there is an adequate comprehension of their general technical\nunderpinnings. The discussion here focuses primarily on the case of enforcement\ndecisions in the criminal justice system, but draws on similar situations\nemerging from other algorithms utilised in controlling access to opportunities,\nto explain how machine learning works and, as a result, how decisions are made\nby modern intelligent algorithms or 'classifiers'. It examines the key aspects\nof the performance of classifiers, including how classifiers learn, the fact\nthat they operate on the basis of correlation rather than causation, and that\nthe term 'bias' in machine learning has a different meaning to common usage.An\nexample of a real world 'classifier', the Harm Assessment Risk Tool (HART), is\nexamined, through identification of its technical features: the classification\nmethod, the training data and the test data, the features and the labels,\nvalidation and performance measures. Four normative benchmarks are then\nconsidered by reference to HART: (a) prediction accuracy (b) fairness and\nequality before the law (c) transparency and accountability (d) informational\nprivacy and freedom of expression, in order to demonstrate how its technical\nfeatures have important normative dimensions that bear directly on the extent\nto which the system can be regarded as a viable and legitimate support for, or\neven alternative to, existing human decision-makers."
    },
    "1804.09843": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Athiwaratkun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ben"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Gordon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Hierarchical Density Order Embeddings",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at ICLR 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "By representing words with probability densities rather than point vectors,\nprobabilistic word embeddings can capture rich and interpretable semantic\ninformation and uncertainty. The uncertainty information can be particularly\nmeaningful in capturing entailment relationships -- whereby general words such\nas \"entity\" correspond to broad distributions that encompass more specific\nwords such as \"animal\" or \"instrument\". We introduce density order embeddings,\nwhich learn hierarchical representations through encapsulation of probability\ndensities. In particular, we propose simple yet effective loss functions and\ndistance metrics, as well as graph-based schemes to select negative samples to\nbetter learn hierarchical density representations. Our approach provides\nstate-of-the-art performance on the WordNet hypernym relationship prediction\ntask and the challenging HyperLex lexical entailment dataset -- while retaining\na rich and interpretable density representation."
    },
    "1702.08608": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Doshi-Velez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Finale"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Been"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards A Rigorous Science of Interpretable Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As machine learning systems become ubiquitous, there has been a surge of\ninterest in interpretable machine learning: systems that provide explanation\nfor their outputs. These explanations are often used to qualitatively assess\nother criteria such as safety or non-discrimination. However, despite the\ninterest in interpretability, there is very little consensus on what\ninterpretable machine learning is and how it should be measured. In this\nposition paper, we first define interpretability and describe when\ninterpretability is needed (and when it is not). Next, we suggest a taxonomy\nfor rigorous evaluation and expose open questions towards a more rigorous\nscience of interpretable machine learning."
    },
    "1608.01835": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-05",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-08-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bogaerts",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bart"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Janhunen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tomi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tasharrofi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shahab"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Stable-Unstable Semantics: Beyond NP with Normal Logic Programs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Paper presented at the 32nd International Conference on Logic\n  Programming (ICLP 2016), New York City, USA, 16-21 October 2016, 16 pages,\n  LaTeX, no figures",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68T30",
        "http://arxiv.org/OAI/arXiv/:acm-class": "D.1.6; F.4.1; I.2.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Standard answer set programming (ASP) targets at solving search problems from\nthe first level of the polynomial time hierarchy (PH). Tackling search problems\nbeyond NP using ASP is less straightforward. The class of disjunctive logic\nprograms offers the most prominent way of reaching the second level of the PH,\nbut encoding respective hard problems as disjunctive programs typically\nrequires sophisticated techniques such as saturation or meta-interpretation.\nThe application of such techniques easily leads to encodings that are\ninaccessible to non-experts. Furthermore, while disjunctive ASP solvers often\nrely on calls to a (co-)NP oracle, it may be difficult to detect from the input\nprogram where the oracle is being accessed. In other formalisms, such as\nQuantified Boolean Formulas (QBFs), the interface to the underlying oracle is\nmore transparent as it is explicitly recorded in the quantifier prefix of a\nformula. On the other hand, ASP has advantages over QBFs from the modeling\nperspective. The rich high-level languages such as ASP-Core-2 offer a wide\nvariety of primitives that enable concise and natural encodings of search\nproblems. In this paper, we present a novel logic programming--based modeling\nparadigm that combines the best features of ASP and QBFs. We develop so-called\ncombined logic programs in which oracles are directly cast as (normal) logic\nprograms themselves. Recursive incarnations of this construction enable logic\nprogramming on arbitrarily high levels of the PH. We develop a proof-of-concept\nimplementation for our new paradigm.\n  This paper is under consideration for acceptance in TPLP."
    },
    "1610.09778": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jingbo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Meng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wenzhu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jinfeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiawei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "DPPred: An Effective Prediction Framework with Concise Discriminative\n  Patterns",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the literature, two series of models have been proposed to address\nprediction problems including classification and regression. Simple models,\nsuch as generalized linear models, have ordinary performance but strong\ninterpretability on a set of simple features. The other series, including\ntree-based models, organize numerical, categorical and high dimensional\nfeatures into a comprehensive structure with rich interpretable information in\nthe data.\n  In this paper, we propose a novel Discriminative Pattern-based Prediction\nframework (DPPred) to accomplish the prediction tasks by taking their\nadvantages of both effectiveness and interpretability. Specifically, DPPred\nadopts the concise discriminative patterns that are on the prefix paths from\nthe root to leaf nodes in the tree-based models. DPPred selects a limited\nnumber of the useful discriminative patterns by searching for the most\neffective pattern combination to fit generalized linear models. Extensive\nexperiments show that in many scenarios, DPPred provides competitive accuracy\nwith the state-of-the-art as well as the valuable interpretability for\ndevelopers and experts. In particular, taking a clinical application dataset as\na case study, our DPPred outperforms the baselines by using only 40 concise\ndiscriminative patterns out of a potentially exponentially large set of\npatterns."
    },
    "1809.06305": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Belta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Calin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automata Guided Reinforcement Learning With Demonstrations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Tasks with complex temporal structures and long horizons pose a challenge for\nreinforcement learning agents due to the difficulty in specifying the tasks in\nterms of reward functions as well as large variances in the learning signals.\nWe propose to address these problems by combining temporal logic (TL) with\nreinforcement learning from demonstrations. Our method automatically generates\nintrinsic rewards that align with the overall task goal given a TL task\nspecification. The policy resulting from our framework has an interpretable and\nhierarchical structure. We validate the proposed method experimentally on a set\nof robotic manipulation tasks."
    },
    "1805.07233": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kaixuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xianzhi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dalin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiwen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zheng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Parallel Recurrent Neural Networks with Convolutional\n  Attentions for Multi-Modality Activity Modeling",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: substantial text overlap with arXiv:1711.07661",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Multimodal features play a key role in wearable sensor-based human activity\nrecognition (HAR). Selecting the most salient features adaptively is a\npromising way to maximize the effectiveness of multimodal sensor data. In this\nregard, we propose a \"collect fully and select wisely\" principle as well as an\ninterpretable parallel recurrent model with convolutional attentions to improve\nthe recognition performance. We first collect modality features and the\nrelations between each pair of features to generate activity frames, and then\nintroduce an attention mechanism to select the most prominent regions from\nactivity frames precisely. The selected frames not only maximize the\nutilization of valid features but also reduce the number of features to be\ncomputed effectively. We further analyze the accuracy and interpretability of\nthe proposed model based on extensive experiments. The results show that our\nmodel achieves competitive performance on two benchmarked datasets and works\nwell in real life scenarios."
    },
    "1801.06689": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Muyesser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Necati Alp"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dunovan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kyle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verstynen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timothy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning model-based strategies in simple environments with hierarchical\n  q-networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent advances in deep learning have allowed artificial agents to rival\nhuman-level performance on a wide range of complex tasks; however, the ability\nof these networks to learn generalizable strategies remains a pressing\nchallenge. This critical limitation is due in part to two factors: the opaque\ninformation representation in deep neural networks and the complexity of the\ntask environments in which they are typically deployed. Here we propose a novel\nHierarchical Q-Network (HQN) motivated by theories of the hierarchical\norganization of the human prefrontal cortex, that attempts to identify lower\ndimensional patterns in the value landscape that can be exploited to construct\nan internal model of rules in simple environments. We draw on combinatorial\ngames, where there exists a single optimal strategy for winning that\ngeneralizes across other features of the game, to probe the strategy\ngeneralization of the HQN and other reinforcement learning (RL) agents using\nvariations of Wythoff's game. Traditional RL approaches failed to reach\nsatisfactory performance on variants of Wythoff's Game; however, the HQN\nlearned heuristic-like strategies that generalized across changes in board\nconfiguration. More importantly, the HQN allowed for transparent inspection of\nthe agent's internal model of the game following training. Our results show how\na biologically inspired hierarchical learner can facilitate learning abstract\nrules to promote robust and flexible action policies in simplified training\nenvironments with clearly delineated optimal strategies."
    },
    "1806.09936": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedreschi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dino"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Giannotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fosca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guidotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Monreale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pappalardo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ruggieri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Salvatore"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Turini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franco"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Open the Black Box Data-Driven Explanation of Black Box Decision Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Black box systems for automated decision making, often based on machine\nlearning over (big) data, map a user's features into a class or a score without\nexposing the reasons why. This is problematic not only for lack of\ntransparency, but also for possible biases hidden in the algorithms, due to\nhuman prejudices and collection artifacts hidden in the training data, which\nmay lead to unfair or wrong decisions. We introduce the local-to-global\nframework for black box explanation, a novel approach with promising early\nresults, which paves the road for a wide spectrum of future developments along\nthree dimensions: (i) the language for expressing explanations in terms of\nhighly expressive logic-based rules, with a statistical and causal\ninterpretation; (ii) the inference of local explanations aimed at revealing the\nlogic of the decision adopted for a specific instance by querying and auditing\nthe black box in the vicinity of the target instance; (iii), the bottom-up\ngeneralization of the many local explanations into simple global ones, with\nalgorithms that optimize the quality and comprehensibility of explanations."
    },
    "1808.08871": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fuge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "B\\'ezierGAN: Automatic Generation of Smooth Curves from Interpretable\n  Low-Dimensional Parameters",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many real-world objects are designed by smooth curves, especially in the\ndomain of aerospace and ship, where aerodynamic shapes (e.g., airfoils) and\nhydrodynamic shapes (e.g., hulls) are designed. To facilitate the design\nprocess of those objects, we propose a deep learning based generative model\nthat can synthesize smooth curves. The model maps a low-dimensional latent\nrepresentation to a sequence of discrete points sampled from a rational\nB\\'ezier curve. We demonstrate the performance of our method in completing both\nsynthetic and real-world generative tasks. Results show that our method can\ngenerate diverse and realistic curves, while preserving consistent shape\nvariation in the latent space, which is favorable for latent space design\noptimization or design space exploration."
    },
    "1804.08069": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tiancheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kyusong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Eskenazi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maxine"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unsupervised Discrete Sentence Representation Learning for Interpretable\n  Neural Dialog Generation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted as a long paper in ACL 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The encoder-decoder dialog model is one of the most prominent methods used to\nbuild dialog systems in complex domains. Yet it is limited because it cannot\noutput interpretable actions as in traditional systems, which hinders humans\nfrom understanding its generation process. We present an unsupervised discrete\nsentence representation learning method that can integrate with any existing\nencoder-decoder dialog models for interpretable response generation. Building\nupon variational autoencoders (VAEs), we present two novel models, DI-VAE and\nDI-VST that improve VAEs and can discover interpretable semantics via either\nauto encoding or context predicting. Our methods have been validated on\nreal-world dialog datasets to discover semantic representations and enhance\nencoder-decoder models with interpretable generation."
    },
    "1811.05106": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sungmin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Park",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David Keetae"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jaehyuk"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Choo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jaegul"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpreting Models by Allowing to Ask",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Questions convey information about the questioner, namely what one does not\nknow. In this paper, we propose a novel approach to allow a learning agent to\nask what it considers as tricky to predict, in the course of producing a final\noutput. By analyzing when and what it asks, we can make our model more\ntransparent and interpretable. We first develop this idea to propose a general\nframework of deep neural networks that can ask questions, which we call asking\nnetworks. A specific architecture and training process for an asking network is\nproposed for the task of colorization, which is an exemplar one-to-many task\nand thus a task where asking questions is helpful in performing the task\naccurately. Our results show that the model learns to generate meaningful\nquestions, asks difficult questions first, and utilizes the provided hint more\nefficiently than baseline models. We conclude that the proposed asking\nframework makes the learning agent reveal its weaknesses, which poses a\npromising new direction in developing interpretable and interactive models."
    },
    "1802.07740": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rabinowitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Neil C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perbet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Frank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "H. Francis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chiyuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Eslami",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S. M. Ali"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Botvinick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Machine Theory of Mind",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "21 pages, 15 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Theory of mind (ToM; Premack & Woodruff, 1978) broadly refers to humans'\nability to represent the mental states of others, including their desires,\nbeliefs, and intentions. We propose to train a machine to build such models\ntoo. We design a Theory of Mind neural network -- a ToMnet -- which uses\nmeta-learning to build models of the agents it encounters, from observations of\ntheir behaviour alone. Through this process, it acquires a strong prior model\nfor agents' behaviour, as well as the ability to bootstrap to richer\npredictions about agents' characteristics and mental states using only a small\nnumber of behavioural observations. We apply the ToMnet to agents behaving in\nsimple gridworld environments, showing that it learns to model random,\nalgorithmic, and deep reinforcement learning agents from varied populations,\nand that it passes classic ToM tasks such as the \"Sally-Anne\" test (Wimmer &\nPerner, 1983; Baron-Cohen et al., 1985) of recognising that others can hold\nfalse beliefs about the world. We argue that this system -- which autonomously\nlearns how to model other agents in its world -- is an important step forward\nfor developing multi-agent AI systems, for building intermediating technology\nfor machine-human interaction, and for advancing the progress on interpretable\nAI."
    },
    "1012.5546": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-12-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gouider",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohamed Salah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Farhat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amine"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mining Multi-Level Frequent Itemsets under Constraints",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI cs.DS",
        "http://arxiv.org/OAI/arXiv/:comments": "20 pages",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68P04, 68Q04, 68T04, 68U04",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.2.4; H.2.8; I.2.6; I.2.4; I.1.2",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Internatinal Journal of Database Theory and Application, Vol. 3,\n  No. 4, PP. 15-35, December, 2010",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Mining association rules is a task of data mining, which extracts knowledge\nin the form of significant implication relation of useful items (objects) from\na database. Mining multilevel association rules uses concept hierarchies, also\ncalled taxonomies and defined as relations of type 'is-a' between objects, to\nextract rules that items belong to different levels of abstraction. These rules\nare more useful, more refined and more interpretable by the user. Several\nalgorithms have been proposed in the literature to discover the multilevel\nassociation rules. In this article, we are interested in the problem of\ndiscovering multi-level frequent itemsets under constraints, involving the user\nin the research process. We proposed a technique for modeling and\ninterpretation of constraints in a context of use of concept hierarchies. Three\napproaches for discovering multi-level frequent itemsets under constraints were\nproposed and discussed: Basic approach, \"Test and Generate\" approach and\nPruning based Approach."
    },
    "1712.06536": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bodin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Malik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carl Henrik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Campbell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Neill D. F."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Nonparametric Inference for Auto-Encoding Variational Bayes",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2017 Workshop on Advances in Approximate Bayesian\n  Inference",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We would like to learn latent representations that are low-dimensional and\nhighly interpretable. A model that has these characteristics is the Gaussian\nProcess Latent Variable Model. The benefits and negative of the GP-LVM are\ncomplementary to the Variational Autoencoder, the former provides interpretable\nlow-dimensional latent representations while the latter is able to handle large\namounts of data and can use non-Gaussian likelihoods. Our inspiration for this\npaper is to marry these two approaches and reap the benefits of both. In order\nto do so we will introduce a novel approximate inference scheme inspired by the\nGP-LVM and the VAE. We show experimentally that the approximation allows the\ncapacity of the generative bottle-neck (Z) of the VAE to be arbitrarily large\nwithout losing a highly interpretable representation, allowing reconstruction\nquality to be unlimited by Z at the same time as a low-dimensional space can be\nused to perform ancestral sampling from as well as a means to reason about the\nembedded data."
    },
    "1811.07253": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yijun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William Yang"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Quantifying Uncertainties in Natural Language Processing Tasks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear at AAAI 2019",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Reliable uncertainty quantification is a first step towards building\nexplainable, transparent, and accountable artificial intelligent systems.\nRecent progress in Bayesian deep learning has made such quantification\nrealizable. In this paper, we propose novel methods to study the benefits of\ncharacterizing model and data uncertainties for natural language processing\n(NLP) tasks. With empirical experiments on sentiment analysis, named entity\nrecognition, and language modeling using convolutional and recurrent neural\nnetwork models, we show that explicitly modeling uncertainties is not only\nnecessary to measure output confidence levels, but also useful at enhancing\nmodel performances in various NLP tasks."
    },
    "1512.07056": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-12-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-02-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bertens",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vreeken",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jilles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Siebes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arno"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Keeping it Short and Simple: Summarising Complex Event Sequences with\n  Multivariate Patterns",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study how to obtain concise descriptions of discrete multivariate\nsequential data. In particular, how to do so in terms of rich multivariate\nsequential patterns that can capture potentially highly interesting\n(cor)relations between sequences. To this end we allow our pattern language to\nspan over the domains (alphabets) of all sequences, allow patterns to overlap\ntemporally, as well as allow for gaps in their occurrences.\n  We formalise our goal by the Minimum Description Length principle, by which\nour objective is to discover the set of patterns that provides the most\nsuccinct description of the data. To discover high-quality pattern sets\ndirectly from data, we introduce DITTO, a highly efficient algorithm that\napproximates the ideal result very well.\n  Experiments show that DITTO correctly discovers the patterns planted in\nsynthetic data. Moreover, it scales favourably with the length of the data, the\nnumber of attributes, the alphabet sizes. On real data, ranging from sensor\nnetworks to annotated text, DITTO discovers easily interpretable summaries that\nprovide clear insight in both the univariate and multivariate structure."
    },
    "1706.01991": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-06-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Tran",
                "http://arxiv.org/OAI/arXiv/:forenames": "Son N."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unsupervised Neural-Symbolic Integration",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Symbolic has been long considered as a language of human intelligence while\nneural networks have advantages of robust computation and dealing with noisy\ndata. The integration of neural-symbolic can offer better learning and\nreasoning while providing a means for interpretability through the\nrepresentation of symbolic knowledge. Although previous works focus intensively\non supervised feedforward neural networks, little has been done for the\nunsupervised counterparts. In this paper we show how to integrate symbolic\nknowledge into unsupervised neural networks. We exemplify our approach with\nknowledge in different forms, including propositional logic for DNA promoter\nprediction and first-order logic for understanding family relationship."
    },
    "1604.02416": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-03-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-06-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khajah",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lindsey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mozer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael C."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "How deep is knowledge tracing?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In theoretical cognitive science, there is a tension between highly\nstructured models whose parameters have a direct psychological interpretation\nand highly complex, general-purpose models whose parameters and representations\nare difficult to interpret. The former typically provide more insight into\ncognition but the latter often perform better. This tension has recently\nsurfaced in the realm of educational data mining, where a deep learning\napproach to predicting students' performance as they work through a series of\nexercises---termed deep knowledge tracing or DKT---has demonstrated a stunning\nperformance advantage over the mainstay of the field, Bayesian knowledge\ntracing or BKT. In this article, we attempt to understand the basis for DKT's\nadvantage by considering the sources of statistical regularity in the data that\nDKT can leverage but which BKT cannot. We hypothesize four forms of regularity\nthat BKT fails to exploit: recency effects, the contextualized trial sequence,\ninter-skill similarity, and individual variation in ability. We demonstrate\nthat when BKT is extended to allow it more flexibility in modeling statistical\nregularities---using extensions previously proposed in the literature---BKT\nachieves a level of performance indistinguishable from that of DKT. We argue\nthat while DKT is a powerful, useful, general-purpose framework for modeling\nstudent learning, its gains do not come from the discovery of novel\nrepresentations---the fundamental advantage of deep learning. To answer the\nquestion posed in our title, knowledge tracing may be a domain that does not\nrequire `depth'; shallow models like BKT can perform just as well and offer us\ngreater interpretability and explanatory power."
    },
    "1706.00400": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Siddharth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "N."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paige",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brooks"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van de Meent",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jan-Willem"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Desmaison",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alban"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goodman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Noah D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wood",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Frank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Torr",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philip H. S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Disentangled Representations with Semi-Supervised Deep\n  Generative Models",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted for publication at NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Variational autoencoders (VAEs) learn representations of data by jointly\ntraining a probabilistic encoder and decoder network. Typically these models\nencode all features of the data into a single variable. Here we are interested\nin learning disentangled representations that encode distinct aspects of the\ndata into separate variables. We propose to learn such representations using\nmodel architectures that generalise from standard VAEs, employing a general\ngraphical model structure in the encoder and decoder. This allows us to train\npartially-specified models that make relatively strong assumptions about a\nsubset of interpretable variables and rely on the flexibility of neural\nnetworks to learn representations for the remaining variables. We further\ndefine a general objective for semi-supervised learning in this model class,\nwhich can be approximated using an importance sampling procedure. We evaluate\nour framework's ability to learn disentangled representations, both by\nqualitative exploration of its generative capacity, and quantitative evaluation\nof its discriminative ability on a variety of models and datasets."
    },
    "1302.3560": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-02-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bonet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Blai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Geffner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hector"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Arguing for Decisions: A Qualitative Model of Decision Making",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1996-PG-98-105",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We develop a qualitative model of decision making with two aims: to describe\nhow people make simple decisions and to enable computer programs to do the\nsame. Current approaches based on Planning or Decisions Theory either ignore\nuncertainty and tradeoffs, or provide languages and algorithms that are too\ncomplex for this task. The proposed model provides a language based on rules, a\nsemantics based on high probabilities and lexicographical preferences, and a\ntransparent decision procedure where reasons for and against decisions\ninteract. The model is no substitude for Decision Theory, yet for decisions\nthat people find easy to explain it may provide an appealing alternative."
    },
    "1807.00154": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Conati",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cristina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Porayska-Pomsta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kaska"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mavrikis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manolis"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "AI in Education needs interpretable machine learning: Lessons from Open\n  Learner Modelling",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockholm, Sweden",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Interpretability of the underlying AI representations is a key raison\nd'\\^{e}tre for Open Learner Modelling (OLM) -- a branch of Intelligent Tutoring\nSystems (ITS) research. OLMs provide tools for 'opening' up the AI models of\nlearners' cognition and emotions for the purpose of supporting human learning\nand teaching. Over thirty years of research in ITS (also known as AI in\nEducation) produced important work, which informs about how AI can be used in\nEducation to best effects and, through the OLM research, what are the necessary\nconsiderations to make it interpretable and explainable for the benefit of\nlearning. We argue that this work can provide a valuable starting point for a\nframework of interpretable AI, and as such is of relevance to the application\nof both knowledge-based and machine learning systems in other high-stakes\ncontexts, beyond education."
    },
    "1811.04350": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gyujeong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hyun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Minsung"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simyung"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kwak",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nojun"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Governing Agent's Efficacy: Action-Conditional $\\beta$-VAE for\n  Deep Transparent Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We tackle the blackbox issue of deep neural networks in the settings of\nreinforcement learning (RL) where neural agents learn towards maximizing reward\ngains in an uncontrollable way. Such learning approach is risky when the\ninteracting environment includes an expanse of state space because it is then\nalmost impossible to foresee all unwanted outcomes and penalize them with\nnegative rewards beforehand. Unlike reverse analysis of learned neural features\nfrom previous works, our proposed method \\nj{tackles the blackbox issue by\nencouraging} an RL policy network to learn interpretable latent features\nthrough an implementation of a disentangled representation learning method.\nToward this end, our method allows an RL agent to understand self-efficacy by\ndistinguishing its influences from uncontrollable environmental factors, which\nclosely resembles the way humans understand their scenes. Our experimental\nresults show that the learned latent factors not only are interpretable, but\nalso enable modeling the distribution of entire visited state space with a\nspecific action condition. We have experimented that this characteristic of the\nproposed structure can lead to ex post facto governance for desired behaviors\nof RL agents."
    },
    "1806.01756": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                "http://arxiv.org/OAI/arXiv/:forenames": "Daniel T"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Concept-Oriented Deep Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Concepts are the foundation of human deep learning, understanding, and\nknowledge integration and transfer. We propose concept-oriented deep learning\n(CODL) which extends (machine) deep learning with concept representations and\nconceptual understanding capability. CODL addresses some of the major\nlimitations of deep learning: interpretability, transferability, contextual\nadaptation, and requirement for lots of labeled training data. We discuss the\nmajor aspects of CODL including concept graph, concept representations, concept\nexemplars, and concept representation learning systems supporting incremental\nand continual learning."
    },
    "1806.07552": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tomsett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Braines",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dave"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harborne",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Preece",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chakraborty",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Supriyo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable to Whom? A Role-based Model for Analyzing Interpretable\n  Machine Learning Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockholm, Sweden",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Several researchers have argued that a machine learning system's\ninterpretability should be defined in relation to a specific agent or task: we\nshould not ask if the system is interpretable, but to whom is it interpretable.\nWe describe a model intended to help answer this question, by identifying\ndifferent roles that agents can fulfill in relation to the machine learning\nsystem. We illustrate the use of our model in a variety of scenarios, exploring\nhow an agent's role influences its goals, and the implications for defining\ninterpretability. Finally, we make suggestions for how our model could be\nuseful to interpretability researchers, system developers, and regulatory\nbodies auditing machine learning systems."
    },
    "1809.11044": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tacchetti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "H. Francis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mediano",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pedro A. M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zambaldi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vinicius"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rabinowitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Neil C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Graepel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thore"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Botvinick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Battaglia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter W."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Relational Forward Models for Multi-Agent Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.MA stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The behavioral dynamics of multi-agent systems have a rich and orderly\nstructure, which can be leveraged to understand these systems, and to improve\nhow artificial agents learn to operate in them. Here we introduce Relational\nForward Models (RFM) for multi-agent learning, networks that can learn to make\naccurate predictions of agents' future behavior in multi-agent environments.\nBecause these models operate on the discrete entities and relations present in\nthe environment, they produce interpretable intermediate representations which\noffer insights into what drives agents' behavior, and what events mediate the\nintensity and valence of social interactions. Furthermore, we show that\nembedding RFM modules inside agents results in faster learning systems compared\nto non-augmented baselines. As more and more of the autonomous systems we\ndevelop and interact with become multi-agent in nature, developing richer\nanalysis tools for characterizing how and why agents make decisions is\nincreasingly necessary. Moreover, developing artificial agents that quickly and\nsafely learn to coordinate with one another, and with humans in shared\nenvironments, is crucial."
    },
    "1401.3432": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-01-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Laet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tinne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Schutter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bruyninckx",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Herman"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Rigorously Bayesian Beam Model and an Adaptive Full Scan Model for\n  Range Finders in Dynamic Environments",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 33, pages\n  179-222, 2008",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.2540",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper proposes and experimentally validates a Bayesian network model of\na range finder adapted to dynamic environments. All modeling assumptions are\nrigorously explained, and all model parameters have a physical interpretation.\nThis approach results in a transparent and intuitive model. With respect to the\nstate of the art beam model this paper: (i) proposes a different functional\nform for the probability of range measurements caused by unmodeled objects,\n(ii) intuitively explains the discontinuity encountered in te state of the art\nbeam model, and (iii) reduces the number of model parameters, while maintaining\nthe same representational power for experimental data. The proposed beam model\nis called RBBM, short for Rigorously Bayesian Beam Model. A maximum likelihood\nand a variational Bayesian estimator (both based on expectation-maximization)\nare proposed to learn the model parameters.\n  Furthermore, the RBBM is extended to a full scan model in two steps: first,\nto a full scan model for static environments and next, to a full scan model for\ngeneral, dynamic environments. The full scan model accounts for the dependency\nbetween beams and adapts to the local sample density when using a particle\nfilter. In contrast to Gaussian-based state of the art models, the proposed\nfull scan model uses a sample-based approximation. This sample-based\napproximation enables handling dynamic environments and capturing\nmulti-modality, which occurs even in simple static environments."
    },
    "1707.04943": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mayo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Frank",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eibe"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving Naive Bayes for Regression with Optimised Artificial Surrogate\n  Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Can we evolve better training data for machine learning algorithms? To\ninvestigate this question we use population-based optimisation algorithms to\ngenerate artificial surrogate training data for naive Bayes for regression. We\ndemonstrate that the generalisation performance of naive Bayes for regression\nmodels is enhanced by training them on the artificial data as opposed to the\nreal data. These results are important for two reasons. Firstly, naive Bayes\nmodels are simple and interpretable but frequently underperform compared to\nmore complex \"black box\" models, and therefore new methods of enhancing\naccuracy are called for. Secondly, the idea of using the real training data\nindirectly in the construction of the artificial training data, as opposed to\ndirectly for model training, is a novel twist on the usual machine learning\nparadigm."
    },
    "1708.06846": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Choi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arthur"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Darwiche",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adnan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Relaxing Determinism in Arithmetic Circuits",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings of the Thirty-fourth International Conference on\n  Machine Learning (ICML)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The past decade has seen a significant interest in learning tractable\nprobabilistic representations. Arithmetic circuits (ACs) were among the first\nproposed tractable representations, with some subsequent representations being\ninstances of ACs with weaker or stronger properties. In this paper, we provide\na formal basis under which variants on ACs can be compared, and where the\nprecise roles and semantics of their various properties can be made more\ntransparent. This allows us to place some recent developments on ACs in a\nclearer perspective and to also derive new results for ACs. This includes an\nexponential separation between ACs with and without determinism; completeness\nand incompleteness results; and tractability results (or lack thereof) when\ncomputing most probable explanations (MPEs)."
    },
    "1803.02100": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hastie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Helen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lohan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Katrin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chantler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mike"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Robb",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamoorthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subramanian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Petrick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ron"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vijayakumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sethu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lane",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The ORCA Hub: Explainable Offshore Robotics through Intelligent\n  Interfaces",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC cs.RO",
        "http://arxiv.org/OAI/arXiv/:comments": "2 pages. Peer reviewed position paper accepted in the Explainable\n  Robotic Systems Workshop, ACM Human-Robot Interaction conference, March 2018,\n  Chicago, IL USA",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.9; H.5.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present the UK Robotics and Artificial Intelligence Hub for Offshore\nRobotics for Certification of Assets (ORCA Hub), a 3.5 year EPSRC funded,\nmulti-site project. The ORCA Hub vision is to use teams of robots and\nautonomous intelligent systems (AIS) to work on offshore energy platforms to\nenable cheaper, safer and more efficient working practices. The ORCA Hub will\nresearch, integrate, validate and deploy remote AIS solutions that can operate\nwith existing and future offshore energy assets and sensors, interacting safely\nin autonomous or semi-autonomous modes in complex and cluttered environments,\nco-operating with remote operators. The goal is that through the use of such\nrobotic systems offshore, the need for personnel will decrease. To enable this\nto happen, the remote operator will need a high level of situation awareness\nand key to this is the transparency of what the autonomous systems are doing\nand why. This increased transparency will facilitate a trusting relationship,\nwhich is particularly key in high-stakes, hazardous situations."
    },
    "1709.10256": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fox",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maria"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Long",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Magazzeni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniele"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Planning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at the IJCAI-17 workshop on Explainable AI\n  (http://home.earthlink.net/~dwaha/research/meetings/ijcai17-xai/). Melbourne,\n  August 2017",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2; I.2.9",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As AI is increasingly being adopted into application solutions, the challenge\nof supporting interaction with humans is becoming more apparent. Partly this is\nto support integrated working styles, in which humans and intelligent systems\ncooperate in problem-solving, but also it is a necessary step in the process of\nbuilding trust as humans migrate greater responsibility to such systems. The\nchallenge is to find effective ways to communicate the foundations of AI-driven\nbehaviour, when the algorithms that drive it are far from transparent to\nhumans. In this paper we consider the opportunities that arise in AI planning,\nexploiting the model-based representations that form a familiar and common\nbasis for communication with users, while acknowledging the gap between\nplanning algorithms and human problem-solving."
    },
    "1709.04517": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chakraborti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tathagata"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fadnis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kshitij P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Talamadupula",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kartik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dholakia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mishal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Srivastava",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Biplav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kephart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeffrey O."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bellamy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rachel K. E."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Visualizations for an Explainable Planning Agent",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "PREVIOUSLY Mr. Jones -- Towards a Proactive Smart Room Orchestrator\n  (appeared in AAAI 2017 Fall Symposium on Human-Agent Groups)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we report on the visualization capabilities of an Explainable\nAI Planning (XAIP) agent that can support human in the loop decision making.\nImposing transparency and explainability requirements on such agents is\nespecially important in order to establish trust and common ground with the\nend-to-end automated planning system. Visualizing the agent's internal\ndecision-making processes is a crucial step towards achieving this. This may\ninclude externalizing the \"brain\" of the agent -- starting from its sensory\ninputs, to progressively higher order decisions made by it in order to drive\nits planning components. We also show how the planner can bootstrap on the\nlatest techniques in explainable planning to cast plan visualization as a plan\nexplanation problem, and thus provide concise model-based visualization of its\nplans. We demonstrate these functionalities in the context of the automated\nplanning components of a smart assistant in an instrumented meeting space."
    },
    "1803.06092": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guangyu Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ganichev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Igor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiao-Jing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shlens",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sussillo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A dataset and architecture for visual reasoning with a working memory",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A vexing problem in artificial intelligence is reasoning about events that\noccur in complex, changing visual stimuli such as in video analysis or game\nplay. Inspired by a rich tradition of visual reasoning and memory in cognitive\npsychology and neuroscience, we developed an artificial, configurable visual\nquestion and answer dataset (COG) to parallel experiments in humans and\nanimals. COG is much simpler than the general problem of video analysis, yet it\naddresses many of the problems relating to visual and logical reasoning and\nmemory -- problems that remain challenging for modern deep learning\narchitectures. We additionally propose a deep learning architecture that\nperforms competitively on other diagnostic VQA datasets (i.e. CLEVR) as well as\neasy settings of the COG dataset. However, several settings of COG result in\ndatasets that are progressively more challenging to learn. After training, the\nnetwork can zero-shot generalize to many new tasks. Preliminary analyses of the\nnetwork architectures trained on COG demonstrate that the network accomplishes\nthe task in a manner interpretable to humans."
    },
    "1704.00260": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tanmay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shih",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Saurabh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hoiem",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Aligned Image-Word Representations Improve Inductive Transfer Across\n  Vision-Language Tasks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted in ICCV 2017. The arxiv version has an extra analysis on\n  correlation with human attention",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "An important goal of computer vision is to build systems that learn visual\nrepresentations over time that can be applied to many tasks. In this paper, we\ninvestigate a vision-language embedding as a core representation and show that\nit leads to better cross-task transfer than standard multi-task learning. In\nparticular, the task of visual recognition is aligned to the task of visual\nquestion answering by forcing each to use the same word-region embeddings. We\nshow this leads to greater inductive transfer from recognition to VQA than\nstandard multitask learning. Visual recognition also improves, especially for\ncategories that have relatively few recognition training labels but appear\noften in the VQA setting. Thus, our paper takes a small step towards creating\nmore general vision systems by showing the benefit of interpretable, flexible,\nand trainable core representations."
    },
    "1809.09419": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guzdial",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Reno",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smith",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gillian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riedl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable PCGML via Game Design Patterns",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 3 figures, Fifth Experimental AI in Games Workshop",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Procedural content generation via Machine Learning (PCGML) is the umbrella\nterm for approaches that generate content for games via machine learning. One\nof the benefits of PCGML is that, unlike search or grammar-based PCG, it does\nnot require hand authoring of initial content or rules. Instead, PCGML relies\non existing content and black box models, which can be difficult to tune or\ntweak without expert knowledge. This is especially problematic when a human\ndesigner needs to understand how to manipulate their data or models to achieve\ndesired results. We present an approach to Explainable PCGML via Design\nPatterns in which the design patterns act as a vocabulary and mode of\ninteraction between user and model. We demonstrate that our technique\noutperforms non-explainable versions of our system in interactions with five\nexpert designers, four of whom lack any machine learning expertise."
    },
    "1003.5899": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-03-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Patyk",
                "http://arxiv.org/OAI/arXiv/:forenames": "Agnieszka"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Geometric Algebra Model of Distributed Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages, 19 figures",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/978-1-84996-108-0_19",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Formalism based on GA is an alternative to distributed representation models\ndeveloped so far --- Smolensky's tensor product, Holographic Reduced\nRepresentations (HRR) and Binary Spatter Code (BSC). Convolutions are replaced\nby geometric products, interpretable in terms of geometry which seems to be the\nmost natural language for visualization of higher concepts. This paper recalls\nthe main ideas behind the GA model and investigates recognition test results\nusing both inner product and a clipped version of matrix representation. The\ninfluence of accidental blade equality on recognition is also studied. Finally,\nthe efficiency of the GA model is compared to that of previously developed\nmodels."
    },
    "1806.05502": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fuchs",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fabian B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Groth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oliver"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kosiorek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bewley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wulfmeier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Markus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vedaldi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Posner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ingmar"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Neural Stethoscopes: Unifying Analytic, Auxiliary and Adversarial\n  Network Probing",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Model interpretability and systematic, targeted model adaptation present\ncentral tenets in machine learning for addressing limited or biased datasets.\nIn this paper, we introduce neural stethoscopes as a framework for quantifying\nthe degree of importance of specific factors of influence in deep networks as\nwell as for actively promoting and suppressing information as appropriate. In\ndoing so we unify concepts from multitask learning as well as training with\nauxiliary and adversarial losses. We showcase the efficacy of neural\nstethoscopes in an intuitive physics domain. Specifically, we investigate the\nchallenge of visually predicting stability of block towers and demonstrate that\nthe network uses visual cues which makes it susceptible to biases in the\ndataset. Through the use of stethoscopes we interrogate the accessibility of\nspecific information throughout the network stack and show that we are able to\nactively de-bias network predictions as well as enhance performance via\nsuitable auxiliary and adversarial stethoscope losses."
    },
    "1809.02193": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Campero",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andres"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pareja",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aldo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Klinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riedel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Logical Rule Induction and Theory Learning Using Neural Theorem Proving",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A hallmark of human cognition is the ability to continually acquire and\ndistill observations of the world into meaningful, predictive theories. In this\npaper we present a new mechanism for logical theory acquisition which takes a\nset of observed facts and learns to extract from them a set of logical rules\nand a small set of core facts which together entail the observations. Our\napproach is neuro-symbolic in the sense that the rule pred- icates and core\nfacts are given dense vector representations. The rules are applied to the core\nfacts using a soft unification procedure to infer additional facts. After k\nsteps of forward inference, the consequences are compared to the initial\nobservations and the rules and core facts are then encouraged towards\nrepresentations that more faithfully generate the observations through\ninference. Our approach is based on a novel neural forward-chaining\ndifferentiable rule induction network. The rules are interpretable and learned\ncompositionally from their predicates, which may be invented. We demonstrate\nthe efficacy of our approach on a variety of ILP rule induction and domain\ntheory learning datasets."
    },
    "1802.02892": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kiela",
                    "http://arxiv.org/OAI/arXiv/:forenames": "D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grave",
                    "http://arxiv.org/OAI/arXiv/:forenames": "E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Joulin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mikolov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "T."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficient Large-Scale Multi-Modal Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at AAAI-18, 7 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While the incipient internet was largely text-based, the modern digital world\nis becoming increasingly multi-modal. Here, we examine multi-modal\nclassification where one modality is discrete, e.g. text, and the other is\ncontinuous, e.g. visual representations transferred from a convolutional neural\nnetwork. In particular, we focus on scenarios where we have to be able to\nclassify large quantities of data quickly. We investigate various methods for\nperforming multi-modal fusion and analyze their trade-offs in terms of\nclassification accuracy and computational efficiency. Our findings indicate\nthat the inclusion of continuous information improves performance over\ntext-only on a range of multi-modal classification tasks, even with simple\nfusion methods. In addition, we experiment with discretizing the continuous\nfeatures in order to speed up and simplify the fusion process even further. Our\nresults show that fusion with discretized features outperforms text-only\nclassification, at a fraction of the computational cost of full multi-modal\nfusion, with the additional benefit of improved interpretability."
    },
    "1802.00682": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Narayanan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Menaka"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emily"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "He",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeffrey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Been"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gershman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Doshi-Velez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Finale"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "How do Humans Understand Explanations from Machine Learning Systems? An\n  Evaluation of the Human-Interpretability of Explanation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent years have seen a boom in interest in machine learning systems that\ncan provide a human-understandable rationale for their predictions or\ndecisions. However, exactly what kinds of explanation are truly\nhuman-interpretable remains poorly understood. This work advances our\nunderstanding of what makes explanations interpretable in the specific context\nof verification. Suppose we have a machine learning system that predicts X, and\nwe provide rationale for this prediction X. Given an input, an explanation, and\nan output, is the output consistent with the input and the supposed rationale?\nVia a series of user-studies, we identify what kinds of increases in complexity\nhave the greatest effect on the time it takes for humans to verify the\nrationale, and which seem relatively insensitive."
    },
    "1805.11535": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Luu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anh Tuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siu Cheung"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "CoupleNet: Paying Attention to Couples with Coupled Attention for\n  Relationship Recommendation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at ICWSM 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Dating and romantic relationships not only play a huge role in our personal\nlives but also collectively influence and shape society. Today, many romantic\npartnerships originate from the Internet, signifying the importance of\ntechnology and the web in modern dating. In this paper, we present a text-based\ncomputational approach for estimating the relationship compatibility of two\nusers on social media. Unlike many previous works that propose reciprocal\nrecommender systems for online dating websites, we devise a distant supervision\nheuristic to obtain real world couples from social platforms such as Twitter.\nOur approach, the CoupleNet is an end-to-end deep learning based estimator that\nanalyzes the social profiles of two users and subsequently performs a\nsimilarity match between the users. Intuitively, our approach performs both\nuser profiling and match-making within a unified end-to-end framework.\nCoupleNet utilizes hierarchical recurrent neural models for learning\nrepresentations of user profiles and subsequently coupled attention mechanisms\nto fuse information aggregated from two users. To the best of our knowledge,\nour approach is the first data-driven deep learning approach for our novel\nrelationship recommendation problem. We benchmark our CoupleNet against several\nmachine learning and deep learning baselines. Experimental results show that\nour approach outperforms all approaches significantly in terms of precision.\nQualitative analysis shows that our model is capable of also producing\nexplainable results to users."
    },
    "1807.07255": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-07-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Can"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Explainable and Controllable Open Domain Dialogue Generation\n  with Dialogue Acts",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "The paper is also available on OpenReview of ICLR 2018\n  (https://openreview.net/forum?id=Bym0cU1CZ)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study open domain dialogue generation with dialogue acts designed to\nexplain how people engage in social chat. To imitate human behavior, we propose\nmanaging the flow of human-machine interactions with the dialogue acts as\npolicies. The policies and response generation are jointly learned from\nhuman-human conversations, and the former is further optimized with a\nreinforcement learning approach. With the dialogue acts, we achieve significant\nimprovement over state-of-the-art methods on response quality for given\ncontexts and dialogue length in both machine-machine simulation and\nhuman-machine conversation."
    },
    "1810.12366": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chandrasekaran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Prabhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Viraj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yadav",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Deshraj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chattopadhyay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prithvijit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Do Explanations make VQA Models more Predictable to a Human?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "EMNLP 2018. 16 pages, 11 figures. Content overlaps with \"It Takes Two\n  to Tango: Towards Theory of AI's Mind\" (arXiv:1704.00717)",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A rich line of research attempts to make deep neural networks more\ntransparent by generating human-interpretable 'explanations' of their decision\nprocess, especially for interactive tasks like Visual Question Answering (VQA).\nIn this work, we analyze if existing explanations indeed make a VQA model --\nits responses as well as failures -- more predictable to a human. Surprisingly,\nwe find that they do not. On the other hand, we find that human-in-the-loop\napproaches that treat the model as a black-box do."
    },
    "1703.08840": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunzhu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiaming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ermon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefano"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The goal of imitation learning is to mimic expert behavior without access to\nan explicit reward signal. Expert demonstrations provided by humans, however,\noften show significant variability due to latent factors that are typically not\nexplicitly modeled. In this paper, we propose a new algorithm that can infer\nthe latent structure of expert demonstrations in an unsupervised way. Our\nmethod, built on top of Generative Adversarial Imitation Learning, can not only\nimitate complex behaviors, but also learn interpretable and meaningful\nrepresentations of complex behavioral data, including visual demonstrations. In\nthe driving domain, we show that a model learned from human demonstrations is\nable to both accurately reproduce a variety of behaviors and accurately\nanticipate human actions using raw visual inputs. Compared with various\nbaselines, our method can better capture the latent structure underlying expert\ndemonstrations, often recovering semantically meaningful factors of variation\nin the data."
    },
    "1610.02683": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aubakirova",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Malika"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bansal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohit"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpreting Neural Networks to Improve Politeness Comprehension",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear at EMNLP 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present an interpretable neural network approach to predicting and\nunderstanding politeness in natural language requests. Our models are based on\nsimple convolutional neural networks directly on raw text, avoiding any manual\nidentification of complex sentiment or syntactic features, while performing\nbetter than such feature-based models from previous work. More importantly, we\nuse the challenging task of politeness prediction as a testbed to next present\na much-needed understanding of what these successful networks are actually\nlearning. For this, we present several network visualizations based on\nactivation clusters, first derivative saliency, and embedding space\ntransformations, helping us automatically identify several subtle linguistics\nmarkers of politeness theories. Further, this analysis reveals multiple novel,\nhigh-scoring politeness strategies which, when added back as new features,\nreduce the accuracy gap between the original featurized system and the neural\nmodel, thus providing a clear quantitative interpretation of the success of\nthese neural networks."
    },
    "1611.09434": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-06-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Foerster",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jakob N."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gilmer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Justin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chorowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sohl-Dickstein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jascha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sussillo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Input Switched Affine Networks: An RNN Architecture Designed for\n  Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "ICLR 2107 submission: https://openreview.net/forum?id=H1MjAnqxg",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There exist many problem domains where the interpretability of neural network\nmodels is essential for deployment. Here we introduce a recurrent architecture\ncomposed of input-switched affine transformations - in other words an RNN\nwithout any explicit nonlinearities, but with input-dependent recurrent\nweights. This simple form allows the RNN to be analyzed via straightforward\nlinear methods: we can exactly characterize the linear contribution of each\ninput to the model predictions; we can use a change-of-basis to disentangle\ninput, output, and computational hidden unit subspaces; we can fully\nreverse-engineer the architecture's solution to a simple task. Despite this\nease of interpretation, the input switched affine network achieves reasonable\nperformance on a text modeling tasks, and allows greater computational\nefficiency than networks with standard nonlinearities."
    },
    "1707.03377": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-11",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-07-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qunzhi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sornette",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Didier"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning like humans with Deep Symbolic Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cond-mat.dis-nn cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce the Deep Symbolic Network (DSN) model, which aims at becoming\nthe white-box version of Deep Neural Networks (DNN). The DSN model provides a\nsimple, universal yet powerful structure, similar to DNN, to represent any\nknowledge of the world, which is transparent to humans. The conjecture behind\nthe DSN model is that any type of real world objects sharing enough common\nfeatures are mapped into human brains as a symbol. Those symbols are connected\nby links, representing the composition, correlation, causality, or other\nrelationships between them, forming a deep, hierarchical symbolic network\nstructure. Powered by such a structure, the DSN model is expected to learn like\nhumans, because of its unique characteristics. First, it is universal, using\nthe same structure to store any knowledge. Second, it can learn symbols from\nthe world and construct the deep symbolic networks automatically, by utilizing\nthe fact that real world objects have been naturally separated by\nsingularities. Third, it is symbolic, with the capacity of performing causal\ndeduction and generalization. Fourth, the symbols and the links between them\nare transparent to us, and thus we will know what it has learned or not - which\nis the key for the security of an AI system. Fifth, its transparency enables it\nto learn with relatively small data. Sixth, its knowledge can be accumulated.\nLast but not least, it is more friendly to unsupervised learning than DNN. We\npresent the details of the model, the algorithm powering its automatic learning\nability, and describe its usefulness in different use cases. The purpose of\nthis paper is to generate broad interest to develop it within an open source\nproject centered on the Deep Symbolic Network (DSN) model towards the\ndevelopment of general AI."
    },
    "1705.07095": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kuzelka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ondrej"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Davis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jesse"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schockaert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steven"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Induction of Interpretable Possibilistic Logic Theories from Relational\n  Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Longer version of a paper appearing in IJCAI 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The field of Statistical Relational Learning (SRL) is concerned with learning\nprobabilistic models from relational data. Learned SRL models are typically\nrepresented using some kind of weighted logical formulas, which make them\nconsiderably more interpretable than those obtained by e.g. neural networks. In\npractice, however, these models are often still difficult to interpret\ncorrectly, as they can contain many formulas that interact in non-trivial ways\nand weights do not always have an intuitive meaning. To address this, we\npropose a new SRL method which uses possibilistic logic to encode relational\nmodels. Learned models are then essentially stratified classical theories,\nwhich explicitly encode what can be derived with a given level of certainty.\nCompared to Markov Logic Networks (MLNs), our method is faster and produces\nconsiderably more interpretable models."
    },
    "1805.02856": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luu Anh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siu Cheung"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Reasoning with Sarcasm by Reading In-between",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to ACL2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Sarcasm is a sophisticated speech act which commonly manifests on social\ncommunities such as Twitter and Reddit. The prevalence of sarcasm on the social\nweb is highly disruptive to opinion mining systems due to not only its tendency\nof polarity flipping but also usage of figurative language. Sarcasm commonly\nmanifests with a contrastive theme either between positive-negative sentiments\nor between literal-figurative scenarios. In this paper, we revisit the notion\nof modeling contrast in order to reason with sarcasm. More specifically, we\npropose an attention-based neural model that looks in-between instead of\nacross, enabling it to explicitly model contrast and incongruity. We conduct\nextensive experiments on six benchmark datasets from Twitter, Reddit and the\nInternet Argument Corpus. Our proposed model not only achieves state-of-the-art\nperformance on all datasets but also enjoys improved interpretability."
    },
    "1710.05720": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rehwald",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ibrahim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amjad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Beckers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kristian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pretschner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "ACCBench: A Framework for Comparing Causality Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.PF cs.SE",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings CREST 2017, arXiv:1710.02770",
        "http://arxiv.org/OAI/arXiv/:proxy": "EPTCS",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "EPTCS 259, 2017, pp. 16-30",
        "http://arxiv.org/OAI/arXiv/:doi": "10.4204/EPTCS.259.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Modern socio-technical systems are increasingly complex. A fundamental\nproblem is that the borders of such systems are often not well-defined\na-priori, which among other problems can lead to unwanted behavior during\nruntime. Ideally, unwanted behavior should be prevented. If this is not\npossible the system shall at least be able to help determine potential cause(s)\na-posterori, identify responsible parties and make them accountable for their\nbehavior. Recently, several algorithms addressing these concepts have been\nproposed. However, the applicability of the corresponding approaches,\nspecifically their effectiveness and performance, is mostly unknown. Therefore,\nin this paper, we propose ACCBench, a benchmark tool that allows to compare and\nevaluate causality algorithms under a consistent setting. Furthermore, we\ncontribute an implementation of the two causality algorithms by G\\\"o{\\ss}ler\nand Metayer and G\\\"o{\\ss}ler and Astefanoaei as well as of a policy compliance\napproach based on some concepts of Main et al. Lastly, we conduct a case study\nof an Intelligent Door Control System, which exposes concrete strengths and\nweaknesses of all algorithms under different aspects. In the course of this, we\nshow that the effectiveness of the algorithms in terms of cause detection as\nwell as their performance differ to some extent. In addition, our analysis\nreports on some qualitative aspects that should be considered when evaluating\neach algorithm. For example, the human effort needed to configure the algorithm\nand model the use case is analyzed."
    },
    "1711.09602": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raghu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniruddh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Komorowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthieu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ahmed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Imran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Celi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Szolovits",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghassemi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marzyeh"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Reinforcement Learning for Sepsis Treatment",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Extensions on earlier work (arXiv:1705.08422). Accepted at workshop\n  on Machine Learning For Health at the conference on Neural Information\n  Processing Systems, 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Sepsis is a leading cause of mortality in intensive care units and costs\nhospitals billions annually. Treating a septic patient is highly challenging,\nbecause individual patients respond very differently to medical interventions\nand there is no universally agreed-upon treatment for sepsis. In this work, we\npropose an approach to deduce treatment policies for septic patients by using\ncontinuous state-space models and deep reinforcement learning. Our model learns\nclinically interpretable treatment policies, similar in important aspects to\nthe treatment policies of physicians. The learned policies could be used to aid\nintensive care clinicians in medical decision making and improve the likelihood\nof patient survival."
    },
    "1611.07579": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameer"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ribeiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco Tulio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guestrin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Programs as Black-Box Explanations",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent work in model-agnostic explanations of black-box machine learning has\ndemonstrated that interpretability of complex models does not have to come at\nthe cost of accuracy or model flexibility. However, it is not clear what kind\nof explanations, such as linear models, decision trees, and rule lists, are the\nappropriate family to consider, and different tasks and models may benefit from\ndifferent kinds of explanations. Instead of picking a single family of\nrepresentations, in this work we propose to use \"programs\" as model-agnostic\nexplanations. We show that small programs can be expressive yet intuitive as\nexplanations, and generalize over a number of existing interpretable families.\nWe propose a prototype program induction method based on simulated annealing\nthat approximates the local behavior of black-box classifiers around a specific\nprediction using random perturbations. Finally, we present preliminary\napplication on small datasets and show that the generated explanations are\nintuitive and accurate for a number of classifiers."
    },
    "1611.05817": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ribeiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco Tulio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameer"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guestrin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Nothing Else Matters: Model-Agnostic Explanations By Identifying\n  Prediction Invariance",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "At the core of interpretable machine learning is the question of whether\nhumans are able to make accurate predictions about a model's behavior. Assumed\nin this question are three properties of the interpretable output: coverage,\nprecision, and effort. Coverage refers to how often humans think they can\npredict the model's behavior, precision to how accurate humans are in those\npredictions, and effort is either the up-front effort required in interpreting\nthe model, or the effort required to make predictions about a model's behavior.\n  In this work, we propose anchor-LIME (aLIME), a model-agnostic technique that\nproduces high-precision rule-based explanations for which the coverage\nboundaries are very clear. We compare aLIME to linear LIME with simulated\nexperiments, and demonstrate the flexibility of aLIME with qualitative examples\nfrom a variety of domains and tasks."
    },
    "1307.7127": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-07-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Ahuja",
                "http://arxiv.org/OAI/arXiv/:forenames": "Piyush"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Man and Machine: Questions of Risk, Trust and Accountability in Today's\n  AI Technology",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Preprint",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial Intelligence began as a field probing some of the most fundamental\nquestions of science - the nature of intelligence and the design of intelligent\nartifacts. But it has grown into a discipline that is deeply entwined with\ncommerce and society. Today's AI technology, such as expert systems and\nintelligent assistants, pose some difficult questions of risk, trust and\naccountability. In this paper, we present these concerns, examining them in the\ncontext of historical developments that have shaped the nature and direction of\nAI research. We also suggest the exploration and further development of two\nparadigms, human intelligence-machine cooperation, and a sociological view of\nintelligence, which might help address some of these concerns."
    },
    "1805.04582": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rukat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tammo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Holmes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "TensOrMachine: Probabilistic Boolean Tensor Decomposition",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG q-bio.GN stat.AP",
        "http://arxiv.org/OAI/arXiv/:comments": "To be published at ICML 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Boolean tensor decomposition approximates data of multi-way binary\nrelationships as product of interpretable low-rank binary factors, following\nthe rules of Boolean algebra. Here, we present its first probabilistic\ntreatment. We facilitate scalable sampling-based posterior inference by\nexploitation of the combinatorial structure of the factor conditionals. Maximum\na posteriori decompositions feature higher accuracies than existing techniques\nthroughout a wide range of simulated conditions. Moreover, the probabilistic\napproach facilitates the treatment of missing data and enables model selection\nwith much greater accuracy. We investigate three real-world data-sets. First,\ntemporal interaction networks in a hospital ward and behavioural data of\nuniversity students demonstrate the inference of instructive latent patterns.\nNext, we decompose a tensor with more than 10 billion data points, indicating\nrelations of gene expression in cancer patients. Not only does this demonstrate\nscalability, it also provides an entirely novel perspective on relational\nproperties of continuous data and, in the present example, on the molecular\nheterogeneity of cancer. Our implementation is available on GitHub:\nhttps://github.com/TammoR/LogicalFactorisationMachines."
    },
    "1807.05527": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Speichert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefanie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Belle",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vaishak"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Probabilistic Logic Programs in Continuous Domains",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at the 2018 KR Workshop on Hybrid Reasoning and Learning",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The field of statistical relational learning aims at unifying logic and\nprobability to reason and learn from data. Perhaps the most successful paradigm\nin the field is probabilistic logic programming: the enabling of stochastic\nprimitives in logic programming, which is now increasingly seen to provide a\ndeclarative background to complex machine learning applications. While many\nsystems offer inference capabilities, the more significant challenge is that of\nlearning meaningful and interpretable symbolic representations from data. In\nthat regard, inductive logic programming and related techniques have paved much\nof the way for the last few decades.\n  Unfortunately, a major limitation of this exciting landscape is that much of\nthe work is limited to finite-domain discrete probability distributions.\nRecently, a handful of systems have been extended to represent and perform\ninference with continuous distributions. The problem, of course, is that\nclassical solutions for inference are either restricted to well-known\nparametric families (e.g., Gaussians) or resort to sampling strategies that\nprovide correct answers only in the limit. When it comes to learning, moreover,\ninducing representations remains entirely open, other than \"data-fitting\"\nsolutions that force-fit points to aforementioned parametric families.\n  In this paper, we take the first steps towards inducing probabilistic logic\nprograms for continuous and mixed discrete-continuous data, without being\npigeon-holed to a fixed set of distribution families. Our key insight is to\nleverage techniques from piecewise polynomial function approximation theory,\nyielding a principled way to learn and compositionally construct density\nfunctions. We test the framework and discuss the learned representations."
    },
    "1602.04938": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-02-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-08-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ribeiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco Tulio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameer"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guestrin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "\"Why Should I Trust You?\": Explaining the Predictions of Any Classifier",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Despite widespread adoption, machine learning models remain mostly black\nboxes. Understanding the reasons behind predictions is, however, quite\nimportant in assessing trust, which is fundamental if one plans to take action\nbased on a prediction, or when choosing whether to deploy a new model. Such\nunderstanding also provides insights into the model, which can be used to\ntransform an untrustworthy model or prediction into a trustworthy one. In this\nwork, we propose LIME, a novel explanation technique that explains the\npredictions of any classifier in an interpretable and faithful manner, by\nlearning an interpretable model locally around the prediction. We also propose\na method to explain models by presenting representative individual predictions\nand their explanations in a non-redundant way, framing the task as a submodular\noptimization problem. We demonstrate the flexibility of these methods by\nexplaining different models for text (e.g. random forests) and image\nclassification (e.g. neural networks). We show the utility of explanations via\nnovel experiments, both simulated and with human subjects, on various scenarios\nthat require trust: deciding if one should trust a prediction, choosing between\nmodels, improving an untrustworthy classifier, and identifying why a classifier\nshould not be trusted."
    },
    "1703.08769": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-04-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Puig",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xavier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bolei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fidler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanja"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Torralba",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Open Vocabulary Scene Parsing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recognizing arbitrary objects in the wild has been a challenging problem due\nto the limitations of existing classification models and datasets. In this\npaper, we propose a new task that aims at parsing scenes with a large and open\nvocabulary, and several evaluation metrics are explored for this problem. Our\nproposed approach to this problem is a joint image pixel and word concept\nembeddings framework, where word concepts are connected by semantic relations.\nWe validate the open vocabulary prediction ability of our framework on ADE20K\ndataset which covers a wide variety of scenes and objects. We further explore\nthe trained joint embedding space to show its interpretability."
    },
    "1809.03864": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hasani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramin M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lechner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Naser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Felix"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grosu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniela"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Response Characterization for Auditing Cell Dynamics in Long Short-term\n  Memory Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we introduce a novel method to interpret recurrent neural\nnetworks (RNNs), particularly long short-term memory networks (LSTMs) at the\ncellular level. We propose a systematic pipeline for interpreting individual\nhidden state dynamics within the network using response characterization\nmethods. The ranked contribution of individual cells to the network's output is\ncomputed by analyzing a set of interpretable metrics of their decoupled step\nand sinusoidal responses. As a result, our method is able to uniquely identify\nneurons with insightful dynamics, quantify relationships between dynamical\nproperties and test accuracy through ablation analysis, and interpret the\nimpact of network capacity on a network's dynamical distribution. Finally, we\ndemonstrate generalizability and scalability of our method by evaluating a\nseries of different benchmark sequential datasets."
    },
    "1707.08852": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dongyeop"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gangal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Varun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hovy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eduard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Detecting and Explaining Causes From Text For a Time Series Event",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at EMNLP 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Explaining underlying causes or effects about events is a challenging but\nvaluable task. We define a novel problem of generating explanations of a time\nseries event by (1) searching cause and effect relationships of the time series\nwith textual data and (2) constructing a connecting chain between them to\ngenerate an explanation. To detect causal features from text, we propose a\nnovel method based on the Granger causality of time series between features\nextracted from text such as N-grams, topics, sentiments, and their composition.\nThe generation of the sequence of causal entities requires a commonsense\ncausative knowledge base with efficient reasoning. To ensure good\ninterpretability and appropriate lexical usage we combine symbolic and neural\nrepresentations, using a neural reasoning algorithm trained on commonsense\ncausal tuples to predict the next cause step. Our quantitative and human\nanalysis show empirical evidence that our method successfully extracts\nmeaningful causality relationships between time series with textual features\nand generates appropriate explanation between them."
    },
    "1711.00399": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wachter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sandra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mittelstadt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Russell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Counterfactual Explanations without Opening the Black Box: Automated\n  Decisions and the GDPR",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Harvard Journal of Law & Technology, 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There has been much discussion of the right to explanation in the EU General\nData Protection Regulation, and its existence, merits, and disadvantages.\nImplementing a right to explanation that opens the black box of algorithmic\ndecision-making faces major legal and technical barriers. Explaining the\nfunctionality of complex algorithmic decision-making systems and their\nrationale in specific cases is a technically challenging problem. Some\nexplanations may offer little meaningful information to data subjects, raising\nquestions around their value. Explanations of automated decisions need not\nhinge on the general public understanding how algorithmic systems function.\nEven though such interpretability is of great importance and should be pursued,\nexplanations can, in principle, be offered without opening the black box.\nLooking at explanations as a means to help a data subject act rather than\nmerely understand, one could gauge the scope and content of explanations\naccording to the specific goal or action they are intended to support. From the\nperspective of individuals affected by automated decision-making, we propose\nthree aims for explanations: (1) to inform and help the individual understand\nwhy a particular decision was reached, (2) to provide grounds to contest the\ndecision if the outcome is undesired, and (3) to understand what would need to\nchange in order to receive a desired result in the future, based on the current\ndecision-making model. We assess how each of these goals finds support in the\nGDPR. We suggest data controllers should offer a particular type of\nexplanation, unconditional counterfactual explanations, to support these three\naims. These counterfactual explanations describe the smallest change to the\nworld that can be made to obtain a desirable outcome, or to arrive at the\nclosest possible world, without needing to explain the internal logic of the\nsystem."
    },
    "1802.06259": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lingyang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Juhua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lanjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Exact and Consistent Interpretation for Piecewise Linear Neural\n  Networks: A Closed Form Solution",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Under review of KDD 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Strong intelligent machines powered by deep neural networks are increasingly\ndeployed as black boxes to make decisions in risk-sensitive domains, such as\nfinance and medical. To reduce potential risk and build trust with users, it is\ncritical to interpret how such machines make their decisions. Existing works\ninterpret a pre-trained neural network by analyzing hidden neurons, mimicking\npre-trained models or approximating local predictions. However, these methods\ndo not provide a guarantee on the exactness and consistency of their\ninterpretation. In this paper, we propose an elegant closed form solution named\n$OpenBox$ to compute exact and consistent interpretations for the family of\nPiecewise Linear Neural Networks (PLNN). The major idea is to first transform a\nPLNN into a mathematically equivalent set of linear classifiers, then interpret\neach linear classifier by the features that dominate its prediction. We further\napply $OpenBox$ to demonstrate the effectiveness of non-negative and sparse\nconstraints on improving the interpretability of PLNNs. The extensive\nexperiments on both synthetic and real world data sets clearly demonstrate the\nexactness and consistency of our interpretation."
    },
    "1601.04126": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-01-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                "http://arxiv.org/OAI/arXiv/:forenames": "Kush R."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Engineering Safety in Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CY cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "2016 Information Theory and Applications Workshop, La Jolla,\n  California",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning algorithms are increasingly influencing our decisions and\ninteracting with us in all parts of our daily lives. Therefore, just like for\npower plants, highways, and myriad other engineered sociotechnical systems, we\nmust consider the safety of systems involving machine learning. In this paper,\nwe first discuss the definition of safety in terms of risk, epistemic\nuncertainty, and the harm incurred by unwanted outcomes. Then we examine\ndimensions, such as the choice of cost function and the appropriateness of\nminimizing the empirical average training cost, along which certain real-world\napplications may not be completely amenable to the foundational principle of\nmodern statistical machine learning: empirical risk minimization. In\nparticular, we note an emerging dichotomy of applications: ones in which safety\nis important and risk minimization is not the complete story (we name these\nType A applications), and ones in which safety is not so critical and risk\nminimization is sufficient (we name these Type B applications). Finally, we\ndiscuss how four different strategies for achieving safety in engineering\n(inherently safe design, safety reserves, safe fail, and procedural safeguards)\ncan be mapped to the machine learning context through interpretability and\ncausality of predictive models, objectives beyond expected prediction accuracy,\nhuman involvement for labeling difficult or rare examples, and user experience\ndesign of software."
    },
    "1808.04449": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bieshaar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maarten"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Depping",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Malte"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schneegans",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Starting Movement Detection of Cyclists Using Smart Devices",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, accepted for publication at DSAA 2018, Turin, Italy",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In near future, vulnerable road users (VRUs) such as cyclists and pedestrians\nwill be equipped with smart devices and wearables which are capable to\ncommunicate with intelligent vehicles and other traffic participants. Road\nusers are then able to cooperate on different levels, such as in cooperative\nintention detection for advanced VRU protection. Smart devices can be used to\ndetect intentions, e.g., an occluded cyclist intending to cross the road, to\nwarn vehicles of VRUs, and prevent potential collisions. This article presents\na human activity recognition approach to detect the starting movement of\ncyclists wearing smart devices. We propose a novel two-stage feature selection\nprocedure using a score specialized for robust starting detection reducing the\nfalse positive detections and leading to understandable and interpretable\nfeatures. The detection is modelled as a classification problem and realized by\nmeans of a machine learning classifier. We introduce an auxiliary class, that\nmodels starting movements and allows to integrate early movement indicators,\ni.e., body part movements indicating future behaviour. In this way we improve\nthe robustness and reduce the detection time of the classifier. Our empirical\nstudies with real-world data originating from experiments which involve 49 test\nsubjects and consists of 84 starting motions show that we are able to detect\nthe starting movements early. Our approach reaches an F1-score of 67 % within\n0.33 s after the first movement of the bicycle wheel. Investigations concerning\nthe device wearing location show that for devices worn in the trouser pocket\nthe detector has less false detections and detects starting movements faster on\naverage. We found that we can further improve the results when we train\ndistinct classifiers for different wearing locations."
    },
    "1809.05070": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhijian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Freeman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiajun"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Physical Primitive Decomposition",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "ECCV 2018. Project page: http://ppd.csail.mit.edu/",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Objects are made of parts, each with distinct geometry, physics,\nfunctionality, and affordances. Developing such a distributed, physical,\ninterpretable representation of objects will facilitate intelligent agents to\nbetter explore and interact with the world. In this paper, we study physical\nprimitive decomposition---understanding an object through its components, each\nwith physical and geometric attributes. As annotated data for object parts and\nphysics are rare, we propose a novel formulation that learns physical\nprimitives by explaining both an object's appearance and its behaviors in\nphysical events. Our model performs well on block towers and tools in both\nsynthetic and real scenarios; we also demonstrate that visual and physical\nobservations often provide complementary signals. We further present ablation\nand behavioral studies to better understand our model and contrast it with\nhuman performance."
    },
    "1610.07045": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julie Yixuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Huichu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor O. K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiawei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "pg-Causality: Identifying Spatiotemporal Causal Pathways for Air\n  Pollutants with Urban Big Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many countries are suffering from severe air pollution. Understanding how\ndifferent air pollutants accumulate and propagate is critical to making\nrelevant public policies. In this paper, we use urban big data (air quality\ndata and meteorological data) to identify the \\emph{spatiotemporal (ST) causal\npathways} for air pollutants. This problem is challenging because: (1) there\nare numerous noisy and low-pollution periods in the raw air quality data, which\nmay lead to unreliable causality analysis, (2) for large-scale data in the ST\nspace, the computational complexity of constructing a causal structure is very\nhigh, and (3) the \\emph{ST causal pathways} are complex due to the interactions\nof multiple pollutants and the influence of environmental factors. Therefore,\nwe present \\emph{p-Causality}, a novel pattern-aided causality analysis\napproach that combines the strengths of \\emph{pattern mining} and\n\\emph{Bayesian learning} to efficiently and faithfully identify the \\emph{ST\ncausal pathways}. First, \\emph{Pattern mining} helps suppress the noise by\ncapturing frequent evolving patterns (FEPs) of each monitoring sensor, and\ngreatly reduce the complexity by selecting the pattern-matched sensors as\n\"causers\". Then, \\emph{Bayesian learning} carefully encodes the local and ST\ncausal relations with a Gaussian Bayesian network (GBN)-based graphical model,\nwhich also integrates environmental influences to minimize biases in the final\nresults. We evaluate our approach with three real-world data sets containing\n982 air quality sensors, in three regions of China from 01-Jun-2013 to\n19-Dec-2015. Results show that our approach outperforms the traditional causal\nstructure learning methods in time efficiency, inference accuracy and\ninterpretability."
    },
    "1612.00837": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goyal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yash"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khot",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tejas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Summers-Stay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Douglas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in\n  Visual Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Problems at the intersection of vision and language are of significant\nimportance both as challenging research questions and for the rich set of\napplications they enable. However, inherent structure in our world and bias in\nour language tend to be a simpler signal for learning than visual modalities,\nresulting in models that ignore visual information, leading to an inflated\nsense of their capability.\n  We propose to counter these language priors for the task of Visual Question\nAnswering (VQA) and make vision (the V in VQA) matter! Specifically, we balance\nthe popular VQA dataset by collecting complementary images such that every\nquestion in our balanced dataset is associated with not just a single image,\nbut rather a pair of similar images that result in two different answers to the\nquestion. Our dataset is by construction more balanced than the original VQA\ndataset and has approximately twice the number of image-question pairs. Our\ncomplete balanced dataset is publicly available at www.visualqa.org as part of\nthe 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA\nv2.0).\n  We further benchmark a number of state-of-art VQA models on our balanced\ndataset. All models perform significantly worse on our balanced dataset,\nsuggesting that these models have indeed learned to exploit language priors.\nThis finding provides the first concrete empirical evidence for what seems to\nbe a qualitative sense among practitioners.\n  Finally, our data collection protocol for identifying complementary images\nenables us to develop a novel interpretable model, which in addition to\nproviding an answer to the given (image, question) pair, also provides a\ncounter-example based explanation. Specifically, it identifies an image that is\nsimilar to the original image, but it believes has a different answer to the\nsame question. This can help in building trust for machines among their users."
    },
    "1301.3903": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-01-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wittig",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Frank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jameson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anthony"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Exploiting Qualitative Knowledge in the Learning of Conditional\n  Probabilities of Bayesian Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Sixteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2000)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2000-PG-644-652",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Algorithms for learning the conditional probabilities of Bayesian networks\nwith hidden variables typically operate within a high-dimensional search space\nand yield only locally optimal solutions. One way of limiting the search space\nand avoiding local optima is to impose qualitative constraints that are based\non background knowledge concerning the domain. We present a method for\nintegrating formal statements of qualitative constraints into two learning\nalgorithms, APN and EM. In our experiments with synthetic data, this method\nyielded networks that satisfied the constraints almost perfectly. The accuracy\nof the learned networks was consistently superior to that of corresponding\nnetworks learned without constraints. The exploitation of qualitative\nconstraints therefore appears to be a promising way to increase both the\ninterpretability and the accuracy of learned Bayesian networks with known\nstructure."
    },
    "0902.0798": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-02-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Diaz-Aviles",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ernesto"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Alleviating Media Bias Through Intelligent Agent Blogging",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.11; J.4; H.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Consumers of mass media must have a comprehensive, balanced and plural\nselection of news to get an unbiased perspective; but achieving this goal can\nbe very challenging, laborious and time consuming. News stories development\nover time, its (in)consistency, and different level of coverage across the\nmedia outlets are challenges that a conscientious reader has to overcome in\norder to alleviate bias.\n  In this paper we present an intelligent agent framework currently\nfacilitating analysis of the main sources of on-line news in El Salvador. We\nshow how prior tools of text analysis and Web 2.0 technologies can be combined\nwith minimal manual intervention to help individuals on their rational decision\nprocess, while holding media outlets accountable for their work."
    },
    "cs_9512107": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "1995-11-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weiss",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S. M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Indurkhya",
                    "http://arxiv.org/OAI/arXiv/:forenames": "N."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Rule-based Machine Learning Methods for Functional Prediction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "See http://www.jair.org/ for any accompanying files",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Artificial Intelligence Research, Vol 3, (1995),\n  383-403",
        "http://arxiv.org/OAI/arXiv/:abstract": "We describe a machine learning method for predicting the value of a\nreal-valued function, given the values of multiple input variables. The method\ninduces solutions from samples in the form of ordered disjunctive normal form\n(DNF) decision rules. A central objective of the method and representation is\nthe induction of compact, easily interpretable solutions. This rule-based\ndecision model can be extended to search efficiently for similar cases prior to\napproximating function values. Experimental results on real-world data\ndemonstrate that the new techniques are competitive with existing machine\nlearning and statistical methods and can sometimes yield superior regression\nperformance."
    },
    "1811.03056": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lihong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brunskill",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emma"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Policy Certificates: Towards Accountable Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The performance of a reinforcement learning algorithm can vary drastically\nduring learning because of exploration. Existing algorithms provide little\ninformation about their current policy's quality before executing it, and thus\nhave limited use in high-stakes applications like healthcare. In this paper, we\naddress such a lack of accountability by proposing that algorithms output\npolicy certificates, which upper bound the suboptimality in the next episode,\nallowing humans to intervene when the certified quality is not satisfactory. We\nfurther present a new learning framework (IPOC) for finite-sample analysis with\npolicy certificates, and develop two IPOC algorithms that enjoy guarantees for\nthe quality of both their policies and certificates."
    },
    "1803.01316": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-04",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "F\u00fcrnkranz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Johannes"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kliegr",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom\u00e1\u0161"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paulheim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Heiko"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Cognitive Preferences and the Interpretability of Rule-based Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "V2: A few references added",
        "http://arxiv.org/OAI/arXiv/:report-no": "TUD-KE-2018-01",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "It is conventional wisdom in machine learning and data mining that logical\nmodels such as rule sets are more interpretable than other models, and that\namong such rule-based models, simpler models are more interpretable than more\ncomplex ones. In this position paper, we question this latter assumption, and\nrecapitulate evidence for and against this postulate. We also report the\nresults of an evaluation in a crowd-sourcing study, which does not reveal a\nstrong preference for simple rules, whereas we can observe a weak preference\nfor longer rules in some domains. We then continue to review criteria for\ninterpretability from the psychological literature, evaluate some of them, and\nbriefly discuss their potential use in machine learning."
    },
    "1702.02604": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bahadori",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad Taha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chalupka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Krzysztof"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Choi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stewart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Walter F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jimeng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Regularization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Adding theoretical analysis, revising the text",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In application domains such as healthcare, we want accurate predictive models\nthat are also causally interpretable. In pursuit of such models, we propose a\ncausal regularizer to steer predictive models towards causally-interpretable\nsolutions and theoretically study its properties. In a large-scale analysis of\nElectronic Health Records (EHR), our causally-regularized model outperforms its\nL1-regularized counterpart in causal accuracy and is competitive in predictive\nperformance. We perform non-linear causality analysis by causally regularizing\na special neural network architecture. We also show that the proposed causal\nregularizer can be used together with neural representation learning algorithms\nto yield up to 20% improvement over multilayer perceptron in detecting\nmultivariate causation, a situation common in healthcare, where many causal\nfactors should occur simultaneously to have an effect on the target variable."
    },
    "1106.1818": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Nock",
                "http://arxiv.org/OAI/arXiv/:forenames": "R."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Inducing Interpretable Voting Classifiers without Trading Accuracy for\n  Simplicity: Theoretical Results, Approximation Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 17, pages\n  137-170, 2002",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.986",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent advances in the study of voting classification algorithms have brought\nempirical and theoretical results clearly showing the discrimination power of\nensemble classifiers. It has been previously argued that the search of this\nclassification power in the design of the algorithms has marginalized the need\nto obtain interpretable classifiers. Therefore, the question of whether one\nmight have to dispense with interpretability in order to keep classification\nstrength is being raised in a growing number of machine learning or data mining\npapers. The purpose of this paper is to study both theoretically and\nempirically the problem. First, we provide numerous results giving insight into\nthe hardness of the simplicity-accuracy tradeoff for voting classifiers. Then\nwe provide an efficient \"top-down and prune\" induction heuristic, WIDC, mainly\nderived from recent results on the weak learning and boosting frameworks. It is\nto our knowledge the first attempt to build a voting classifier as a base\nformula using the weak learning framework (the one which was previously highly\nsuccessful for decision tree induction), and not the strong learning framework\n(as usual for such classifiers with boosting-like approaches). While it uses a\nwell-known induction scheme previously successful in other classes of concept\nrepresentations, thus making it easy to implement and compare, WIDC also relies\non recent or new results we give about particular cases of boosting known as\npartition boosting and ranking loss boosting. Experimental results on\nthirty-one domains, most of which readily available, tend to display the\nability of WIDC to produce small, accurate, and interpretable decision\ncommittees."
    },
    "1711.02301": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raghu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maithra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Irpan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Andreas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jacob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kleinberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Le",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Quoc V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kleinberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted into ICLR Workshop 2018. New results on self play",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep reinforcement learning has achieved many recent successes, but our\nunderstanding of its strengths and limitations is hampered by the lack of rich\nenvironments in which we can fully characterize optimal behavior, and\ncorrespondingly diagnose individual actions against such a characterization.\nHere we consider a family of combinatorial games, arising from work of Erdos,\nSelfridge, and Spencer, and we propose their use as environments for evaluating\nand comparing different approaches to reinforcement learning. These games have\na number of appealing features: they are challenging for current learning\napproaches, but they form (i) a low-dimensional, simply parametrized\nenvironment where (ii) there is a linear closed form solution for optimal\nbehavior from any state, and (iii) the difficulty of the game can be tuned by\nchanging environment parameters in an interpretable way. We use these\nErdos-Selfridge-Spencer games not only to compare different algorithms, but\ntest for generalization, make comparisons to supervised learning, analyse\nmultiagent play, and even develop a self play algorithm."
    },
    "1605.04056": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-06-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marazopoulou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Katerina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghosh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rumi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lade",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prasanth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jensen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Discovery for Manufacturing Domains",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Yield and quality improvement is of paramount importance to any manufacturing\ncompany. One of the ways of improving yield is through discovery of the root\ncausal factors affecting yield. We propose the use of data-driven interpretable\ncausal models to identify key factors affecting yield. We focus on factors that\nare measured in different stages of production and testing in the manufacturing\ncycle of a product. We apply causal structure learning techniques on real data\ncollected from this line. Specifically, the goal of this work is to learn\ninterpretable causal models from observational data produced by manufacturing\nlines.\n  Emphasis has been given to the interpretability of the models to make them\nactionable in the field of manufacturing. We highlight the challenges presented\nby assembly line data and propose ways to alleviate them.We also identify\nunique characteristics of data originating from assembly lines and how to\nleverage them in order to improve causal discovery. Standard evaluation\ntechniques for causal structure learning shows that the learned causal models\nseem to closely represent the underlying latent causal relationship between\ndifferent factors in the production process. These results were also validated\nby manufacturing domain experts who found them promising. This work\ndemonstrates how data mining and knowledge discovery can be used for root cause\nanalysis in the domain of manufacturing and connected industry."
    },
    "1807.06228": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ming",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Qu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Huamin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bertini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Enrico"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "RuleMatrix: Visualizing and Understanding Classifiers with Rules",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.HC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted by IEEE Conference of Visual Analytics Science and\n  Technology 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "With the growing adoption of machine learning techniques, there is a surge of\nresearch interest towards making machine learning systems more transparent and\ninterpretable. Various visualizations have been developed to help model\ndevelopers understand, diagnose, and refine machine learning models. However, a\nlarge number of potential but neglected users are the domain experts with\nlittle knowledge of machine learning but are expected to work with machine\nlearning systems. In this paper, we present an interactive visualization\ntechnique to help users with little expertise in machine learning to\nunderstand, explore and validate predictive models. By viewing the model as a\nblack box, we extract a standardized rule-based knowledge representation from\nits input-output behavior. We design RuleMatrix, a matrix-based visualization\nof rules to help users navigate and verify the rules and the black-box model.\nWe evaluate the effectiveness of RuleMatrix via two use cases and a usability\nstudy."
    },
    "1709.07941": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kalofolias",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Janis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mario"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vreeken",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jilles"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficiently Discovering Locally Exceptional yet Globally Representative\n  Subgroups",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, To appear in ICDM17",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Subgroup discovery is a local pattern mining technique to find interpretable\ndescriptions of sub-populations that stand out on a given target variable. That\nis, these sub-populations are exceptional with regard to the global\ndistribution. In this paper we argue that in many applications, such as\nscientific discovery, subgroups are only useful if they are additionally\nrepresentative of the global distribution with regard to a control variable.\nThat is, when the distribution of this control variable is the same, or almost\nthe same, as over the whole data.\n  We formalise this objective function and give an efficient algorithm to\ncompute its tight optimistic estimator for the case of a numeric target and a\nbinary control variable. This enables us to use the branch-and-bound framework\nto efficiently discover the top-$k$ subgroups that are both exceptional as well\nas representative. Experimental evaluation on a wide range of datasets shows\nthat with this algorithm we discover meaningful representative patterns and are\nup to orders of magnitude faster in terms of node evaluations as well as time."
    },
    "1611.06174": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kuzelka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ondrej"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Davis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jesse"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schockaert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steven"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Stratified Knowledge Bases as Interpretable Probabilistic Models\n  (Extended Abstract)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we advocate the use of stratified logical theories for\nrepresenting probabilistic models. We argue that such encodings can be more\ninterpretable than those obtained in existing frameworks such as Markov logic\nnetworks. Among others, this allows for the use of domain experts to improve\nlearned models by directly removing, adding, or modifying logical formulas."
    },
    "1706.02952": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dhurandhar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Iyengar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vijay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Luss",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ronny"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shanmugam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthikeyan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "TIP: Typifying the Interpretability of Procedures",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.AP stat.CO stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking it to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability. Finally, principled interpretable strategies are\nproposed and empirically evaluated on synthetic data, as well as on the largest\npublic olfaction dataset that was made recently available \\cite{olfs}. We also\nexperiment on MNIST with a simple target model and different oracle models of\nvarying complexity. This leads to the insight that the improvement in the\ntarget model is not only a function of the oracle models performance, but also\nits relative complexity with respect to the target model."
    },
    "1612.07896": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Burges",
                    "http://arxiv.org/OAI/arXiv/:forenames": "C. J. C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cucerzan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "White",
                    "http://arxiv.org/OAI/arXiv/:forenames": "R. W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pastusiak",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lewis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Base Camp for Scaling AI",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Modern statistical machine learning (SML) methods share a major limitation\nwith the early approaches to AI: there is no scalable way to adapt them to new\ndomains. Human learning solves this in part by leveraging a rich, shared,\nupdateable world model. Such scalability requires modularity: updating part of\nthe world model should not impact unrelated parts. We have argued that such\nmodularity will require both \"correctability\" (so that errors can be corrected\nwithout introducing new errors) and \"interpretability\" (so that we can\nunderstand what components need correcting).\n  To achieve this, one could attempt to adapt state of the art SML systems to\nbe interpretable and correctable; or one could see how far the simplest\npossible interpretable, correctable learning methods can take us, and try to\ncontrol the limitations of SML methods by applying them only where needed. Here\nwe focus on the latter approach and we investigate two main ideas: \"Teacher\nAssisted Learning\", which leverages crowd sourcing to learn language; and\n\"Factored Dialog Learning\", which factors the process of application\ndevelopment into roles where the language competencies needed are isolated,\nenabling non-experts to quickly create new applications.\n  We test these ideas in an \"Automated Personal Assistant\" (APA) setting, with\ntwo scenarios: that of detecting user intent from a user-APA dialog; and that\nof creating a class of event reminder applications, where a non-expert\n\"teacher\" can then create specific apps. For the intent detection task, we use\na dataset of a thousand labeled utterances from user dialogs with Cortana, and\nwe show that our approach matches state of the art SML methods, but in addition\nprovides full transparency: the whole (editable) model can be summarized on one\nhuman-readable page. For the reminder app task, we ran small user studies to\nverify the efficacy of the approach."
    },
    "1706.06383": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Denil",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Misha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Colmenarejo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergio G\u00f3mez"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cabi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serkan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saxton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "de Freitas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nando"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Programmable Agents",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We build deep RL agents that execute declarative programs expressed in formal\nlanguage. The agents learn to ground the terms in this language in their\nenvironment, and can generalize their behavior at test time to execute new\nprograms that refer to objects that were not referenced during training. The\nagents develop disentangled interpretable representations that allow them to\ngeneralize to a wide variety of zero-shot semantic tasks."
    },
    "1711.00404": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ling",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hutchinson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maxwell"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Antono",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "DeCost",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Holm",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Elizabeth A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meredig",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bryce"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Building Data-driven Models with Microstructural Images: Generalization\n  and Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cond-mat.mtrl-sci",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As data-driven methods rise in popularity in materials science applications,\na key question is how these machine learning models can be used to understand\nmicrostructure. Given the importance of process-structure-property relations\nthroughout materials science, it seems logical that models that can leverage\nmicrostructural data would be more capable of predicting property information.\nWhile there have been some recent attempts to use convolutional neural networks\nto understand microstructural images, these early studies have focused only on\nwhich featurizations yield the highest machine learning model accuracy for a\nsingle data set. This paper explores the use of convolutional neural networks\nfor classifying microstructure with a more holistic set of objectives in mind:\ngeneralization between data sets, number of features required, and\ninterpretability."
    },
    "1604.08709": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-11-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yanjing"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "\"Knowing value\" logic as a normal modal logic",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "21 pages, in Advances in Modal Logic Vol 11: 362-381 College\n  Publications. This is a draft with a more detailed proof of Prop. 3.5",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent years witness a growing interest in nonstandard epistemic logics of\n\"knowing whether\", \"knowing what\", \"knowing how\", and so on. These logics are\nusually not normal, i.e., the standard axioms and reasoning rules for modal\nlogic may be invalid. In this paper, we show that the conditional \"knowing\nvalue\" logic proposed by Wang and Fan \\cite{WF13} can be viewed as a disguised\nnormal modal logic by treating the negation of the Kv operator as a special\ndiamond. Under this perspective, it turns out that the original first-order\nKripke semantics can be greatly simplified by introducing a ternary relation\n$R_i^c$ in standard Kripke models, which associates one world with two\n$i$-accessible worlds that do not agree on the value of constant $c$. Under\nintuitive constraints, the modal logic based on such Kripke models is exactly\nthe one studied by Wang and Fan (2013,2014}. Moreover, there is a very natural\nbinary generalization of the \"knowing value\" diamond, which, surprisingly, does\nnot increase the expressive power of the logic. The resulting logic with the\nbinary diamond has a transparent normal modal system, which sharpens our\nunderstanding of the \"knowing value\" logic and simplifies some previously hard\nproblems."
    },
    "1810.06338": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Borgo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rita"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cashmore",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Magazzeni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniele"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Providing Explanations for AI Planner Decisions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at the IJCAI/ECAI 2018 Workshop on Explainable Artificial\n  Intelligence (XAI)\n  (http://home.earthlink.net/~dwaha/research/meetings/faim18-xai). Stockholm,\n  July 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order to engender trust in AI, humans must understand what an AI system is\ntrying to achieve, and why. To overcome this problem, the underlying AI process\nmust produce justifications and explanations that are both transparent and\ncomprehensible to the user. AI Planning is well placed to be able to address\nthis challenge. In this paper we present a methodology to provide initial\nexplanations for the decisions made by the planner. Explanations are created by\nallowing the user to suggest alternative actions in plans and then compare the\nresulting plans with the one found by the planner. The methodology is\nimplemented in the new XAI-Plan framework."
    },
    "1703.04741": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Charisi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vicky"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dennis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Louise"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fisher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lieck",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Matthias",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Slavkovik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marija"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sombetzki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Janina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Winfield",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alan F. T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yampolskiy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roman"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Moral Autonomous Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Both the ethics of autonomous systems and the problems of their technical\nimplementation have by now been studied in some detail. Less attention has been\ngiven to the areas in which these two separate concerns meet. This paper,\nwritten by both philosophers and engineers of autonomous systems, addresses a\nnumber of issues in machine ethics that are located at precisely the\nintersection between ethics and engineering. We first discuss the main\nchallenges which, in our view, machine ethics posses to moral philosophy. We\nthem consider different approaches towards the conceptual design of autonomous\nsystems and their implications on the ethics implementation in such systems.\nThen we examine problematic areas regarding the specification and verification\nof ethical behavior in autonomous systems, particularly with a view towards the\nrequirements of future legislation. We discuss transparency and accountability\nissues that will be crucial for any future wide deployment of autonomous\nsystems in society. Finally we consider the, often overlooked, possibility of\nintentional misuse of AI systems and the possible dangers arising out of\ndeliberately unethical design, implementation, and use of autonomous robots."
    },
    "1810.03993": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mitchell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Margaret"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simone"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zaldivar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barnes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Parker"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vasserman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lucy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hutchinson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ben"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Spitzer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Elena"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raji",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Inioluwa Deborah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gebru",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timnit"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Model Cards for Model Reporting",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Trained machine learning models are increasingly used to perform high-impact\ntasks in areas such as law enforcement, medicine, education, and employment. In\norder to clarify the intended use cases of machine learning models and minimize\ntheir usage in contexts for which they are not well suited, we recommend that\nreleased models be accompanied by documentation detailing their performance\ncharacteristics. In this paper, we propose a framework that we call model\ncards, to encourage such transparent model reporting. Model cards are short\ndocuments accompanying trained machine learning models that provide benchmarked\nevaluation in a variety of conditions, such as across different cultural,\ndemographic, or phenotypic groups (e.g., race, geographic location, sex,\nFitzpatrick skin type) and intersectional groups (e.g., age and race, or sex\nand Fitzpatrick skin type) that are relevant to the intended application\ndomains. Model cards also disclose the context in which models are intended to\nbe used, details of the performance evaluation procedures, and other relevant\ninformation. While we focus primarily on human-centered machine learning models\nin the application fields of computer vision and natural language processing,\nthis framework can be used to document any trained machine learning model. To\nsolidify the concept, we provide cards for two supervised models: One trained\nto detect smiling faces in images, and one trained to detect toxic comments in\ntext. We propose model cards as a step towards the responsible democratization\nof machine learning and related AI technology, increasing transparency into how\nwell AI technology works. We hope this work encourages those releasing trained\nmachine learning models to accompany model releases with similar detailed\nevaluation numbers and other relevant documentation."
    },
    "1806.02215": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pfau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Petersen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stig"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barrett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stachenfeld",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Spectral Inference Networks: Unifying Spectral Methods With Deep\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present Spectral Inference Networks, a framework for learning\neigenfunctions of linear operators by stochastic optimization. Spectral\nInference Networks generalize Slow Feature Analysis to generic symmetric\noperators, and are closely related to Variational Monte Carlo methods from\ncomputational physics. As such, they can be a powerful tool for unsupervised\nrepresentation learning from video or pairs of data. We derive a training\nalgorithm for Spectral Inference Networks that addresses the bias in the\ngradients due to finite batch size and allows for online learning of multiple\neigenfunctions. We show results of training Spectral Inference Networks on\nproblems in quantum mechanics and feature learning for videos on synthetic\ndatasets as well as the Arcade Learning Environment. Our results demonstrate\nthat Spectral Inference Networks accurately recover eigenfunctions of linear\noperators, can discover interpretable representations from video and find\nmeaningful subgoals in reinforcement learning environments."
    },
    "1710.10600": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Lopez-Martinez",
                "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Regularization approaches for support vector machines with applications\n  to biomedical data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The support vector machine (SVM) is a widely used machine learning tool for\nclassification based on statistical learning theory. Given a set of training\ndata, the SVM finds a hyperplane that separates two different classes of data\npoints by the largest distance. While the standard form of SVM uses L2-norm\nregularization, other regularization approaches are particularly attractive for\nbiomedical datasets where, for example, sparsity and interpretability of the\nclassifier's coefficient values are highly desired features. Therefore, in this\npaper we consider different types of regularization approaches for SVMs, and\nexplore them in both synthetic and real biomedical datasets."
    },
    "1804.06620": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Casalicchio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giuseppe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Molnar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bischl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernd"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Visualizing the Feature Importance for Black Box Models",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to ECML-PKDD 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent years, a large amount of model-agnostic methods to improve the\ntransparency, trustability and interpretability of machine learning models have\nbeen developed. We introduce local feature importance as a local version of a\nrecent model-agnostic global feature importance method. Based on local feature\nimportance, we propose two visual tools: partial importance (PI) and individual\nconditional importance (ICI) plots which visualize how changes in a feature\naffect the model performance on average, as well as for individual\nobservations. Our proposed methods are related to partial dependence (PD) and\nindividual conditional expectation (ICE) plots, but visualize the expected\n(conditional) feature importance instead of the expected (conditional)\nprediction. Furthermore, we show that averaging ICI curves across observations\nyields a PI curve, and integrating the PI curve with respect to the\ndistribution of the considered feature results in the global feature\nimportance. Another contribution of our paper is the Shapley feature\nimportance, which fairly distributes the overall performance of a model among\nthe features according to the marginal contributions and which can be used to\ncompare the feature importance across different models."
    },
    "1007.2364": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-07-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bozzato",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Loris",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "DICOM - Universit\u00e0 degli Studi dell'Insubria"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ferrari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mauro",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "DICOM - Universit\u00e0 degli Studi dell'Insubria"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Note on Semantic Web Services Specification and Composition in\n  Constructive Description Logics",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 2 figures. Part of this work will appear as a position\n  paper in Proceedings of 4th Int. Conf. on Web Reasoning and Rule Systems (RR\n  2010)",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.4; F.4.1; H.3.5",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The idea of the Semantic Web is to annotate Web content and services with\ncomputer interpretable descriptions with the aim to automatize many tasks\ncurrently performed by human users. In the context of Web services, one of the\nmost interesting tasks is their composition. In this paper we formalize this\nproblem in the framework of a constructive description logic. In particular we\npropose a declarative service specification language and a calculus for service\ncomposition. We show by means of an example how this calculus can be used to\ndefine composed Web services and we discuss the problem of automatic service\nsynthesis."
    },
    "1810.00184": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Preece",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harborne",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Braines",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dave"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tomsett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chakraborty",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Supriyo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Stakeholders in Explainable AI",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There is general consensus that it is important for artificial intelligence\n(AI) and machine learning systems to be explainable and/or interpretable.\nHowever, there is no general consensus over what is meant by 'explainable' and\n'interpretable'. In this paper, we argue that this lack of consensus is due to\nthere being several distinct stakeholder communities. We note that, while the\nconcerns of the individual communities are broadly compatible, they are not\nidentical, which gives rise to different intents and requirements for\nexplainability/interpretability. We use the software engineering distinction\nbetween validation and verification, and the epistemological distinctions\nbetween knowns/unknowns, to tease apart the concerns of the stakeholder\ncommunities and highlight the areas where their foci overlap or diverge. It is\nnot the purpose of the authors of this paper to 'take sides' - we count\nourselves as members, to varying degrees, of multiple communities - but rather\nto help disambiguate what stakeholders mean when they ask 'Why?' of an AI."
    },
    "1401.3531": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-01-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-05-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fulcher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ben D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jones",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nick S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Highly comparative feature-based time-series classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.DB physics.data-an q-bio.QM",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IEEE Trans. Knowl. Data Eng. 26, 3026 (2014)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/TKDE.2014.2316504",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A highly comparative, feature-based approach to time series classification is\nintroduced that uses an extensive database of algorithms to extract thousands\nof interpretable features from time series. These features are derived from\nacross the scientific time-series analysis literature, and include summaries of\ntime series in terms of their correlation structure, distribution, entropy,\nstationarity, scaling properties, and fits to a range of time-series models.\nAfter computing thousands of features for each time series in a training set,\nthose that are most informative of the class structure are selected using\ngreedy forward feature selection with a linear classifier. The resulting\nfeature-based classifiers automatically learn the differences between classes\nusing a reduced number of time-series properties, and circumvent the need to\ncalculate distances between time series. Representing time series in this way\nresults in orders of magnitude of dimensionality reduction, allowing the method\nto perform well on very large datasets containing long time series or time\nseries of different lengths. For many of the datasets studied, classification\nperformance exceeded that of conventional instance-based classifiers, including\none nearest neighbor classifiers using Euclidean distances and dynamic time\nwarping and, most importantly, the features selected provide an understanding\nof the properties of the dataset, insight that can guide further scientific\ninvestigation."
    },
    "1810.01541": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boicu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mihai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marcu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dorin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tecuci",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gheorghe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kaiser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lou"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Uttamsingh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chirag"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kalale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Navya"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Co-Arg: Cogent Argumentation with Crowd Elicitation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper presents Co-Arg, a new type of cognitive assistant to an\nintelligence analyst that enables the synergistic integration of analyst\nimagination and expertise, computer knowledge and critical reasoning, and crowd\nwisdom, to draw defensible and persuasive conclusions from masses of evidence\nof all types, in a world that is changing all the time. Co-Arg's goal is to\nimprove the quality of the analytic results and enhance their understandability\nfor both experts and novices. The performed analysis is based on a sound and\ntransparent argumentation that links evidence to conclusions in a way that\nshows very clearly how the conclusions have been reached, what evidence was\nused and how, what is not known, and what assumptions have been made. The\nanalytic results are presented in a report describes the analytic conclusion\nand its probability, the main favoring and disfavoring arguments, the\njustification of the key judgments and assumptions, and the missing information\nthat might increase the accuracy of the solution."
    },
    "1805.07472": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Morton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeremy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Witherden",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Freddie D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jameson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antony"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kochenderfer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mykel J."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Dynamical Modeling and Control of Unsteady Fluid Flows",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CE cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The design of flow control systems remains a challenge due to the nonlinear\nnature of the equations that govern fluid flow. However, recent advances in\ncomputational fluid dynamics (CFD) have enabled the simulation of complex fluid\nflows with high accuracy, opening the possibility of using learning-based\napproaches to facilitate controller design. We present a method for learning\nthe forced and unforced dynamics of airflow over a cylinder directly from CFD\ndata. The proposed approach, grounded in Koopman theory, is shown to produce\nstable dynamical models that can predict the time evolution of the cylinder\nsystem over extended time horizons. Finally, by performing model predictive\ncontrol with the learned dynamical models, we are able to find a\nstraightforward, interpretable control law for suppressing vortex shedding in\nthe wake of the cylinder."
    },
    "1805.04032": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Camacho-Collados",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jose"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pilehvar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad Taher"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "From Word to Sense Embeddings: A Survey on Vector Representations of\n  Meaning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "40 pages, 8 figures. Submitted to JAIR",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Over the past years, distributed representations have proven effective and\nflexible keepers of prior knowledge to be integrated into downstream\napplications. This survey is focused on semantic representation of meaning. We\nstart from the theoretical background behind word vector space models and\nhighlight one of their main limitations: the meaning conflation deficiency,\nwhich arises from representing a word with all its possible meanings as a\nsingle vector. Then, we explain how this deficiency can be addressed through a\ntransition from word level to the more fine-grained level of word senses (in\nits broader acceptation) as a method for modelling unambiguous lexical meaning.\nWe present a comprehensive overview of the wide range of techniques in the two\nmain branches of sense representation, i.e., unsupervised and knowledge-based.\nFinally, this survey covers the main evaluation procedures and provides an\nanalysis of five important aspects: interpretability, sense granularity,\nadaptability to different domains, compositionality and integration into\ndownstream applications."
    },
    "1706.07269": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Miller",
                "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explanation in Artificial Intelligence: Insights from the Social\n  Sciences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There has been a recent resurgence in the area of explainable artificial\nintelligence as researchers and practitioners seek to make their algorithms\nmore understandable. Much of this research is focused on explicitly explaining\ndecisions or actions to a human observer, and it should not be controversial to\nsay that looking at how humans explain to each other can serve as a useful\nstarting point for explanation in artificial intelligence. However, it is fair\nto say that most work in explainable artificial intelligence uses only the\nresearchers' intuition of what constitutes a `good' explanation. There exists\nvast and valuable bodies of research in philosophy, psychology, and cognitive\nscience of how people define, generate, select, evaluate, and present\nexplanations, which argues that people employ certain cognitive biases and\nsocial expectations towards the explanation process. This paper argues that the\nfield of explainable artificial intelligence should build on this existing\nresearch, and reviews relevant papers from philosophy, cognitive\npsychology/science, and social psychology, which study these topics. It draws\nout some important findings, and discusses ways that these can be infused with\nwork on explainable artificial intelligence."
    },
    "1604.00266": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-03-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abdelwahab",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Elnaserledinellah Mahmood"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Daghbouche",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shannan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nadra Ahmad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Algorithm of Islamic Jurisprudence (Fiqh) with Validation of an\n  Entscheidungsproblem",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "36 pages, 6 Figures. J.Acad.(N.Y.)4,2:52-87, published May 16 2014",
        "http://arxiv.org/OAI/arXiv/:acm-class": "D.1.6; F.2; F.3; F.4; I.2; F.1.3",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "J.Acad.(N.Y.)4,2:52-87 May 16 2014",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The historic background of algorithmic processing with regard to etymology\nand methodology is translated into terms of mathematical logic and Computer\nScience. A formal logic structure is introduced by exemplaryquestions posed to\nFiqh-chapters to define alogic query language. As a foundation, ageneric\nalgorithm for deciding Fiqh-rulings is designed to enable and further leverage\nrule of law (vs. rule by law) with full transparency and complete algorithmic\ncoverage of Islamic law eventually providing legal security, legal equality,\nand full legal accountability.This is implemented by disentangling and\nreinstating classic Fiqh-methodology (usul al-Fiqh) with the expressive power\nof subsets of First Order Logic (FOL)sustainably substituting ad hoc reasoning\nwith falsifiable rational argumentation. The results are discussed in formal\nterms of completeness, decidability and complexity of formal Fiqh-systems.\nAnEntscheidungsproblem for formal Fiqh-Systems is formulated and validated."
    },
    "1712.09923": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Holzinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Biemann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pattichis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Constantinos S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Douglas B."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "What do we need to build explainable AI systems for the medical domain?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "This is a survey article and section 3.1. draws heavily from\n  arXiv:1706.07979",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence (AI) generally and machine learning (ML) specifically\ndemonstrate impressive practical success in many different application domains,\ne.g. in autonomous driving, speech recognition, or recommender systems. Deep\nlearning approaches, trained on extremely large data sets or using\nreinforcement learning methods have even exceeded human performance in visual\ntasks, particularly on playing games such as Atari, or mastering the game of\nGo. Even in the medical domain there are remarkable results. The central\nproblem of such models is that they are regarded as black-box models and even\nif we understand the underlying mathematical principles, they lack an explicit\ndeclarative knowledge representation, hence have difficulty in generating the\nunderlying explanatory structures. This calls for systems enabling to make\ndecisions transparent, understandable and explainable. A huge motivation for\nour approach are rising legal and privacy aspects. The new European General\nData Protection Regulation entering into force on May 25th 2018, will make\nblack-box approaches difficult to use in business. This does not imply a ban on\nautomatic learning approaches or an obligation to explain everything all the\ntime, however, there must be a possibility to make the results re-traceable on\ndemand. In this paper we outline some of our research topics in the context of\nthe relatively new area of explainable-AI with a focus on the application in\nmedicine, which is a very special domain. This is due to the fact that medical\nprofessionals are working mostly with distributed heterogeneous and complex\nsources of data. In this paper we concentrate on three sources: images, *omics\ndata and text. We argue that research in explainable-AI would generally help to\nfacilitate the implementation of AI/ML in the medical domain, and specifically\nhelp to facilitate transparency and trust."
    },
    "1806.01264": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guineng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mukherjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subhabrata"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xin Luna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Feifei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "OpenTag: Open Attribute Value Extraction from Product Profiles",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining, London, UK, August 19-23, 2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3219819.3219839",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Extraction of missing attribute values is to find values describing an\nattribute of interest from a free text input. Most past related work on\nextraction of missing attribute values work with a closed world assumption with\nthe possible set of values known beforehand, or use dictionaries of values and\nhand-crafted features. How can we discover new attribute values that we have\nnever seen before? Can we do this with limited human annotation or supervision?\nWe study this problem in the context of product catalogs that often have\nmissing values for many attributes of interest.\n  In this work, we leverage product profile information such as titles and\ndescriptions to discover missing values of product attributes. We develop a\nnovel deep tagging model OpenTag for this extraction problem with the following\ncontributions: (1) we formalize the problem as a sequence tagging task, and\npropose a joint model exploiting recurrent neural networks (specifically,\nbidirectional LSTM) to capture context and semantics, and Conditional Random\nFields (CRF) to enforce tagging consistency, (2) we develop a novel attention\nmechanism to provide interpretable explanation for our model's decisions, (3)\nwe propose a novel sampling strategy exploring active learning to reduce the\nburden of human annotation. OpenTag does not use any dictionary or hand-crafted\nfeatures as in prior works. Extensive experiments in real-life datasets in\ndifferent domains show that OpenTag with our active learning strategy discovers\nnew attribute values from as few as 150 annotated samples (reduction in 3.3x\namount of annotation effort) with a high F-score of 83%, outperforming\nstate-of-the-art models."
    },
    "1702.06831": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mihel\u010di\u0107",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matej"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "\u0160imi\u0107",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Goran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Leko",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mirjana Babi\u0107"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lavra\u010d",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nada"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "D\u017eeroski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sa\u0161o"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "\u0160muc",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tomislav"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Using Redescription Mining to Relate Clinical and Biological\n  Characteristics of Cognitively Impaired and Alzheimer's Disease Patients",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.QM cs.AI q-bio.NC",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1371/journal.pone.0187364",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We used redescription mining to find interpretable rules revealing\nassociations between those determinants that provide insights about the\nAlzheimer's disease (AD). We extended the CLUS-RM redescription mining\nalgorithm to a constraint-based redescription mining (CBRM) setting, which\nenables several modes of targeted exploration of specific, user-constrained\nassociations. Redescription mining enabled finding specific constructs of\nclinical and biological attributes that describe many groups of subjects of\ndifferent size, homogeneity and levels of cognitive impairment. We confirmed\nsome previously known findings. However, in some instances, as with the\nattributes: testosterone, the imaging attribute Spatial Pattern of\nAbnormalities for Recognition of Early AD, as well as the levels of leptin and\nangiopoietin-2 in plasma, we corroborated previously debatable findings or\nprovided additional information about these variables and their association\nwith AD pathogenesis. Applying redescription mining on ADNI data resulted with\nthe discovery of one largely unknown attribute: the Pregnancy-Associated\nProtein-A (PAPP-A), which we found highly associated with cognitive impairment\nin AD. Statistically significant correlations (p <= 0.01) were found between\nPAPP-A and various different clinical tests. The high importance of this\nfinding lies in the fact that PAPP-A is a metalloproteinase, known to cleave\ninsulin-like growth factor binding proteins. Since it also shares similar\nsubstrates with A Disintegrin and the Metalloproteinase family of enzymes that\nact as {\\alpha}-secretase to physiologically cleave amyloid precursor protein\n(APP) in the non-amyloidogenic pathway, it could be directly involved in the\nmetabolism of APP very early during the disease course. Therefore, further\nstudies should investigate the role of PAPP-A in the development of AD more\nthoroughly."
    },
    "1804.11192": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongfeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Recommendation: A Survey and New Perspectives",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.MM",
        "http://arxiv.org/OAI/arXiv/:comments": "88 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Explainable Recommendation refers to the personalized recommendation\nalgorithms that address the problem of why -- they not only provide the user\nwith the recommendations, but also make the user aware why such items are\nrecommended by generating recommendation explanations, which help to improve\nthe effectiveness, efficiency, persuasiveness, and user satisfaction of\nrecommender systems. In recent years, a large number of explainable\nrecommendation approaches -- especially model-based explainable recommendation\nalgorithms -- have been proposed and adopted in real-world systems.\n  In this survey, we review the work on explainable recommendation that has\nbeen published in or before the year of 2018. We first high-light the position\nof explainable recommendation in recommender system research by categorizing\nrecommendation problems into the 5W, i.e., what, when, who, where, and why. We\nthen conduct a comprehensive survey of explainable recommendation itself in\nterms of three aspects: 1) We provide a chronological research line of\nexplanations in recommender systems, including the user study approaches in the\nearly years, as well as the more recent model-based approaches. 2) We provide a\ntaxonomy for explainable recommendation algorithms, including user-based,\nitem-based, model-based, and post-model explanations. 3) We summarize the\napplication of explainable recommendation in different recommendation tasks,\nincluding product recommendation, social recommendation, POI recommendation,\netc. We devote a chapter to discuss the explanation perspectives in the broader\nIR and machine learning settings, as well as their relationship with\nexplainable recommendation research. We end the survey by discussing potential\nfuture research directions to promote the explainable recommendation research\narea."
    },
    "1607.00992": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pujara",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Getoor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lise"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generic Statistical Relational Entity Resolution in Knowledge Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "In the Sixth International Workshop on Statistical Relational AI,\n  2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Entity resolution, the problem of identifying the underlying entity of\nreferences found in data, has been researched for many decades in many\ncommunities. A common theme in this research has been the importance of\nincorporating relational features into the resolution process. Relational\nentity resolution is particularly important in knowledge graphs (KGs), which\nhave a regular structure capturing entities and their interrelationships. We\nidentify three major problems in KG entity resolution: (1) intra-KG reference\nambiguity; (2) inter-KG reference ambiguity; and (3) ambiguity when extending\nKGs with new facts. We implement a framework that generalizes across these\nthree settings and exploits this regular structure of KGs. Our framework has\nmany advantages over custom solutions widely deployed in industry, including\ncollective inference, scalability, and interpretability. We apply our framework\nto two real-world KG entity resolution problems, ambiguity in NELL and merging\ndata from Freebase and MusicBrainz, demonstrating the importance of relational\nfeatures."
    },
    "1807.10935": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Renz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jochen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hua",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Explainable Inference about Object Motion using Qualitative\n  Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The capability of making explainable inferences regarding physical processes\nhas long been desired. One fundamental physical process is object motion.\nInferring what causes the motion of a group of objects can even be a\nchallenging task for experts, e.g., in forensics science. Most of the work in\nthe literature relies on physics simulation to draw such infer- ences. The\nsimulation requires a precise model of the under- lying domain to work well and\nis essentially a black-box from which one can hardly obtain any useful\nexplanation. By contrast, qualitative reasoning methods have the advan- tage in\nmaking transparent inferences with ambiguous infor- mation, which makes it\nsuitable for this task. However, there has been no suitable qualitative theory\nproposed for object motion in three-dimensional space. In this paper, we take\nthis challenge and develop a qualitative theory for the motion of rigid\nobjects. Based on this theory, we develop a reasoning method to solve a very\ninteresting problem: Assuming there are several objects that were initially at\nrest and now have started to move. We want to infer what action causes the\nmovement of these objects."
    },
    "1706.07160": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Puri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nikaash"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Piyush"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pratiksha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sukriti"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishnamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Balaji"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "MAGIX: Model Agnostic Globally Interpretable Explanations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Explaining the behavior of a black box machine learning model at the instance\nlevel is useful for building trust. However, what is also important is\nunderstanding how the model behaves globally. Such an understanding provides\ninsight into both the data on which the model was trained and the\ngeneralization power of the rules it learned. We present here an approach that\nlearns rules to explain globally the behavior of black box machine learning\nmodels. Collectively these rules represent the logic learned by the model and\nare hence useful for gaining insight into its behavior. We demonstrate the\npower of the approach on three publicly available data sets."
    },
    "1511.02210": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-11-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Optimized Or's of And's",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Or's of And's (OA) models are comprised of a small number of disjunctions of\nconjunctions, also called disjunctive normal form. An example of an OA model is\nas follows: If ($x_1 = $ `blue' AND $x_2=$ `middle') OR ($x_1 = $ `yellow'),\nthen predict $Y=1$, else predict $Y=0$. Or's of And's models have the advantage\nof being interpretable to human experts, since they are a set of conditions\nthat concisely capture the characteristics of a specific subset of data. We\npresent two optimization-based machine learning frameworks for constructing OA\nmodels, Optimized OA (OOA) and its faster version, Optimized OA with\nApproximations (OOAx). We prove theoretical bounds on the properties of\npatterns in an OA model. We build OA models as a diagnostic screening tool for\nobstructive sleep apnea, that achieves high accuracy with a substantial gain in\ninterpretability over other methods."
    },
    "cs_0307014": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2003-07-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wolff",
                "http://arxiv.org/OAI/arXiv/:forenames": "J Gerard"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Syntax, Parsing and Production of Natural Language in a Framework of\n  Information Compression by Multiple Alignment, Unification and Search",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.7",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Universal Computer Science 6(8), 781--829, 2000",
        "http://arxiv.org/OAI/arXiv/:abstract": "This article introduces the idea that \"information compression by multiple\nalignment, unification and search\" (ICMAUS) provides a framework within which\nnatural language syntax may be represented in a simple format and the parsing\nand production of natural language may be performed in a transparent manner.\n  The ICMAUS concepts are embodied in a software model, SP61. The organisation\nand operation of the model are described and a simple example is presented\nshowing how the model can achieve parsing of natural language.\n  Notwithstanding the apparent paradox of 'decompression by compression', the\nICMAUS framework, without any modification, can produce a sentence by decoding\na compressed code for the sentence. This is illustrated with output from the\nSP61 model.\n  The article includes four other examples - one of the parsing of a sentence\nin French and three from the domain of English auxiliary verbs. These examples\nshow how the ICMAUS framework and the SP61 model can accommodate 'context\nsensitive' features of syntax in a relatively simple and direct manner."
    },
    "0808.0973": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2008-08-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chemudugunta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chaitanya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smyth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Padhraic"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Steyvers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Text Modeling using Unsupervised Topic Models and Concept Hierarchies",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.IR",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Statistical topic models provide a general data-driven framework for\nautomated discovery of high-level knowledge from large collections of text\ndocuments. While topic models can potentially discover a broad range of themes\nin a data set, the interpretability of the learned topics is not always ideal.\nHuman-defined concepts, on the other hand, tend to be semantically richer due\nto careful selection of words to define concepts but they tend not to cover the\nthemes in a data set exhaustively. In this paper, we propose a probabilistic\nframework to combine a hierarchy of human-defined semantic concepts with\nstatistical topic models to seek the best of both worlds. Experimental results\nusing two different sources of concept hierarchies and two collections of text\ndocuments indicate that this combination leads to systematic improvements in\nthe quality of the associated language models as well as enabling new\ntechniques for inferring and visualizing the semantics of a document."
    },
    "1712.00846": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hundman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kyle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gowda",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thamme"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kejriwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mayank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boecking",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benedikt"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Always Lurking: Understanding and Mitigating Bias in Online Human\n  Trafficking Detection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to 2018 AAAI 1st conference on AI, Ethics, and Society.\n  Awaiting review",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "AAAI/ACM First conference on Artificial Intelligence, Ethics, and\n  Society, New Orleans, USA, February 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Web-based human trafficking activity has increased in recent years but it\nremains sparsely dispersed among escort advertisements and difficult to\nidentify due to its often-latent nature. The use of intelligent systems to\ndetect trafficking can thus have a direct impact on investigative resource\nallocation and decision-making, and, more broadly, help curb a widespread\nsocial problem. Trafficking detection involves assigning a normalized score to\na set of escort advertisements crawled from the Web -- a higher score indicates\na greater risk of trafficking-related (involuntary) activities. In this paper,\nwe define and study the problem of trafficking detection and present a\ntrafficking detection pipeline architecture developed over three years of\nresearch within the DARPA Memex program. Drawing on multi-institutional data,\nsystems, and experiences collected during this time, we also conduct post hoc\nbias analyses and present a bias mitigation plan. Our findings show that, while\nautomatic trafficking detection is an important application of AI for social\ngood, it also provides cautionary lessons for deploying predictive machine\nlearning algorithms without appropriate de-biasing. This ultimately led to\nintegration of an interpretable solution into a search system that contains\nover 100 million advertisements and is used by over 200 law enforcement\nagencies to investigate leads."
    },
    "1709.09093": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Geiger",
                "http://arxiv.org/OAI/arXiv/:forenames": "R. Stuart"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Beyond opening up the black box: Investigating the role of algorithmic\n  systems in Wikipedian organizational culture",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, typo fixed in v2",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Big Data & Society 4(2). 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1177/2053951717730735",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Scholars and practitioners across domains are increasingly concerned with\nalgorithmic transparency and opacity, interrogating the values and assumptions\nembedded in automated, black-boxed systems, particularly in user-generated\ncontent platforms. I report from an ethnography of infrastructure in Wikipedia\nto discuss an often understudied aspect of this topic: the local, contextual,\nlearned expertise involved in participating in a highly automated\nsocial-technical environment. Today, the organizational culture of Wikipedia is\ndeeply intertwined with various data-driven algorithmic systems, which\nWikipedians rely on to help manage and govern the \"anyone can edit\"\nencyclopedia at a massive scale. These bots, scripts, tools, plugins, and\ndashboards make Wikipedia more efficient for those who know how to work with\nthem, but like all organizational culture, newcomers must learn them if they\nwant to fully participate. I illustrate how cultural and organizational\nexpertise is enacted around algorithmic agents by discussing two\nautoethnographic vignettes, which relate my personal experience as a veteran in\nWikipedia. I present thick descriptions of how governance and gatekeeping\npractices are articulated through and in alignment with these automated\ninfrastructures. Over the past 15 years, Wikipedian veterans and administrators\nhave made specific decisions to support administrative and editorial workflows\nwith automation in particular ways and not others. I use these cases of\nWikipedia's bot-supported bureaucracy to discuss several issues in the fields\nof critical algorithms studies, critical data studies, and fairness,\naccountability, and transparency in machine learning -- most principally\narguing that scholarship and practice must go beyond trying to \"open up the\nblack box\" of such systems and also examine sociocultural processes like\nnewcomer socialization."
    },
    "1708.08296": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Samek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wojciech"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wiegand",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "M\u00fcller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Klaus-Robert"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable Artificial Intelligence: Understanding, Visualizing and\n  Interpreting Deep Learning Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "With the availability of large databases and recent improvements in deep\nlearning methodology, the performance of AI systems is reaching or even\nexceeding the human level on an increasing number of complex tasks. Impressive\nexamples of this development can be found in domains such as image\nclassification, sentiment analysis, speech understanding or strategic game\nplaying. However, because of their nested non-linear structure, these highly\nsuccessful machine learning and artificial intelligence models are usually\napplied in a black box manner, i.e., no information is provided about what\nexactly makes them arrive at their predictions. Since this lack of transparency\ncan be a major drawback, e.g., in medical applications, the development of\nmethods for visualizing, explaining and interpreting deep learning models has\nrecently attracted increasing attention. This paper summarizes recent\ndevelopments in this field and makes a plea for more interpretability in\nartificial intelligence. Furthermore, it presents two approaches to explaining\npredictions of deep learning models, one method which computes the sensitivity\nof the prediction with respect to changes in the input and one approach which\nmeaningfully decomposes the decision in terms of the input variables. These\nmethods are evaluated on three classification tasks."
    },
    "1605.04934": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Reardon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lynne E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hao"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Self-Reflective Risk-Aware Artificial Cognitive Modeling for Robot\n  Response to Human Behaviors",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "40 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order for cooperative robots (\"co-robots\") to respond to human behaviors\naccurately and efficiently in human-robot collaboration, interpretation of\nhuman actions, awareness of new situations, and appropriate decision making are\nall crucial abilities for co-robots. For this purpose, the human behaviors\nshould be interpreted by co-robots in the same manner as human peers. To\naddress this issue, a novel interpretability indicator is introduced so that\nrobot actions are appropriate to the current human behaviors. In addition, the\ncomplete consideration of all potential situations of a robot's environment is\nnearly impossible in real-world applications, making it difficult for the\nco-robot to act appropriately and safely in new scenarios. This is true even\nwhen the pretrained model is highly accurate in a known situation. For\neffective and safe teaming with humans, we introduce a new generalizability\nindicator that allows a co-robot to self-reflect and reason about when an\nobservation falls outside the co-robot's learned model. Based on topic modeling\nand two novel indicators, we propose a new Self-reflective Risk-aware\nArtificial Cognitive (SRAC) model. The co-robots are able to consider action\nrisks and identify new situations so that better decisions can be made.\nExperiments both using real-world datasets and on physical robots suggest that\nour SRAC model significantly outperforms the traditional methodology and\nenables better decision making in response to human activities."
    },
    "1708.01776": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rosenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Clemens"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Klinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "e-QRAQ: A Multi-turn Reasoning Dataset and Simulator with Explanations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, 3 figures, presented at 2017 ICML Workshop on Human\n  Interpretability in Machine Learning (WHI 2017), Sydney, NSW, Australia",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper we present a new dataset and user simulator e-QRAQ (explainable\nQuery, Reason, and Answer Question) which tests an Agent's ability to read an\nambiguous text; ask questions until it can answer a challenge question; and\nexplain the reasoning behind its questions and answer. The User simulator\nprovides the Agent with a short, ambiguous story and a challenge question about\nthe story. The story is ambiguous because some of the entities have been\nreplaced by variables. At each turn the Agent may ask for the value of a\nvariable or try to answer the challenge question. In response the User\nsimulator provides a natural language explanation of why the Agent's query or\nanswer was useful in narrowing down the set of possible answers, or not. To\ndemonstrate one potential application of the e-QRAQ dataset, we train a new\nneural architecture based on End-to-End Memory Networks to successfully\ngenerate both predictions and partial explanations of its current understanding\nof the problem. We observe a strong correlation between the quality of the\nprediction and explanation."
    },
    "1801.00690": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tassa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuval"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Doron",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yotam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Muldal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alistair"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Erez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yazhe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Casas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diego de Las"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Budden",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abdolmaleki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abbas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Merel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lefrancq",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lillicrap",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timothy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riedmiller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "DeepMind Control Suite",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages, 7 figures, 2 tables",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The DeepMind Control Suite is a set of continuous control tasks with a\nstandardised structure and interpretable rewards, intended to serve as\nperformance benchmarks for reinforcement learning agents. The tasks are written\nin Python and powered by the MuJoCo physics engine, making them easy to use and\nmodify. We include benchmarks for several learning algorithms. The Control\nSuite is publicly available at https://www.github.com/deepmind/dm_control . A\nvideo summary of all tasks is available at http://youtu.be/rAai4QzcYbs ."
    },
    "1806.08340": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wagstaff",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kiri L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jake"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Discovery in Large Image Data Sets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at the 2018 ICML Workshop on Human Interpretability in\n  Machine Learning (WHI 2018), Stockholm, Sweden",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automated detection of new, interesting, unusual, or anomalous images within\nlarge data sets has great value for applications from surveillance (e.g.,\nairport security) to science (observations that don't fit a given theory can\nlead to new discoveries). Many image data analysis systems are turning to\nconvolutional neural networks (CNNs) to represent image content due to their\nsuccess in achieving high classification accuracy rates. However, CNN\nrepresentations are notoriously difficult for humans to interpret. We describe\na new strategy that combines novelty detection with CNN image features to\nachieve rapid discovery with interpretable explanations of novel image content.\nWe applied this technique to familiar images from ImageNet as well as to a\nscientific image collection from planetary science."
    },
    "1610.02391": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Selvaraju",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramprasaath R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cogswell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Das",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhishek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vedantam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramakrishna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based\n  Localization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages, 22 figures. Adds bias experiments, and robustness to\n  adversarial noise",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a technique for producing \"visual explanations\" for decisions from\na large class of CNN-based models, making them more transparent. Our approach -\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of\nany target concept, flowing into the final convolutional layer to produce a\ncoarse localization map highlighting the important regions in the image for\npredicting the concept. Unlike previous approaches, GradCAM is applicable to a\nwide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.\nVGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in\ntasks with multimodal inputs (e.g. VQA) or reinforcement learning, without any\narchitectural changes or re-training. We combine GradCAM with fine-grained\nvisualizations to create a high-resolution class-discriminative visualization\nand apply it to off-the-shelf image classification, captioning, and visual\nquestion answering (VQA) models, including ResNet-based architectures. In the\ncontext of image classification models, our visualizations (a) lend insights\ninto their failure modes (showing that seemingly unreasonable predictions have\nreasonable explanations), (b) are robust to adversarial images, (c) outperform\nprevious methods on weakly-supervised localization, (d) are more faithful to\nthe underlying model and (e) help achieve generalization by identifying dataset\nbias. For captioning and VQA, our visualizations show that even non-attention\nbased models can localize inputs. Finally, we conduct human studies to measure\nif GradCAM explanations help users establish trust in predictions from deep\nnetworks and show that GradCAM helps untrained users successfully discern a\n\"stronger\" deep network from a \"weaker\" one. Our code is available at\nhttps://github.com/ramprs/grad-cam. A demo and a video of the demo can be found\nat http://gradcam.cloudcv.org and youtu.be/COjUB9Izk6E."
    },
    "1709.04571": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harb",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jean"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bacon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre-Luc"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Klissarov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Precup",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Doina"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "When Waiting is not an Option : Learning Options with a Deliberation\n  Cost",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent work has shown that temporally extended actions (options) can be\nlearned fully end-to-end as opposed to being specified in advance. While the\nproblem of \"how\" to learn options is increasingly well understood, the question\nof \"what\" good options should be has remained elusive. We formulate our answer\nto what \"good\" options should be in the bounded rationality framework (Simon,\n1957) through the notion of deliberation cost. We then derive practical\ngradient-based learning algorithms to implement this objective. Our results in\nthe Arcade Learning Environment (ALE) show increased performance and\ninterpretability."
    },
    "1711.06362": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Narv\u00e1ez",
                "http://arxiv.org/OAI/arXiv/:forenames": "David E."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Exploring the Use of Shatter for AllSAT Through Ramsey-Type Problems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the context of SAT solvers, Shatter is a popular tool for symmetry\nbreaking on CNF formulas. Nevertheless, little has been said about its use in\nthe context of AllSAT problems: problems where we are interested in listing all\nthe models of a Boolean formula. AllSAT has gained much popularity in recent\nyears due to its many applications in domains like model checking, data mining,\netc. One example of a particularly transparent application of AllSAT to other\nfields of computer science is computational Ramsey theory. In this paper we\nstudy the effect of incorporating Shatter to the workflow of using Boolean\nformulas to generate all possible edge colorings of a graph avoiding prescribed\nmonochromatic subgraphs. Generating complete sets of colorings is an important\nbuilding block in computational Ramsey theory. We identify two drawbacks in the\nna\\\"ive use of Shatter to break the symmetries of Boolean formulas encoding\nRamsey-type problems for graphs: a \"blow-up\" in the number of models and the\ngeneration of incomplete sets of colorings. The issues presented in this work\nare not intended to discourage the use of Shatter as a preprocessing tool for\nAllSAT problems in combinatorial computing but to help researchers properly use\nthis tool by avoiding these potential pitfalls. To this end, we provide\nstrategies and additional tools to cope with the negative effects of using\nShatter for AllSAT. While the specific application addressed in this paper is\nthat of Ramsey-type problems, the analysis we carry out applies to many other\nareas in which highly-symmetrical Boolean formulas arise and we wish to find\nall of their models."
    },
    "1607.06186": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Navarro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Javier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wagner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aickelin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Uwe"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Applying Interval Type-2 Fuzzy Rule Based Classifiers Through a\n  Cluster-Based Class Representation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "2015 IEEE Symposium Series on Computational Intelligence, pp.\n  1816-1823, IEEE, 2015, ISBN: 978-1-4799-7560-0",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fuzzy Rule-Based Classification Systems (FRBCSs) have the potential to\nprovide so-called interpretable classifiers, i.e. classifiers which can be\nintrospective, understood, validated and augmented by human experts by relying\non fuzzy-set based rules. This paper builds on prior work for interval type-2\nfuzzy set based FRBCs where the fuzzy sets and rules of the classifier are\ngenerated using an initial clustering stage. By introducing Subtractive\nClustering in order to identify multiple cluster prototypes, the proposed\napproach has the potential to deliver improved classification performance while\nmaintaining good interpretability, i.e. without resulting in an excessive\nnumber of rules. The paper provides a detailed overview of the proposed FRBC\nframework, followed by a series of exploratory experiments on both linearly and\nnon-linearly separable datasets, comparing results to existing rule-based and\nSVM approaches. Overall, initial results indicate that the approach enables\ncomparable classification performance to non rule-based classifiers such as\nSVM, while often achieving this with a very small number of rules."
    },
    "1706.05171": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kazmi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mishal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sch\u00fcller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sayg\u0131n",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Y\u00fccel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving Scalability of Inductive Logic Programming via Pruning and\n  Best-Effort Optimisation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages, preprint of article accepted at Expert Systems With\n  Applications",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Expert Systems With Applications 87, pages 291-303, 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.eswa.2017.06.013",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Inductive Logic Programming (ILP) combines rule-based and statistical\nartificial intelligence methods, by learning a hypothesis comprising a set of\nrules given background knowledge and constraints for the search space. We focus\non extending the XHAIL algorithm for ILP which is based on Answer Set\nProgramming and we evaluate our extensions using the Natural Language\nProcessing application of sentence chunking. With respect to processing natural\nlanguage, ILP can cater for the constant change in how we use language on a\ndaily basis. At the same time, ILP does not require huge amounts of training\nexamples such as other statistical methods and produces interpretable results,\nthat means a set of rules, which can be analysed and tweaked if necessary. As\ncontributions we extend XHAIL with (i) a pruning mechanism within the\nhypothesis generalisation algorithm which enables learning from larger\ndatasets, (ii) a better usage of modern solver technology using recently\ndeveloped optimisation methods, and (iii) a time budget that permits the usage\nof suboptimal results. We evaluate these improvements on the task of sentence\nchunking using three datasets from a recent SemEval competition. Results show\nthat our improvements allow for learning on bigger datasets with results that\nare of similar quality to state-of-the-art systems on the same task. Moreover,\nwe compare the hypotheses obtained on datasets to gain insights on the\nstructure of each dataset."
    },
    "1801.07729": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Elgammal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ahmed"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mazzone",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bingchen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diana"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Elhoseiny",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohamed"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Shape of Art History in the Eyes of the Machine",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "How does the machine classify styles in art? And how does it relate to art\nhistorians' methods for analyzing style? Several studies have shown the ability\nof the machine to learn and predict style categories, such as Renaissance,\nBaroque, Impressionism, etc., from images of paintings. This implies that the\nmachine can learn an internal representation encoding discriminative features\nthrough its visual analysis. However, such a representation is not necessarily\ninterpretable. We conducted a comprehensive study of several of the\nstate-of-the-art convolutional neural networks applied to the task of style\nclassification on 77K images of paintings, and analyzed the learned\nrepresentation through correlation analysis with concepts derived from art\nhistory. Surprisingly, the networks could place the works of art in a smooth\ntemporal arrangement mainly based on learning style labels, without any a\npriori knowledge of time of creation, the historical time and context of\nstyles, or relations between styles. The learned representations showed that\nthere are few underlying factors that explain the visual variations of style in\nart. Some of these factors were found to correlate with style patterns\nsuggested by Heinrich W\\\"olfflin (1846-1945). The learned representations also\nconsistently highlighted certain artists as the extreme distinctive\nrepresentative of their styles, which quantitatively confirms art historian\nobservations."
    },
    "1810.00424": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van Dijk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stanley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jay S.",
                    "http://arxiv.org/OAI/arXiv/:suffix": "III"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amodio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wolf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishnaswamy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Smita"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Graph Spectral Regularization for Neural Network Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "fixed typos",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks can learn meaningful representations of data. However,\nthese representations are hard to interpret. For example, visualizing a latent\nlayer is generally only possible for at most three dimensions. Neural networks\nare able to learn and benefit from much higher dimensional representationsm but\nthese are not visually interpretable because neurons have arbitrary ordering\nwithin a layer. Here, we utilize the ability of a human observer to identify\npatterns in structured representations to visualize higher dimensions. To do\nso, we propose a class of regularizations we call Graph Spectral\nRegularizations that impose graph structure on latent layers. This is achieved\nby treating activations as signals on a predefined graph and constraining those\nactivations using graph filters, such as low pass and wavelet-like filters.\nThis framework allows for any kind of graphs and filters to achieve a wide\nrange of structured regularizations depending on the inference needs of the\ndata. First, we show a synthetic example where a graph-structured layer reveals\ntopological features of the data. Next, we show that a smoothing regularization\nimposes semantically consistent ordering of nodes when applied to capsule nets.\nFurther, we show that the graph-structured layer, using wavelet-like spatially\nlocalized filters, can form local receptive fields for improved image and\nbiomedical data interpretation. In other words, the mapping between latent\nlayer, neurons and the output space becomes clear due to the localization of\nthe activations. Finally, we show that when structured as a grid, the\nrepresentations create coherent images that allow for image processing\ntechniques such as convolutions."
    },
    "1710.10532": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kasenberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scheutz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthias"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Apprenticeship Learning with Temporal Logic Specifications",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SY cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to the 56th IEEE Conference on Decision and Control (CDC\n  2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent work has addressed using formulas in linear temporal logic (LTL) as\nspecifications for agents planning in Markov Decision Processes (MDPs). We\nconsider the inverse problem: inferring an LTL specification from demonstrated\nbehavior trajectories in MDPs. We formulate this as a multiobjective\noptimization problem, and describe state-based (\"what actually happened\") and\naction-based (\"what the agent expected to happen\") objective functions based on\na notion of \"violation cost\". We demonstrate the efficacy of the approach by\nemploying genetic programming to solve this problem in two simple domains."
    },
    "1809.09468": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pereira",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Raphael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Alves",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Reyes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mauricio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Silva",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlos A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automatic brain tumor grading from MRI data using convolutional neural\n  networks and quality assessment",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted and presented at iMIMIC - Workshop on Interpretability of\n  Machine Intelligence in Medical Image Computing",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/978-3-030-02628-8",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Glioblastoma Multiforme is a high grade, very aggressive, brain tumor, with\npatients having a poor prognosis. Lower grade gliomas are less aggressive, but\nthey can evolve into higher grade tumors over time. Patient management and\ntreatment can vary considerably with tumor grade, ranging from tumor resection\nfollowed by a combined radio- and chemotherapy to a \"wait and see\" approach.\nHence, tumor grading is important for adequate treatment planning and\nmonitoring. The gold standard for tumor grading relies on histopathological\ndiagnosis of biopsy specimens. However, this procedure is invasive, time\nconsuming, and prone to sampling error. Given these disadvantages, automatic\ntumor grading from widely used MRI protocols would be clinically important, as\na way to expedite treatment planning and assessment of tumor evolution. In this\npaper, we propose to use Convolutional Neural Networks for predicting tumor\ngrade directly from imaging data. In this way, we overcome the need for expert\nannotations of regions of interest. We evaluate two prediction approaches: from\nthe whole brain, and from an automatically defined tumor region. Finally, we\nemploy interpretability methodologies as a quality assurance stage to check if\nthe method is using image regions indicative of tumor grade for classification."
    },
    "cs_0504065": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2005-04-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schetinin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vitaly"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fieldsend",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Partridge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krzanowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wojtek J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Everson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bailey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Trevor C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adolfo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Estimating Classification Uncertainty of Bayesian Decision Tree\n  Technique on Financial Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bayesian averaging over classification models allows the uncertainty of\nclassification outcomes to be evaluated, which is of crucial importance for\nmaking reliable decisions in applications such as financial in which risks have\nto be estimated. The uncertainty of classification is determined by a trade-off\nbetween the amount of data available for training, the diversity of a\nclassifier ensemble and the required performance. The interpretability of\nclassification models can also give useful information for experts responsible\nfor making reliable classifications. For this reason Decision Trees (DTs) seem\nto be attractive classification models. The required diversity of the DT\nensemble can be achieved by using the Bayesian model averaging all possible\nDTs. In practice, the Bayesian approach can be implemented on the base of a\nMarkov Chain Monte Carlo (MCMC) technique of random sampling from the posterior\ndistribution. For sampling large DTs, the MCMC method is extended by Reversible\nJump technique which allows inducing DTs under given priors. For the case when\nthe prior information on the DT size is unavailable, the sweeping technique\ndefining the prior implicitly reveals a better performance. Within this Chapter\nwe explore the classification uncertainty of the Bayesian MCMC techniques on\nsome datasets from the StatLog Repository and real financial data. The\nclassification uncertainty is compared within an Uncertainty Envelope technique\ndealing with the class posterior distribution and a given confidence\nprobability. This technique provides realistic estimates of the classification\nuncertainty which can be easily interpreted in statistical terms with the aim\nof risk evaluation."
    },
    "1807.06161": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bharadhwaj",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Homanga"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Joshi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shruti"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explanations for Temporal Recommendations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC cs.IR cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at the XAI Workshop in IJCAI/ECAI 2018",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Homanga Bharadhwaj and Shruti Joshi. \"Explanations for Temporal\n  Recommendations\" IJCAI-18 Workshop on Explainable AI (XAI). 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recommendation systems are an integral part of Artificial Intelligence (AI)\nand have become increasingly important in the growing age of commercialization\nin AI. Deep learning (DL) techniques for recommendation systems (RS) provide\npowerful latent-feature models for effective recommendation but suffer from the\nmajor drawback of being non-interpretable. In this paper we describe a\nframework for explainable temporal recommendations in a DL model. We consider\nan LSTM based Recurrent Neural Network (RNN) architecture for recommendation\nand a neighbourhood-based scheme for generating explanations in the model. We\ndemonstrate the effectiveness of our approach through experiments on the\nNetflix dataset by jointly optimizing for both prediction accuracy and\nexplainability."
    },
    "1708.06374": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shalev-Shwartz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shammah",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shaked"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shashua",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amnon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On a Formal Model of Safe and Scalable Self-driving Cars",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent years, car makers and tech companies have been racing towards self\ndriving cars. It seems that the main parameter in this race is who will have\nthe first car on the road. The goal of this paper is to add to the equation two\nadditional crucial parameters. The first is standardization of safety assurance\n--- what are the minimal requirements that every self-driving car must satisfy,\nand how can we verify these requirements. The second parameter is scalability\n--- engineering solutions that lead to unleashed costs will not scale to\nmillions of cars, which will push interest in this field into a niche academic\ncorner, and drive the entire field into a \"winter of autonomous driving\". In\nthe first part of the paper we propose a white-box, interpretable, mathematical\nmodel for safety assurance, which we call Responsibility-Sensitive Safety\n(RSS). In the second part we describe a design of a system that adheres to our\nsafety assurance requirements and is scalable to millions of cars."
    },
    "1805.00314": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josiah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madhyastha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranava"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Specia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lucia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Object Counts! Bringing Explicit Detections Back into Image Captioning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "Please cite: In Proceedings of 2018 Conference of the North American\n  Chapter of the Association for Computational Linguistics (NAACL 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The use of explicit object detectors as an intermediate step to image\ncaptioning - which used to constitute an essential stage in early work - is\noften bypassed in the currently dominant end-to-end approaches, where the\nlanguage model is conditioned directly on a mid-level image embedding. We argue\nthat explicit detections provide rich semantic information, and can thus be\nused as an interpretable representation to better understand why end-to-end\nimage captioning systems work well. We provide an in-depth analysis of\nend-to-end image captioning by exploring a variety of cues that can be derived\nfrom such object detections. Our study reveals that end-to-end image captioning\nsystems rely on matching image representations to generate captions, and that\nencoding the frequency, size and position of objects are complementary and all\nplay a role in forming a good image representation. It also reveals that\ndifferent object categories contribute in different ways towards image\ncaptioning."
    },
    "1709.00572": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cangea",
                    "http://arxiv.org/OAI/arXiv/:forenames": "C\u0103t\u0103lina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veli\u010dkovi\u0107",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Petar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li\u00f2",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pietro"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "XFlow: 1D-2D Cross-modal Deep Neural Networks for Audiovisual\n  Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at the IEEE ICDL-EPIROB 2017 Workshop on Computational\n  Models for Crossmodal Learning (CMCML), 4 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose two multimodal deep learning architectures that allow for\ncross-modal dataflow (XFlow) between the feature extractors, thereby extracting\nmore interpretable features and obtaining a better representation than through\nunimodal learning, for the same amount of training data. These models can\nusefully exploit correlations between audio and visual data, which have a\ndifferent dimensionality and are therefore nontrivially exchangeable. Our work\nimproves on existing multimodal deep learning metholodogies in two essential\nways: (1) it presents a novel method for performing cross-modality (before\nfeatures are learned from individual modalities) and (2) extends the previously\nproposed cross-connections, which only transfer information between streams\nthat process compatible data. Both cross-modal architectures outperformed their\nbaselines (by up to 7.5%) when evaluated on the AVletters dataset."
    },
    "1808.07074": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Besold",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tarek R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Uckelman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sara L."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The What, the Why, and the How of Artificial Explanations in Automated\n  Decision-Making",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "working draft, comments/feedback welcome",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The increasing incorporation of Artificial Intelligence in the form of\nautomated systems into decision-making procedures highlights not only the\nimportance of decision theory for automated systems but also the need for these\ndecision procedures to be explainable to the people involved in them.\nTraditional realist accounts of explanation, wherein explanation is a relation\nthat holds (or does not hold) eternally between an explanans and an\nexplanandum, are not adequate to account for the notion of explanation required\nfor artificial decision procedures. We offer an alternative account of\nexplanation as used in the context of automated decision-making that makes\nexplanation an epistemic phenomenon, and one that is dependent on context. This\naccount of explanation better accounts for the way that we talk about, and use,\nexplanations and derived concepts, such as `explanatory power', and also allows\nus to differentiate between reasons or causes on the one hand, which do not\nneed to have an epistemic aspect, and explanations on the other, which do have\nsuch an aspect. Against this theoretical backdrop we then review existing\napproaches to explanation in Artificial Intelligence and Machine Learning, and\nsuggest desiderata which truly explainable decision systems should fulfill."
    },
    "1808.07561": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bapna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ankur"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mia Xu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Firat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Orhan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yonghui"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Training Deeper Neural Machine Translation Models with Transparent\n  Attention",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in EMNLP 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While current state-of-the-art NMT models, such as RNN seq2seq and\nTransformers, possess a large number of parameters, they are still shallow in\ncomparison to convolutional models used for both text and vision applications.\nIn this work we attempt to train significantly (2-3x) deeper Transformer and\nBi-RNN encoders for machine translation. We propose a simple modification to\nthe attention mechanism that eases the optimization of deeper models, and\nresults in consistent gains of 0.7-1.1 BLEU on the benchmark WMT'14\nEnglish-German and WMT'15 Czech-English tasks for both architectures."
    },
    "1708.04670": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dianbo",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Oggi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fengjiao",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Oggi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shea",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Oggi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ognjen",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Oggi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudovic"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Picard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rosalind"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "DeepFaceLIFT: Interpretable Personalized Models for Automatic Estimation\n  of Self-Reported Pain",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Previous research on automatic pain estimation from facial expressions has\nfocused primarily on \"one-size-fits-all\" metrics (such as PSPI). In this work,\nwe focus on directly estimating each individual's self-reported visual-analog\nscale (VAS) pain metric, as this is considered the gold standard for pain\nmeasurement. The VAS pain score is highly subjective and context-dependent, and\nits range can vary significantly among different persons. To tackle these\nissues, we propose a novel two-stage personalized model, named DeepFaceLIFT,\nfor automatic estimation of VAS. This model is based on (1) Neural Network and\n(2) Gaussian process regression models, and is used to personalize the\nestimation of self-reported pain via a set of hand-crafted personal features\nand multi-task learning. We show on the benchmark dataset for pain analysis\n(The UNBC-McMaster Shoulder Pain Expression Archive) that the proposed\npersonalized model largely outperforms the traditional, unpersonalized models:\nthe intra-class correlation improves from a baseline performance of 19\\% to a\npersonalized performance of 35\\% while also providing confidence in the\nmodel\\textquotesingle s estimates -- in contrast to existing models for the\ntarget task. Additionally, DeepFaceLIFT automatically discovers the\npain-relevant facial regions for each person, allowing for an easy\ninterpretation of the pain-related facial cues."
    },
    "1711.00848": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhishek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sattigeri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prasanna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Balakrishnan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Avinash"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Variational Inference of Disentangled Latent Concepts from Unlabeled\n  Observations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "added more related work",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Disentangled representations, where the higher level data generative factors\nare reflected in disjoint latent dimensions, offer several benefits such as\nease of deriving invariant representations, transferability to other tasks,\ninterpretability, etc. We consider the problem of unsupervised learning of\ndisentangled representations from large pool of unlabeled observations, and\npropose a variational inference based approach to infer disentangled latent\nfactors. We introduce a regularizer on the expectation of the approximate\nposterior over observed data that encourages the disentanglement. We evaluate\nthe proposed approach using several quantitative metrics and empirically\nobserve significant gains over existing methods in terms of both\ndisentanglement and data likelihood (reconstruction quality)."
    },
    "1610.05984": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-08-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hentschel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Runkler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Udluft",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steffen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Particle Swarm Optimization for Generating Interpretable Fuzzy\n  Reinforcement Learning Policies",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG cs.SY",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Engineering Applications of Artificial Intelligence, Volume 65C,\n  October 2017, Pages 87-98",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.engappai.2017.07.005",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fuzzy controllers are efficient and interpretable system controllers for\ncontinuous state and action spaces. To date, such controllers have been\nconstructed manually or trained automatically either using expert-generated\nproblem-specific cost functions or incorporating detailed knowledge about the\noptimal control strategy. Both requirements for automatic training processes\nare not found in most real-world reinforcement learning (RL) problems. In such\napplications, online learning is often prohibited for safety reasons because\nonline learning requires exploration of the problem's dynamics during policy\ntraining. We introduce a fuzzy particle swarm reinforcement learning (FPSRL)\napproach that can construct fuzzy RL policies solely by training parameters on\nworld models that simulate real system dynamics. These world models are created\nby employing an autonomous machine learning technique that uses previously\ngenerated transition samples of a real system. To the best of our knowledge,\nthis approach is the first to relate self-organizing fuzzy controllers to\nmodel-based batch RL. Therefore, FPSRL is intended to solve problems in domains\nwhere online learning is prohibited, system dynamics are relatively easy to\nmodel from previously generated default policy transition samples, and it is\nexpected that a relatively easily interpretable control policy exists. The\nefficiency of the proposed approach with problems from such domains is\ndemonstrated using three standard RL benchmarks, i.e., mountain car, cart-pole\nbalancing, and cart-pole swing-up. Our experimental results demonstrate\nhigh-performing, interpretable fuzzy policies."
    },
    "1711.07661": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kaixuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiwen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xianzhi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dalin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fullie and Wiselie: A Dual-Stream Recurrent Convolutional Attention\n  Model for Activity Recognition",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Multimodal features play a key role in wearable sensor based Human Activity\nRecognition (HAR). Selecting the most salient features adaptively is a\npromising way to maximize the effectiveness of multimodal sensor data. In this\nregard, we propose a \"collect fully and select wisely (Fullie and Wiselie)\"\nprinciple as well as a dual-stream recurrent convolutional attention model,\nRecurrent Attention and Activity Frame (RAAF), to improve the recognition\nperformance. We first collect modality features and the relations between each\npair of features to generate activity frames, and then introduce an attention\nmechanism to select the most prominent regions from activity frames precisely.\nThe selected frames not only maximize the utilization of valid features but\nalso reduce the number of features to be computed effectively. We further\nanalyze the hyper-parameters, accuracy, interpretability, and annotation\ndependency of the proposed model based on extensive experiments. The results\nshow that RAAF achieves competitive performance on two benchmarked datasets and\nworks well in real life scenarios."
    },
    "1802.05998": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Teijeiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom\u00e1s"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garc\u00eda",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Constantino A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Castro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "F\u00e9lix",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paulo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Abductive reasoning as the basis to reproduce expert criteria in ECG\n  Atrial Fibrillation identification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 6 figures, 6 tables",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68T10",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Objective: This work aims at providing a new method for the automatic\ndetection of atrial fibrillation, other arrhythmia and noise on short single\nlead ECG signals, emphasizing the importance of the interpretability of the\nclassification results.\n  Approach: A morphological and rhythm description of the cardiac behavior is\nobtained by a knowledge-based interpretation of the signal using the\n\\textit{Construe} abductive framework. Then, a set of meaningful features are\nextracted for each individual heartbeat and as a summary of the full record.\nThe feature distributions were used to elucidate the expert criteria underlying\nthe labeling of the 2017 Physionet/CinC Challenge dataset, enabling a manual\npartial relabeling to improve the consistency of the classification rules.\nFinally, state-of-the-art machine learning methods are combined to provide an\nanswer on the basis of the feature values.\n  Main results: The proposal tied for the first place in the official stage of\nthe Challenge, with a combined $F_1$ score of 0.83, and was even improved in\nthe follow-up stage to 0.85 with a significant simplification of the model.\n  Significance: This approach demonstrates the potential of \\textit{Construe}\nto provide robust and valuable descriptions of temporal data even with\nsignificant amounts of noise and artifacts. Also, we discuss the importance of\na consistent classification criteria in manually labeled training datasets, and\nthe fundamental advantages of knowledge-based approaches to formalize and\nvalidate that criteria."
    },
    "1709.07223": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Horstmeyer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roarke"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard Y."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kappes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Barbara"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Judkewitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benjamin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Convolutional neural networks that teach microscopes how to image",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG physics.optics",
        "http://arxiv.org/OAI/arXiv/:comments": "13 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep learning algorithms offer a powerful means to automatically analyze the\ncontent of medical images. However, many biological samples of interest are\nprimarily transparent to visible light and contain features that are difficult\nto resolve with a standard optical microscope. Here, we use a convolutional\nneural network (CNN) not only to classify images, but also to optimize the\nphysical layout of the imaging device itself. We increase the classification\naccuracy of a microscope's recorded images by merging an optical model of image\nformation into the pipeline of a CNN. The resulting network simultaneously\ndetermines an ideal illumination arrangement to highlight important sample\nfeatures during image acquisition, along with a set of convolutional weights to\nclassify the detected images post-capture. We demonstrate our joint\noptimization technique with an experimental microscope configuration that\nautomatically identifies malaria-infected cells with 5-10% higher accuracy than\nstandard and alternative microscope lighting designs."
    },
    "1802.08129": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Park",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dong Huk"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hendricks",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lisa Anne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Akata",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zeynep"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rohrbach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schiele",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernt"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Darrell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Trevor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rohrbach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcus"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multimodal Explanations: Justifying Decisions and Pointing to the\n  Evidence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: text overlap with arXiv:1612.04757",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep models that are both effective and explainable are desirable in many\nsettings; prior explainable models have been unimodal, offering either\nimage-based visualization of attention weights or text-based generation of\npost-hoc justifications. We propose a multimodal approach to explanation, and\nargue that the two modalities provide complementary explanatory strengths. We\ncollect two new datasets to define and evaluate this task, and propose a novel\nmodel which can provide joint textual rationale generation and attention\nvisualization. Our datasets define visual and textual justifications of a\nclassification decision for activity recognition tasks (ACT-X) and for visual\nquestion answering tasks (VQA-X). We quantitatively show that training with the\ntextual explanations not only yields better textual justification models, but\nalso better localizes the evidence that supports the decision. We also\nqualitatively show cases where visual explanation is more insightful than\ntextual explanation, and vice versa, supporting our thesis that multimodal\nexplanation models offer significant benefits over unimodal approaches."
    },
    "1806.07470": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van der Waa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jasper"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Robeer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van Diggelen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jurriaan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brinkhuis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthieu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Neerincx",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Contrastive Explanations with Local Foil Trees",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at 2018 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2018), Stockholm, Sweden",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent advances in interpretable Machine Learning (iML) and eXplainable AI\n(XAI) construct explanations based on the importance of features in\nclassification tasks. However, in a high-dimensional feature space this\napproach may become unfeasible without restraining the set of important\nfeatures. We propose to utilize the human tendency to ask questions like \"Why\nthis output (the fact) instead of that output (the foil)?\" to reduce the number\nof features to those that play a main role in the asked contrast. Our proposed\nmethod utilizes locally trained one-versus-all decision trees to identify the\ndisjoint set of rules that causes the tree to classify data points as the foil\nand not as the fact. In this study we illustrate this approach on three\nbenchmark classification tasks."
    },
    "1809.06709": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pankaj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chaudhary",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yatin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Buettner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Florian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sch\u00fctze",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hinrich"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Document Informed Neural Autoregressive Topic Models with Distributional\n  Prior",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "AAAI2019. arXiv admin note: substantial text overlap with\n  arXiv:1808.03793",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address two challenges in topic models: (1) Context information around\nwords helps in determining their actual meaning, e.g., \"networks\" used in the\ncontexts artificial neural networks vs. biological neuron networks. Generative\ntopic models infer topic-word distributions, taking no or only little context\ninto account. Here, we extend a neural autoregressive topic model to exploit\nthe full context information around words in a document in a language modeling\nfashion. The proposed model is named as iDocNADE. (2) Due to the small number\nof word occurrences (i.e., lack of context) in short text and data sparsity in\na corpus of few documents, the application of topic models is challenging on\nsuch texts. Therefore, we propose a simple and efficient way of incorporating\nexternal knowledge into neural autoregressive topic models: we use embeddings\nas a distributional prior. The proposed variants are named as DocNADE2 and\niDocNADE2. We present novel neural autoregressive topic model variants that\nconsistently outperform state-of-the-art generative topic models in terms of\ngeneralization, interpretability (topic coherence) and applicability (retrieval\nand classification) over 6 long-text and 8 short-text datasets from diverse\ndomains."
    },
    "1706.08502": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-08-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kottur",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Satwik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moura",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jos\u00e9 M. F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 7 figures, 2 tables, accepted at EMNLP 2017 as short paper",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A number of recent works have proposed techniques for end-to-end learning of\ncommunication protocols among cooperative multi-agent populations, and have\nsimultaneously found the emergence of grounded human-interpretable language in\nthe protocols developed by the agents, all learned without any human\nsupervision!\n  In this paper, using a Task and Tell reference game between two agents as a\ntestbed, we present a sequence of 'negative' results culminating in a\n'positive' one -- showing that while most agent-invented languages are\neffective (i.e. achieve near-perfect task rewards), they are decidedly not\ninterpretable or compositional.\n  In essence, we find that natural language does not emerge 'naturally',\ndespite the semblance of ease of natural-language-emergence that one may gather\nfrom recent literature. We discuss how it is possible to coax the invented\nlanguages to become more and more human-like and compositional by increasing\nrestrictions on how two agents may communicate."
    },
    "1810.11921": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Weiping"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chence"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiping"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Duan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhijian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yewen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "AutoInt: Automatic Feature Interaction Learning via Self-Attentive\n  Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Click-through rate (CTR) prediction, which aims to predict the probability of\na user clicking an ad or an item, is critical to many online applications such\nas online advertising and recommender systems. The problem is very challenging\nsince (1) the input features (e.g., the user id, user age, item id, item\ncategory) are usually sparse and high-dimensional, and (2) an effective\nprediction relies on high-order combinatorial features (a.k.a. cross features),\nwhich are very time-consuming to hand-craft by domain experts and are\nimpossible to be enumerated. Therefore, there have been efforts in finding\nlow-dimensional representations of the sparse and high-dimensional raw features\nand their meaningful combinations. In this paper, we propose an effective and\nefficient algorithm to automatically learn the high-order feature combinations\nof input features. Our proposed algorithm is very general, which can be applied\nto both numerical and categorical input features. Specifically, we map both the\nnumerical and categorical features into the same low-dimensional space.\nAfterward, a multi-head self-attentive neural network with residual connections\nis proposed to explicitly model the feature interactions in the low-dimensional\nspace. With different layers of the multi-head self-attentive neural networks,\ndifferent orders of feature combinations of input features can be modeled. The\nwhole model can be efficiently fit on large-scale raw data in an end-to-end\nfashion. Experimental results on four real-world datasets show that our\nproposed approach not only outperforms existing state-of-the-art approaches for\nprediction but also offers good explainability."
    },
    "1809.09444": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barclay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iain"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Preece",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Taylor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Defining the Collective Intelligence Supply Chain",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Organisations are increasingly open to scrutiny, and need to be able to prove\nthat they operate in a fair and ethical way. Accountability should extend to\nthe production and use of the data and knowledge assets used in AI systems, as\nit would for any raw material or process used in production of physical goods.\nThis paper considers collective intelligence, comprising data and knowledge\ngenerated by crowd-sourced workforces, which can be used as core components of\nAI systems. A proposal is made for the development of a supply chain model for\ntracking the creation and use of crowdsourced collective intelligence assets,\nwith a blockchain based decentralised architecture identified as an appropriate\nmeans of providing validation, accountability and fairness."
    },
    "1811.05249": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kirsch",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Louis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kunze",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julius"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barber",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modular Networks: Learning to Decompose Neural Computation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "NIPS 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Scaling model capacity has been vital in the success of deep learning. For a\ntypical network, necessary compute resources and training time grow\ndramatically with model size. Conditional computation is a promising way to\nincrease the number of parameters with a relatively small increase in\nresources. We propose a training algorithm that flexibly chooses neural modules\nbased on the data to be processed. Both the decomposition and modules are\nlearned end-to-end. In contrast to existing approaches, training does not rely\non regularization to enforce diversity in module use. We apply modular networks\nboth to image recognition and language modeling tasks, where we achieve\nsuperior performance compared to several baselines. Introspection reveals that\nmodules specialize in interpretable contexts."
    },
    "1504.01004": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-04-04",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-11-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chonghui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mart\u00ednez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luis"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Managing Multi-Granular Linguistic Distribution Assessments in\n  Large-Scale Multi-Attribute Group Decision Making",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "32 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Linguistic large-scale group decision making (LGDM) problems are more and\nmore common nowadays. In such problems a large group of decision makers are\ninvolved in the decision process and elicit linguistic information that are\nusually assessed in different linguistic scales with diverse granularity\nbecause of decision makers' distinct knowledge and background. To keep maximum\ninformation in initial stages of the linguistic LGDM problems, the use of\nmulti-granular linguistic distribution assessments seems a suitable choice,\nhowever to manage such multigranular linguistic distribution assessments, it is\nnecessary the development of a new linguistic computational approach. In this\npaper it is proposed a novel computational model based on the use of extended\nlinguistic hierarchies, which not only can be used to operate with\nmulti-granular linguistic distribution assessments, but also can provide\ninterpretable linguistic results to decision makers. Based on this new\nlinguistic computational model, an approach to linguistic large-scale\nmulti-attribute group decision making is proposed and applied to a talent\nselection process in universities."
    },
    "1811.00196": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qingyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William Yang"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Explainable NLP: A Generative Explanation Framework for Text\n  Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Building explainable systems is a critical problem in the field of Natural\nLanguage Processing (NLP), since most machine learning models provide no\nexplanations for the predictions. Existing approaches for explainable machine\nlearning systems tend to focus on interpreting the outputs or the connections\nbetween inputs and outputs. However, the fine-grained information is often\nignored, and the systems do not explicitly generate the human-readable\nexplanations. To better alleviate this problem, we propose a novel generative\nexplanation framework that learns to make classification decisions and generate\nfine-grained explanations at the same time. More specifically, we introduce the\nexplainable factor and the minimum risk training approach that learn to\ngenerate more reasonable explanations. We construct two new datasets that\ncontain summaries, rating scores, and fine-grained reasons. We conduct\nexperiments on both datasets, comparing with several strong neural network\nbaseline systems. Experimental results show that our method surpasses all\nbaselines on both datasets, and is able to generate concise explanations at the\nsame time."
    },
    "1611.04488": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-02-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sutherland",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dougal J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tung",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hsiao-Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Strathmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Heiko"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Soumyajit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramdas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aaditya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smola",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gretton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arthur"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generative Models and Model Criticism via Optimized Maximum Mean\n  Discrepancy",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG cs.NE stat.ME",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at ICLR 2017 (public comments:\n  http://openreview.net/forum?id=HJWHIKqgl ). v4: minor edits",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a method to optimize the representation and distinguishability of\nsamples from two probability distributions, by maximizing the estimated power\nof a statistical test based on the maximum mean discrepancy (MMD). This\noptimized MMD is applied to the setting of unsupervised learning by generative\nadversarial networks (GAN), in which a model attempts to generate realistic\nsamples, and a discriminator attempts to tell these apart from data samples. In\nthis context, the MMD may be used in two roles: first, as a discriminator,\neither directly on the samples, or on features of the samples. Second, the MMD\ncan be used to evaluate the performance of a generative model, by testing the\nmodel's samples against a reference data set. In the latter role, the optimized\nMMD is particularly helpful, as it gives an interpretable indication of how the\nmodel and data distributions differ, even in cases where individual model\nsamples are not easily distinguished either by eye or by classifier."
    },
    "1810.00869": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Ross",
                "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Slavin"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Training Machine Learning Models by Regularizing their Explanations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Harvard CSE master's thesis; includes portions of arxiv:1703.03717\n  and arxiv:1711.09404",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neural networks are among the most accurate supervised learning methods in\nuse today. However, their opacity makes them difficult to trust in critical\napplications, especially when conditions in training may differ from those in\npractice. Recent efforts to develop explanations for neural networks and\nmachine learning models more generally have produced tools to shed light on the\nimplicit rules behind predictions. These tools can help us identify when models\nare right for the wrong reasons. However, they do not always scale to\nexplaining predictions for entire datasets, are not always at the right level\nof abstraction, and most importantly cannot correct the problems they reveal.\nIn this thesis, we explore the possibility of training machine learning models\n(with a particular focus on neural networks) using explanations themselves. We\nconsider approaches where models are penalized not only for making incorrect\npredictions but also for providing explanations that are either inconsistent\nwith domain knowledge or overly complex. These methods let us train models\nwhich can not only provide more interpretable rationales for their predictions\nbut also generalize better when training data is confounded or meaningfully\ndifferent from test data (even adversarially so)."
    },
    "1107.2090": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-07-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sellner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schwarz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zinser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erwin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semantic-ontological combination of Business Rules and Business\n  Processes in IT Service Management",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of the Doctoral Consortium and Poster Session of the 5th\n  International Symposium on Rules (RuleML 2011@IJCAI), pages 33-40\n  (arXiv:1107.1686)",
        "http://arxiv.org/OAI/arXiv/:report-no": "RuleML-DC/2011/05",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "IT Service Management deals with managing a broad range of items related to\ncomplex system environments. As there is both, a close connection to business\ninterests and IT infrastructure, the application of semantic expressions which\nare seamlessly integrated within applications for managing ITSM environments,\ncan help to improve transparency and profitability. This paper focuses on the\nchallenges regarding the integration of semantics and ontologies within ITSM\nenvironments. It will describe the paradigm of relationships and inheritance\nwithin complex service trees and will present an approach of ontologically\nexpressing them. Furthermore, the application of SBVR-based rules as executable\nSQL triggers will be discussed. Finally, the broad range of topics for further\nresearch, derived from the findings, will be presented."
    },
    "0906.4982": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-06-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ignatov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dmitry I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kuznetsov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergei O."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Concept-based Recommendations for Internet Advertisement",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.IR stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "D.I.Ignatov, S.O. Kuznetsov. Concept-based Recommendations for\n  Internet Advertisement//In proceedings of The Sixth International Conference\n  Concept Lattices and Their Applications (CLA'08), Olomouc, Czech Republic,\n  2008 ISBN 978-80-244-2111-7",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.1; H.2.8",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The problem of detecting terms that can be interesting to the advertiser is\nconsidered. If a company has already bought some advertising terms which\ndescribe certain services, it is reasonable to find out the terms bought by\ncompeting companies. A part of them can be recommended as future advertising\nterms to the company. The goal of this work is to propose better interpretable\nrecommendations based on FCA and association rules."
    },
    "1804.10960": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Udluft",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steffen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Runkler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generating Interpretable Fuzzy Controllers using Particle Swarm\n  Optimization and Genetic Programming",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Genetic and Evolutionary Computation Conference 2018\n  (GECCO '18)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3205651.3208277",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Autonomously training interpretable control strategies, called policies,\nusing pre-existing plant trajectory data is of great interest in industrial\napplications. Fuzzy controllers have been used in industry for decades as\ninterpretable and efficient system controllers. In this study, we introduce a\nfuzzy genetic programming (GP) approach called fuzzy GP reinforcement learning\n(FGPRL) that can select the relevant state features, determine the size of the\nrequired fuzzy rule set, and automatically adjust all the controller parameters\nsimultaneously. Each GP individual's fitness is computed using model-based\nbatch reinforcement learning (RL), which first trains a model using available\nsystem samples and subsequently performs Monte Carlo rollouts to predict each\npolicy candidate's performance. We compare FGPRL to an extended version of a\nrelated method called fuzzy particle swarm reinforcement learning (FPSRL),\nwhich uses swarm intelligence to tune the fuzzy policy parameters. Experiments\nusing an industrial benchmark show that FGPRL is able to autonomously learn\ninterpretable fuzzy policies with high control performance."
    },
    "1411.6721": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-11-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Solanas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marc"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez-Castro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dutta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Debojyoti"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Detecting fraudulent activity in a cloud using privacy-friendly data\n  aggregates",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CR cs.AI cs.DC",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/3.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "More users and companies make use of cloud services every day. They all\nexpect a perfect performance and any issue to remain transparent to them. This\nlast statement is very challenging to perform. A user's activities in our cloud\ncan affect the overall performance of our servers, having an impact on other\nresources. We can consider these kind of activities as fraudulent. They can be\neither illegal activities, such as launching a DDoS attack or just activities\nwhich are undesired by the cloud provider, such as Bitcoin mining, which uses\nsubstantial power, reduces the life of the hardware and can possibly slow down\nother user's activities. This article discusses a method to detect such\nactivities by using non-intrusive, privacy-friendly data: billing data. We use\nOpenStack as an example with data provided by Telemetry, the component in\ncharge of measuring resource usage for billing purposes. Results will be shown\nproving the efficiency of this method and ways to improve it will be provided\nas well as its advantages and disadvantages."
    },
    "1810.09598": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                "http://arxiv.org/OAI/arXiv/:forenames": "Tae Wan"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explainable artificial intelligence (XAI), the goodness criteria and the\n  grasp-ability test",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper introduces the \"grasp-ability test\" as a \"goodness\" criteria by\nwhich to compare which explanation is more or less meaningful than others for\nusers to understand the automated algorithmic data processing."
    },
    "1810.09648": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boyd-Graber",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jordan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "What can AI do for me: Evaluating Machine Learning Interpretations in\n  Cooperative Play",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning is an important tool for decision making, but its ethical\nand responsible application requires rigorous vetting of its interpretability\nand utility: an understudied problem, particularly for natural language\nprocessing models. We design a task-specific evaluation for a question\nanswering task and evaluate how well a model interpretation improves human\nperformance in a human-machine cooperative setting. We evaluate interpretation\nmethods in a grounded, realistic setting: playing a trivia game as a team. We\nalso provide design guidance for natural language processing human-in-the-loop\nsettings."
    },
    "1811.02017": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cohen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Taco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Geiger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mario"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weiler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maurice"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A General Theory of Equivariant CNNs on Homogeneous Spaces",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CG cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Group equivariant convolutional neural networks (G-CNNs) have recently\nemerged as a very effective model class for learning from signals in the\ncontext of known symmetries. A wide variety of equivariant layers has been\nproposed for signals on 2D and 3D Euclidean space, graphs, and the sphere, and\nit has become difficult to see how all of these methods are related, and how\nthey may be generalized.\n  In this paper, we present a fairly general theory of equivariant\nconvolutional networks. Convolutional feature spaces are described as fields\nover a homogeneous base space, such as the plane $\\mathbb{R}^2$, sphere $S^2$\nor a graph $\\mathcal{G}$. The theory enables a systematic classification of all\nexisting G-CNNs in terms of their group of symmetry, base space, and field type\n(e.g. scalar, vector, or tensor field, etc.).\n  In addition to this classification, we use Mackey theory to show that\nconvolutions with equivariant kernels are the most general class of equivariant\nmaps between such fields, thus establishing G-CNNs as a universal class of\nequivariant networks. The theory also explains how the space of equivariant\nkernels can be parameterized for learning, thereby simplifying the development\nof G-CNNs for new spaces and symmetries. Finally, the theory introduces a rich\ngeometric semantics to learned feature spaces, thus improving interpretability\nof deep networks, and establishing a connection to central ideas in mathematics\nand physics."
    },
    "1810.04538": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Juefei-Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Felix"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xue",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Minhui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianxiong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "See",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Secure Deep Learning Engineering: A Software Quality Assurance\n  Perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SE cs.AI cs.CR cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Over the past decades, deep learning (DL) systems have achieved tremendous\nsuccess and gained great popularity in various applications, such as\nintelligent machines, image processing, speech processing, and medical\ndiagnostics. Deep neural networks are the key driving force behind its recent\nsuccess, but still seem to be a magic black box lacking interpretability and\nunderstanding. This brings up many open safety and security issues with\nenormous and urgent demands on rigorous methodologies and engineering practice\nfor quality enhancement. A plethora of studies have shown that the\nstate-of-the-art DL systems suffer from defects and vulnerabilities that can\nlead to severe loss and tragedies, especially when applied to real-world\nsafety-critical applications. In this paper, we perform a large-scale study and\nconstruct a paper repository of 223 relevant works to the quality assurance,\nsecurity, and interpretation of deep learning. We, from a software quality\nassurance perspective, pinpoint challenges and future opportunities towards\nuniversal secure deep learning engineering. We hope this work and the\naccompanied paper repository can pave the path for the software engineering\ncommunity towards addressing the pressing industrial demand of secure\nintelligent applications."
    },
    "1805.10820": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guidotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Monreale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ruggieri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Salvatore"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedreschi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dino"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Turini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Giannotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fosca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Local Rule-Based Explanations of Black Box Decision Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The recent years have witnessed the rise of accurate but obscure decision\nsystems which hide the logic of their internal decision processes to the users.\nThe lack of explanations for the decisions of black box systems is a key\nethical issue, and a limitation to the adoption of machine learning components\nin socially sensitive and safety-critical contexts. %Therefore, we need\nexplanations that reveals the reasons why a predictor takes a certain decision.\nIn this paper we focus on the problem of black box outcome explanation, i.e.,\nexplaining the reasons of the decision taken on a specific instance. We propose\nLORE, an agnostic method able to provide interpretable and faithful\nexplanations. LORE first leans a local interpretable predictor on a synthetic\nneighborhood generated by a genetic algorithm. Then it derives from the logic\nof the local interpretable predictor a meaningful explanation consisting of: a\ndecision rule, which explains the reasons of the decision; and a set of\ncounterfactual rules, suggesting the changes in the instance's features that\nlead to a different outcome. Wide experiments show that LORE outperforms\nexisting methods and baselines both in the quality of explanations and in the\naccuracy in mimicking the black box."
    },
    "1705.05098": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poddar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lahari"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hsu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wynne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mong Li"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Quantifying Aspect Bias in Ordinal Ratings using a Bayesian Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted for publication in IJCAI 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "User opinions expressed in the form of ratings can influence an individual's\nview of an item. However, the true quality of an item is often obfuscated by\nuser biases, and it is not obvious from the observed ratings the importance\ndifferent users place on different aspects of an item. We propose a\nprobabilistic modeling of the observed aspect ratings to infer (i) each user's\naspect bias and (ii) latent intrinsic quality of an item. We model multi-aspect\nratings as ordered discrete data and encode the dependency between different\naspects by using a latent Gaussian structure. We handle the\nGaussian-Categorical non-conjugacy using a stick-breaking formulation coupled\nwith P\\'{o}lya-Gamma auxiliary variable augmentation for a simple, fully\nBayesian inference. On two real world datasets, we demonstrate the predictive\nability of our model and its effectiveness in learning explainable user biases\nto provide insights towards a more reliable product quality estimation."
    },
    "1712.04170": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-12",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Udluft",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steffen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Runkler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Policies for Reinforcement Learning by Genetic Programming",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE cs.SY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The search for interpretable reinforcement learning policies is of high\nacademic and industrial interest. Especially for industrial systems, domain\nexperts are more likely to deploy autonomously learned controllers if they are\nunderstandable and convenient to evaluate. Basic algebraic equations are\nsupposed to meet these requirements, as long as they are restricted to an\nadequate complexity. Here we introduce the genetic programming for\nreinforcement learning (GPRL) approach based on model-based batch reinforcement\nlearning and genetic programming, which autonomously learns policy equations\nfrom pre-existing default state-action trajectory samples. GPRL is compared to\na straight-forward method which utilizes genetic programming for symbolic\nregression, yielding policies imitating an existing well-performing, but\nnon-interpretable policy. Experiments on three reinforcement learning\nbenchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark,\ndemonstrate the superiority of our GPRL approach compared to the symbolic\nregression method. GPRL is capable of producing well-performing interpretable\nreinforcement learning policies from pre-existing default trajectory data."
    },
    "1707.02385": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brugere",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ivan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kanich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Berger-Wolf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tanya Y."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evaluating Social Networks Using Task-Focused Network Inference",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Networks are representations of complex underlying social processes. However,\nthe same given network may be more suitable to model one behavior of\nindividuals than another. In many cases, aggregate population models may be\nmore effective than modeling on the network. We present a general framework for\nevaluating the suitability of given networks for a set of predictive tasks of\ninterest, compared against alternative, networks inferred from data. We present\nseveral interpretable network models and measures for our comparison. We apply\nthis general framework to the case study on collective classification of music\npreferences in a newly available dataset of the Last.fm social network."
    },
    "1611.06175": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bibal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adrien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fr\u00e9nay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benoit"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Interpretability for Visualizations using Adapted Cox Models\n  through a User Experiment",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.HC cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order to be useful, visualizations need to be interpretable. This paper\nuses a user-based approach to combine and assess quality measures in order to\nbetter model user preferences. Results show that cluster separability measures\nare outperformed by a neighborhood conservation measure, even though the former\nare usually considered as intuitively representative of user motives. Moreover,\ncombining measures, as opposed to using a single measure, further improves\nprediction performances."
    },
    "1703.00955": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zichao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Salakhutdinov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ruslan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Toward Controlled Generation of Text",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Fixed typos; ICML 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Generic generation and manipulation of text is challenging and has limited\nsuccess compared to recent deep generative modeling in visual domain. This\npaper aims at generating plausible natural language sentences, whose attributes\nare dynamically controlled by learning disentangled latent representations with\ndesignated semantics. We propose a new neural generative model which combines\nvariational auto-encoders and holistic attribute discriminators for effective\nimposition of semantic structures. With differentiable approximation to\ndiscrete text samples, explicit constraints on independent attribute controls,\nand efficient collaborative learning of generator and discriminators, our model\nlearns highly interpretable representations from even only word annotations,\nand produces realistic sentences with desired attributes. Quantitative\nevaluation validates the accuracy of sentence and attribute generation."
    },
    "1809.04684": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                "http://arxiv.org/OAI/arXiv/:forenames": "Jiahao"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fair lending needs explainable models for responsible recommendation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY stat.AP stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "4 pages, position paper accepted for FATREC 2018 conference at ACM\n  RecSys",
        "http://arxiv.org/OAI/arXiv/:msc-class": "91G40, 68T01",
        "http://arxiv.org/OAI/arXiv/:acm-class": "J.1; I.5.1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The financial services industry has unique explainability and fairness\nchallenges arising from compliance and ethical considerations in credit\ndecisioning. These challenges complicate the use of model machine learning and\nartificial intelligence methods in business decision processes."
    },
    "0710.2611": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2007-10-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2007-10-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aerts",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diederik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Czachor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Moor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bart"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Geometric Analogue of Holographic Reduced Representation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI quant-ph",
        "http://arxiv.org/OAI/arXiv/:comments": "typos in eqs. (57-58) are corrected",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Mathematical Psychology 53, 389-398 (2009)",
        "http://arxiv.org/OAI/arXiv/:abstract": "Holographic reduced representations (HRR) are based on superpositions of\nconvolution-bound $n$-tuples, but the $n$-tuples cannot be regarded as vectors\nsince the formalism is basis dependent. This is why HRR cannot be associated\nwith geometric structures. Replacing convolutions by geometric products one\narrives at reduced representations analogous to HRR but interpretable in terms\nof geometry. Variable bindings occurring in both HRR and its geometric analogue\nmathematically correspond to two different representations of\n$Z_2\\times...\\times Z_2$ (the additive group of binary $n$-tuples with addition\nmodulo 2). As opposed to standard HRR, variable binding performed by means of\ngeometric product allows for computing exact inverses of all nonzero vectors, a\nprocedure even simpler than approximate inverses employed in HRR. The formal\nstructure of the new reduced representation is analogous to cartoon\ncomputation, a geometric analogue of quantum computation."
    },
    "1806.00340": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Oakden-Rayner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luke"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Carneiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gustavo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bradley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew P"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Palmer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lyle J"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Producing radiologist-quality reports for interpretable artificial\n  intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Current approaches to explaining the decisions of deep learning systems for\nmedical tasks have focused on visualising the elements that have contributed to\neach decision. We argue that such approaches are not enough to \"open the black\nbox\" of medical decision making systems because they are missing a key\ncomponent that has been used as a standard communication tool between doctors\nfor centuries: language. We propose a model-agnostic interpretability method\nthat involves training a simple recurrent neural network model to produce\ndescriptive sentences to clarify the decision of deep learning classifiers.\n  We test our method on the task of detecting hip fractures from frontal pelvic\nx-rays. This process requires minimal additional labelling despite producing\ntext containing elements that the original deep learning classification model\nwas not specifically trained to detect.\n  The experimental results show that: 1) the sentences produced by our method\nconsistently contain the desired information, 2) the generated sentences are\npreferred by doctors compared to current tools that create saliency maps, and\n3) the combination of visualisations and generated text is better than either\nalone."
    },
    "1708.06303": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brugere",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ivan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kanich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Berger-Wolf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tanya Y."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Network Model Selection for Task-Focused Attributed Network Inference",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Networks are models representing relationships between entities. Often these\nrelationships are explicitly given, or we must learn a representation which\ngeneralizes and predicts observed behavior in underlying individual data (e.g.\nattributes or labels). Whether given or inferred, choosing the best\nrepresentation affects subsequent tasks and questions on the network. This work\nfocuses on model selection to evaluate network representations from data,\nfocusing on fundamental predictive tasks on networks. We present a modular\nmethodology using general, interpretable network models, task neighborhood\nfunctions found across domains, and several criteria for robust model\nselection. We demonstrate our methodology on three online user activity\ndatasets and show that network model selection for the appropriate network task\nvs. an alternate task increases performance by an order of magnitude in our\nexperiments."
    },
    "1805.11122": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jonschkowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rico"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rastogi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Divyam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brock",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oliver"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Differentiable Particle Filters: End-to-End Learning with Algorithmic\n  Priors",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Robotics: Science and Systems 2018\n  (http://www.roboticsconference.org)",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present differentiable particle filters (DPFs): a differentiable\nimplementation of the particle filter algorithm with learnable motion and\nmeasurement models. Since DPFs are end-to-end differentiable, we can\nefficiently train their models by optimizing end-to-end state estimation\nperformance, rather than proxy objectives such as model accuracy. DPFs encode\nthe structure of recursive state estimation with prediction and measurement\nupdate that operate on a probability distribution over states. This structure\nrepresents an algorithmic prior that improves learning performance in state\nestimation problems while enabling explainability of the learned model. Our\nexperiments on simulated and real data show substantial benefits from end-to-\nend learning with algorithmic priors, e.g. reducing error rates by ~80%. Our\nexperiments also show that, unlike long short-term memory networks, DPFs learn\nlocalization in a policy-agnostic way and thus greatly improve generalization.\nSource code is available at\nhttps://github.com/tu-rbo/differentiable-particle-filters ."
    },
    "1806.00069": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gilpin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leilani H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ben Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bajwa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ayesha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Specter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kagal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lalana"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explaining Explanations: An Approach to Evaluating Interpretability of\n  Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Edited author email",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There has recently been a surge of work in explanatory artificial\nintelligence (XAI). This research area tackles the important problem that\ncomplex machines and algorithms often cannot provide insights into their\nbehavior and thought processes. XAI allows users and parts of the internal\nsystem to be more transparent, providing explanations of their decisions in\nsome level of detail. These explanations are important to ensure algorithmic\nfairness, identify potential bias/problems in the training data, and to ensure\nthat the algorithms perform as expected. However, explanations produced by\nthese systems is neither standardized nor systematically assessed. In an effort\nto create best practices and identify open challenges, we provide our\ndefinition of explainability and show how it can be used to classify existing\nliterature. We discuss why current approaches to explanatory methods especially\nfor deep neural networks are insufficient. Finally, based on our survey, we\nconclude with suggested future research directions for explanatory artificial\nintelligence."
    },
    "1511.07361": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-11-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guolong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dennis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kush R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Malioutov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dmitry M."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Two-level Boolean Rule Learning for Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper proposes algorithms for learning two-level Boolean rules in\nConjunctive Normal Form (CNF, i.e. AND-of-ORs) or Disjunctive Normal Form (DNF,\ni.e. OR-of-ANDs) as a type of human-interpretable classification model, aiming\nfor a favorable trade-off between the classification accuracy and the\nsimplicity of the rule. Two formulations are proposed. The first is an integer\nprogram whose objective function is a combination of the total number of errors\nand the total number of features used in the rule. We generalize a previously\nproposed linear programming (LP) relaxation from one-level to two-level rules.\nThe second formulation replaces the 0-1 classification error with the Hamming\ndistance from the current two-level rule to the closest rule that correctly\nclassifies a sample. Based on this second formulation, block coordinate descent\nand alternating minimization algorithms are developed. Experiments show that\nthe two-level rules can yield noticeably better performance than one-level\nrules due to their dramatically larger modeling capacity, and the two\nalgorithms based on the Hamming distance formulation are generally superior to\nthe other two-level rule learning methods in our comparison. A proposed\napproach to binarize any fractional values in the optimal solutions of LP\nrelaxations is also shown to be effective."
    },
    "1612.04868": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lopez-Gazpio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Maritxalar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gonzalez-Agirre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rigau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "G."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Uria",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agirre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "E."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Semantic Textual Similarity: Finding and explaining\n  differences between sentences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Preprint version, Knowledge-Based Systems (ISSN: 0950-7051). (2016)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.knosys.2016.12.013",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "User acceptance of artificial intelligence agents might depend on their\nability to explain their reasoning, which requires adding an interpretability\nlayer that fa- cilitates users to understand their behavior. This paper focuses\non adding an in- terpretable layer on top of Semantic Textual Similarity (STS),\nwhich measures the degree of semantic equivalence between two sentences. The\ninterpretability layer is formalized as the alignment between pairs of segments\nacross the two sentences, where the relation between the segments is labeled\nwith a relation type and a similarity score. We present a publicly available\ndataset of sentence pairs annotated following the formalization. We then\ndevelop a system trained on this dataset which, given a sentence pair, explains\nwhat is similar and different, in the form of graded and typed segment\nalignments. When evaluated on the dataset, the system performs better than an\ninformed baseline, showing that the dataset and task are well-defined and\nfeasible. Most importantly, two user studies show how the system output can be\nused to automatically produce explanations in natural language. Users performed\nbetter when having access to the explanations, pro- viding preliminary evidence\nthat our dataset and method to automatically produce explanations is useful in\nreal applications."
    },
    "1304.1491": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Bacchus",
                "http://arxiv.org/OAI/arXiv/:forenames": "Fahiem"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Lp : A Logic for Statistical Information",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1989-PG-1-6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This extended abstract presents a logic, called Lp, that is capable of\nrepresenting and reasoning with a wide variety of both qualitative and\nquantitative statistical information. The advantage of this logical formalism\nis that it offers a declarative representation of statistical knowledge;\nknowledge represented in this manner can be used for a variety of reasoning\ntasks. The logic differs from previous work in probability logics in that it\nuses a probability distribution over the domain of discourse, whereas most\nprevious work (e.g., Nilsson [2], Scott et al. [3], Gaifinan [4], Fagin et al.\n[5]) has investigated the attachment of probabilities to the sentences of the\nlogic (also, see Halpern [6] and Bacchus [7] for further discussion of the\ndifferences). The logic Lp possesses some further important features. First, Lp\nis a superset of first order logic, hence it can represent ordinary logical\nassertions. This means that Lp provides a mechanism for integrating statistical\ninformation and reasoning about uncertainty into systems based solely on logic.\nSecond, Lp possesses transparent semantics, based on sets and probabilities of\nthose sets. Hence, knowledge represented in Lp can be understood in terms of\nthe simple primative concepts of sets and probabilities. And finally, the there\nis a sound proof theory that has wide coverage (the proof theory is complete\nfor certain classes of models). The proof theory captures a sufficient range of\nvalid inferences to subsume most previous probabilistic uncertainty reasoning\nsystems. For example, the linear constraints like those generated by Nilsson's\nprobabilistic entailment [2] can be generated by the proof theory, and the\nBayesian inference underlying belief nets [8] can be performed. In addition,\nthe proof theory integrates quantitative and qualitative reasoning as well as\nstatistical and logical reasoning. In the next section we briefly examine\nprevious work in probability logics, comparing it to Lp. Then we present some\nof the varieties of statistical information that Lp is capable of expressing.\nAfter this we present, briefly, the syntax, semantics, and proof theory of the\nlogic. We conclude with a few examples of knowledge representation and\nreasoning in Lp, pointing out the advantages of the declarative representation\noffered by Lp. We close with a brief discussion of probabilities as degrees of\nbelief, indicating how such probabilities can be generated from statistical\nknowledge encoded in Lp. The reader who is interested in a more complete\ntreatment should consult Bacchus [7]."
    },
    "1803.08024": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kuang-Huei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hua",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Houdong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "He",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Stacked Cross Attention for Image-Text Matching",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we study the problem of image-text matching. Inferring the\nlatent semantic alignment between objects or other salient stuffs (e.g. snow,\nsky, lawn) and the corresponding words in sentences allows to capture\nfine-grained interplay between vision and language, and makes image-text\nmatching more interpretable. Prior works either simply aggregate the similarity\nof all possible pairs of regions and words without attending differentially to\nmore and less important words or regions, or use a multi-step attentional\nprocess to capture limited number of semantic alignments which is less\ninterpretable. In this paper, we present Stacked Cross Attention to discover\nthe full latent alignments using both image regions and words in sentence as\ncontext and infer the image-text similarity. Our approach achieves the\nstate-of-the-art results on the MS-COCO and Flickr30K datasets. On Flickr30K,\nour approach outperforms the current best methods by 22.1% in text retrieval\nfrom image query, and 18.2% in image retrieval with text query (based on\nRecall@1). On MS-COCO, our approach improves sentence retrieval by 17.8% and\nimage retrieval by 16.6% (based on Recall@1 using the 5K test set)."
    },
    "1810.03947": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pankaj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chaudhary",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yatin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Buettner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Florian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sch\u00fctze",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hinrich"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "textTOvec: Deep Contextualized Neural Autoregressive Models of Language\n  with Distributed Compositional Prior",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.IR cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "#ICLR2019 under review",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address two challenges of probabilistic topic modelling in order to better\nestimate the probability of a word in a given context, i.e., P(word|context):\n(1) No Language Structure in Context: Probabilistic topic models ignore word\norder by summarizing a given context as a \"bag-of-word\" and consequently the\nsemantics of words in the context is lost. The LSTM-LM learns a vector-space\nrepresentation of each word by accounting for word order in local collocation\npatterns and models complex characteristics of language (e.g., syntax and\nsemantics), while the TM simultaneously learns a latent representation from the\nentire document and discovers the underlying thematic structure. We unite two\ncomplementary paradigms of learning the meaning of word occurrences by\ncombining a TM and a LM in a unified probabilistic framework, named as\nctx-DocNADE. (2) Limited Context and/or Smaller training corpus of documents:\nIn settings with a small number of word occurrences (i.e., lack of context) in\nshort text or data sparsity in a corpus of few documents, the application of\nTMs is challenging. We address this challenge by incorporating external\nknowledge into neural autoregressive topic models via a language modelling\napproach: we use word embeddings as input of a LSTM-LM with the aim to improve\nthe word-topic mapping on a smaller and/or short-text corpus. The proposed\nDocNADE extension is named as ctx-DocNADEe.\n  We present novel neural autoregressive topic model variants coupled with\nneural LMs and embeddings priors that consistently outperform state-of-the-art\ngenerative TMs in terms of generalization (perplexity), interpretability (topic\ncoherence) and applicability (retrieval and classification) over 6 long-text\nand 8 short-text datasets from diverse domains."
    },
    "1707.03490": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gurciullo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefano"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mikhaylov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Slava"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Detecting Policy Preferences and Dynamics in the UN General Debate with\n  Neural Word Embeddings",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Foreign policy analysis has been struggling to find ways to measure policy\npreferences and paradigm shifts in international political systems. This paper\npresents a novel, potential solution to this challenge, through the application\nof a neural word embedding (Word2vec) model on a dataset featuring speeches by\nheads of state or government in the United Nations General Debate. The paper\nprovides three key contributions based on the output of the Word2vec model.\nFirst, it presents a set of policy attention indices, synthesizing the semantic\nproximity of political speeches to specific policy themes. Second, it\nintroduces country-specific semantic centrality indices, based on topological\nanalyses of countries' semantic positions with respect to each other. Third, it\ntests the hypothesis that there exists a statistical relation between the\nsemantic content of political speeches and UN voting behavior, falsifying it\nand suggesting that political speeches contain information of different nature\nthen the one behind voting outcomes. The paper concludes with a discussion of\nthe practical use of its results and consequences for foreign policy analysis,\npublic accountability, and transparency."
    },
    "1707.03886": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dhurandhar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Iyengar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vijay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Luss",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ronny"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shanmugam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthikeyan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Formal Framework to Characterize Interpretability of Procedures",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "presented at 2017 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2017), Sydney, NSW, Australia",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We provide a novel notion of what it means to be interpretable, looking past\nthe usual association with human understanding. Our key insight is that\ninterpretability is not an absolute concept and so we define it relative to a\ntarget model, which may or may not be a human. We define a framework that\nallows for comparing interpretable procedures by linking it to important\npractical aspects such as accuracy and robustness. We characterize many of the\ncurrent state-of-the-art interpretable methods in our framework portraying its\ngeneral applicability."
    },
    "1109.5370": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-09-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zeng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cheung",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chun-Hung"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Higher-Order Markov Tag-Topic Models for Tagged Documents and Images",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.IR cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "13 pages, 9 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper studies the topic modeling problem of tagged documents and images.\nHigher-order relations among tagged documents and images are major and\nubiquitous characteristics, and play positive roles in extracting reliable and\ninterpretable topics. In this paper, we propose the tag-topic models (TTM) to\ndepict such higher-order topic structural dependencies within the Markov random\nfield (MRF) framework. First, we use the novel factor graph representation of\nlatent Dirichlet allocation (LDA)-based topic models from the MRF perspective,\nand present an efficient loopy belief propagation (BP) algorithm for\napproximate inference and parameter estimation. Second, we propose the factor\nhypergraph representation of TTM, and focus on both pairwise and higher-order\nrelation modeling among tagged documents and images. Efficient loopy BP\nalgorithm is developed to learn TTM, which encourages the topic labeling\nsmoothness among tagged documents and images. Extensive experimental results\nconfirm the incorporation of higher-order relations to be effective in\nenhancing the overall topic modeling performance, when compared with current\nstate-of-the-art topic models, in many text and image mining tasks of broad\ninterests such as word and link prediction, document classification, and tag\nrecommendation."
    },
    "1506.08813": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-06-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-07-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Young",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anthony P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Modgil",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanjay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rodrigues",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Odinaldo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Argumentation Semantics for Prioritised Default Logic",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "46 pages, 4 figures",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We endow prioritised default logic (PDL) with argumentation semantics using\nthe ASPIC+ framework for structured argumentation, and prove that the\nconclusions of the justified arguments are exactly the prioritised default\nextensions. Argumentation semantics for PDL will allow for the application of\nargument game proof theories to the process of inference in PDL, making the\nreasons for accepting a conclusion transparent and the inference process more\nintuitive. This also opens up the possibility for argumentation-based\ndistributed reasoning and communication amongst agents with PDL representations\nof mental attitudes."
    },
    "1811.05245": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grath",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rory Mc"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Costabello",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Van",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chan Le"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sweeney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kamiab",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Farbod"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lecue",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Freddy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Credit Application Predictions With Counterfactual\n  Explanations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We predict credit applications with off-the-shelf, interchangeable black-box\nclassifiers and we explain single predictions with counterfactual explanations.\nCounterfactual explanations expose the minimal changes required on the input\ndata to obtain a different result e.g., approved vs rejected application.\nDespite their effectiveness, counterfactuals are mainly designed for changing\nan undesired outcome of a prediction i.e. loan rejected. Counterfactuals,\nhowever, can be difficult to interpret, especially when a high number of\nfeatures are involved in the explanation. Our contribution is two-fold: i) we\npropose positive counterfactuals, i.e. we adapt counterfactual explanations to\nalso explain accepted loan applications, and ii) we propose two weighting\nstrategies to generate more interpretable counterfactuals. Experiments on the\nHELOC loan applications dataset show that our contribution outperforms the\nbaseline counterfactual generation strategy, by leading to smaller and hence\nmore interpretable counterfactuals."
    }
}