{
    "1304.1514": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Lehmann",
                "http://arxiv.org/OAI/arXiv/:forenames": "Harold P."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Decision-Theoretic Model for Using Scientific Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1989-PG-208-215",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many Artificial Intelligence systems depend on the agent's updating its\nbeliefs about the world on the basis of experience. Experiments constitute one\ntype of experience, so scientific methodology offers a natural environment for\nexamining the issues attendant to using this class of evidence. This paper\npresents a framework which structures the process of using scientific data from\nresearch reports for the purpose of making decisions, using decision analysis\nas the basis for the structure and using medical research as the general\nscientific domain. The structure extends the basic influence diagram for\nupdating belief in an object domain parameter of interest by expanding the\nparameter into four parts: those of the patient, the population, the study\nsample, and the effective study sample. The structure uses biases to perform\nthe transformation of one parameter into another, so that, for instance,\nselection biases, in concert with the population parameter, yield the study\nsample parameter. The influence diagram structure provides decision theoretic\njustification for practices of good clinical research such as randomized\nassignment and blindfolding of care providers. The model covers most research\ndesigns used in medicine: case-control studies, cohort studies, and controlled\nclinical trials, and provides an architecture to separate clearly between\nstatistical knowledge and domain knowledge. The proposed general model can be\nthe basis for clinical epidemiological advisory systems, when coupled with\nheuristic pruning of irrelevant biases; of statistical workstations, when the\ncomputational machinery for calculation of posterior distributions is added;\nand of meta-analytic reviews, when multiple studies may impact on a single\npopulation parameter."
    },
    "1706.01350": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-05",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Achille",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Soatto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefano"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Emergence of Invariance and Disentangling in Deep Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Deep learning, neural network, representation, flat minima,\n  information bottleneck, overfitting, generalization, sufficiency, minimality,\n  sensitivity, information complexity, stochastic gradient descent,\n  regularization, total correlation, PAC-Bayes",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Using established principles from Information Theory and Statistics, we show\nthat in a deep neural network invariance to nuisance factors is equivalent to\ninformation minimality of the learned representation, and that stacking layers\nand injecting noise during training naturally bias the network towards learning\ninvariant representations. We then show that, in order to avoid memorization,\nwe need to limit the quantity of information stored in the weights, which leads\nto a novel usage of the Information Bottleneck Lagrangian on the weights as a\nlearning criterion. This also has an alternative interpretation as minimizing a\nPAC-Bayesian bound on the test error. Finally, we exploit a duality between\nweights and activations induced by the architecture, to show that the\ninformation in the weights bounds the minimality and Total Correlation of the\nlayers, therefore showing that regularizing the weights explicitly or\nimplicitly, using SGD, not only helps avoid overfitting, but also fosters\ninvariance and disentangling of the learned representation. The theory also\nenables predicting sharp phase transitions between underfitting and overfitting\nrandom labels at precise information values, and sheds light on the relation\nbetween the geometry of the loss function, in particular so-called \"flat\nminima,\" and generalization."
    },
    "1805.11818": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cirik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Volkan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Morency",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Louis-Philippe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Berg-Kirkpatrick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Taylor"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Visual Referring Expression Recognition: What Do Systems Actually Learn?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.CV cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "NAACL2018 short",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present an empirical analysis of the state-of-the-art systems for\nreferring expression recognition -- the task of identifying the object in an\nimage referred to by a natural language expression -- with the goal of gaining\ninsight into how these systems reason about language and vision. Surprisingly,\nwe find strong evidence that even sophisticated and linguistically-motivated\nmodels for this task may ignore the linguistic structure, instead relying on\nshallow correlations introduced by unintended biases in the data selection and\nannotation process. For example, we show that a system trained and tested on\nthe input image $\\textit{without the input referring expression}$ can achieve a\nprecision of 71.2% in top-2 predictions. Furthermore, a system that predicts\nonly the object category given the input can achieve a precision of 84.2% in\ntop-2 predictions. These surprisingly positive results for what should be\ndeficient prediction scenarios suggest that careful analysis of what our models\nare learning -- and further, how our data is constructed -- is critical as we\nseek to make substantive progress on grounded language tasks."
    },
    "1811.05817": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chung",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Audrey G."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fieguth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khalvati",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Farzad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Haider",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Masoom A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "ProstateGAN: Mitigating Data Bias via Prostate Diffusion Imaging\n  Synthesis with Generative Adversarial Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:cs/0101200",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Generative Adversarial Networks (GANs) have shown considerable promise for\nmitigating the challenge of data scarcity when building machine learning-driven\nanalysis algorithms. Specifically, a number of studies have shown that\nGAN-based image synthesis for data augmentation can aid in improving\nclassification accuracy in a number of medical image analysis tasks, such as\nbrain and liver image analysis. However, the efficacy of leveraging GANs for\ntackling prostate cancer analysis has not been previously explored. Motivated\nby this, in this study we introduce ProstateGAN, a GAN-based model for\nsynthesizing realistic prostate diffusion imaging data. More specifically, in\norder to generate new diffusion imaging data corresponding to a particular\ncancer grade (Gleason score), we propose a conditional deep convolutional GAN\narchitecture that takes Gleason scores into consideration during the training\nprocess. Experimental results show that high-quality synthetic prostate\ndiffusion imaging data can be generated using the proposed ProstateGAN for\nspecified Gleason scores."
    },
    "1804.07121": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez-Orallo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jose"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Telle",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jan Arne"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Finite Biased Teaching with Infinite Concept Classes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.IT math.IT",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We investigate the teaching of infinite concept classes through the effect of\nthe learning bias (which is used by the learner to prefer some concepts over\nothers and by the teacher to devise the teaching examples) and the sampling\nbias (which determines how the concepts are sampled from the class). We analyse\ntwo important classes: Turing machines and finite-state machines. We derive\nbounds for the biased teaching dimension when the learning bias is derived from\na complexity measure (Kolmogorov complexity and minimal number of states\nrespectively) and analyse the sampling distributions that lead to finite\nexpected biased teaching dimensions. We highlight the existing trade-off\nbetween the bound and the representativeness of the sample, and its\nimplications for the understanding of what teaching rich concepts to machines\nentails."
    },
    "1711.10938": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fulton"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cynthia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Extreme Dimension Reduction for Handling Covariate Shift",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the covariate shift learning scenario, the training and test covariate\ndistributions differ, so that a predictor's average loss over the training and\ntest distributions also differ. In this work, we explore the potential of\nextreme dimension reduction, i.e. to very low dimensions, in improving the\nperformance of importance weighting methods for handling covariate shift, which\nfail in high dimensions due to potentially high train/test covariate divergence\nand the inability to accurately estimate the requisite density ratios. We first\nformulate and solve a problem optimizing over linear subspaces a combination of\ntheir predictive utility and train/test divergence within. Applying it to\nsimulated and real data, we show extreme dimension reduction helps sometimes\nbut not always, due to a bias introduced by dimension reduction."
    },
    "1706.02897": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bouneffouf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Djallel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rish",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Irina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cecchi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guillermo A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bandit Models of Human Behavior: Reward Processing in Mental Disorders",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Conference on Artificial General Intelligence, AGI-17",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Drawing an inspiration from behavioral studies of human decision making, we\npropose here a general parametric framework for multi-armed bandit problem,\nwhich extends the standard Thompson Sampling approach to incorporate reward\nprocessing biases associated with several neurological and psychiatric\nconditions, including Parkinson's and Alzheimer's diseases,\nattention-deficit/hyperactivity disorder (ADHD), addiction, and chronic pain.\nWe demonstrate empirically that the proposed parametric approach can often\noutperform the baseline Thompson Sampling on a variety of datasets. Moreover,\nfrom the behavioral modeling perspective, our parametric framework can be\nviewed as a first step towards a unifying computational model capturing reward\nprocessing abnormalities across multiple mental conditions."
    },
    "1707.02353": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chekanov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Konstantin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mamoshina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Polina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yampolskiy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roman V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Timofte",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scheibye-Knudsen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Morten"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhavoronkov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evaluating race and sex diversity in the world's largest companies using\n  deep neural networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Diversity is one of the fundamental properties for the survival of species,\npopulations, and organizations. Recent advances in deep learning allow for the\nrapid and automatic assessment of organizational diversity and possible\ndiscrimination by race, sex, age and other parameters. Automating the process\nof assessing the organizational diversity using the deep neural networks and\neliminating the human factor may provide a set of real-time unbiased reports to\nall stakeholders. In this pilot study we applied the deep-learned predictors of\nrace and sex to the executive management and board member profiles of the 500\nlargest companies from the 2016 Forbes Global 2000 list and compared the\npredicted ratios to the ratios within each company's country of origin and\nranked them by the sex-, age- and race- diversity index (DI). While the study\nhas many limitations and no claims are being made concerning the individual\ncompanies, it demonstrates a method for the rapid and impartial assessment of\norganizational diversity using deep neural networks."
    },
    "1710.03184": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gajane",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pratik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pechenizkiy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mykola"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Formalizing Fairness in Prediction with Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning algorithms for prediction are increasingly being used in\ncritical decisions affecting human lives. Various fairness formalizations, with\nno firm consensus yet, are employed to prevent such algorithms from\nsystematically discriminating against people based on certain attributes\nprotected by law. The aim of this article is to survey how fairness is\nformalized in the machine learning literature for the task of prediction and\npresent these formalizations with their corresponding notions of distributive\njustice from the social sciences literature. We provide theoretical as well as\nempirical critiques of these notions from the social sciences literature and\nexplain how these critiques limit the suitability of the corresponding fairness\nformalizations to certain domains. We also suggest two notions of distributive\njustice which address some of these critiques and discuss avenues for\nprospective fairness formalizations."
    },
    "1801.06176": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-18",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Baolin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiujun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianfeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jingjing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kam-Fai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shang-Yu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages, 8 figures, Accepted in ACL 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Training a task-completion dialogue agent via reinforcement learning (RL) is\ncostly because it requires many interactions with real users. One common\nalternative is to use a user simulator. However, a user simulator usually lacks\nthe language complexity of human interlocutors and the biases in its design may\ntend to degrade the agent. To address these issues, we present Deep Dyna-Q,\nwhich to our knowledge is the first deep RL framework that integrates planning\nfor task-completion dialogue policy learning. We incorporate into the dialogue\nagent a model of the environment, referred to as the world model, to mimic real\nuser response and generate simulated experience. During dialogue policy\nlearning, the world model is constantly updated with real user experience to\napproach real user behavior, and in turn, the dialogue agent is optimized using\nboth real experience and simulated experience. The effectiveness of our\napproach is demonstrated on a movie-ticket booking task in both simulated and\nhuman-in-the-loop settings."
    },
    "1304.2729": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wise",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ben P."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Satisfaction of Assumptions is a Weak Predictor of Performance",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1987-PG-163-169",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper demonstrates a methodology for examining the accuracy of uncertain\ninference systems (UIS), after their parameters have been optimized, and does\nso for several common UIS's. This methodology may be used to test the accuracy\nwhen either the prior assumptions or updating formulae are not exactly\nsatisfied. Surprisingly, these UIS's were revealed to be no more accurate on\nthe average than a simple linear regression. Moreover, even on prior\ndistributions which were deliberately biased so as give very good accuracy,\nthey were less accurate than the simple probabilistic model which assumes\nmarginal independence between inputs. This demonstrates that the importance of\nupdating formulae can outweigh that of prior assumptions. Thus, when UIS's are\njudged by their final accuracy after optimization, we get completely different\nresults than when they are judged by whether or not their prior assumptions are\nperfectly satisfied."
    },
    "1604.04138": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Osaba",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eneko"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xin-She"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Diaz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fernando"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lopez-Garcia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pedro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Carballedo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roberto"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Improved Discrete Bat Algorithm for Symmetric and Asymmetric\n  Traveling Salesman Problems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI math.OC",
        "http://arxiv.org/OAI/arXiv/:comments": "1 figure, 8 tables",
        "http://arxiv.org/OAI/arXiv/:msc-class": "78M32",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Engineering Applications of Artificial Intelligence, 48 (1), 59-71\n  (2016)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.engappai.2015.10.006",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bat algorithm is a population metaheuristic proposed in 2010 which is based\non the echolocation or bio-sonar characteristics of microbats. Since its first\nimplementation, the bat algorithm has been used in a wide range of fields. In\nthis paper, we present a discrete version of the bat algorithm to solve the\nwell-known symmetric and asymmetric traveling salesman problems. In addition,\nwe propose an improvement in the basic structure of the classic bat algorithm.\nTo prove that our proposal is a promising approximation method, we have\ncompared its performance in 37 instances with the results obtained by five\ndifferent techniques: evolutionary simulated annealing, genetic algorithm, an\nisland based distributed genetic algorithm, a discrete firefly algorithm and an\nimperialist competitive algorithm. In order to obtain fair and rigorous\ncomparisons, we have conducted three different statistical tests along the\npaper: the Student's $t$-test, the Holm's test, and the Friedman test. We have\nalso compared the convergence behaviour shown by our proposal with the ones\nshown by the evolutionary simulated annealing, and the discrete firefly\nalgorithm. The experimentation carried out in this study has shown that the\npresented improved bat algorithm outperforms significantly all the other\nalternatives in most of the cases."
    },
    "0907.0589": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-07-03",
        "http://arxiv.org/OAI/arXiv/:updated": "2009-07-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rahul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sarawagi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sunita"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Diwan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ajit A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generalized Collective Inference with Symmetric Clique Potentials",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Collective graphical models exploit inter-instance associative dependence to\noutput more accurate labelings. However existing models support very limited\nkind of associativity which restricts accuracy gains. This paper makes two\nmajor contributions. First, we propose a general collective inference framework\nthat biases data instances to agree on a set of {\\em properties} of their\nlabelings. Agreement is encouraged through symmetric clique potentials. We show\nthat rich properties leads to bigger gains, and present a systematic inference\nprocedure for a large class of such properties. The procedure performs message\npassing on the cluster graph, where property-aware messages are computed with\ncluster specific algorithms. This provides an inference-only solution for\ndomain adaptation. Our experiments on bibliographic information extraction\nillustrate significant test error reduction over unseen domains. Our second\nmajor contribution consists of algorithms for computing outgoing messages from\nclique clusters with symmetric clique potentials. Our algorithms are exact for\narbitrary symmetric potentials on binary labels and for max-like and\nmajority-like potentials on multiple labels. For majority potentials, we also\nprovide an efficient Lagrangian Relaxation based algorithm that compares\nfavorably with the exact algorithm. We present a 13/15-approximation algorithm\nfor the NP-hard Potts potential, with runtime sub-quadratic in the clique size.\nIn contrast, the best known previous guarantee for graphs with Potts potentials\nis only 1/2. We empirically show that our method for Potts potentials is an\norder of magnitude faster than the best alternatives, and our Lagrangian\nRelaxation based algorithm for majority potentials beats the best applicable\nheuristic -- ICM."
    },
    "1301.0561": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-12-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chickering",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David Maxwell"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Finding Optimal Bayesian Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2002-PG-94-102",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we derive optimality results for greedy Bayesian-network\nsearch algorithms that perform single-edge modifications at each step and use\nasymptotically consistent scoring criteria. Our results extend those of Meek\n(1997) and Chickering (2002), who demonstrate that in the limit of large\ndatasets, if the generative distribution is perfect with respect to a DAG\ndefined over the observable variables, such search algorithms will identify\nthis optimal (i.e. generative) DAG model. We relax their assumption about the\ngenerative distribution, and assume only that this distribution satisfies the\n{em composition property} over the observable variables, which is a more\nrealistic assumption for real domains. Under this assumption, we guarantee that\nthe search algorithms identify an {em inclusion-optimal} model; that is, a\nmodel that (1) contains the generative distribution and (2) has no sub-model\nthat contains this distribution. In addition, we show that the composition\nproperty is guaranteed to hold whenever the dependence relationships in the\ngenerative distribution can be characterized by paths between singleton\nelements in some generative graphical model (e.g. a DAG, a chain graph, or a\nMarkov network) even when the generative model includes unobserved variables,\nand even when the observed data is subject to selection bias."
    },
    "1506.04366": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-06-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Franz",
                "http://arxiv.org/OAI/arXiv/:forenames": "Arthur"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Artificial general intelligence through recursive data compression and\n  grounded reasoning: a position paper",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "27 pages, 3 figures, position paper",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper presents a tentative outline for the construction of an\nartificial, generally intelligent system (AGI). It is argued that building a\ngeneral data compression algorithm solving all problems up to a complexity\nthreshold should be the main thrust of research. A measure for partial progress\nin AGI is suggested. Although the details are far from being clear, some\ngeneral properties for a general compression algorithm are fleshed out. Its\ninductive bias should be flexible and adapt to the input data while constantly\nsearching for a simple, orthogonal and complete set of hypotheses explaining\nthe data. It should recursively reduce the size of its representations thereby\ncompressing the data increasingly at every iteration.\n  Abstract Based on that fundamental ability, a grounded reasoning system is\nproposed. It is argued how grounding and flexible feature bases made of\nhypotheses allow for resourceful thinking. While the simulation of\nrepresentation contents on the mental stage accounts for much of the power of\npropositional logic, compression leads to simple sets of hypotheses that allow\nthe detection and verification of universally quantified statements.\n  Abstract Together, it is highlighted how general compression and grounded\nreasoning could account for the birth and growth of first concepts about the\nworld and the commonsense reasoning about them."
    },
    "1201.2241": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-01-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pelikan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hauschild",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark W."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Distance-Based Bias in Model-Directed Optimization of Additively\n  Decomposable Problems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI",
        "http://arxiv.org/OAI/arXiv/:report-no": "MEDAL Report No. 2012001",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6; I.2.8; G.1.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "For many optimization problems it is possible to define a distance metric\nbetween problem variables that correlates with the likelihood and strength of\ninteractions between the variables. For example, one may define a metric so\nthat the dependencies between variables that are closer to each other with\nrespect to the metric are expected to be stronger than the dependencies between\nvariables that are further apart. The purpose of this paper is to describe a\nmethod that combines such a problem-specific distance metric with information\nmined from probabilistic models obtained in previous runs of estimation of\ndistribution algorithms with the goal of solving future problem instances of\nsimilar type with increased speed, accuracy and reliability. While the focus of\nthe paper is on additively decomposable problems and the hierarchical Bayesian\noptimization algorithm, it should be straightforward to generalize the approach\nto other model-directed optimization techniques and other problem classes.\nCompared to other techniques for learning from experience put forward in the\npast, the proposed technique is both more practical and more broadly\napplicable."
    },
    "1808.04600": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Uprety",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sagar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dawei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Reconciling Irrational Human Behavior with AI based Decision Making: A\n  Quantum Probabilistic Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at the Workshop on AI and Computational Psychology at\n  IJCAI-ECAI 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There are many examples of human decision making which cannot be modeled by\nclassical probabilistic and logic models, on which the current AI systems are\nbased. Hence the need for a modeling framework which can enable intelligent\nsystems to detect and predict cognitive biases in human decisions to facilitate\nbetter human-agent interaction. We give a few examples of irrational behavior\nand use a generalized probabilistic model inspired by the mathematical\nframework of Quantum Theory to model and explain such behavior."
    },
    "1810.01943": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bellamy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rachel K. E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kuntal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hind",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hoffman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Samuel C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Houde",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stephanie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kannan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kalapriya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lohia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Martino",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jacquelyn"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mehta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameep"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mojsilovic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aleksandra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nagar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seema"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthikeyan Natesan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Richards",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diptikalyan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sattigeri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prasanna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moninder"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kush R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunfeng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "AI Fairness 360: An Extensible Toolkit for Detecting, Understanding, and\n  Mitigating Unwanted Algorithmic Bias",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "20 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fairness is an increasingly important concern as machine learning models are\nused to support decision making in high-stakes applications such as mortgage\nlending, hiring, and prison sentencing. This paper introduces a new open source\nPython toolkit for algorithmic fairness, AI Fairness 360 (AIF360), released\nunder an Apache v2.0 license {https://github.com/ibm/aif360). The main\nobjectives of this toolkit are to help facilitate the transition of fairness\nresearch algorithms to use in an industrial setting and to provide a common\nframework for fairness researchers to share and evaluate algorithms.\n  The package includes a comprehensive set of fairness metrics for datasets and\nmodels, explanations for these metrics, and algorithms to mitigate bias in\ndatasets and models. It also includes an interactive Web experience\n(https://aif360.mybluemix.net) that provides a gentle introduction to the\nconcepts and capabilities for line-of-business users, as well as extensive\ndocumentation, usage guidance, and industry-specific tutorials to enable data\nscientists and practitioners to incorporate the most appropriate tool for their\nproblem into their work products. The architecture of the package has been\nengineered to conform to a standard paradigm used in data science, thereby\nfurther improving usability for practitioners. Such architectural design and\nabstractions enable researchers and developers to extend the toolkit with their\nnew algorithms and improvements, and to use it for performance benchmarking. A\nbuilt-in testing infrastructure maintains code quality."
    },
    "1805.01048": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chatterjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Baibhab"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Das",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Debayan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shreyas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "RF-PUF: IoT Security Enhancement through Authentication of Wireless\n  Nodes using In-situ Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CR cs.AI cs.NE eess.SP",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented in Hardware Oriented Security and Trust (HOST), 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Physical unclonable functions (PUF) in silicon exploit die-to-die\nmanufacturing variations during fabrication for uniquely identifying each die.\nSince it is practically a hard problem to recreate exact silicon features\nacross dies, a PUFbased authentication system is robust, secure and\ncost-effective, as long as bias removal and error correction are taken into\naccount. In this work, we utilize the effects of inherent process variation on\nanalog and radio-frequency (RF) properties of multiple wireless transmitters\n(Tx) in a sensor network, and detect the features at the receiver (Rx) using a\ndeep neural network based framework. The proposed mechanism/framework, called\nRF-PUF, harnesses already existing RF communication hardware and does not\nrequire any additional PUF-generation circuitry in the Tx for practical\nimplementation. Simulation results indicate that the RF-PUF framework can\ndistinguish up to 10000 transmitters (with standard foundry defined variations\nfor a 65 nm process, leading to non-idealities such as LO offset and I-Q\nimbalance) under varying channel conditions, with a probability of false\ndetection < 10e-3"
    },
    "1803.07540": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Edwards",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lilian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Enslaving the Algorithm: From a \"Right to an Explanation\" to a \"Right to\n  Better Decisions\"?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 0 figures, forthcoming in IEEE Security and Privacy, 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As concerns about unfairness and discrimination in \"black box\" machine\nlearning systems rise, a legal \"right to an explanation\" has emerged as a\ncompellingly attractive approach for challenge and redress. We outline recent\ndebates on the limited provisions in European data protection law, and\nintroduce and analyze newer explanation rights in French administrative law and\nthe draft modernized Council of Europe Convention 108. While individual rights\ncan be useful, in privacy law they have historically unreasonably burdened the\naverage data subject. \"Meaningful information\" about algorithmic logics is more\ntechnically possible than commonly thought, but this exacerbates a new\n\"transparency fallacy\"---an illusion of remedy rather than anything\nsubstantively helpful. While rights-based approaches deserve a firm place in\nthe toolbox, other forms of governance, such as impact assessments, \"soft law,\"\njudicial review, and model repositories deserve more attention, alongside\ncatalyzing agencies acting for users to control algorithmic system design."
    },
    "1308.3780": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-08-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Halpern",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joseph Y."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pass",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rafael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Seeman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lior"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Decision Theory with Resource-Bounded Agents",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear, Topics in Cognitive Science",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There have been two major lines of research aimed at capturing\nresource-bounded players in game theory. The first, initiated by Rubinstein,\ncharges an agent for doing costly computation; the second, initiated by Neyman,\ndoes not charge for computation, but limits the computation that agents can do,\ntypically by modeling agents as finite automata. We review recent work on\napplying both approaches in the context of decision theory. For the first\napproach, we take the objects of choice in a decision problem to be Turing\nmachines, and charge players for the ``complexity'' of the Turing machine\nchosen (e.g., its running time). This approach can be used to explain\nwell-known phenomena like first-impression-matters biases (i.e., people tend to\nput more weight on evidence they hear early on) and belief polarization (two\npeople with different prior beliefs, hearing the same evidence, can end up with\ndiametrically opposed conclusions) as the outcomes of quite rational decisions.\nFor the second approach, we model people as finite automata, and provide a\nsimple algorithm that, on a problem that captures a number of settings of\ninterest, provably performs optimally as the number of states in the automaton\nincreases."
    },
    "1705.09391": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-06-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mandros",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Panagiotis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mario"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vreeken",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jilles"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Discovering Reliable Approximate Functional Dependencies",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI cs.IT math.IT",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted: In Proceedings of the ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD), August 13-17, 2017, Halifax, NS, Canada",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.2.8; G.3",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3097983.3098062",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Given a database and a target attribute of interest, how can we tell whether\nthere exists a functional, or approximately functional dependence of the target\non any set of other attributes in the data? How can we reliably, without bias\nto sample size or dimensionality, measure the strength of such a dependence?\nAnd, how can we efficiently discover the optimal or $\\alpha$-approximate\ntop-$k$ dependencies? These are exactly the questions we answer in this paper.\n  As we want to be agnostic on the form of the dependence, we adopt an\ninformation-theoretic approach, and construct a reliable, bias correcting score\nthat can be efficiently computed. Moreover, we give an effective optimistic\nestimator of this score, by which for the first time we can mine the\napproximate functional dependencies from data with guarantees of optimality.\nEmpirical evaluation shows that the derived score achieves a good bias for\nvariance trade-off, can be used within an efficient discovery algorithm, and\nindeed discovers meaningful dependencies. Most important, it remains reliable\nin the face of data sparsity."
    },
    "1805.04661": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Klubi\u010dka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Filip"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fern\u00e1ndez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Raquel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Examining a hate speech corpus for hate speech detection and popularity\n  prediction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 1 figure, 10 tables, published in proceedings of 4REAL2018:\n  Workshop on Replicability and Reproducibility of Research Results in Science\n  and Technology of Language",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68T50",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "In Proceedings of 4REAL Workshop 9-16 (2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As research on hate speech becomes more and more relevant every day, most of\nit is still focused on hate speech detection. By attempting to replicate a hate\nspeech detection experiment performed on an existing Twitter corpus annotated\nfor hate speech, we highlight some issues that arise from doing research in the\nfield of hate speech, which is essentially still in its infancy. We take a\ncritical look at the training corpus in order to understand its biases, while\nalso using it to venture beyond hate speech detection and investigate whether\nit can be used to shed light on other facets of research, such as popularity of\nhate tweets."
    },
    "1605.03416": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "You",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hub",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthias"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Concept based Attention",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI q-bio.NC",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:report-no": "CS-5230-481",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "NeuroSci.Proc.Suppl. 89 (2007) 4-11",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Attention endows animals an ability to concentrate on the most relevant\ninformation among a deluge of distractors at any given time, either through\nvolitionally 'top-down' biasing, or driven by automatically 'bottom-up'\nsaliency of stimuli, in favour of advantageous competition in neural\nmodulations for information processing. Nevertheless, instead of being limited\nto perceive simple features, human and other advanced animals adaptively learn\nthe world into categories and abstract concepts from experiences, imparting the\nworld meanings. This thesis suggests that the high-level cognitive ability of\nhuman is more likely driven by attention basing on abstract perceptions, which\nis defined as concept based attention (CbA)."
    },
    "1712.02224": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pappalardo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cintia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paolo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedreschi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dino"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Giannotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fosca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barabasi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Albert-Laszlo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Human Perception of Performance",
        "http://arxiv.org/OAI/arXiv/:categories": "physics.soc-ph cs.AI physics.data-an stat.AP",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.2.8; J.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Humans are routinely asked to evaluate the performance of other individuals,\nseparating success from failure and affecting outcomes from science to\neducation and sports. Yet, in many contexts, the metrics driving the human\nevaluation process remain unclear. Here we analyse a massive dataset capturing\nplayers' evaluations by human judges to explore human perception of performance\nin soccer, the world's most popular sport. We use machine learning to design an\nartificial judge which accurately reproduces human evaluation, allowing us to\ndemonstrate how human observers are biased towards diverse contextual features.\nBy investigating the structure of the artificial judge, we uncover the aspects\nof the players' behavior which attract the attention of human judges,\ndemonstrating that human evaluation is based on a noticeability heuristic where\nonly feature values far from the norm are considered to rate an individual's\nperformance."
    },
    "1803.07517": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ras",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gabrielle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van Gerven",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Haselager",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explanation Methods in Deep Learning: Users, Values, Concerns and\n  Challenges",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, 1 figure, This article will appear as a chapter in\n  Explainable and Interpretable Models in Computer Vision and Machine Learning\n  Springer series on Challenges in Machine Learning",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68-02",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Issues regarding explainable AI involve four components: users, laws &\nregulations, explanations and algorithms. Together these components provide a\ncontext in which explanation methods can be evaluated regarding their adequacy.\nThe goal of this chapter is to bridge the gap between expert users and lay\nusers. Different kinds of users are identified and their concerns revealed,\nrelevant statements from the General Data Protection Regulation are analyzed in\nthe context of Deep Neural Networks (DNNs), a taxonomy for the classification\nof existing explanation methods is introduced, and finally, the various classes\nof explanation methods are analyzed to verify if user concerns are justified.\nOverall, it is clear that (visual) explanations can be given about various\naspects of the influence of the input on the output. However, it is noted that\nexplanation methods or interfaces for lay users are missing and we speculate\nwhich criteria these methods / interfaces should satisfy. Finally it is noted\nthat two important concerns are difficult to address with explanation methods:\nthe concern about bias in datasets that leads to biased DNNs, as well as the\nsuspicion about unfair outcomes."
    },
    "1007.0859": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-07-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gelain",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M. S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rossi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Venable",
                    "http://arxiv.org/OAI/arXiv/:forenames": "K. B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "T."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Local search for stable marriage problems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "12 pages, Proc. COMSOC 2010 (Third International Workshop on\n  Computational Social Choice)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The stable marriage (SM) problem has a wide variety of practical\napplications, ranging from matching resident doctors to hospitals, to matching\nstudents to schools, or more generally to any two-sided market. In the\nclassical formulation, n men and n women express their preferences (via a\nstrict total order) over the members of the other sex. Solving a SM problem\nmeans finding a stable marriage where stability is an envy-free notion: no man\nand woman who are not married to each other would both prefer each other to\ntheir partners or to being single. We consider both the classical stable\nmarriage problem and one of its useful variations (denoted SMTI) where the men\nand women express their preferences in the form of an incomplete preference\nlist with ties over a subset of the members of the other sex. Matchings are\npermitted only with people who appear in these lists, an we try to find a\nstable matching that marries as many people as possible. Whilst the SM problem\nis polynomial to solve, the SMTI problem is NP-hard. We propose to tackle both\nproblems via a local search approach, which exploits properties of the problems\nto reduce the size of the neighborhood and to make local moves efficiently. We\nevaluate empirically our algorithm for SM problems by measuring its runtime\nbehaviour and its ability to sample the lattice of all possible stable\nmarriages. We evaluate our algorithm for SMTI problems in terms of both its\nruntime behaviour and its ability to find a maximum cardinality stable\nmarriage.For SM problems, the number of steps of our algorithm grows only as\nO(nlog(n)), and that it samples very well the set of all stable marriages. It\nis thus a fair and efficient approach to generate stable marriages.Furthermore,\nour approach for SMTI problems is able to solve large problems, quickly\nreturning stable matchings of large and often optimal size despite the\nNP-hardness of this problem."
    },
    "1206.5239": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-06-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamze",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Firas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "de Freitas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nando"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Large-Flip Importance Sampling",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.CO cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2007-PG-167-174",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a new Monte Carlo algorithm for complex discrete distributions.\nThe algorithm is motivated by the N-Fold Way, which is an ingenious\nevent-driven MCMC sampler that avoids rejection moves at any specific state.\nThe N-Fold Way can however get \"trapped\" in cycles. We surmount this problem by\nmodifying the sampling process. This correction does introduce bias, but the\nbias is subsequently corrected with a carefully engineered importance sampler."
    },
    "1103.4601": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-03-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2011-05-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dudik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Miroslav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Langford",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lihong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Doubly Robust Policy Evaluation and Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO stat.AP stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at ICML 2011, 8 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study decision making in environments where the reward is only partially\nobserved, but can be modeled as a function of an action and an observed\ncontext. This setting, known as contextual bandits, encompasses a wide variety\nof applications including health-care policy and Internet advertising. A\ncentral task is evaluation of a new policy given historic data consisting of\ncontexts, actions and received rewards. The key challenge is that the past data\ntypically does not faithfully represent proportions of actions taken by a new\npolicy. Previous approaches rely either on models of rewards or models of the\npast policy. The former are plagued by a large bias whereas the latter have a\nlarge variance.\n  In this work, we leverage the strength and overcome the weaknesses of the two\napproaches by applying the doubly robust technique to the problems of policy\nevaluation and optimization. We prove that this approach yields accurate value\nestimates when we have either a good (but not necessarily consistent) model of\nrewards or a good (but not necessarily consistent) model of past policy.\nExtensive empirical comparison demonstrates that the doubly robust approach\nuniformly improves over existing techniques, achieving both lower variance in\nvalue estimation and better policies. As such, we expect the doubly robust\napproach to become common practice."
    },
    "1202.3700": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bachrach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoram"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meir",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Reshef"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feldman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tennenholtz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moshe"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Solving Cooperative Reliability Games",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2011-PG-27-34",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Cooperative games model the allocation of profit from joint actions,\nfollowing considerations such as stability and fairness. We propose the\nreliability extension of such games, where agents may fail to participate in\nthe game. In the reliability extension, each agent only \"survives\" with a\ncertain probability, and a coalition's value is the probability that its\nsurviving members would be a winning coalition in the base game. We study\nprominent solution concepts in such games, showing how to approximate the\nShapley value and how to compute the core in games with few agent types. We\nalso show that applying the reliability extension may stabilize the game,\nmaking the core non-empty even when the base game has an empty core."
    },
    "1412.8704": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-12-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aerts",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diederik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sozzo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veloz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tomas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Quantum Structure in Cognition and the Foundations of Human Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI quant-ph",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages, no figures",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Theoretical Physics, 54, pp 4557-4569,\n  2015",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s10773-015-2717-9",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Traditional cognitive science rests on a foundation of classical logic and\nprobability theory. This foundation has been seriously challenged by several\nfindings in experimental psychology on human decision making. Meanwhile, the\nformalism of quantum theory has provided an efficient resource for modeling\nthese classically problematical situations. In this paper, we start from our\nsuccessful quantum-theoretic approach to the modeling of concept combinations\nto formulate a unifying explanatory hypothesis. In it, human reasoning is the\nsuperposition of two processes -- a conceptual reasoning, whose nature is\nemergence of new conceptuality, and a logical reasoning, founded on an\nalgebraic calculus of the logical type. In most cognitive processes however,\nthe former reasoning prevails over the latter. In this perspective, the\nobserved deviations from classical logical reasoning should not be interpreted\nas biases but, rather, as natural expressions of emergence in its deepest form."
    },
    "1711.07414": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Herman",
                "http://arxiv.org/OAI/arXiv/:forenames": "Bernease"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Promise and Peril of Human Evaluation for Model Interpretability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Transparency, user trust, and human comprehension are popular ethical\nmotivations for interpretable machine learning. In support of these goals,\nresearchers evaluate model explanation performance using humans and real world\napplications. This alone presents a challenge in many areas of artificial\nintelligence. In this position paper, we propose a distinction between\ndescriptive and persuasive explanations. We discuss reasoning suggesting that\nfunctional interpretability may be correlated with cognitive function and user\npreferences. If this is indeed the case, evaluation and optimization using\nfunctional metrics could perpetuate implicit cognitive bias in explanations\nthat threaten transparency. Finally, we propose two potential research\ndirections to disambiguate cognitive function and explanation models, retaining\ncontrol over the tradeoff between accuracy and interpretability."
    },
    "1605.04812": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Swaminathan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adith"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishnamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Akshay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alekh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dud\u00edk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Miroslav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Langford",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jose",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Damien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zitouni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Imed"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Off-policy evaluation for slate recommendation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "31 pages (9 main paper, 20 supplementary), 12 figures (2 main paper,\n  10 supplementary)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper studies the evaluation of policies that recommend an ordered set\nof items (e.g., a ranking) based on some context---a common scenario in web\nsearch, ads, and recommendation. We build on techniques from combinatorial\nbandits to introduce a new practical estimator that uses logged data to\nestimate a policy's performance. A thorough empirical evaluation on real-world\ndata reveals that our estimator is accurate in a variety of settings, including\nas a subroutine in a learning-to-rank task, where it achieves competitive\nperformance. We derive conditions under which our estimator is unbiased---these\nconditions are weaker than prior heuristics for slate evaluation---and\nexperimentally demonstrate a smaller bias than parametric approaches, even when\nthese conditions are violated. Finally, our theory and experiments also show\nexponential savings in the amount of required data compared with general\nunbiased estimators."
    },
    "1807.00468": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-07-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Udeshi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sakshi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Arora",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pryanshu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chattopadhyay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sudipta"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automated Directed Fairness Testing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.SE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings of the 2018 33rd ACM/IEEE International Conference on\n  Automated Software Engineering (ASE 18), September 3-7, 2018, Montpellier,\n  France",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Automated Directed Fairness Testing. In Proceedings of the 2018\n  33rd ACM/IEEE International Conference on Automated Software Engineering (ASE\n  18), September 3-7, 2018, Montpellier, France",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3238147.3238165",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fairness is a critical trait in decision making. As machine-learning models\nare increasingly being used in sensitive application domains (e.g. education\nand employment) for decision making, it is crucial that the decisions computed\nby such models are free of unintended bias. But how can we automatically\nvalidate the fairness of arbitrary machine-learning models? For a given\nmachine-learning model and a set of sensitive input parameters, our AEQUITAS\napproach automatically discovers discriminatory inputs that highlight fairness\nviolation. At the core of AEQUITAS are three novel strategies to employ\nprobabilistic search over the input space with the objective of uncovering\nfairness violation. Our AEQUITAS approach leverages inherent robustness\nproperty in common machine-learning models to design and implement scalable\ntest generation methodologies. An appealing feature of our generated test\ninputs is that they can be systematically added to the training set of the\nunderlying model and improve its fairness. To this end, we design a fully\nautomated module that guarantees to improve the fairness of the underlying\nmodel.\n  We implemented AEQUITAS and we have evaluated it on six state-of-the-art\nclassifiers, including a classifier that was designed with fairness\nconstraints. We show that AEQUITAS effectively generates inputs to uncover\nfairness violation in all the subject classifiers and systematically improves\nthe fairness of the respective models using the generated test inputs. In our\nevaluation, AEQUITAS generates up to 70% discriminatory inputs (w.r.t. the\ntotal number of inputs generated) and leverages these inputs to improve the\nfairness up to 94%."
    },
    "1807.01279": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jasrasaria",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dipti"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pyzer-Knapp",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward O."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Dynamic Control of Explore/Exploit Trade-Off In Bayesian Optimization",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted for publication in the proceedings of 2018 Computing\n  Conference",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bayesian optimization offers the possibility of optimizing black-box\noperations not accessible through traditional techniques. The success of\nBayesian optimization methods such as Expected Improvement (EI) are\nsignificantly affected by the degree of trade-off between exploration and\nexploitation. Too much exploration can lead to inefficient optimization\nprotocols, whilst too much exploitation leaves the protocol open to strong\ninitial biases, and a high chance of getting stuck in a local minimum.\nTypically, a constant margin is used to control this trade-off, which results\nin yet another hyper-parameter to be optimized. We propose contextual\nimprovement as a simple, yet effective heuristic to counter this - achieving a\none-shot optimization strategy. Our proposed heuristic can be swiftly\ncalculated and improves both the speed and robustness of discovery of optimal\nsolutions. We demonstrate its effectiveness on both synthetic and real world\nproblems and explore the unaccounted for uncertainty in the pre-determination\nof search hyperparameters controlling explore-exploit trade-off."
    },
    "1804.05560": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Naman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Faltings",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Bayesian Trust : A Dominant Strategy and Fair Reward Mechanism for\n  Crowdsourcing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A common mechanism to assess trust in crowdworkers is to have them answer\ngold tasks. However, assigning gold tasks to all workers reduces the efficiency\nof the platform. We propose a mechanism that exploits transitivity so that a\nworker can be certified as trusted by other trusted workers who solve common\ntasks. Thus, trust can be derived from a smaller number of gold tasks\nassignment through multiple layers of peer relationship among the workers, a\nmodel we call deep trust. We use the derived trust to incentivize workers for\nhigh quality work and show that the resulting mechanism is dominant strategy\nincentive compatible. We also show that the mechanism satisfies a notion of\nfairness in that the trust assessment (and thus the reward) of a worker in the\nlimit is independent of the quality of other workers."
    },
    "1212.1942": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-12-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sumedha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishnamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Supriya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sahoo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sharmistha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Balanced K-SAT and Biased random K-SAT on trees",
        "http://arxiv.org/OAI/arXiv/:categories": "cond-mat.stat-mech cs.AI cs.CC",
        "http://arxiv.org/OAI/arXiv/:comments": "22 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Phys. Rev. E 87, 042130 (2013)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study and solve some variations of the random K-satisfiability problem -\nbalanced K-SAT and biased random K-SAT - on a regular tree, using techniques we\nhave developed earlier(arXiv:1110.2065). In both these problems, as well as\nvariations of these that we have looked at, we find that the SAT-UNSAT\ntransition obtained on the Bethe lattice matches the exact threshold for the\nsame model on a random graph for K=2 and is very close to the numerical value\nobtained for K=3. For higher K it deviates from the numerical estimates of the\nsolvability threshold on random graphs, but is very close to the dynamical\n1-RSB threshold as obtained from the first non-trivial fixed point of the\nsurvey propagation algorithm."
    },
    "1002.0102": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-01-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Smarandache",
                "http://arxiv.org/OAI/arXiv/:forenames": "Florentin"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "$\\alpha$-Discounting Multi-Criteria Decision Making ($\\alpha$-D MCDM)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "62 pages",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.3",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of Fusion 2010 International Conference, Edinburgh,\n  Scotland, 26-29 July, 2010",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this book we introduce a new procedure called \\alpha-Discounting Method\nfor Multi-Criteria Decision Making (\\alpha-D MCDM), which is as an alternative\nand extension of Saaty Analytical Hierarchy Process (AHP). It works for any\nnumber of preferences that can be transformed into a system of homogeneous\nlinear equations. A degree of consistency (and implicitly a degree of\ninconsistency) of a decision-making problem are defined. \\alpha-D MCDM is\nafterwards generalized to a set of preferences that can be transformed into a\nsystem of linear and or non-linear homogeneous and or non-homogeneous equations\nand or inequalities. The general idea of \\alpha-D MCDM is to assign non-null\npositive parameters \\alpha_1, \\alpha_2, and so on \\alpha_p to the coefficients\nin the right-hand side of each preference that diminish or increase them in\norder to transform the above linear homogeneous system of equations which has\nonly the null-solution, into a system having a particular non-null solution.\nAfter finding the general solution of this system, the principles used to\nassign particular values to all parameters \\alpha is the second important part\nof \\alpha-D, yet to be deeper investigated in the future. In the current book\nwe propose the Fairness Principle, i.e. each coefficient should be discounted\nwith the same percentage (we think this is fair: not making any favoritism or\nunfairness to any coefficient), but the reader can propose other principles.\nFor consistent decision-making problems with pairwise comparisons,\n\\alpha-Discounting Method together with the Fairness Principle give the same\nresult as AHP. But for weak inconsistent decision-making problem,\n\\alpha-Discounting together with the Fairness Principle give a different result\nfrom AHP. Many consistent, weak inconsistent, and strong inconsistent examples\nare given in this book."
    },
    "1711.06317": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sheikhan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mansour"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hemmati",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ehsan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shahnazi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Reza"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "GA-PSO-Optimized Neural-Based Control Scheme for Adaptive Congestion\n  Control to Improve Performance in Multimedia Applications",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.NI",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: text overlap with arXiv:1711.06356",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Majlesi Journal of Electrical Engineering, [S.l.], v. 6, n. 1,\n  jan. 2012",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Active queue control aims to improve the overall communication network\nthroughput while providing lower delay and small packet loss rate. The basic\nidea is to actively trigger packet dropping (or marking provided by explicit\ncongestion notification (ECN)) before buffer overflow. In this paper, two\nartificial neural networks (ANN)-based control schemes are proposed for\nadaptive queue control in TCP communication networks. The structure of these\ncontrollers is optimized using genetic algorithm (GA) and the output weights of\nANNs are optimized using particle swarm optimization (PSO) algorithm. The\ncontrollers are radial bias function (RBF)-based, but to improve the robustness\nof RBF controller, an error-integral term is added to RBF equation in the\nsecond scheme. Experimental results show that GA- PSO-optimized improved RBF\n(I-RBF) model controls network congestion effectively in terms of link\nutilization with a low packet loss rate and outperform Drop Tail,\nproportional-integral (PI), random exponential marking (REM), and adaptive\nrandom early detection (ARED) controllers."
    },
    "1004.2870": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-03-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Aickelin",
                "http://arxiv.org/OAI/arXiv/:forenames": "Uwe"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Nurse Rostering with Genetic Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "22 pages, Young Operational Research Conference 12",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Young Operational Research Conference 12, 1998",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent years genetic algorithms have emerged as a useful tool for the\nheuristic solution of complex discrete optimisation problems. In particular\nthere has been considerable interest in their use in tackling problems arising\nin the areas of scheduling and timetabling. However, the classical genetic\nalgorithm paradigm is not well equipped to handle constraints and successful\nimplementations usually require some sort of modification to enable the search\nto exploit problem specific knowledge in order to overcome this shortcoming.\nThis paper is concerned with the development of a family of genetic algorithms\nfor the solution of a nurse rostering problem at a major UK hospital. The\nhospital is made up of wards of up to 30 nurses. Each ward has its own group of\nnurses whose shifts have to be scheduled on a weekly basis. In addition to\nfulfilling the minimum demand for staff over three daily shifts, nurses' wishes\nand qualifications have to be taken into account. The schedules must also be\nseen to be fair, in that unpopular shifts have to be spread evenly amongst all\nnurses, and other restrictions, such as team nursing and special conditions for\nsenior staff, have to be satisfied. The basis of the family of genetic\nalgorithms is a classical genetic algorithm consisting of n-point crossover,\nsingle-bit mutation and a rank-based selection. The solution space consists of\nall schedules in which each nurse works the required number of shifts, but the\nremaining constraints, both hard and soft, are relaxed and penalised in the\nfitness function. The talk will start with a detailed description of the\nproblem and the initial implementation and will go on to highlight the\nshortcomings of such an approach, in terms of the key element of balancing\nfeasibility, i.e. covering the demand and work regulations, and quality, as\nmeasured by the nurses' preferences. A series of experiments involving\nparameter adaptation, niching, intelligent weights, delta coding, local hill\nclimbing, migration and special selection rules will then be outlined and it\nwill be shown how a series of these enhancements were able to eradicate these\ndifficulties. Results based on several months' real data will be used to\nmeasure the impact of each modification, and to show that the final algorithm\nis able to compete with a tabu search approach currently employed at the\nhospital. The talk will conclude with some observations as to the overall\nquality of this approach to this and similar problems."
    },
    "1808.10012": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tandon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Niket"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mishra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bhavana Dalvi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yih",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wen-tau"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bosselut",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antoine"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Clark",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Reasoning about Actions and State Changes by Injecting Commonsense\n  Knowledge",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at EMNLP 2018. Niket Tandon and Bhavana Dalvi Mishra\n  contributed equally to this work",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Comprehending procedural text, e.g., a paragraph describing photosynthesis,\nrequires modeling actions and the state changes they produce, so that questions\nabout entities at different timepoints can be answered. Although several recent\nsystems have shown impressive progress in this task, their predictions can be\nglobally inconsistent or highly improbable. In this paper, we show how the\npredicted effects of actions in the context of a paragraph can be improved in\ntwo ways: (1) by incorporating global, commonsense constraints (e.g., a\nnon-existent entity cannot be destroyed), and (2) by biasing reading with\npreferences from large-scale corpora (e.g., trees rarely move). Unlike earlier\nmethods, we treat the problem as a neural structured prediction task, allowing\nhard and soft constraints to steer the model away from unlikely predictions. We\nshow that the new model significantly outperforms earlier systems on a\nbenchmark dataset for procedural text comprehension (+8% relative gain), and\nthat it also avoids some of the nonsensical predictions that earlier systems\nmake."
    },
    "1811.06606": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-11-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Muller",
                "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Economics of Human-AI Ecosystem: Value Bias and Lost Utility in\n  Multi-Dimensional Gaps",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI econ.GN q-fin.EC",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, typos corrected, examples added to Table 1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent years, artificial intelligence (AI) decision-making and autonomous\nsystems became an integrated part of the economy, industry, and society. The\nevolving economy of the human-AI ecosystem raising concerns regarding the risks\nand values inherited in AI systems. This paper investigates the dynamics of\ncreation and exchange of values and points out gaps in perception of\ncost-value, knowledge, space and time dimensions. It shows aspects of value\nbias in human perception of achievements and costs that encoded in AI systems.\nIt also proposes rethinking hard goals definitions and cost-optimal\nproblem-solving principles in the lens of effectiveness and efficiency in the\ndevelopment of trusted machines. The paper suggests a value-driven with cost\nawareness strategy and principles for problem-solving and planning of effective\nresearch progress to address real-world problems that involve diverse forms of\nachievements, investments, and survival scenarios."
    },
    "1806.06055": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-08-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Celis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L. Elisa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lingxiao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Keswani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vijay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vishnoi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nisheeth K."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Classification with Fairness Constraints: A Meta-Algorithm with Provable\n  Guarantees",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY cs.DS stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Developing classification algorithms that are fair with respect to sensitive\nattributes of the data has become an important problem due to the growing\ndeployment of classification algorithms in various social contexts. Several\nrecent works have focused on fairness with respect to a specific metric,\nmodeled the corresponding fair classification problem as a constrained\noptimization problem, and developed tailored algorithms to solve them. Despite\nthis, there still remain important metrics for which we do not have fair\nclassifiers and many of the aforementioned algorithms do not come with\ntheoretical guarantees; perhaps because the resulting optimization problem is\nnon-convex. The main contribution of this paper is a new meta-algorithm for\nclassification that takes as input a large class of fairness constraints, with\nrespect to multiple non-disjoint sensitive attributes, and which comes with\nprovable guarantees. This is achieved by first developing a meta-algorithm for\na large family of classification problems with convex constraints, and then\nshowing that classification problems with general types of fairness constraints\ncan be reduced to those in this family. We present empirical results that show\nthat our algorithm can achieve near-perfect fairness with respect to various\nfairness metrics, and that the loss in accuracy due to the imposed fairness\nconstraints is often small. Overall, this work unifies several prior works on\nfair classification, presents a practical algorithm with theoretical\nguarantees, and can handle fairness metrics that were previously not possible."
    },
    "1809.08935": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Balikas",
                "http://arxiv.org/OAI/arXiv/:forenames": "Georgios"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Lexical Bias In Essay Level Prediction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "CAp 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automatically predicting the level of non-native English speakers given their\nwritten essays is an interesting machine learning problem. In this work I\npresent the system \"balikasg\" that achieved the state-of-the-art performance in\nthe CAp 2018 data science challenge among 14 systems. I detail the feature\nextraction, feature engineering and model selection steps and I evaluate how\nthese decisions impact the system's performance. The paper concludes with\nremarks for future work."
    },
    "1106.5316": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Online Cake Cutting (published version)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.GT cs.MA",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in the Proceedings of the Second International Conference\n  on Algorithmic Decision Theory (ADT 2011)",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an online form of the cake cutting problem. This models situations\nwhere agents arrive and depart during the process of dividing a resource. We\nshow that well known fair division procedures like cut-and-choose and the\nDubins-Spanier moving knife procedure can be adapted to apply to such online\nproblems. We propose some fairness properties that online cake cutting\nprocedures can possess like online forms of proportionality and envy-freeness.\nWe also consider the impact of collusion between agents. Finally, we study\ntheoretically and empirically the competitive ratio of these online cake\ncutting procedures. Based on its resistance to collusion, and its good\nperformance in practice, our results favour the online version of the\ncut-and-choose procedure over the online version of the moving knife procedure."
    },
    "1604.02737": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ortiz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luis E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boshen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ze"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Correlated Equilibria for Approximate Variational Inference in MRFs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.GT stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "54 pages, 8 figures, 20 plots, Extension of Section 4 of a manuscript\n  by the first author first drafted on August 25, 2009 (see\n  http://www-personal.umd.umich.edu/~leortiz/papers/infeq.pdf). Changes:\n  experiments with multiplicative-weight learning algorithms on larger (12x12)\n  synthetic Ising models and 28x28 Ising models learned from MNIST dataset; and\n  misc. edits to improve presentation",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Almost all of the work in graphical models for game theory has mirrored\nprevious work in probabilistic graphical models. Our work considers the\nopposite direction: Taking advantage of recent advances in equilibrium\ncomputation for probabilistic inference. We present formulations of inference\nproblems in Markov random fields (MRFs) as computation of equilibria in a\ncertain class of game-theoretic graphical models. We concretely establishes the\nprecise connection between variational probabilistic inference in MRFs and\ncorrelated equilibria. No previous work exploits recent theoretical and\nempirical results from the literature on algorithmic and computational game\ntheory on the tractable, polynomial-time computation of exact or approximate\ncorrelated equilibria in graphical games with arbitrary, loopy graph structure.\nWe discuss how to design new algorithms with equally tractable guarantees for\nthe computation of approximate variational inference in MRFs. Also, inspired by\na previously stated game-theoretic view of state-of-the-art tree-reweighed\n(TRW) message-passing techniques for belief inference as zero-sum game, we\npropose a different, general-sum potential game to design approximate\nfictitious-play techniques. We perform synthetic experiments evaluating our\nproposed approximation algorithms with standard methods and TRW on several\nclasses of classical Ising models (i.e., with binary random variables). We also\nevaluate the algorithms using Ising models learned from the MNIST dataset. Our\nexperiments show that our global approach is competitive, particularly shinning\nin a class of Ising models with constant, \"highly attractive\" edge-weights, in\nwhich it is often better than all other alternatives we evaluated. With a\nnotable exception, our more local approach was not as effective. Yet, in\nfairness, almost all of the alternatives are often no better than a simple\nbaseline: estimate 0.5."
    },
    "0712.0938": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2007-12-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Deepthi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dasika Ratna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "G. R. Aditya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Eswaran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "K."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automatic Pattern Classification by Unsupervised Learning Using\n  Dimensionality Reduction of Data with Mirroring Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented in IEEE International Conference on Advances in Computer\n  Vision and Information Technology (ACVIT-07), Nov. 28-30 2007",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IEEE International Conference on Advances in Computer Vision and\n  Information Tech. (IEEE, ACVIT-07), pp. 354 - 360 (2007)",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper proposes an unsupervised learning technique by using Multi-layer\nMirroring Neural Network and Forgy's clustering algorithm. Multi-layer\nMirroring Neural Network is a neural network that can be trained with\ngeneralized data inputs (different categories of image patterns) to perform\nnon-linear dimensionality reduction and the resultant low-dimensional code is\nused for unsupervised pattern classification using Forgy's algorithm. By\nadapting the non-linear activation function (modified sigmoidal function) and\ninitializing the weights and bias terms to small random values, mirroring of\nthe input pattern is initiated. In training, the weights and bias terms are\nchanged in such a way that the input presented is reproduced at the output by\nback propagating the error. The mirroring neural network is capable of reducing\nthe input vector to a great degree (approximately 1/30th the original size) and\nalso able to reconstruct the input pattern at the output layer from this\nreduced code units. The feature set (output of central hidden layer) extracted\nfrom this network is fed to Forgy's algorithm, which classify input data\npatterns into distinguishable classes. In the implementation of Forgy's\nalgorithm, initial seed points are selected in such a way that they are distant\nenough to be perfectly grouped into different categories. Thus a new method of\nunsupervised learning is formulated and demonstrated in this paper. This method\ngave impressive results when applied to classification of different image\npatterns."
    },
    "1808.05908": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Brahma",
                "http://arxiv.org/OAI/arXiv/:forenames": "Siddhartha"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improved Language Modeling by Decoding the Past",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Highly regularized LSTMs achieve impressive results on several benchmark\ndatasets in language modeling. We propose a new regularization method based on\ndecoding the last token in the context using the predicted distribution of the\nnext token. This biases the model towards retaining more contextual\ninformation, in turn improving its ability to predict the next token. With\nnegligible overhead in the number of parameters and training time, our past\ndecode regularization (PDR) method achieves state-of-the-art word level\nperplexity on the Penn Treebank (55.6) and WikiText-2 (63.5) datasets and\nbits-per-character on the Penn Treebank Character (1.169) dataset for character\nlevel language modeling. Using dynamic evaluation, we also achieve the first\nsub 50 perplexity of 49.3 on the Penn Treebank test set."
    },
    "1803.09211": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Misra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vinith"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bhatia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sumit"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bernoulli Embeddings for Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "The Thirty-Second AAAI Conference on Artificial Intelligence\n  (AAAI-18)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Just as semantic hashing can accelerate information retrieval, binary valued\nembeddings can significantly reduce latency in the retrieval of graphical data.\nWe introduce a simple but effective model for learning such binary vectors for\nnodes in a graph. By imagining the embeddings as independent coin flips of\nvarying bias, continuous optimization techniques can be applied to the\napproximate expected loss. Embeddings optimized in this fashion consistently\noutperform the quantization of both spectral graph embeddings and various\nlearned real-valued embeddings, on both ranking and pre-ranking tasks for a\nvariety of datasets."
    },
    "1606.05611": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-06-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zimmermann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kotschenreuther",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schmidt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karsten"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Data-driven HR - R\\'esum\\'e Analysis Based on Natural Language\n  Processing and Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Research Prototype, Technical Report",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recruiters usually spend less than a minute looking at each r\\'esum\\'e when\ndeciding whether it's worth continuing the recruitment process with the\ncandidate. Recruiters focus on keywords, and it's almost impossible to\nguarantee a fair process of candidate selection. The main scope of this paper\nis to tackle this issue by introducing a data-driven approach that shows how to\nprocess r\\'esum\\'es automatically and give recruiters more time to only examine\npromising candidates. Furthermore, we show how to leverage Machine Learning and\nNatural Language Processing in order to extract all required information from\nthe r\\'esum\\'es. Once the information is extracted, a ranking score is\ncalculated. The score describes how well the candidates fit based on their\neducation, work experience and skills. Later this paper illustrates a prototype\napplication that shows how this novel approach can increase the productivity of\nrecruiters. The application enables them to filter and rank candidates based on\npredefined job descriptions. Guided by the ranking, recruiters can get deeper\ninsights from candidate profiles and validate why and how the application\nranked them. This application shows how to improve the hiring process by giving\nan unbiased hiring decision support."
    },
    "1608.05151": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "van Seijen",
                "http://arxiv.org/OAI/arXiv/:forenames": "Harm"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Effective Multi-step Temporal-Difference Learning for Non-Linear\n  Function Approximation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Multi-step temporal-difference (TD) learning, where the update targets\ncontain information from multiple time steps ahead, is one of the most popular\nforms of TD learning for linear function approximation. The reason is that\nmulti-step methods often yield substantially better performance than their\nsingle-step counter-parts, due to a lower bias of the update targets. For\nnon-linear function approximation, however, single-step methods appear to be\nthe norm. Part of the reason could be that on many domains the popular\nmulti-step methods TD($\\lambda$) and Sarsa($\\lambda$) do not perform well when\ncombined with non-linear function approximation. In particular, they are very\nsusceptible to divergence of value estimates. In this paper, we identify the\nreason behind this. Furthermore, based on our analysis, we propose a new\nmulti-step TD method for non-linear function approximation that addresses this\nissue. We confirm the effectiveness of our method using two benchmark tasks\nwith neural networks as function approximation."
    },
    "1709.04524": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Talamadupula",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kartik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Srivastava",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Biplav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kephart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeffrey O."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Workflow Complexity for Collaborative Interactions: Where are the\n  Metrics? -- A Challenge",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "4 pages, 1 figure, 1 table Appeared in the ICAPS 2017 UISP Workshop",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we introduce the problem of denoting and deriving the\ncomplexity of workflows (plans, schedules) in collaborative, planner-assisted\nsettings where humans and agents are trying to jointly solve a task. The\ninteractions -- and hence the workflows that connect the human and the agents\n-- may differ according to the domain and the kind of agents. We adapt insights\nfrom prior work in human-agent teaming and workflow analysis to suggest metrics\nfor workflow complexity. The main motivation behind this work is to highlight\nmetrics for human comprehensibility of plans and schedules. The planning\ncommunity has seen its fair share of work on the synthesis of plans that take\ndiversity into account -- what value do such plans hold if their generation is\nnot guided at least in part by metrics that reflect the ease of engaging with\nand using those plans?"
    },
    "1312.7606": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-12-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-11-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Macua",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergio Valcarcel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianshu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zazo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Santiago"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sayed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ali H."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Distributed Policy Evaluation Under Multiple Behavior Strategies",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.MA cs.AI cs.DC cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "36 pages, 4 figures, accepted for publication on IEEE Transactions on\n  Automatic Control",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We apply diffusion strategies to develop a fully-distributed cooperative\nreinforcement learning algorithm in which agents in a network communicate only\nwith their immediate neighbors to improve predictions about their environment.\nThe algorithm can also be applied to off-policy learning, meaning that the\nagents can predict the response to a behavior different from the actual\npolicies they are following. The proposed distributed strategy is efficient,\nwith linear complexity in both computation time and memory footprint. We\nprovide a mean-square-error performance analysis and establish convergence\nunder constant step-size updates, which endow the network with continuous\nlearning capabilities. The results show a clear gain from cooperation: when the\nindividual agents can estimate the solution, cooperation increases stability\nand reduces bias and variance of the prediction error; but, more importantly,\nthe network is able to approach the optimal solution even when none of the\nindividual agents can (e.g., when the individual behavior policies restrict\neach agent to sample a small portion of the state space)."
    },
    "1801.01596": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiazhuo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jason"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuejun"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Combination of Hyperband and Bayesian Optimization for Hyperparameter\n  Optimization in Deep Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "preprint",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep learning has achieved impressive results on many problems. However, it\nrequires high degree of expertise or a lot of experience to tune well the\nhyperparameters, and such manual tuning process is likely to be biased.\nMoreover, it is not practical to try out as many different hyperparameter\nconfigurations in deep learning as in other machine learning scenarios, because\nevaluating each single hyperparameter configuration in deep learning would mean\ntraining a deep neural network, which usually takes quite long time. Hyperband\nalgorithm achieves state-of-the-art performance on various hyperparameter\noptimization problems in the field of deep learning. However, Hyperband\nalgorithm does not utilize history information of previous explored\nhyperparameter configurations, thus the solution found is suboptimal. We\npropose to combine Hyperband algorithm with Bayesian optimization (which does\nnot ignore history when sampling next trial configuration). Experimental\nresults show that our combination approach is superior to other hyperparameter\noptimization approaches including Hyperband algorithm."
    },
    "1811.02736": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-11-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hyungjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Younggwan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jung",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Youngmoon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jung",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Myunghun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hoirin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning acoustic word embeddings with phonetically associated triplet\n  network",
        "http://arxiv.org/OAI/arXiv/:categories": "eess.AS cs.AI cs.CL cs.SD eess.SP",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 4 figures, submitted to ICASSP 2019",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Previous researches on acoustic word embeddings used in query-by-example\nspoken term detection have shown remarkable performance improvements when using\na triplet network. However, the triplet network is trained using only a limited\ninformation about acoustic similarity between words. In this paper, we propose\na novel architecture, phonetically associated triplet network (PATN), which\naims at increasing discriminative power of acoustic word embeddings by\nutilizing phonetic information as well as word identity. The proposed model is\nlearned to minimize a combined loss function that was made by introducing a\ncross entropy loss to the lower layer of LSTM-based triplet network. We\nobserved that the proposed method performs significantly better than the\nbaseline triplet network on a word discrimination task with the WSJ dataset\nresulting in over 40% relative improvement in recall rate at 1.0 false alarm\nper hour. Finally, we examined the generalization ability by conducting the\nout-of-domain test on the RM dataset."
    },
    "1301.0582": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-12-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lerner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Uri"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moses",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brooks"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scott",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maricia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "McIlraith",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sheila"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Koller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daphne"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Monitoring a Complez Physical System using a Hybrid Dynamic Bayes Net",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2002-PG-301-310",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The Reverse Water Gas Shift system (RWGS) is a complex physical system\ndesigned to produce oxygen from the carbon dioxide atmosphere on Mars. If sent\nto Mars, it would operate without human supervision, thus requiring a reliable\nautomated system for monitoring and control. The RWGS presents many challenges\ntypical of real-world systems, including: noisy and biased sensors, nonlinear\nbehavior, effects that are manifested over different time granularities, and\nunobservability of many important quantities. In this paper we model the RWGS\nusing a hybrid (discrete/continuous) Dynamic Bayesian Network (DBN), where the\nstate at each time slice contains 33 discrete and 184 continuous variables. We\nshow how the system state can be tracked using probabilistic inference over the\nmodel. We discuss how to deal with the various challenges presented by the\nRWGS, providing a suite of techniques that are likely to be useful in a wide\nrange of applications. In particular, we describe a general framework for\ndealing with nonlinear behavior using numerical integration techniques,\nextending the successful Unscented Filter. We also show how to use a\nfixed-point computation to deal with effects that develop at different time\nscales, specifically rapid changes occurring during slowly changing processes.\nWe test our model using real data collected from the RWGS, demonstrating the\nfeasibility of hybrid DBNs for monitoring complex real-world physical systems."
    },
    "1802.07877": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sabzevari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maryam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mart\u00ednez-Mu\u00f1oz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gonzalo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su\u00e1rez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alberto"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Pooling homogeneous ensembles to build heterogeneous ensembles",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In ensemble methods, the outputs of a collection of diverse classifiers are\ncombined in the expectation that the global prediction be more accurate than\nthe individual ones. Heterogeneous ensembles consist of predictors of different\ntypes, which are likely to have different biases. If these biases are\ncomplementary, the combination of their decisions is beneficial. In this work,\na family of heterogeneous ensembles is built by pooling classifiers from M\nhomogeneous ensembles of different types of size T. Depending on the fraction\nof base classifiers of each type, a particular heterogeneous combination in\nthis family is represented by a point in a regular simplex in M dimensions. The\nM vertices of this simplex represent the different homogeneous ensembles. A\ndisplacement away from one of these vertices effects a smooth transformation of\nthe corresponding homogeneous ensemble into a heterogeneous one. The optimal\ncomposition of such heterogeneous ensemble can be determined using\ncross-validation or, if bootstrap samples are used to build the individual\nclassifiers, out-of-bag data. An empirical analysis of such combinations of\nbootstraped ensembles composed of neural networks, SVMs, and random trees (i.e.\nfrom a standard random forest) illustrates the gains that can be achieved by\nthis heterogeneous ensemble creation method."
    },
    "1611.02512": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wen-Chieh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi-ting"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Cognitive Discriminative Mappings for Rapid Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Humans can learn concepts or recognize items from just a handful of examples,\nwhile machines require many more samples to perform the same task. In this\npaper, we build a computational model to investigate the possibility of this\nkind of rapid learning. The proposed method aims to improve the learning task\nof input from sensory memory by leveraging the information retrieved from\nlong-term memory. We present a simple and intuitive technique called cognitive\ndiscriminative mappings (CDM) to explore the cognitive problem. First, CDM\nseparates and clusters the data instances retrieved from long-term memory into\ndistinct classes with a discrimination method in working memory when a sensory\ninput triggers the algorithm. CDM then maps each sensory data instance to be as\nclose as possible to the median point of the data group with the same class.\nThe experimental results demonstrate that the CDM approach is effective for\nlearning the discriminative features of supervised classifications with few\ntraining sensory input instances."
    },
    "1810.09352": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guidotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ruggieri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Salvatore"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Assessing the Stability of Interpretable Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Interpretable classification models are built with the purpose of providing a\ncomprehensible description of the decision logic to an external oversight\nagent. When considered in isolation, a decision tree, a set of classification\nrules, or a linear model, are widely recognized as human-interpretable.\nHowever, such models are generated as part of a larger analytical process,\nwhich, in particular, comprises data collection and filtering. Selection bias\nin data collection or in data pre-processing may affect the model learned.\nAlthough model induction algorithms are designed to learn to generalize, they\npursue optimization of predictive accuracy. It remains unclear how\ninterpretability is instead impacted. We conduct an experimental analysis to\ninvestigate whether interpretable models are able to cope with data selection\nbias as far as interpretability is concerned."
    },
    "1610.09064": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-12-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lakkaraju",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Himabindu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kamar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ece"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Caruana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rich"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Horvitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Identifying Unknown Unknowns in the Open World: Representations and\n  Policies for Guided Exploration",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in AAAI 2017; Presented at NIPS Workshop on Reliability in\n  ML, 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Predictive models deployed in the real world may assign incorrect labels to\ninstances with high confidence. Such errors or unknown unknowns are rooted in\nmodel incompleteness, and typically arise because of the mismatch between\ntraining data and the cases encountered at test time. As the models are blind\nto such errors, input from an oracle is needed to identify these failures. In\nthis paper, we formulate and address the problem of informed discovery of\nunknown unknowns of any given predictive model where unknown unknowns occur due\nto systematic biases in the training data. We propose a model-agnostic\nmethodology which uses feedback from an oracle to both identify unknown\nunknowns and to intelligently guide the discovery. We employ a two-phase\napproach which first organizes the data into multiple partitions based on the\nfeature similarity of instances and the confidence scores assigned by the\npredictive model, and then utilizes an explore-exploit strategy for discovering\nunknown unknowns across these partitions. We demonstrate the efficacy of our\nframework by varying the underlying causes of unknown unknowns across various\napplications. To the best of our knowledge, this paper presents the first\nalgorithmic approach to the problem of discovering unknown unknowns of\npredictive models."
    },
    "0802.1306": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2008-02-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Pavlovic",
                "http://arxiv.org/OAI/arXiv/:forenames": "Dusko"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Network as a computer: ranking paths to find flows",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI math.CT",
        "http://arxiv.org/OAI/arXiv/:comments": "12 pages, CSR 2008",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.3.3; I.2.4; I.2.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We explore a simple mathematical model of network computation, based on\nMarkov chains. Similar models apply to a broad range of computational\nphenomena, arising in networks of computers, as well as in genetic, and neural\nnets, in social networks, and so on. The main problem of interaction with such\nspontaneously evolving computational systems is that the data are not uniformly\nstructured. An interesting approach is to try to extract the semantical content\nof the data from their distribution among the nodes. A concept is then\nidentified by finding the community of nodes that share it. The task of data\nstructuring is thus reduced to the task of finding the network communities, as\ngroups of nodes that together perform some non-local data processing. Towards\nthis goal, we extend the ranking methods from nodes to paths. This allows us to\nextract some information about the likely flow biases from the available static\ninformation about the network."
    },
    "1612.02136": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Che",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yanran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jacob",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Athul Paul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wenjie"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mode Regularized Generative Adversarial Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "Published as a conference paper at ICLR 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Although Generative Adversarial Networks achieve state-of-the-art results on\na variety of generative tasks, they are regarded as highly unstable and prone\nto miss modes. We argue that these bad behaviors of GANs are due to the very\nparticular functional shape of the trained discriminators in high dimensional\nspaces, which can easily make training stuck or push probability mass in the\nwrong direction, towards that of higher concentration than that of the data\ngenerating distribution. We introduce several ways of regularizing the\nobjective, which can dramatically stabilize the training of GAN models. We also\nshow that our regularizers can help the fair distribution of probability mass\nacross the modes of the data generating distribution, during the early phases\nof training and thus providing a unified solution to the missing modes problem."
    },
    "1803.05859": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oscar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lipson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hod"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Neural Network Quine",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Self-replication is a key aspect of biological life that has been largely\noverlooked in Artificial Intelligence systems. Here we describe how to build\nand train self-replicating neural networks. The network replicates itself by\nlearning to output its own weights. The network is designed using a loss\nfunction that can be optimized with either gradient-based or non-gradient-based\nmethods. We also describe a method we call regeneration to train the network\nwithout explicit optimization, by injecting the network with predictions of its\nown parameters. The best solution for a self-replicating network was found by\nalternating between regeneration and optimization steps. Finally, we describe a\ndesign for a self-replicating neural network that can solve an auxiliary task\nsuch as MNIST image classification. We observe that there is a trade-off\nbetween the network's ability to classify images and its ability to replicate,\nbut training is biased towards increasing its specialization at image\nclassification at the expense of replication. This is analogous to the\ntrade-off between reproduction and other tasks observed in nature. We suggest\nthat a self-replication mechanism for artificial intelligence is useful because\nit introduces the possibility of continual improvement through natural\nselection."
    },
    "1704.06885": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                "http://arxiv.org/OAI/arXiv/:forenames": "Hong"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "A General Theory for Training Learning Machine",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "55 pages, 18 figures. arXiv admin note: substantial text overlap with\n  arXiv:1602.03950",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Though the deep learning is pushing the machine learning to a new stage,\nbasic theories of machine learning are still limited. The principle of\nlearning, the role of the a prior knowledge, the role of neuron bias, and the\nbasis for choosing neural transfer function and cost function, etc., are still\nfar from clear. In this paper, we present a general theoretical framework for\nmachine learning. We classify the prior knowledge into common and\nproblem-dependent parts, and consider that the aim of learning is to maximally\nincorporate them. The principle we suggested for maximizing the former is the\ndesign risk minimization principle, while the neural transfer function, the\ncost function, as well as pretreatment of samples, are endowed with the role\nfor maximizing the latter. The role of the neuron bias is explained from a\ndifferent angle. We develop a Monte Carlo algorithm to establish the\ninput-output responses, and we control the input-output sensitivity of a\nlearning machine by controlling that of individual neurons. Applications of\nfunction approaching and smoothing, pattern recognition and classification, are\nprovided to illustrate how to train general learning machines based on our\ntheory and algorithm. Our method may in addition induce new applications, such\nas the transductive inference."
    },
    "1306.5601": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-06-24",
        "http://arxiv.org/OAI/arXiv/:updated": "2013-08-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "M\u00fchlenthaler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moritz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wanka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rolf"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Decomposition of the Max-min Fair Curriculum-based Course Timetabling\n  Problem",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "revised version (fixed problems in the notation and general\n  improvements); original paper: 16 pages, accepted for publication at the\n  Multidisciplinary International Scheduling Conference 2013 (MISTA 2013)",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.8; F.2.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a decomposition of the max-min fair curriculum-based course\ntimetabling (MMF-CB-CTT) problem. The decomposition models the room assignment\nsubproblem as a generalized lexicographic bottleneck optimization problem\n(LBOP). We show that the generalized LBOP can be solved efficiently if the\ncorresponding sum optimization problem can be solved efficiently. As a\nconsequence, the room assignment subproblem of the MMF-CB-CTT problem can be\nsolved efficiently. We use this insight to improve a previously proposed\nheuristic algorithm for the MMF-CB-CTT problem. Our experimental results\nindicate that using the new decomposition improves the performance of the\nalgorithm on most of the 21 ITC2007 test instances with respect to the quality\nof the best solution found. Furthermore, we introduce a measure of the quality\nof a solution to a max-min fair optimization problem. This measure helps to\novercome some limitations imposed by the qualitative nature of max-min fairness\nand aids the statistical evaluation of the performance of randomized algorithms\nfor such problems. We use this measure to show that using the new decomposition\nthe algorithm outperforms the original one on most instances with respect to\nthe average solution quality."
    },
    "1412.5244": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-12-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yujia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Swersky",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zemel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning unbiased features",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Published in NIPS 2014 Workshop on Transfer and Multitask Learning,\n  see http://nips.cc/Conferences/2014/Program/event.php?ID=4282",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A key element in transfer learning is representation learning; if\nrepresentations can be developed that expose the relevant factors underlying\nthe data, then new tasks and domains can be learned readily based on mappings\nof these salient factors. We propose that an important aim for these\nrepresentations are to be unbiased. Different forms of representation learning\ncan be derived from alternative definitions of unwanted bias, e.g., bias to\nparticular tasks, domains, or irrelevant underlying data dimensions. One very\nuseful approach to estimating the amount of bias in a representation comes from\nmaximum mean discrepancy (MMD) [5], a measure of distance between probability\ndistributions. We are not the first to suggest that MMD can be a useful\ncriterion in developing representations that apply across multiple domains or\ntasks [1]. However, in this paper we describe a number of novel applications of\nthis criterion that we have devised, all based on the idea of developing\nunbiased representations. These formulations include: a standard domain\nadaptation framework; a method of learning invariant representations; an\napproach based on noise-insensitive autoencoders; and a novel form of\ngenerative model."
    },
    "1109.2156": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-09-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fern",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Givan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yoon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Approximate Policy Iteration with a Policy Language Bias: Solving\n  Relational Markov Decision Processes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 25, pages\n  75-118, 2006",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.1700",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study an approach to policy selection for large relational Markov Decision\nProcesses (MDPs). We consider a variant of approximate policy iteration (API)\nthat replaces the usual value-function learning step with a learning step in\npolicy space. This is advantageous in domains where good policies are easier to\nrepresent and learn than the corresponding value functions, which is often the\ncase for the relational MDPs we are interested in. In order to apply API to\nsuch problems, we introduce a relational policy language and corresponding\nlearner. In addition, we introduce a new bootstrapping routine for goal-based\nplanning domains, based on random walks. Such bootstrapping is necessary for\nmany large relational MDPs, where reward is extremely sparse, as API is\nineffective in such domains when initialized with an uninformed policy. Our\nexperiments show that the resulting system is able to find good policies for a\nnumber of classical planning domains and their stochastic variants by solving\nthem as extremely large relational MDPs. The experiments also point to some\nlimitations of our approach, suggesting future work."
    },
    "1606.08808": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Miao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsoi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ah Chung"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adaptive Training of Random Mapping for Data Quantization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "6 pages, 5 figures, 15.8",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Data quantization learns encoding results of data with certain requirements,\nand provides a broad perspective of many real-world applications to data\nhandling. Nevertheless, the results of encoder is usually limited to\nmultivariate inputs with the random mapping, and side information of binary\ncodes are hardly to mostly depict the original data patterns as possible. In\nthe literature, cosine based random quantization has attracted much attentions\ndue to its intrinsic bounded results. Nevertheless, it usually suffers from the\nuncertain outputs, and information of original data fails to be fully preserved\nin the reduced codes. In this work, a novel binary embedding method, termed\nadaptive training quantization (ATQ), is proposed to learn the ideal transform\nof random encoder, where the limitation of cosine random mapping is tackled. As\nan adaptive learning idea, the reduced mapping is adaptively calculated with\nidea of data group, while the bias of random transform is to be improved to\nhold most matching information. Experimental results show that the proposed\nmethod is able to obtain outstanding performance compared with other random\nquantization methods."
    },
    "1609.06492": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-09-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brodic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Darko"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amelio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Milivojevic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zoran N."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jevtic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Milena"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Document Image Coding and Clustering for Script Discrimination",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 4 figures, 2 tables",
        "http://arxiv.org/OAI/arXiv/:msc-class": "97R40, 62H35, 68U15, 68T50,",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "ICIC Express Letters Vol. 10 n. 7 July 2016 pp. 1561-1566",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The paper introduces a new method for discrimination of documents given in\ndifferent scripts. The document is mapped into a uniformly coded text of\nnumerical values. It is derived from the position of the letters in the text\nline, based on their typographical characteristics. Each code is considered as\na gray level. Accordingly, the coded text determines a 1-D image, on which\ntexture analysis by run-length statistics and local binary pattern is\nperformed. It defines feature vectors representing the script content of the\ndocument. A modified clustering approach employed on document feature vector\ngroups documents written in the same script. Experimentation performed on two\ncustom oriented databases of historical documents in old Cyrillic, angular and\nround Glagolitic as well as Antiqua and Fraktur scripts demonstrates the\nsuperiority of the proposed method with respect to well-known methods in the\nstate-of-the-art."
    },
    "1801.07593": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brian Hu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lemoine",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Blake"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mitchell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Margaret"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mitigating Unwanted Biases with Adversarial Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning is a tool for building models that accurately represent\ninput training data. When undesired biases concerning demographic groups are in\nthe training data, well-trained models will reflect those biases. We present a\nframework for mitigating such biases by including a variable for the group of\ninterest and simultaneously learning a predictor and an adversary. The input to\nthe network X, here text or census data, produces a prediction Y, such as an\nanalogy completion or income bracket, while the adversary tries to model a\nprotected variable Z, here gender or zip code.\n  The objective is to maximize the predictor's ability to predict Y while\nminimizing the adversary's ability to predict Z. Applied to analogy completion,\nthis method results in accurate predictions that exhibit less evidence of\nstereotyping Z. When applied to a classification task using the UCI Adult\n(Census) Dataset, it results in a predictive model that does not lose much\naccuracy while achieving very close to equality of odds (Hardt, et al., 2016).\nThe method is flexible and applicable to multiple definitions of fairness as\nwell as a wide range of gradient-based learning models, including both\nregression and classification tasks."
    },
    "1701.03868": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-01-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Hansen",
                "http://arxiv.org/OAI/arXiv/:forenames": "Steven Stenberg"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Minimally Naturalistic Artificial Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted into the NIPS 2016 Workshop on Machine Intelligence\n  (M.A.I.N.)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The rapid advancement of machine learning techniques has re-energized\nresearch into general artificial intelligence. While the idea of\ndomain-agnostic meta-learning is appealing, this emerging field must come to\nterms with its relationship to human cognition and the statistics and structure\nof the tasks humans perform. The position of this article is that only by\naligning our agents' abilities and environments with those of humans do we\nstand a chance at developing general artificial intelligence (GAI). A broad\nreading of the famous 'No Free Lunch' theorem is that there is no universally\noptimal inductive bias or, equivalently, bias-free learning is impossible. This\nfollows from the fact that there are an infinite number of ways to extrapolate\ndata, any of which might be the one used by the data generating environment; an\ninductive bias prefers some of these extrapolations to others, which lowers\nperformance in environments using these adversarial extrapolations. We may\nposit that the optimal GAI is the one that maximally exploits the statistics of\nits environment to create its inductive bias; accepting the fact that this\nagent is guaranteed to be extremely sub-optimal for some alternative\nenvironments. This trade-off appears benign when thinking about the environment\nas being the physical universe, as performance on any fictive universe is\nobviously irrelevant. But, we should expect a sharper inductive bias if we\nfurther constrain our environment. Indeed, we implicitly do so by defining GAI\nin terms of accomplishing that humans consider useful. One common version of\nthis is need the for 'common-sense reasoning', which implicitly appeals to the\nstatistics of physical universe as perceived by humans."
    },
    "1810.06033": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xutan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shanghang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianxin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lihong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Hierarchical Attention Networks for Knowledge Base Completion via Joint\n  Adversarial Training",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Knowledge Base (KB) completion, which aims to determine missing relation\nbetween entities, has raised increasing attention in recent years. Most\nexisting methods either focus on the positional relationship between entity\npair and single relation (1-hop path) in semantic space or concentrate on the\njoint probability of Random Walks on multi-hop paths among entities. However,\nthey do not fully consider the intrinsic relationships of all the links among\nentities. By observing that the single relation and multi-hop paths between the\nsame entity pair generally contain shared/similar semantic information, this\npaper proposes a novel method to capture the shared features between them as\nthe basis for inferring missing relations. To capture the shared features\njointly, we develop Hierarchical Attention Networks (HANs) to automatically\nencode the inputs into low-dimensional vectors, and exploit two partial\nparameter-shared components, one for feature source discrimination and the\nother for determining missing relations. By joint Adversarial Training (AT) the\nentire model, our method minimizes the classification error of missing\nrelations, and ensures the source of shared features are difficult to\ndiscriminate in the meantime. The AT mechanism encourages our model to extract\nfeatures that are both discriminative for missing relation prediction and\nshareable between single relation and multi-hop paths. We extensively evaluate\nour method on several large-scale KBs for relation completion. Experimental\nresults show that our method consistently outperforms the baseline approaches.\nIn addition, the hierarchical attention mechanism and the feature extractor in\nour model can be well interpreted and utilized in the related downstream tasks."
    },
    "1612.05299": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Ridgeway",
                "http://arxiv.org/OAI/arXiv/:forenames": "Karl"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Survey of Inductive Biases for Factorial Representation-Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "With the resurgence of interest in neural networks, representation learning\nhas re-emerged as a central focus in artificial intelligence. Representation\nlearning refers to the discovery of useful encodings of data that make\ndomain-relevant information explicit. Factorial representations identify\nunderlying independent causal factors of variation in data. A factorial\nrepresentation is compact and faithful, makes the causal factors explicit, and\nfacilitates human interpretation of data. Factorial representations support a\nvariety of applications, including the generation of novel examples, indexing\nand search, novelty detection, and transfer learning.\n  This article surveys various constraints that encourage a learning algorithm\nto discover factorial representations. I dichotomize the constraints in terms\nof unsupervised and supervised inductive bias. Unsupervised inductive biases\nexploit assumptions about the environment, such as the statistical distribution\nof factor coefficients, assumptions about the perturbations a factor should be\ninvariant to (e.g. a representation of an object can be invariant to rotation,\ntranslation or scaling), and assumptions about how factors are combined to\nsynthesize an observation. Supervised inductive biases are constraints on the\nrepresentations based on additional information connected to observations.\nSupervisory labels come in variety of types, which vary in how strongly they\nconstrain the representation, how many factors are labeled, how many\nobservations are labeled, and whether or not we know the associations between\nthe constraints and the factors they are related to.\n  This survey brings together a wide variety of models that all touch on the\nproblem of learning factorial representations and lays out a framework for\ncomparing these models based on the strengths of the underlying supervised and\nunsupervised inductive biases."
    },
    "1806.05337": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chandan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Murdoch",
                    "http://arxiv.org/OAI/arXiv/:forenames": "W. James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Hierarchical interpretations for neural network predictions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "main text: 8 pages, references: 2 pages, supplement: 13 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks (DNNs) have achieved impressive predictive performance\ndue to their ability to learn complex, non-linear relationships between\nvariables. However, the inability to effectively visualize these relationships\nhas led to DNNs being characterized as black boxes and consequently limited\ntheir applications. To ameliorate this problem, we introduce the use of\nhierarchical interpretations to explain DNN predictions through our proposed\nmethod, agglomerative contextual decomposition (ACD). Given a prediction from a\ntrained DNN, ACD produces a hierarchical clustering of the input features,\nalong with the contribution of each cluster to the final prediction. This\nhierarchy is optimized to identify clusters of features that the DNN learned\nare predictive. Using examples from Stanford Sentiment Treebank and ImageNet,\nwe show that ACD is effective at diagnosing incorrect predictions and\nidentifying dataset bias. Through human experiments, we demonstrate that ACD\nenables users both to identify the more accurate of two DNNs and to better\ntrust a DNN's outputs. We also find that ACD's hierarchy is largely robust to\nadversarial perturbations, implying that it captures fundamental aspects of the\ninput and ignores spurious noise."
    },
    "1211.2399": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-11-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Tagiew",
                "http://arxiv.org/OAI/arXiv/:forenames": "Rustam"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mining Determinism in Human Strategic Behavior",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, no figures, EEML 2012",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Experimental Economics and Machine Learning 2012, CEUR-WS Vol-870,\n  urn:nbn:de:0074-870-0",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This work lies in the fusion of experimental economics and data mining. It\ncontinues author's previous work on mining behaviour rules of human subjects\nfrom experimental data, where game-theoretic predictions partially fail to\nwork. Game-theoretic predictions aka equilibria only tend to success with\nexperienced subjects on specific games, what is rarely given. Apart from game\ntheory, contemporary experimental economics offers a number of alternative\nmodels. In relevant literature, these models are always biased by psychological\nand near-psychological theories and are claimed to be proven by the data. This\nwork introduces a data mining approach to the problem without using vast\npsychological background. Apart from determinism, no other biases are regarded.\nTwo datasets from different human subject experiments are taken for evaluation.\nThe first one is a repeated mixed strategy zero sum game and the second -\nrepeated ultimatum game. As result, the way of mining deterministic\nregularities in human strategic behaviour is described and evaluated. As future\nwork, the design of a new representation formalism is discussed."
    },
    "1809.04737": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongkai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xintao"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness-aware Classification: Criterion, Convexity, and Bounds",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fairness-aware classification is receiving increasing attention in the\nmachine learning fields. Recently research proposes to formulate the\nfairness-aware classification as constrained optimization problems. However,\nseveral limitations exist in previous works due to the lack of a theoretical\nframework for guiding the formulation. In this paper, we propose a general\nframework for learning fair classifiers which addresses previous limitations.\nThe framework formulates various commonly-used fairness metrics as convex\nconstraints that can be directly incorporated into classic classification\nmodels. Within the framework, we propose a constraint-free criterion on the\ntraining data which ensures that any classifier learned from the data is fair.\nWe also derive the constraints which ensure that the real fairness metric is\nsatisfied when surrogate functions are used to achieve convexity. Our framework\ncan be used to for formulating fairness-aware classification with fairness\nguarantee and computational efficiency. The experiments using real-world\ndatasets demonstrate our theoretical results and show the effectiveness of\nproposed framework and methods."
    },
    "1804.05184": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saeed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Muhammad Rizwan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chelmis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charalampos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Prasanna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Viktor K."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Not all Embeddings are created Equal: Extracting Entity-specific\n  Substructures for RDF Graph Embedding",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Knowledge Graphs (KGs) are becoming essential to information systems that\nrequire access to structured data. Several approaches have been recently\nproposed, for obtaining vector representations of KGs suitable for Machine\nLearning tasks, based on identifying and extracting relevant graph\nsubstructures using uniform and biased random walks. However, such approaches\nlead to representations comprising mostly \"popular\", instead of \"relevant\",\nentities in the KG. In KGs, in which different types of entities often exist\n(such as in Linked Open Data), a given target entity may have its own distinct\nset of most \"relevant\" nodes and edges. We propose specificity as an accurate\nmeasure of identifying most relevant, entity-specific, nodes and edges. We\ndevelop a scalable method based on bidirectional random walks to compute\nspecificity. Our experimental evaluation results show that specificity-based\nbiased random walks extract more \"meaningful\" (in terms of size and relevance)\nRDF substructures compared to the state-of-the-art and, the graph embedding\nlearned from the extracted substructures, outperform existing techniques in the\ntask of entity recommendation in DBpedia."
    },
    "1807.11367": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Oh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hoon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Procaccia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ariel D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Suksompong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Warut"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairly Allocating Many Goods with Few Queries",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI cs.MA",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We investigate the query complexity of the fair allocation of indivisible\ngoods. For two agents with arbitrary monotonic valuations, we design an\nalgorithm that computes an allocation satisfying envy-freeness up to one good\n(EF1), a relaxation of envy-freeness, using a logarithmic number of queries. We\nshow that the logarithmic query complexity bound also holds for three agents\nwith additive valuations. These results suggest that it is possible to fairly\nallocate goods in practice even when the number of goods is extremely large. By\ncontrast, we prove that computing an allocation satisfying envy-freeness and\nanother of its relaxations, envy-freeness up to any good (EFX), requires a\nlinear number of queries even when there are only two agents with identical\nadditive valuations."
    },
    "1802.08254": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wanling"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianfeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Luo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chunjie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daoyi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ren",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jingwei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shujie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haoning"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "BigDataBench: A Dwarf-based Big Data and AI Benchmark Suite",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DC cs.AI cs.PF",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages, 10 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As architecture, system, data management, and machine learning communities\npay greater attention to innovative big data and data-driven artificial\nintelligence (in short, AI) algorithms, architecture, and systems, the pressure\nof benchmarking rises. However, complexity, diversity, frequently changed\nworkloads, and rapid evolution of big data, especially AI systems raise great\nchallenges in benchmarking. First, for the sake of conciseness, benchmarking\nscalability, portability cost, reproducibility, and better interpretation of\nperformance data, we need understand what are the abstractions of\nfrequently-appearing units of computation, which we call dwarfs, among big data\nand AI workloads. Second, for the sake of fairness, the benchmarks must include\ndiversity of data and workloads. Third, for co-design of software and hardware,\nthe benchmarks should be consistent across different communities. Other than\ncreating a new benchmark or proxy for every possible workload, we propose using\ndwarf-based benchmarks--the combination of eight dwarfs--to represent diversity\nof big data and AI workloads. The current version--BigDataBench 4.0 provides 13\nrepresentative real-world data sets and 47 big data and AI benchmarks,\nincluding seven workload types: online service, offline analytics, graph\nanalytics, AI, data warehouse, NoSQL, and streaming. BigDataBench 4.0 is\npublicly available from http://prof.ict.ac.cn/BigDataBench. Also, for the first\ntime, we comprehensively characterize the benchmarks of seven workload types in\nBigDataBench 4.0 in addition to traditional benchmarks like SPECCPU, PARSEC and\nHPCC in a hierarchical manner and drill down on five levels, using the Top-Down\nanalysis from an architecture perspective."
    },
    "1802.02209": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Changhao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoxuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Markham",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Trigoni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Niki"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "IONet: Learning to Cure the Curse of Drift in Inertial Odometry",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in AAAI18 (Oral)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Inertial sensors play a pivotal role in indoor localization, which in turn\nlays the foundation for pervasive personal applications. However, low-cost\ninertial sensors, as commonly found in smartphones, are plagued by bias and\nnoise, which leads to unbounded growth in error when accelerations are double\nintegrated to obtain displacement. Small errors in state estimation propagate\nto make odometry virtually unusable in a matter of seconds. We propose to break\nthe cycle of continuous integration, and instead segment inertial data into\nindependent windows. The challenge becomes estimating the latent states of each\nwindow, such as velocity and orientation, as these are not directly observable\nfrom sensor data. We demonstrate how to formulate this as an optimization\nproblem, and show how deep recurrent neural networks can yield highly accurate\ntrajectories, outperforming state-of-the-art shallow techniques, on a wide\nrange of tests and attachments. In particular, we demonstrate that IONet can\ngeneralize to estimate odometry for non-periodic motion, such as a shopping\ntrolley or baby-stroller, an extremely challenging task for existing\ntechniques."
    },
    "1705.09558": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saatchi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Gordon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian GAN",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Updated to the version that appears at Advances in Neural Information\n  Processing Systems 30 (NIPS), 2017",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Generative adversarial networks (GANs) can implicitly learn rich\ndistributions over images, audio, and data which are hard to model with an\nexplicit likelihood. We present a practical Bayesian formulation for\nunsupervised and semi-supervised learning with GANs. Within this framework, we\nuse stochastic gradient Hamiltonian Monte Carlo to marginalize the weights of\nthe generator and discriminator networks. The resulting approach is\nstraightforward and obtains good performance without any standard interventions\nsuch as feature matching, or mini-batch discrimination. By exploring an\nexpressive posterior over the parameters of the generator, the Bayesian GAN\navoids mode-collapse, produces interpretable and diverse candidate samples, and\nprovides state-of-the-art quantitative results for semi-supervised learning on\nbenchmarks including SVHN, CelebA, and CIFAR-10, outperforming DCGAN,\nWasserstein GANs, and DCGAN ensembles."
    },
    "1805.08966": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramakrishnan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kamar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ece"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Debadeepta"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shah",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Horvitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Discovering Blind Spots in Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear at AAMAS 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Agents trained in simulation may make errors in the real world due to\nmismatches between training and execution environments. These mistakes can be\ndangerous and difficult to discover because the agent cannot predict them a\npriori. We propose using oracle feedback to learn a predictive model of these\nblind spots to reduce costly errors in real-world applications. We focus on\nblind spots in reinforcement learning (RL) that occur due to incomplete state\nrepresentation: The agent does not have the appropriate features to represent\nthe true state of the world and thus cannot distinguish among numerous states.\nWe formalize the problem of discovering blind spots in RL as a noisy supervised\nlearning problem with class imbalance. We learn models to predict blind spots\nin unseen regions of the state space by combining techniques for label\naggregation, calibration, and supervised learning. The models take into\nconsideration noise emerging from different forms of oracle feedback, including\ndemonstrations and corrections. We evaluate our approach on two domains and\nshow that it achieves higher predictive performance than baseline methods, and\nthat the learned model can be used to selectively query an oracle at execution\ntime to prevent errors. We also empirically analyze the biases of various\nfeedback types and how they influence the discovery of blind spots."
    },
    "1703.00760": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Roy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Papadopoulos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexandre"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pachet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fran\u00e7ois"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Sampling Variations of Lead Sheets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages, 11 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine-learning techniques have been recently used with spectacular results\nto generate artefacts such as music or text. However, these techniques are\nstill unable to capture and generate artefacts that are convincingly\nstructured. In this paper we present an approach to generate structured musical\nsequences. We introduce a mechanism for sampling efficiently variations of\nmusical sequences. Given a input sequence and a statistical model, this\nmechanism samples a set of sequences whose distance to the input sequence is\napproximately within specified bounds. This mechanism is implemented as an\nextension of belief propagation, and uses local fields to bias the generation.\nWe show experimentally that sampled sequences are indeed closely correlated to\nthe standard musical similarity measure defined by Mongeau and Sankoff. We then\nshow how this mechanism can used to implement composition strategies that\nenforce arbitrary structure on a musical lead sheet generation problem."
    },
    "1611.02315": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-06-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Charikar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moses"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Steinhardt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jacob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Valiant",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gregory"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning from Untrusted Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CC cs.CR math.ST stat.TH",
        "http://arxiv.org/OAI/arXiv/:comments": "Updated based on STOC camera-ready",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The vast majority of theoretical results in machine learning and statistics\nassume that the available training data is a reasonably reliable reflection of\nthe phenomena to be learned or estimated. Similarly, the majority of machine\nlearning and statistical techniques used in practice are brittle to the\npresence of large amounts of biased or malicious data. In this work we consider\ntwo frameworks in which to study estimation, learning, and optimization in the\npresence of significant fractions of arbitrary data.\n  The first framework, list-decodable learning, asks whether it is possible to\nreturn a list of answers, with the guarantee that at least one of them is\naccurate. For example, given a dataset of $n$ points for which an unknown\nsubset of $\\alpha n$ points are drawn from a distribution of interest, and no\nassumptions are made about the remaining $(1-\\alpha)n$ points, is it possible\nto return a list of $\\operatorname{poly}(1/\\alpha)$ answers, one of which is\ncorrect? The second framework, which we term the semi-verified learning model,\nconsiders the extent to which a small dataset of trusted data (drawn from the\ndistribution in question) can be leveraged to enable the accurate extraction of\ninformation from a much larger but untrusted dataset (of which only an\n$\\alpha$-fraction is drawn from the distribution).\n  We show strong positive results in both settings, and provide an algorithm\nfor robust learning in a very general stochastic optimization setting. This\ngeneral result has immediate implications for robust estimation in a number of\nsettings, including for robustly estimating the mean of distributions with\nbounded second moments, robustly learning mixtures of such distributions, and\nrobustly finding planted partitions in random graphs in which significant\nportions of the graph have been perturbed by an adversary."
    },
    "1712.00193": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ryu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hee Jung"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mitchell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Margaret"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Adam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hartwig"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving Smiling Detection with Race and Gender Diversity",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent progress in deep learning has been accompanied by a growing concern\nfor whether models are fair for users, with equally good performance across\ndifferent demographics. In computer vision research, such questions are\nrelevant to face detection and the related task of face attribute detection,\namong others. We measure race and gender inclusion in the context of smiling\ndetection, and introduce a method for improving smiling detection across\ndemographic groups. Our method introduces several modifications over existing\ndetection methods, leveraging twofold transfer learning to better model facial\ndiversity. Results show that this technique improves accuracy against strong\nbaselines for most demographic groups as well as overall. Our best-performing\nmodel defines a new state-of-the-art for smiling detection, reaching 91% on the\nFaces of the World dataset. The accompanying multi-head diversity classifier\nalso defines a new state-of-the-art for gender classification, reaching 93.87%\non the Faces of the World dataset. This research demonstrates the utility of\nmodeling race and gender to improve a face attribute detection task, using a\ntwofold transfer learning framework that allows for privacy towards individuals\nin a target dataset."
    },
    "1507.01269": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-07-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianpei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nasrabadi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nasser M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hero",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alfred O.",
                    "http://arxiv.org/OAI/arXiv/:suffix": "III"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semi-supervised Multi-sensor Classification via Consensus-based\n  Multi-View Maximum Entropy Discrimination",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IT cs.AI cs.LG math.IT",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 4 figures, Accepted in 40th IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP 15)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ICASSP.2015.7178308",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we consider multi-sensor classification when there is a large\nnumber of unlabeled samples. The problem is formulated under the multi-view\nlearning framework and a Consensus-based Multi-View Maximum Entropy\nDiscrimination (CMV-MED) algorithm is proposed. By iteratively maximizing the\nstochastic agreement between multiple classifiers on the unlabeled dataset, the\nalgorithm simultaneously learns multiple high accuracy classifiers. We\ndemonstrate that our proposed method can yield improved performance over\nprevious multi-view learning approaches by comparing performance on three real\nmulti-sensor data sets."
    },
    "1407.7008": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-07-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-12-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Santis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Enrico"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Livi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lorenzo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sadeghian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alireza"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rizzi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonello"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling and Recognition of Smart Grid Faults by a Combined Approach of\n  Dissimilarity Learning and One-Class Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6; K.3.2",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.neucom.2015.05.112",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Detecting faults in electrical power grids is of paramount importance, either\nfrom the electricity operator and consumer viewpoints. Modern electric power\ngrids (smart grids) are equipped with smart sensors that allow to gather\nreal-time information regarding the physical status of all the component\nelements belonging to the whole infrastructure (e.g., cables and related\ninsulation, transformers, breakers and so on). In real-world smart grid\nsystems, usually, additional information that are related to the operational\nstatus of the grid itself are collected such as meteorological information.\nDesigning a suitable recognition (discrimination) model of faults in a\nreal-world smart grid system is hence a challenging task. This follows from the\nheterogeneity of the information that actually determine a typical fault\ncondition. The second point is that, for synthesizing a recognition model, in\npractice only the conditions of observed faults are usually meaningful.\nTherefore, a suitable recognition model should be synthesized by making use of\nthe observed fault conditions only. In this paper, we deal with the problem of\nmodeling and recognizing faults in a real-world smart grid system, which\nsupplies the entire city of Rome, Italy. Recognition of faults is addressed by\nfollowing a combined approach of multiple dissimilarity measures customization\nand one-class classification techniques. We provide here an in-depth study\nrelated to the available data and to the models synthesized by the proposed\none-class classifier. We offer also a comprehensive analysis of the fault\nrecognition results by exploiting a fuzzy set based reliability decision rule."
    },
    "1510.00552": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-10-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bonchi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hajian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sara"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mishra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bud"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramazzotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniele"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Exposing the Probabilistic Causal Structure of Discrimination",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DB cs.AI",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s41060-016-0040-z",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Discrimination discovery from data is an important task aiming at identifying\npatterns of illegal and unethical discriminatory activities against\nprotected-by-law groups, e.g., ethnic minorities. While any legally-valid proof\nof discrimination requires evidence of causality, the state-of-the-art methods\nare essentially correlation-based, albeit, as it is well known, correlation\ndoes not imply causation.\n  In this paper we take a principled causal approach to the data mining problem\nof discrimination detection in databases. Following Suppes' probabilistic\ncausation theory, we define a method to extract, from a dataset of historical\ndecision records, the causal structures existing among the attributes in the\ndata. The result is a type of constrained Bayesian network, which we dub\nSuppes-Bayes Causal Network (SBCN). Next, we develop a toolkit of methods based\non random walks on top of the SBCN, addressing different anti-discrimination\nlegal concepts, such as direct and indirect discrimination, group and\nindividual discrimination, genuine requirement, and favoritism. Our experiments\non real-world datasets confirm the inferential power of our approach in all\nthese different tasks."
    },
    "1811.00458": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Di"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gomes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carla P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bias Reduction via End-to-End Shift Learning: Application to Citizen\n  Science",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Citizen science projects are successful at gathering rich datasets for\nvarious applications. Nevertheless, the data collected by the citizen\nscientists are often biased, more aligned with the citizens' preferences rather\nthan scientific objectives. We propose the Shift Compensation Network (SCN), an\nend-to-end learning scheme which learns the shift from the scientific\nobjectives to the biased data, while compensating the shift by re-weighting the\ntraining data. Applied to bird observational data from the citizen science\nproject \\textit{eBird}, we demonstrate how SCN quantifies the data distribution\nshift as well as outperforms supervised learning models that do not address the\ndata bias. Compared with other competing models in the context of covariate\nshift, we further demonstrate the advantage of SCN in both the effectiveness\nand the capability of handling massive high-dimensional data."
    },
    "1807.01798": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nguyen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Duc Minh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsiligianni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Evaggelia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Calderbank",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Deligiannis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nikos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Regularizing Autoencoder-Based Matrix Completion Models via Manifold\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, Eusipco 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Autoencoders are popular among neural-network-based matrix completion models\ndue to their ability to retrieve potential latent factors from the partially\nobserved matrices. Nevertheless, when training data is scarce their performance\nis significantly degraded due to overfitting. In this paper, we mit- igate\noverfitting with a data-dependent regularization technique that relies on the\nprinciples of multi-task learning. Specifically, we propose an\nautoencoder-based matrix completion model that performs prediction of the\nunknown matrix values as a main task, and manifold learning as an auxiliary\ntask. The latter acts as an inductive bias, leading to solutions that\ngeneralize better. The proposed model outperforms the existing\nautoencoder-based models designed for matrix completion, achieving high\nreconstruction accuracy in well-known datasets."
    },
    "1511.05493": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-11-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yujia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tarlow",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brockschmidt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marc"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zemel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Gated Graph Sequence Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Published as a conference paper in ICLR 2016. Fixed a typo",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Graph-structured data appears frequently in domains including chemistry,\nnatural language semantics, social networks, and knowledge bases. In this work,\nwe study feature learning techniques for graph-structured inputs. Our starting\npoint is previous work on Graph Neural Networks (Scarselli et al., 2009), which\nwe modify to use gated recurrent units and modern optimization techniques and\nthen extend to output sequences. The result is a flexible and broadly useful\nclass of neural network models that has favorable inductive biases relative to\npurely sequence-based models (e.g., LSTMs) when the problem is\ngraph-structured. We demonstrate the capabilities on some simple AI (bAbI) and\ngraph algorithm learning tasks. We then show it achieves state-of-the-art\nperformance on a problem from program verification, in which subgraphs need to\nbe matched to abstract data structures."
    },
    "1804.02969": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kliegr",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom\u00e1\u0161"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bahn\u00edk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "\u0160t\u011bp\u00e1n"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "F\u00fcrnkranz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Johannes"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A review of possible effects of cognitive biases on interpretation of\n  rule-based machine learning models",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper investigates to what extent do cognitive biases affect human\nunderstanding of interpretable machine learning models, in particular of rules\ndiscovered from data. Twenty cognitive biases (illusions, effects) are covered,\nas are possibly effective debiasing techniques that can be adopted by designers\nof machine learning algorithms and software. While there seems no universal\napproach for eliminating all the identified cognitive biases, it follows from\nour analysis that the effect of most biases can be ameliorated by making\nrule-based models more concise. Due to lack of previous research, our review\ntransfers general results obtained in cognitive psychology to the domain of\nmachine learning. It needs to be succeeded by empirical studies specifically\naimed at the machine learning domain."
    },
    "1809.02070": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lanka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameera"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianfu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience\n  Replay",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Experience replay is an important technique for addressing\nsample-inefficiency in deep reinforcement learning (RL), but faces difficulty\nin learning from binary and sparse rewards due to disproportionately few\nsuccessful experiences in the replay buffer. Hindsight experience replay (HER)\nwas recently proposed to tackle this difficulty by manipulating unsuccessful\ntransitions, but in doing so, HER introduces a significant bias in the replay\nbuffer experiences and therefore achieves a suboptimal improvement in\nsample-efficiency. In this paper, we present an analysis on the source of bias\nin HER, and propose a simple and effective method to counter the bias, to most\neffectively harness the sample-efficiency provided by HER. Our method,\nmotivated by counter-factual reasoning and called ARCHER, extends HER with a\ntrade-off to make rewards calculated for hindsight experiences numerically\ngreater than real rewards. We validate our algorithm on two continuous control\nenvironments from DeepMind Control Suite - Reacher and Finger, which simulate\nmanipulation tasks with a robotic arm - in combination with various reward\nfunctions, task complexities and goal sampling strategies. Our experiments\nconsistently demonstrate that countering bias using more aggressive hindsight\nrewards increases sample efficiency, thus establishing the greater benefit of\nARCHER in RL applications with limited computing budget."
    },
    "1810.08647": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jaques",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Natasha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lazaridou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Angeliki"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hughes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gulcehre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Caglar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ortega",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pedro A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Strouse",
                    "http://arxiv.org/OAI/arXiv/:forenames": "DJ"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Leibo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joel Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "de Freitas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nando"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Intrinsic Social Motivation via Causal Influence in Multi-Agent RL",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.MA stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We derive a new intrinsic social motivation for multi-agent reinforcement\nlearning (MARL), in which agents are rewarded for having causal influence over\nanother agent's actions. Causal influence is assessed using counterfactual\nreasoning. The reward does not depend on observing another agent's reward\nfunction, and is thus a more realistic approach to MARL than taken in previous\nwork. We show that the causal influence reward is related to maximizing the\nmutual information between agents' actions. We test the approach in challenging\nsocial dilemma environments, where it consistently leads to enhanced\ncooperation between agents and higher collective reward. Moreover, we find that\nrewarding influence can lead agents to develop emergent communication\nprotocols. We therefore employ influence to train agents to use an explicit\ncommunication channel, and find that it leads to more effective communication\nand higher collective reward. Finally, we show that influence can be computed\nby equipping each agent with an internal model that predicts the actions of\nother agents. This allows the social influence reward to be computed without\nthe use of a centralised controller, and as such represents a significantly\nmore general and scalable inductive bias for MARL with independent agents."
    },
    "1512.05832": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-12-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Evans",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Owain"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stuhlmueller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goodman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Noah D."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning the Preferences of Ignorant, Inconsistent Agents",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "AAAI 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "An important use of machine learning is to learn what people value. What\nposts or photos should a user be shown? Which jobs or activities would a person\nfind rewarding? In each case, observations of people's past choices can inform\nour inferences about their likes and preferences. If we assume that choices are\napproximately optimal according to some utility function, we can treat\npreference inference as Bayesian inverse planning. That is, given a prior on\nutility functions and some observed choices, we invert an optimal\ndecision-making process to infer a posterior distribution on utility functions.\nHowever, people often deviate from approximate optimality. They have false\nbeliefs, their planning is sub-optimal, and their choices may be temporally\ninconsistent due to hyperbolic discounting and other biases. We demonstrate how\nto incorporate these deviations into algorithms for preference inference by\nconstructing generative models of planning for agents who are subject to false\nbeliefs and time inconsistency. We explore the inferences these models make\nabout preferences, beliefs, and biases. We present a behavioral experiment in\nwhich human subjects perform preference inference given the same observations\nof choices as our model. Results show that human subjects (like our model)\nexplain choices in terms of systematic deviations from optimal behavior and\nsuggest that they take such deviations into account when inferring preferences."
    },
    "1710.04924": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Komiyama",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Junpei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shimao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hajime"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Two-stage Algorithm for Fairness-aware Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Algorithmic decision making process now affects many aspects of our lives.\nStandard tools for machine learning, such as classification and regression, are\nsubject to the bias in data, and thus direct application of such off-the-shelf\ntools could lead to a specific group being unfairly discriminated. Removing\nsensitive attributes of data does not solve this problem because a\n\\textit{disparate impact} can arise when non-sensitive attributes and sensitive\nattributes are correlated. Here, we study a fair machine learning algorithm\nthat avoids such a disparate impact when making a decision. Inspired by the\ntwo-stage least squares method that is widely used in the field of economics,\nwe propose a two-stage algorithm that removes bias in the training data. The\nproposed algorithm is conceptually simple. Unlike most of existing fair\nalgorithms that are designed for classification tasks, the proposed method is\nable to (i) deal with regression tasks, (ii) combine explanatory attributes to\nremove reverse discrimination, and (iii) deal with numerical sensitive\nattributes. The performance and fairness of the proposed algorithm are\nevaluated in simulations with synthetic and real-world datasets."
    },
    "1412.0315": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-11-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Broeck",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guy Van den"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Niepert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathias"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Lifted Probabilistic Inference for Asymmetric Graphical Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Proceedings of AAAI-2015",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Lifted probabilistic inference algorithms have been successfully applied to a\nlarge number of symmetric graphical models. Unfortunately, the majority of\nreal-world graphical models is asymmetric. This is even the case for relational\nrepresentations when evidence is given. Therefore, more recent work in the\ncommunity moved to making the models symmetric and then applying existing\nlifted inference algorithms. However, this approach has two shortcomings.\nFirst, all existing over-symmetric approximations require a relational\nrepresentation such as Markov logic networks. Second, the induced symmetries\noften change the distribution significantly, making the computed probabilities\nhighly biased. We present a framework for probabilistic sampling-based\ninference that only uses the induced approximate symmetries to propose steps in\na Metropolis-Hastings style Markov chain. The framework, therefore, leads to\nimproved probability estimates while remaining unbiased. Experiments\ndemonstrate that the approach outperforms existing MCMC algorithms."
    },
    "1605.06377": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fisch",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dominik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gruhl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kalkowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edgar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernhard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ovaska",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seppo J."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Automation of Knowledge Understanding: An Approach for\n  Probabilistic Generative Classifiers",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "29 pages with 9 figures and 4 tables. Currently under review for\n  Information Sciences",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "After data selection, pre-processing, transformation, and feature extraction,\nknowledge extraction is not the final step in a data mining process. It is then\nnecessary to understand this knowledge in order to apply it efficiently and\neffectively. Up to now, there is a lack of appropriate techniques that support\nthis significant step. This is partly due to the fact that the assessment of\nknowledge is often highly subjective, e.g., regarding aspects such as novelty\nor usefulness. These aspects depend on the specific knowledge and requirements\nof the data miner. There are, however, a number of aspects that are objective\nand for which it is possible to provide appropriate measures. In this article\nwe focus on classification problems and use probabilistic generative\nclassifiers based on mixture density models that are quite common in data\nmining applications. We define objective measures to assess the\ninformativeness, uniqueness, importance, discrimination, representativity,\nuncertainty, and distinguishability of rules contained in these classifiers\nnumerically. These measures not only support a data miner in evaluating results\nof a data mining process based on such classifiers. As we will see in\nillustrative case studies, they may also be used to improve the data mining\nprocess itself or to support the later application of the extracted knowledge."
    },
    "1404.3862": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-04-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-11-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tamar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aviv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Glassner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yonatan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mannor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shie"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Optimizing the CVaR via Sampling",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in AAAI 2015",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Conditional Value at Risk (CVaR) is a prominent risk measure that is being\nused extensively in various domains. We develop a new formula for the gradient\nof the CVaR in the form of a conditional expectation. Based on this formula, we\npropose a novel sampling-based estimator for the CVaR gradient, in the spirit\nof the likelihood-ratio method. We analyze the bias of the estimator, and prove\nthe convergence of a corresponding stochastic gradient descent algorithm to a\nlocal CVaR optimum. Our method allows to consider CVaR optimization in new\ndomains. As an example, we consider a reinforcement learning application, and\nlearn a risk-sensitive controller for the game of Tetris."
    },
    "cs_0106008": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2001-06-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "van Emden",
                "http://arxiv.org/OAI/arXiv/:forenames": "M. H."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Computing Functional and Relational Box Consistency by Structured\n  Propagation in Atomic Constraint Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.PL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at the Sixth Annual Workshop of the ERCIM Working Group on\n  Constraints. 12 pages",
        "http://arxiv.org/OAI/arXiv/:report-no": "Univ. of Victoria Computer Science Dept Technical Report DCS-266-IR",
        "http://arxiv.org/OAI/arXiv/:acm-class": "D.3.2; D.3.3; F.4.1",
        "http://arxiv.org/OAI/arXiv/:abstract": "Box consistency has been observed to yield exponentially better performance\nthan chaotic constraint propagation in the interval constraint system obtained\nby decomposing the original expression into primitive constraints. The claim\nwas made that the improvement is due to avoiding decomposition. In this paper\nwe argue that the improvement is due to replacing chaotic iteration by a more\nstructured alternative.\n  To this end we distinguish the existing notion of box consistency from\nrelational box consistency. We show that from a computational point of view it\nis important to maintain the functional structure in constraint systems that\nare associated with a system of equations. So far, it has only been considered\ncomputationally important that constraint propagation be fair. With the\nadditional structure of functional constraint systems, one can define and\nimplement computationally effective, structured, truncated constraint\npropagations. The existing algorithm for box consistency is one such. Our\nresults suggest that there are others worth investigating."
    },
    "1003.5956": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-03-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2012-03-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lihong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Langford",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuanhui"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unbiased Offline Evaluation of Contextual-bandit-based News Article\n  Recommendation Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 7 figures, revised from the published version at the WSDM\n  2011 conference",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.3.5; I.2.6",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/1935826.1935878",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Contextual bandit algorithms have become popular for online recommendation\nsystems such as Digg, Yahoo! Buzz, and news recommendation in general.\n\\emph{Offline} evaluation of the effectiveness of new algorithms in these\napplications is critical for protecting online user experiences but very\nchallenging due to their \"partial-label\" nature. Common practice is to create a\nsimulator which simulates the online environment for the problem at hand and\nthen run an algorithm against this simulator. However, creating simulator\nitself is often difficult and modeling bias is usually unavoidably introduced.\nIn this paper, we introduce a \\emph{replay} methodology for contextual bandit\nalgorithm evaluation. Different from simulator-based approaches, our method is\ncompletely data-driven and very easy to adapt to different applications. More\nimportantly, our method can provide provably unbiased evaluations. Our\nempirical results on a large-scale news article recommendation dataset\ncollected from Yahoo! Front Page conform well with our theoretical results.\nFurthermore, comparisons between our offline replay and online bucket\nevaluation of several contextual bandit algorithms show accuracy and\neffectiveness of our offline evaluation method."
    },
    "1507.07295": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-07-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dyagilev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kirill"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saria",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suchi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning (Predictive) Risk Scores in the Presence of Censoring due to\n  Interventions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.AP",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Machine Learning Journal, Special Issue on on Machine Learning for\n  Health and Medicine, pp. 1-26, 2015",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A large and diverse set of measurements are regularly collected during a\npatient's hospital stay to monitor their health status. Tools for integrating\nthese measurements into severity scores, that accurately track changes in\nillness severity, can improve clinicians ability to provide timely\ninterventions. Existing approaches for creating such scores either 1) rely on\nexperts to fully specify the severity score, or 2) train a predictive score,\nusing supervised learning, by regressing against a surrogate marker of severity\nsuch as the presence of downstream adverse events. The first approach does not\nextend to diseases where an accurate score cannot be elicited from experts. The\nsecond approach often produces scores that suffer from bias due to\ntreatment-related censoring (Paxton, 2013). We propose a novel ranking based\nframework for disease severity score learning (DSSL). DSSL exploits the\nfollowing key observation: while it is challenging for experts to quantify the\ndisease severity at any given time, it is often easy to compare the disease\nseverity at two different times. Extending existing ranking algorithms, DSSL\nlearns a function that maps a vector of patient's measurements to a scalar\nseverity score such that the resulting score is temporally smooth and\nconsistent with the expert's ranking of pairs of disease states. We apply DSSL\nto the problem of learning a sepsis severity score using a large, real-world\ndataset. The learned scores significantly outperform state-of-the-art clinical\nscores in ranking patient states by severity and in early detection of future\nadverse events. We also show that the learned disease severity trajectories are\nconsistent with clinical expectations of disease evolution. Further, using\nsimulated datasets, we show that DSSL exhibits better generalization\nperformance to changes in treatment patterns compared to the above approaches."
    },
    "1302.4983": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-02-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Spirtes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Richardson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Inference in the Presence of Latent Variables and Selection Bias",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Eleventh Conference on Uncertainty in\n  Artificial Intelligence (UAI1995)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1995-PG-499-506",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We show that there is a general, informative and reliable procedure for\ndiscovering causal relations when, for all the investigator knows, both latent\nvariables and selection bias may be at work. Given information about\nconditional independence and dependence relations between measured variables,\neven when latent variables and selection bias may be present, there are\nsufficient conditions for reliably concluding that there is a causal path from\none variable to another, and sufficient conditions for reliably concluding when\nno such causal path exists."
    },
    "1708.06233": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aymanns",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Foerster",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jakob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Georg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Co-Pierre"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fake News in Social Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.MA cs.SI physics.soc-ph q-fin.EC",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.1; I.2.6; J.4; K.4.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We model the spread of news as a social learning game on a network. Agents\ncan either endorse or oppose a claim made in a piece of news, which itself may\nbe either true or false. Agents base their decision on a private signal and\ntheir neighbors' past actions. Given these inputs, agents follow strategies\nderived via multi-agent deep reinforcement learning and receive utility from\nacting in accordance with the veracity of claims. Our framework yields\nstrategies with agent utility close to a theoretical, Bayes optimal benchmark,\nwhile remaining flexible to model re-specification. Optimized strategies allow\nagents to correctly identify most false claims, when all agents receive\nunbiased private signals. However, an adversary's attempt to spread fake news\nby targeting a subset of agents with a biased private signal can be successful.\nEven more so when the adversary has information about agents' network position\nor private signal. When agents are aware of the presence of an adversary they\nre-optimize their strategies in the training stage and the adversary's attack\nis less effective. Hence, exposing agents to the possibility of fake news can\nbe an effective way to curtail the spread of fake news in social networks. Our\nresults also highlight that information about the users' private beliefs and\ntheir social network structure can be extremely valuable to adversaries and\nshould be well protected."
    },
    "1606.03402": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-09-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sountsov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pavel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sarawagi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sunita"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Length bias in Encoder Decoder Models and a Case for Global Conditioning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Encoder-decoder networks are popular for modeling sequences probabilistically\nin many applications. These models use the power of the Long Short-Term Memory\n(LSTM) architecture to capture the full dependence among variables, unlike\nearlier models like CRFs that typically assumed conditional independence among\nnon-adjacent variables. However in practice encoder-decoder models exhibit a\nbias towards short sequences that surprisingly gets worse with increasing beam\nsize.\n  In this paper we show that such phenomenon is due to a discrepancy between\nthe full sequence margin and the per-element margin enforced by the locally\nconditioned training objective of a encoder-decoder model. The discrepancy more\nadversely impacts long sequences, explaining the bias towards predicting short\nsequences.\n  For the case where the predicted sequences come from a closed set, we show\nthat a globally conditioned model alleviates the above problems of\nencoder-decoder models. From a practical point of view, our proposed model also\neliminates the need for a beam-search during inference, which reduces to an\nefficient dot-product based search in a vector-space."
    },
    "1404.3659": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Konigsberg",
                "http://arxiv.org/OAI/arXiv/:forenames": "Amir"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Avoiding Undesired Choices Using Intelligent Adaptive Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol. 5, No. 2, March 2014",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a number of heuristics that can be used for identifying when\nintransitive choice behaviour is likely to occur in choice situations. We also\nsuggest two methods for avoiding undesired choice behaviour, namely transparent\ncommunication and adaptive choice-set generation. We believe that these two\nways can contribute to the avoidance of decision biases in choice situations\nthat may often be regretted."
    },
    "1802.00560": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoguang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Matwin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpretable Deep Convolutional Neural Networks via Meta-learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 9 figures, submitted to the 2018 International Joint\n  Conference on Neural Networks",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Model interpretability is a requirement in many applications in which crucial\ndecisions are made by users relying on a model's outputs. The recent movement\nfor \"algorithmic fairness\" also stipulates explainability, and therefore\ninterpretability of learning models. And yet the most successful contemporary\nMachine Learning approaches, the Deep Neural Networks, produce models that are\nhighly non-interpretable. We attempt to address this challenge by proposing a\ntechnique called CNN-INTE to interpret deep Convolutional Neural Networks (CNN)\nvia meta-learning. In this work, we interpret a specific hidden layer of the\ndeep CNN model on the MNIST image dataset. We use a clustering algorithm in a\ntwo-level structure to find the meta-level training data and Random Forest as\nbase learning algorithms to generate the meta-level test data. The\ninterpretation results are displayed visually via diagrams, which clearly\nindicates how a specific test instance is classified. Our method achieves\nglobal interpretation for all the test instances without sacrificing the\naccuracy obtained by the original deep CNN model. This means our model is\nfaithful to the deep CNN model, which leads to reliable interpretations."
    },
    "cs_9503102": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "1995-02-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Turney",
                "http://arxiv.org/OAI/arXiv/:forenames": "P. D."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Cost-Sensitive Classification: Empirical Evaluation of a Hybrid Genetic\n  Decision Tree Induction Algorithm",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "See http://www.jair.org/ for any accompanying files",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Artificial Intelligence Research, Vol 2, (1995),\n  369-409",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper introduces ICET, a new algorithm for cost-sensitive\nclassification. ICET uses a genetic algorithm to evolve a population of biases\nfor a decision tree induction algorithm. The fitness function of the genetic\nalgorithm is the average cost of classification when using the decision tree,\nincluding both the costs of tests (features, measurements) and the costs of\nclassification errors. ICET is compared here with three other algorithms for\ncost-sensitive classification - EG2, CS-ID3, and IDX - and also with C4.5,\nwhich classifies without regard to cost. The five algorithms are evaluated\nempirically on five real-world medical datasets. Three sets of experiments are\nperformed. The first set examines the baseline performance of the five\nalgorithms on the five datasets and establishes that ICET performs\nsignificantly better than its competitors. The second set tests the robustness\nof ICET under a variety of conditions and shows that ICET maintains its\nadvantage. The third set looks at ICET's search in bias space and discovers a\nway to improve the search."
    },
    "0907.0592": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-07-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Whitacre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pham",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tuan Q."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sarker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ruhul A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Credit Assignment in Adaptive Evolutionary Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Genetic And Evolutionary Computation Conference, 2006",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/1143997.1144206",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, a new method for assigning credit to search operators is\npresented. Starting with the principle of optimizing search bias, search\noperators are selected based on an ability to create solutions that are\nhistorically linked to future generations. Using a novel framework for defining\nperformance measurements, distributing credit for performance, and the\nstatistical interpretation of this credit, a new adaptive method is developed\nand shown to outperform a variety of adaptive and non-adaptive competitors."
    },
    "1505.05723": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-05-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zliobaite",
                "http://arxiv.org/OAI/arXiv/:forenames": "Indre"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the relation between accuracy and fairness in binary classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted for presentation to the 2nd workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (http://www.fatml.org/)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Our study revisits the problem of accuracy-fairness tradeoff in binary\nclassification. We argue that comparison of non-discriminatory classifiers\nneeds to account for different rates of positive predictions, otherwise\nconclusions about performance may be misleading, because accuracy and\ndiscrimination of naive baselines on the same dataset vary with different rates\nof positive predictions. We provide methodological recommendations for sound\ncomparison of non-discriminatory classifiers, and present a brief theoretical\nand empirical analysis of tradeoffs between accuracy and non-discrimination."
    },
    "1707.09457": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jieyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianlu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yatskar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ordonez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vicente"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kai-Wei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Men Also Like Shopping: Reducing Gender Bias Amplification using\n  Corpus-level Constraints",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages, published in EMNLP 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Language is increasingly being used to define rich visual recognition\nproblems with supporting image collections sourced from the web. Structured\nprediction models are used in these tasks to take advantage of correlations\nbetween co-occurring labels and visual input but risk inadvertently encoding\nsocial biases found in web corpora. In this work, we study data and models\nassociated with multilabel object classification and visual semantic role\nlabeling. We find that (a) datasets for these tasks contain significant gender\nbias and (b) models trained on these datasets further amplify existing bias.\nFor example, the activity cooking is over 33% more likely to involve females\nthan males in a training set, and a trained model further amplifies the\ndisparity to 68% at test time. We propose to inject corpus-level constraints\nfor calibrating existing structured prediction models and design an algorithm\nbased on Lagrangian relaxation for collective inference. Our method results in\nalmost no performance loss for the underlying recognition task but decreases\nthe magnitude of bias amplification by 47.5% and 40.5% for multilabel\nclassification and visual semantic role labeling, respectively."
    },
    "1807.04723": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Serban",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iulian Vlad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sankar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chinnadhurai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pieper",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pineau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joelle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Bottleneck Simulator: A Model-based Deep Reinforcement Learning\n  Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "26 pages, 2 figures, 4 tables",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.5.1; I.2.7",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep reinforcement learning has recently shown many impressive successes.\nHowever, one major obstacle towards applying such methods to real-world\nproblems is their lack of data-efficiency. To this end, we propose the\nBottleneck Simulator: a model-based reinforcement learning method which\ncombines a learned, factorized transition model of the environment with rollout\nsimulations to learn an effective policy from few examples. The learned\ntransition model employs an abstract, discrete (bottleneck) state, which\nincreases sample efficiency by reducing the number of model parameters and by\nexploiting structural properties of the environment. We provide a mathematical\nanalysis of the Bottleneck Simulator in terms of fixed points of the learned\npolicy, which reveals how performance is affected by four distinct sources of\nerror: an error related to the abstract space structure, an error related to\nthe transition model estimation variance, an error related to the transition\nmodel estimation bias, and an error related to the transition model class bias.\nFinally, we evaluate the Bottleneck Simulator on two natural language\nprocessing tasks: a text adventure game and a real-world, complex dialogue\nresponse selection task. On both tasks, the Bottleneck Simulator yields\nexcellent performance beating competing approaches."
    },
    "1007.0614": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-07-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Online Cake Cutting",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Proceedings of the Third International Workshop on\n  Computational Social Choice (COMSOC-2010)",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an online form of the cake cutting problem. This models situations\nwhere players arrive and depart during the process of dividing a resource. We\nshow that well known fair division procedures like cut-and-choose and the\nDubins-Spanier moving knife procedure can be adapted to apply to such online\nproblems. We propose some desirable properties that online cake cutting\nprocedures might possess like online forms of proportionality and\nenvy-freeness, and identify which properties are in fact possessed by the\ndifferent online cake procedures."
    },
    "1510.07389": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-10-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-12-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Gordon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lucas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christopher G."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Human Kernel",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages, 5 figures. To appear in Neural Information Processing\n  Systems (NIPS) 2015. Version 2: Figure 2 (i)-(n) now displays the second set\n  of progressive function learning experiments",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bayesian nonparametric models, such as Gaussian processes, provide a\ncompelling framework for automatic statistical modelling: these models have a\nhigh degree of flexibility, and automatically calibrated complexity. However,\nautomating human expertise remains elusive; for example, Gaussian processes\nwith standard kernels struggle on function extrapolation problems that are\ntrivial for human learners. In this paper, we create function extrapolation\nproblems and acquire human responses, and then design a kernel learning\nframework to reverse engineer the inductive biases of human learners across a\nset of behavioral experiments. We use the learned kernels to gain psychological\ninsights and to extrapolate in human-like ways that go beyond traditional\nstationary and polynomial kernels. Finally, we investigate Occam's razor in\nhuman and Gaussian process based function learning."
    },
    "1611.06589": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abebe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rediet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kleinberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parkes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fair Division via Social Comparison",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DS cs.AI cs.GT math.CO",
        "http://arxiv.org/OAI/arXiv/:comments": "18 pages, 3 figures, Proceedings of the 16th Conference on Autonomous\n  Agents and Multi-Agent Systems (AAMAS, 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the classical cake cutting problem, a resource must be divided among\nagents with different utilities so that each agent believes they have received\na fair share of the resource relative to the other agents. We introduce a\nvariant of the problem in which we model an underlying social network on the\nagents with a graph, and agents only evaluate their shares relative to their\nneighbors' in the network. This formulation captures many situations in which\nit is unrealistic to assume a global view, and also exposes interesting\nphenomena in the original problem.\n  Specifically, we say an allocation is locally envy-free if no agent envies a\nneighbor's allocation and locally proportional if each agent values her own\nallocation as much as the average value of her neighbor's allocations, with the\nformer implying the latter. While global envy-freeness implies local\nenvy-freeness, global proportionality does not imply local proportionality, or\nvice versa. A general result is that for any two distinct graphs on the same\nset of nodes and an allocation, there exists a set of valuation functions such\nthat the allocation is locally proportional on one but not the other.\n  We fully characterize the set of graphs for which an oblivious single-cutter\nprotocol-- a protocol that uses a single agent to cut the cake into pieces\n--admits a bounded protocol with $O(n^2)$ query complexity for locally\nenvy-free allocations in the Robertson-Webb model. We also consider the price\nof envy-freeness, which compares the total utility of an optimal allocation to\nthe best utility of an allocation that is envy-free. We show that a lower bound\nof $\\Omega(\\sqrt{n})$ on the price of envy-freeness for global allocations in\nfact holds for local envy-freeness in any connected undirected graph. Thus,\nsparse graphs surprisingly do not provide more flexibility with respect to the\nquality of envy-free allocations."
    },
    "1608.00667": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hong-Min"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hsuan-Tien"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Can Active Learning Experience Be Transferred?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 8 figs, 4 tables, conference",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Active learning is an important machine learning problem in reducing the\nhuman labeling effort. Current active learning strategies are designed from\nhuman knowledge, and are applied on each dataset in an immutable manner. In\nother words, experience about the usefulness of strategies cannot be updated\nand transferred to improve active learning on other datasets. This paper\ninitiates a pioneering study on whether active learning experience can be\ntransferred. We first propose a novel active learning model that linearly\naggregates existing strategies. The linear weights can then be used to\nrepresent the active learning experience. We equip the model with the popular\nlinear upper- confidence-bound (LinUCB) algorithm for contextual bandit to\nupdate the weights. Finally, we extend our model to transfer the experience\nacross datasets with the technique of biased regularization. Empirical studies\ndemonstrate that the learned experience not only is competitive with existing\nstrategies on most single datasets, but also can be transferred across datasets\nto improve the performance on future learning tasks."
    },
    "1809.07842": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Lloyd",
                "http://arxiv.org/OAI/arXiv/:forenames": "Kirsten"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bias Amplification in Artificial Intelligence Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As Artificial Intelligence (AI) technologies proliferate, concern has\ncentered around the long-term dangers of job loss or threats of machines\ncausing harm to humans. All of this concern, however, detracts from the more\npertinent and already existing threats posed by AI today: its ability to\namplify bias found in training datasets, and swiftly impact marginalized\npopulations at scale. Government and public sector institutions have a\nresponsibility to citizens to establish a dialogue with technology developers\nand release thoughtful policy around data standards to ensure diverse\nrepresentation in datasets to prevent bias amplification and ensure that AI\nsystems are built with inclusion in mind."
    },
    "1709.07796": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Francois-Lavet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vincent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ernst",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Damien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fonteneau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Raphael"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On overfitting and asymptotic bias in batch reinforcement learning with\n  partial observability",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper stands in the context of reinforcement learning with partial\nobservability and limited data. In this setting, we focus on the tradeoff\nbetween asymptotic bias (suboptimality with unlimited data) and overfitting\n(additional suboptimality due to limited data), and theoretically show that\nwhile potentially increasing the asymptotic bias, a smaller state\nrepresentation decreases the risk of overfitting. Our analysis relies on\nexpressing the quality of a state representation by bounding L1 error terms of\nthe associated belief states. Theoretical results are empirically illustrated\nwhen the state representation is a truncated history of observations. Finally,\nwe also discuss and empirically illustrate how using function approximators and\nadapting the discount factor may enhance the tradeoff between asymptotic bias\nand overfitting."
    },
    "1811.01480": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jixue"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiuyong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Le",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thuc Duy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ye",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Feiyue"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gefei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "FairMod - Making Predictive Models Discrimination Aware",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Predictive models such as decision trees and neural networks may produce\ndiscrimination in their predictions. This paper proposes a method to\npost-process the predictions of a predictive model to make the processed\npredictions non-discriminatory. The method considers multiple protected\nvariables together. Multiple protected variables make the problem more\nchallenging than a simple protected variable. The method uses a well-cited\ndiscrimination metric and adapts it to allow the specification of explanatory\nvariables, such as position, profession, education, that describe the contexts\nof the applications. It models the post-processing of predictions problem as a\nnonlinear optimization problem to find best adjustments to the predictions so\nthat the discrimination constraints of all protected variables are all met at\nthe same time. The proposed method is independent of classification methods. It\ncan handle the cases that existing methods cannot handle: satisfying multiple\nprotected attributes at the same time, allowing multiple explanatory\nattributes, and being independent of classification model types. An evaluation\nusing four real world data sets shows that the proposed method is as\neffectively as existing methods, in addition to its extra power."
    },
    "1809.02251": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhong",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Fred"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jinyu",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Fred"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yifan",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Fred"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Biing-Hwang",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Fred"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Juang"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adversarial Feature-Mapping for Speech Enhancement",
        "http://arxiv.org/OAI/arXiv/:categories": "eess.AS cs.AI cs.CL cs.SD",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Interspeech 2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.21437/Interspeech.2018-2461",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Feature-mapping with deep neural networks is commonly used for single-channel\nspeech enhancement, in which a feature-mapping network directly transforms the\nnoisy features to the corresponding enhanced ones and is trained to minimize\nthe mean square errors between the enhanced and clean features. In this paper,\nwe propose an adversarial feature-mapping (AFM) method for speech enhancement\nwhich advances the feature-mapping approach with adversarial learning. An\nadditional discriminator network is introduced to distinguish the enhanced\nfeatures from the real clean ones. The two networks are jointly optimized to\nminimize the feature-mapping loss and simultaneously mini-maximize the\ndiscrimination loss. The distribution of the enhanced features is further\npushed towards that of the clean features through this adversarial multi-task\ntraining. To achieve better performance on ASR task, senone-aware (SA) AFM is\nfurther proposed in which an acoustic model network is jointly trained with the\nfeature-mapping and discriminator networks to optimize the senone\nclassification loss in addition to the AFM losses. Evaluated on the CHiME-3\ndataset, the proposed AFM achieves 16.95% and 5.27% relative word error rate\n(WER) improvements over the real noisy data and the feature-mapping baseline\nrespectively and the SA-AFM achieves 9.85% relative WER improvement over the\nmulti-conditional acoustic model."
    },
    "1201.5946": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-01-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "James",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex Pappachen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dimitrijev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sima"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Feature selection using nearest attributes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Feature selection is an important problem in high-dimensional data analysis\nand classification. Conventional feature selection approaches focus on\ndetecting the features based on a redundancy criterion using learning and\nfeature searching schemes. In contrast, we present an approach that identifies\nthe need to select features based on their discriminatory ability among\nclasses. Area of overlap between inter-class and intra-class distances\nresulting from feature to feature comparison of an attribute is used as a\nmeasure of discriminatory ability of the feature. A set of nearest attributes\nin a pattern having the lowest area of overlap within a degree of tolerance\ndefined by a selection threshold is selected to represent the best available\ndiscriminable features. State of the art recognition results are reported for\npattern classification problems by using the proposed feature selection scheme\nwith the nearest neighbour classifier. These results are reported with\nbenchmark databases having high dimensional feature vectors in the problems\ninvolving images and micro array data."
    },
    "1611.09328": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yangchen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "White",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "White",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Accelerated Gradient Temporal Difference Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "AAAI Conference on Artificial Intelligence (AAAI), 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The family of temporal difference (TD) methods span a spectrum from\ncomputationally frugal linear methods like TD({\\lambda}) to data efficient\nleast squares methods. Least square methods make the best use of available data\ndirectly computing the TD solution and thus do not require tuning a typically\nhighly sensitive learning rate parameter, but require quadratic computation and\nstorage. Recent algorithmic developments have yielded several sub-quadratic\nmethods that use an approximation to the least squares TD solution, but incur\nbias. In this paper, we propose a new family of accelerated gradient TD (ATD)\nmethods that (1) provide similar data efficiency benefits to least-squares\nmethods, at a fraction of the computation and storage (2) significantly reduce\nparameter sensitivity compared to linear TD methods, and (3) are asymptotically\nunbiased. We illustrate these claims with a proof of convergence in expectation\nand experiments on several benchmark domains and a large-scale industrial\nenergy allocation domain."
    },
    "cs_0602083": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2006-02-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Frailis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mansutti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oriana"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boinee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Praveen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cabras",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giuseppe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Angelis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Lotto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Barbara"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Forti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alberto"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dell'Orso",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mauro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paoletti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scribano",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Angelo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Turini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicola"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mariotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mose'"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peruzzo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luigi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saggion",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A third level trigger programmable on FPGA for the gamma/hadron\n  separation in a Cherenkov telescope using pseudo-Zernike moments and the SVM\n  classifier",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.5.2; C.3",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1142/9789812773548_0024",
        "http://arxiv.org/OAI/arXiv/:abstract": "We studied the application of the Pseudo-Zernike features as image parameters\n(instead of the Hillas parameters) for the discrimination between the images\nproduced by atmospheric electromagnetic showers caused by gamma-rays and the\nones produced by atmospheric electromagnetic showers caused by hadrons in the\nMAGIC Experiment. We used a Support Vector Machine as classification algorithm\nwith the computed Pseudo-Zernike features as classification parameters. We\nimplemented on a FPGA board a kernel function of the SVM and the Pseudo-Zernike\nfeatures to build a third level trigger for the gamma-hadron separation task of\nthe MAGIC Experiment."
    },
    "1803.04551": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ball",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Anderson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek T."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multi-Sensor Conflict Measurement and Information Fusion",
        "http://arxiv.org/OAI/arXiv/:categories": "eess.SP cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 9 figures, conference paper",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "SPIE Defense, Security, and Sensing, April, 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/publicdomain/zero/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In sensing applications where multiple sensors observe the same scene, fusing\nsensor outputs can provide improved results. However, if some of the sensors\nare providing lower quality outputs, the fused results can be degraded. In this\nwork, a multi-sensor conflict measure is proposed which estimates multi-sensor\nconflict by representing each sensor output as interval-valued information and\nexamines the sensor output overlaps on all possible n-tuple sensor\ncombinations. The conflict is based on the sizes of the intervals and how many\nsensors output values lie in these intervals. In this work, conflict is defined\nin terms of how little the output from multiple sensors overlap. That is, high\ndegrees of overlap mean low sensor conflict, while low degrees of overlap mean\nhigh conflict. This work is a preliminary step towards a robust conflict and\nsensor fusion framework. In addition, a sensor fusion algorithm is proposed\nbased on a weighted sum of sensor outputs, where the weights for each sensor\ndiminish as the conflict measure increases. The proposed methods can be\nutilized to (1) assess a measure of multi-sensor conflict, and (2) improve\nsensor output fusion by lessening weighting for sensors with high conflict.\nUsing this measure, a simulated example is given to explain the mechanics of\ncalculating the conflict measure, and stereo camera 3D outputs are analyzed and\nfused. In the stereo camera case, the sensor output is corrupted by additive\nimpulse noise, DC offset, and Gaussian noise. Impulse noise is common in\nsensors due to intermittent interference, a DC offset a sensor bias or\nregistration error, and Gaussian noise represents a sensor output with low SNR.\nThe results show that sensor output fusion based on the conflict measure shows\nimproved accuracy over a simple averaging fusion strategy."
    },
    "1810.06710": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nobandegani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ardavan S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Campoli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shultz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas R."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bringing Order to the Cognitive Fallacy Zoo",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.NC cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the eyes of a rationalist like Descartes or Spinoza, human reasoning is\nflawless, marching toward uncovering ultimate truth. A few centuries later,\nhowever, culminating in the work of Kahneman and Tversky, human reasoning was\nportrayed as anything but flawless, filled with numerous misjudgments, biases,\nand cognitive fallacies. With further investigations, new cognitive fallacies\ncontinually emerged, leading to a state of affairs which can fairly be\ncharacterized as the cognitive fallacy zoo! In this largely methodological\nwork, we formally present a principled way to bring order to this zoo. We\nintroduce the idea of establishing implication relationships (IRs) between\ncognitive fallacies, formally characterizing how one fallacy implies another.\nIR is analogous to, and partly inspired by, the fundamental concept of\nreduction in computational complexity theory. We present several examples of\nIRs involving experimentally well-documented cognitive fallacies: base-rate\nneglect, availability bias, conjunction fallacy, decoy effect, framing effect,\nand Allais paradox. We conclude by discussing how our work: (i) allows for\nidentifying those pivotal cognitive fallacies whose investigation would be the\nmost rewarding research agenda, and importantly (ii) permits a systematized,\nguided research program on cognitive fallacies, motivating influential\ntheoretical as well as experimental avenues of future research."
    },
    "1004.3260": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-04-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mohemad",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rosmayati"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamdan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abdul Razak"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Othman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zulaiha Ali"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Noor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Noor Maizura Mohamad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Decision Support Systems (DSS) in Construction Tendering Processes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "International Journal of Computer Science Issues online at\n  http://ijcsi.org/articles/Decision-Support-Systems-DSS-in-Construction-Tendering-Processes.php",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IJCSI, Volume 7, Issue 2, March 2010",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The successful execution of a construction project is heavily impacted by\nmaking the right decision during tendering processes. Managing tender\nprocedures is very complex and uncertain involving coordination of many tasks\nand individuals with different priorities and objectives. Bias and inconsistent\ndecision are inevitable if the decision-making process is totally depends on\nintuition, subjective judgement or emotion. In making transparent decision and\nhealthy competition tendering, there exists a need for flexible guidance tool\nfor decision support. Aim of this paper is to give a review on current\npractices of Decision Support Systems (DSS) technology in construction\ntendering processes. Current practices of general tendering processes as\napplied to the most countries in different regions such as United States,\nEurope, Middle East and Asia are comprehensively discussed. Applications of\nWeb-based tendering processes is also summarised in terms of its properties.\nBesides that, a summary of Decision Support System (DSS) components is included\nin the next section. Furthermore, prior researches on implementation of DSS\napproaches in tendering processes are discussed in details. Current issues\narise from both of paper-based and Web-based tendering processes are outlined.\nFinally, conclusion is included at the end of this paper."
    },
    "1711.02857": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wangni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianqiao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dahua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Sparse Visual Representations with Leaky Capped Norm\n  Regularizers",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV math.NA stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Sparsity inducing regularization is an important part for learning\nover-complete visual representations. Despite the popularity of $\\ell_1$\nregularization, in this paper, we investigate the usage of non-convex\nregularizations in this problem. Our contribution consists of three parts.\nFirst, we propose the leaky capped norm regularization (LCNR), which allows\nmodel weights below a certain threshold to be regularized more strongly as\nopposed to those above, therefore imposes strong sparsity and only introduces\ncontrollable estimation bias. We propose a majorization-minimization algorithm\nto optimize the joint objective function. Second, our study over monocular 3D\nshape recovery and neural networks with LCNR outperforms $\\ell_1$ and other\nnon-convex regularizations, achieving state-of-the-art performance and faster\nconvergence. Third, we prove a theoretical global convergence speed on the 3D\nrecovery problem. To the best of our knowledge, this is the first convergence\nanalysis of the 3D recovery problem."
    },
    "1809.02904": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stephenson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Anderson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Damien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khalifa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ahmed"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Levine",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Renz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jochen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Togelius",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Salge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christoph"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Continuous Information Gain Measure to Find the Most Discriminatory\n  Problems for AI Benchmarking",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper introduces an information-theoretic method for selecting a small\nsubset of problems which gives us the most information about a group of\nproblem-solving algorithms. This method was tested on the games in the General\nVideo Game AI (GVGAI) framework, allowing us to identify a smaller set of games\nthat still gives a large amount of information about the game-playing agents.\nThis approach can be used to make agent testing more efficient in the future.\nWe can achieve almost as good discriminatory accuracy when testing on only a\nhandful of games as when testing on more than a hundred games, something which\nis often computationally infeasible. Furthermore, this method can be extended\nto study the dimensions of effective variance in game design between these\ngames, allowing us to identify which games differentiate between agents in the\nmost complementary ways. As a side effect of this investigation, we provide an\nup-to-date comparison on agent performance for all GVGAI games, and an analysis\nof correlations between scores and win-rates across both games and agents."
    },
    "1607.06520": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bolukbasi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tolga"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kai-Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saligrama",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Venkatesh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kalai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word\n  Embeddings",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The blind application of machine learning runs the risk of amplifying biases\npresent in data. Such a danger is facing us with word embedding, a popular\nframework to represent text data as vectors which has been used in many machine\nlearning and natural language processing tasks. We show that even word\nembeddings trained on Google News articles exhibit female/male gender\nstereotypes to a disturbing extent. This raises concerns because their\nwidespread use, as we describe, often tends to amplify these biases.\nGeometrically, gender bias is first shown to be captured by a direction in the\nword embedding. Second, gender neutral words are shown to be linearly separable\nfrom gender definition words in the word embedding. Using these properties, we\nprovide a methodology for modifying an embedding to remove gender stereotypes,\nsuch as the association between between the words receptionist and female,\nwhile maintaining desired associations such as between the words queen and\nfemale. We define metrics to quantify both direct and indirect gender biases in\nembeddings, and develop algorithms to \"debias\" the embedding. Using\ncrowd-worker evaluation as well as standard benchmarks, we empirically\ndemonstrate that our algorithms significantly reduce gender bias in embeddings\nwhile preserving the its useful properties such as the ability to cluster\nrelated concepts and to solve analogy tasks. The resulting embeddings can be\nused in applications without amplifying gender bias."
    },
    "1707.03017": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ethan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "de Vries",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Harm"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Strub",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Florian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dumoulin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vincent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Courville",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aaron"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Visual Reasoning Without Strong Priors",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Full AAAI 2018 paper is at arXiv:1709.07871. Presented at ICML 2017's\n  Machine Learning in Speech and Language Processing Workshop. Code is at\n  http://github.com/ethanjperez/film",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Achieving artificial visual reasoning - the ability to answer image-related\nquestions which require a multi-step, high-level process - is an important step\ntowards artificial general intelligence. This multi-modal task requires\nlearning a question-dependent, structured reasoning process over images from\nlanguage. Standard deep learning approaches tend to exploit biases in the data\nrather than learn this underlying structure, while leading methods learn to\nvisually reason successfully but are hand-crafted for reasoning. We show that a\ngeneral-purpose, Conditional Batch Normalization approach achieves\nstate-of-the-art results on the CLEVR Visual Reasoning benchmark with a 2.4%\nerror rate. We outperform the next best end-to-end method (4.5%) and even\nmethods that use extra supervision (3.1%). We probe our model to shed light on\nhow it reasons, showing it has learned a question-dependent, multi-step\nprocess. Previous work has operated under the assumption that visual reasoning\ncalls for a specialized architecture, but we show that a general architecture\nwith proper conditioning can learn to visually reason effectively."
    },
    "1404.3301": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-04-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mazaitis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kathryn"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ni"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mitchell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cohen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William W."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficient Inference and Learning in a Large Knowledge Base: Reasoning\n  with Extracted Information using a Locally Groundable First-Order\n  Probabilistic Logic",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: substantial text overlap with arXiv:1305.2254",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "One important challenge for probabilistic logics is reasoning with very large\nknowledge bases (KBs) of imperfect information, such as those produced by\nmodern web-scale information extraction systems. One scalability problem shared\nby many probabilistic logics is that answering queries involves \"grounding\" the\nquery---i.e., mapping it to a propositional representation---and the size of a\n\"grounding\" grows with database size. To address this bottleneck, we present a\nfirst-order probabilistic language called ProPPR in which that approximate\n\"local groundings\" can be constructed in time independent of database size.\nTechnically, ProPPR is an extension to stochastic logic programs (SLPs) that is\nbiased towards short derivations; it is also closely related to an earlier\nrelational learning algorithm called the path ranking algorithm (PRA). We show\nthat the problem of constructing proofs for this logic is related to\ncomputation of personalized PageRank (PPR) on a linearized version of the proof\nspace, and using on this connection, we develop a proveably-correct approximate\ngrounding scheme, based on the PageRank-Nibble algorithm. Building on this, we\ndevelop a fast and easily-parallelized weight-learning algorithm for ProPPR. In\nexperiments, we show that learning for ProPPR is orders magnitude faster than\nlearning for Markov logic networks; that allowing mutual recursion (joint\nlearning) in KB inference leads to improvements in performance; and that ProPPR\ncan learn weights for a mutually recursive program with hundreds of clauses,\nwhich define scores of interrelated predicates, over a KB containing one\nmillion entities."
    },
    "1811.00497": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaoran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Songpeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chengliang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling Attention Flow on Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Real-world scenarios demand reasoning about process, more than final outcome\nprediction, to discover latent causal chains and better understand complex\nsystems. It requires the learning algorithms to offer both accurate predictions\nand clear interpretations. We design a set of trajectory reasoning tasks on\ngraphs with only the source and the destination observed. We present the\nattention flow mechanism to explicitly model the reasoning process, leveraging\nthe relational inductive biases by basing our models on graph networks. We\nstudy the way attention flow can effectively act on the underlying information\nflow implemented by message passing. Experiments demonstrate that the attention\nflow driven by and interacting with graph networks can provide higher accuracy\nin prediction and better interpretation for trajectories reasoning."
    },
    "1806.07917": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fernando",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chrisantha Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sygnowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jakub"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Osindero",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jane"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schaul",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Teplyashin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Denis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sprechmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pablo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pritzel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rusu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrei A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Meta-Learning by the Baldwin Effect",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3205651.3205763",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The scope of the Baldwin effect was recently called into question by two\npapers that closely examined the seminal work of Hinton and Nowlan. To this\ndate there has been no demonstration of its necessity in empirically\nchallenging tasks. Here we show that the Baldwin effect is capable of evolving\nfew-shot supervised and reinforcement learning mechanisms, by shaping the\nhyperparameters and the initial parameters of deep learning algorithms.\nFurthermore it can genetically accommodate strong learning biases on the same\nset of problems as a recent machine learning algorithm called MAML \"Model\nAgnostic Meta-Learning\" which uses second-order gradients instead of evolution\nto learn a set of reference parameters (initial weights) that can allow rapid\nadaptation to tasks sampled from a distribution. Whilst in simple cases MAML is\nmore data efficient than the Baldwin effect, the Baldwin effect is more general\nin that it does not require gradients to be backpropagated to the reference\nparameters or hyperparameters, and permits effectively any number of gradient\nupdates in the inner loop. The Baldwin effect learns strong learning dependent\nbiases, rather than purely genetically accommodating fixed behaviours in a\nlearning independent manner."
    },
    "1606.00776": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-06-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Serban",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iulian Vlad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Klinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tesauro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerald"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Talamadupula",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kartik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bowen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Courville",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aaron"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "21 pages, 2 figures, 10 tables",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.5.1; I.2.7",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure."
    },
    "1708.00754": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zliobaite",
                "http://arxiv.org/OAI/arXiv/:forenames": "Indre"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness-aware machine learning: a perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Algorithms learned from data are increasingly used for deciding many aspects\nin our life: from movies we see, to prices we pay, or medicine we get. Yet\nthere is growing evidence that decision making by inappropriately trained\nalgorithms may unintentionally discriminate people. For example, in automated\nmatching of candidate CVs with job descriptions, algorithms may capture and\npropagate ethnicity related biases. Several repairs for selected algorithms\nhave already been proposed, but the underlying mechanisms how such\ndiscrimination happens from the computational perspective are not yet\nscientifically understood. We need to develop theoretical understanding how\nalgorithms may become discriminatory, and establish fundamental machine\nlearning principles for prevention. We need to analyze machine learning process\nas a whole to systematically explain the roots of discrimination occurrence,\nwhich will allow to devise global machine learning optimization criteria for\nguaranteed prevention, as opposed to pushing empirical constraints into\nexisting algorithms case-by-case. As a result, the state-of-the-art will\nadvance from heuristic repairing, to proactive and theoretically supported\nprevention. This is needed not only because law requires to protect vulnerable\npeople. Penetration of big data initiatives will only increase, and computer\nscience needs to provide solid explanations and accountability to the public,\nbefore public concerns lead to unnecessarily restrictive regulations against\nmachine learning."
    },
    "1807.00392": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raff",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sylvester",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jared"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Gradient Reversal Against Discrimination",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of the 5'th Workshop on Fairness, Accountability and\n  Transparency in Machine Learning, 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "No methods currently exist for making arbitrary neural networks fair. In this\nwork we introduce GRAD, a new and simplified method to producing fair neural\nnetworks that can be used for auto-encoding fair representations or directly\nwith predictive networks. It is easy to implement and add to existing\narchitectures, has only one (insensitive) hyper-parameter, and provides\nimproved individual and group fairness. We use the flexibility of GRAD to\ndemonstrate multi-attribute protection."
    },
    "1108.5250": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-08-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mohamed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A. K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marwala",
                    "http://arxiv.org/OAI/arXiv/:forenames": "T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "John",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L. R."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Single-trial EEG Discrimination between Wrist and Finger Movement\n  Imagery and Execution in a Sensorimotor BCI",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "33rd Annual International IEEE EMBS Conference 2011",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/IEMBS.2011.6091552",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A brain-computer interface (BCI) may be used to control a prosthetic or\northotic hand using neural activity from the brain. The core of this\nsensorimotor BCI lies in the interpretation of the neural information extracted\nfrom electroencephalogram (EEG). It is desired to improve on the interpretation\nof EEG to allow people with neuromuscular disorders to perform daily\nactivities. This paper investigates the possibility of discriminating between\nthe EEG associated with wrist and finger movements. The EEG was recorded from\ntest subjects as they executed and imagined five essential hand movements using\nboth hands. Independent component analysis (ICA) and time-frequency techniques\nwere used to extract spectral features based on event-related\n(de)synchronisation (ERD/ERS), while the Bhattacharyya distance (BD) was used\nfor feature reduction. Mahalanobis distance (MD) clustering and artificial\nneural networks (ANN) were used as classifiers and obtained average accuracies\nof 65 % and 71 % respectively. This shows that EEG discrimination between wrist\nand finger movements is possible. The research introduces a new combination of\nmotor tasks to BCI research."
    },
    "1211.0501": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-11-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-04-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Costello",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fintan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Watts",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paul"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Surprisingly Rational: Probability theory plus noise explains biases in\n  judgment",
        "http://arxiv.org/OAI/arXiv/:categories": "physics.data-an cs.AI stat.AP",
        "http://arxiv.org/OAI/arXiv/:comments": "64 pages. Final preprint version. In press, Psychological Review",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The systematic biases seen in people's probability judgments are typically\ntaken as evidence that people do not reason about probability using the rules\nof probability theory, but instead use heuristics which sometimes yield\nreasonable judgments and sometimes systematic biases. This view has had a major\nimpact in economics, law, medicine, and other fields; indeed, the idea that\npeople cannot reason with probabilities has become a widespread truism. We\npresent a simple alternative to this view, where people reason about\nprobability according to probability theory but are subject to random variation\nor noise in the reasoning process. In this account the effect of noise is\ncancelled for some probabilistic expressions: analysing data from two\nexperiments we find that, for these expressions, people's probability judgments\nare strikingly close to those required by probability theory. For other\nexpressions this account produces systematic deviations in probability\nestimates. These deviations explain four reliable biases in human probabilistic\nreasoning (conservatism, subadditivity, conjunction and disjunction fallacies).\nThese results suggest that people's probability judgments embody the rules of\nprobability theory, and that biases in those judgments are due to the effects\nof random noise."
    },
    "1609.06221": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-09-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mishra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Saraswati"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Suman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Avnish Chandra"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Efficient Method of Partitioning High Volumes of Multidimensional\n  Data for Parallel Clustering Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DC",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.5.3; D.1.3",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Int. Journal of Engineering Research and Application ISSN :\n  2248-9622, Vol. 6, Issue 8, August 2016, pp.67-71",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "An optimal data partitioning in parallel & distributed implementation of\nclustering algorithms is a necessary computation as it ensures independent task\ncompletion, fair distribution, less number of affected points and better &\nfaster merging. Though partitioning using Kd Tree is being conventionally used\nin academia, it suffers from performance drenches and bias (non equal\ndistribution) as dimensionality of data increases and hence is not suitable for\npractical use in industry where dimensionality can be of order of 100s to\n1000s. To address these issues we propose two new partitioning techniques using\nexisting mathematical models & study their feasibility, performance (bias and\npartitioning speed) & possible variants in choosing initial seeds. First method\nuses an n dimensional hashed grid based approach which is based on mapping the\npoints in space to a set of cubes which hashes the points. Second method uses a\ntree of voronoi planes where each plane corresponds to a partition. We found\nthat grid based approach was computationally impractical, while using a tree of\nvoronoi planes (using scalable K-Means++ initial seeds) drastically\noutperformed the Kd-tree tree method as dimensionality increased."
    },
    "1810.13314": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Naman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Faltings",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Crowdsourcing with Fairness, Diversity and Budget Constraints",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent studies have shown that the labels collected from crowdworkers can be\ndiscriminatory with respect to sensitive attributes such as gender and race.\nThis raises questions about the suitability of using crowdsourced data for\nfurther use, such as for training machine learning algorithms. In this work, we\naddress the problem of fair and diverse data collection from a crowd under\nbudget constraints. We propose a novel algorithm which maximizes the expected\naccuracy of the collected data, while ensuring that the errors satisfy desired\nnotions of fairness. We provide guarantees on the performance of our algorithm\nand show that the algorithm performs well in practice through experiments on\nreal dataset."
    },
    "1405.2664": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-05-12",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-06-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ji"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Deyu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "FastMMD: Ensemble of Circular Discrepancy for Efficient Two-Sample Test",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Neural Computation, 2015 June, Vol. 27, No. 6, Pages 1345-1372",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1162/NECO_a_00732",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The maximum mean discrepancy (MMD) is a recently proposed test statistic for\ntwo-sample test. Its quadratic time complexity, however, greatly hampers its\navailability to large-scale applications. To accelerate the MMD calculation, in\nthis study we propose an efficient method called FastMMD. The core idea of\nFastMMD is to equivalently transform the MMD with shift-invariant kernels into\nthe amplitude expectation of a linear combination of sinusoid components based\non Bochner's theorem and Fourier transform (Rahimi & Recht, 2007). Taking\nadvantage of sampling of Fourier transform, FastMMD decreases the time\ncomplexity for MMD calculation from $O(N^2 d)$ to $O(L N d)$, where $N$ and $d$\nare the size and dimension of the sample set, respectively. Here $L$ is the\nnumber of basis functions for approximating kernels which determines the\napproximation accuracy. For kernels that are spherically invariant, the\ncomputation can be further accelerated to $O(L N \\log d)$ by using the Fastfood\ntechnique (Le et al., 2013). The uniform convergence of our method has also\nbeen theoretically proved in both unbiased and biased estimates. We have\nfurther provided a geometric explanation for our method, namely ensemble of\ncircular discrepancy, which facilitates us to understand the insight of MMD,\nand is hopeful to help arouse more extensive metrics for assessing two-sample\ntest. Experimental results substantiate that FastMMD is with similar accuracy\nas exact MMD, while with faster computation speed and lower variance than the\nexisting MMD approximation methods."
    },
    "1802.00530": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Phillip A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Loeb",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Davidow",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Gordon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Scalable L\\'evy Process Priors for Spectral Kernel Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Advances in Neural Information Processing Systems 30\n  (NIPS), 2017",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Advances in Neural Information Processing Systems 30 (NIPS), 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Gaussian processes are rich distributions over functions, with generalization\nproperties determined by a kernel function. When used for long-range\nextrapolation, predictions are particularly sensitive to the choice of kernel\nparameters. It is therefore critical to account for kernel uncertainty in our\npredictive distributions. We propose a distribution over kernels formed by\nmodelling a spectral mixture density with a L\\'evy process. The resulting\ndistribution has support for all stationary covariances--including the popular\nRBF, periodic, and Mat\\'ern kernels--combined with inductive biases which\nenable automatic and data efficient learning, long-range extrapolation, and\nstate of the art predictive performance. The proposed model also presents an\napproach to spectral regularization, as the L\\'evy process introduces a\nsparsity-inducing prior over mixture components, allowing automatic selection\nover model order and pruning of extraneous components. We exploit the algebraic\nstructure of the proposed process for $\\mathcal{O}(n)$ training and\n$\\mathcal{O}(1)$ predictions. We perform extrapolations having reasonable\nuncertainty estimates on several benchmarks, show that the proposed model can\nrecover flexible ground truth covariances and that it is robust to errors in\ninitialization."
    },
    "1802.08679": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Atan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Onur"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zame",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van der Schaar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Optimal Policies from Observational Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Choosing optimal (or at least better) policies is an important problem in\ndomains from medicine to education to finance and many others. One approach to\nthis problem is through controlled experiments/trials - but controlled\nexperiments are expensive. Hence it is important to choose the best policies on\nthe basis of observational data. This presents two difficult challenges: (i)\nmissing counterfactuals, and (ii) selection bias. This paper presents\ntheoretical bounds on estimation errors of counterfactuals from observational\ndata by making connections to domain adaptation theory. It also presents a\nprincipled way of choosing optimal policies using domain adversarial neural\nnetworks. We illustrate the effectiveness of domain adversarial training\ntogether with various features of our algorithm on a semi-synthetic breast\ncancer dataset and a supervised UCI dataset (Statlog)."
    },
    "1304.0564": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-04-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "VanderWeele",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tyler J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shpitser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ilya"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the definition of a confounder",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ME cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Published in at http://dx.doi.org/10.1214/12-AOS1058 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)",
        "http://arxiv.org/OAI/arXiv/:proxy": "vtex",
        "http://arxiv.org/OAI/arXiv/:report-no": "IMS-AOS-AOS1058",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 196-220",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1214/12-AOS1058",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The causal inference literature has provided a clear formal definition of\nconfounding expressed in terms of counterfactual independence. The literature\nhas not, however, come to any consensus on a formal definition of a confounder,\nas it has given priority to the concept of confounding over that of a\nconfounder. We consider a number of candidate definitions arising from various\nmore informal statements made in the literature. We consider the properties\nsatisfied by each candidate definition, principally focusing on (i) whether\nunder the candidate definition control for all \"confounders\" suffices to\ncontrol for \"confounding\" and (ii) whether each confounder in some context\nhelps eliminate or reduce confounding bias. Several of the candidate\ndefinitions do not have these two properties. Only one candidate definition of\nthose considered satisfies both properties. We propose that a \"confounder\" be\ndefined as a pre-exposure covariate C for which there exists a set of other\ncovariates X such that effect of the exposure on the outcome is unconfounded\nconditional on (X,C) but such that for no proper subset of (X,C) is the effect\nof the exposure on the outcome unconfounded given the subset. We also provide a\nconditional analogue of the above definition; and we propose a variable that\nhelps reduce bias but not eliminate bias be referred to as a \"surrogate\nconfounder.\" These definitions are closely related to those given by Robins and\nMorgenstern [Comput. Math. Appl. 14 (1987) 869-916]. The implications that hold\namong the various candidate definitions are discussed."
    },
    "1507.02439": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-07-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Olugbara",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oludayo O."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Joshi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Modiba",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bhavsar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Virendrakumar C."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automated Matchmaking to Improve Accuracy of Applicant Selection for\n  University Education System",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, 5 Text boxes, 2 tables and a figure",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The accurate applicant selection for university education is imperative to\nensure fairness and optimal use of institutional resources. Although various\napproaches are operational in tertiary educational institutions for selecting\napplicants, a novel method of automated matchmaking is explored in the current\nstudy. The method functions by matching a prospective students skills profile\nto a programmes requisites profile.\n  Empirical comparisons of the results, calculated by automated matchmaking and\ntwo other selection methods, show matchmaking to be a viable alternative for\naccurate selection of applicants. Matchmaking offers a unique advantage that it\nneither requires data from other applicants nor compares applicants with each\nother. Instead, it emphasises norms that define admissibility to a programme.\n  We have proposed the use of technology to minimize the gap between students\naspirations, skill sets and course requirements. It is a solution to minimize\nthe number of students who get frustrated because of mismatched course\nselection."
    },
    "1801.01705": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "van Otterlo",
                "http://arxiv.org/OAI/arXiv/:forenames": "Martijn"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Gatekeeping Algorithms with Human Ethical Bias: The ethics of algorithms\n  in archives, libraries and society",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted (Nov 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the age of algorithms, I focus on the question of how to ensure algorithms\nthat will take over many of our familiar archival and library tasks, will\nbehave according to human ethical norms that have evolved over many years. I\nstart by characterizing physical archives in the context of related\ninstitutions such as libraries and museums. In this setting I analyze how\nethical principles, in particular about access to information, have been\nformalized and communicated in the form of ethical codes, or: codes of\nconducts. After that I describe two main developments: digitalization, in which\nphysical aspects of the world are turned into digital data, and\nalgorithmization, in which intelligent computer programs turn this data into\npredictions and decisions. Both affect interactions that were once physical but\nnow digital. In this new setting I survey and analyze the ethical aspects of\nalgorithms and how they shape a vision on the future of archivists and\nlibrarians, in the form of algorithmic documentalists, or: codementalists.\nFinally I outline a general research strategy, called IntERMEeDIUM, to obtain\nalgorithms that obey are human ethical values encoded in code of ethics."
    },
    "1302.3607": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-02-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Teng",
                "http://arxiv.org/OAI/arXiv/:forenames": "Choh Man"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Possible World Partition Sequences: A Unifying Framework for Uncertain\n  Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1996-PG-517-524",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "When we work with information from multiple sources, the formalism each\nemploys to handle uncertainty may not be uniform. In order to be able to\ncombine these knowledge bases of different formats, we need to first establish\na common basis for characterizing and evaluating the different formalisms, and\nprovide a semantics for the combined mechanism. A common framework can provide\nan infrastructure for building an integrated system, and is essential if we are\nto understand its behavior. We present a unifying framework based on an ordered\npartition of possible worlds called partition sequences, which corresponds to\nour intuitive notion of biasing towards certain possible scenarios when we are\nuncertain of the actual situation. We show that some of the existing\nformalisms, namely, default logic, autoepistemic logic, probabilistic\nconditioning and thresholding (generalized conditioning), and possibility\ntheory can be incorporated into this general framework."
    },
    "1806.04234": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Endriss",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ulle"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Lecture Notes on Fair Division",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.GT",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fair division is the problem of dividing one or several goods amongst two or\nmore agents in a way that satisfies a suitable fairness criterion. These Notes\nprovide a succinct introduction to the field. We cover three main topics.\nFirst, we need to define what is to be understood by a \"fair\" allocation of\ngoods to individuals. We present an overview of the most important fairness\ncriteria (as well as the closely related criteria for economic efficiency)\ndeveloped in the literature, together with a short discussion of their\naxiomatic foundations. Second, we give an introduction to cake-cutting\nprocedures as an example of methods for fairly dividing a single divisible\nresource amongst a group of individuals. Third, we discuss the combinatorial\noptimisation problem of fairly allocating a set of indivisible goods to a group\nof agents, covering both centralised algorithms (similar to auctions) and a\ndistributed approach based on negotiation.\n  While the classical literature on fair division has largely developed within\nEconomics, these Notes are specifically written for readers with a background\nin Computer Science or similar, and who may be (or may wish to be) engaged in\nresearch in Artificial Intelligence, Multiagent Systems, or Computational\nSocial Choice. References for further reading, as well as a small number of\nexercises, are included.\n  Notes prepared for a tutorial at the 11th European Agent Systems Summer\nSchool (EASSS-2009), Torino, Italy, 31 August and 1 September 2009. Updated for\na tutorial at the COST-ADT Doctoral School on Computational Social Choice,\nEstoril, Portugal, 9--14 April 2010."
    },
    "1601.06071": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-01-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Minje"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smaragdis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paris"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bitwise Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "This paper was presented at the International Conference on Machine\n  Learning (ICML) Workshop on Resource-Efficient Machine Learning, Lille,\n  France, Jul. 6-11, 2015",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Based on the assumption that there exists a neural network that efficiently\nrepresents a set of Boolean functions between all binary inputs and outputs, we\npropose a process for developing and deploying neural networks whose weight\nparameters, bias terms, input, and intermediate hidden layer output signals,\nare all binary-valued, and require only basic bit logic for the feedforward\npass. The proposed Bitwise Neural Network (BNN) is especially suitable for\nresource-constrained environments, since it replaces either floating or\nfixed-point arithmetic with significantly more efficient bitwise operations.\nHence, the BNN requires for less spatial complexity, less memory bandwidth, and\nless power consumption in hardware. In order to design such networks, we\npropose to add a few training schemes, such as weight compression and noisy\nbackpropagation, which result in a bitwise network that performs almost as well\nas its corresponding real-valued network. We test the proposed network on the\nMNIST dataset, represented using binary features, and show that BNNs result in\ncompetitive performance while offering dramatic computational savings."
    },
    "1802.06108": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Freire",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ismael T."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moulin-Frier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Clement"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sanchez-Fibla",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marti"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Arsiwalla",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xerxes D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verschure",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paul"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling the Formation of Social Conventions in Multi-Agent Populations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.MA cs.AI cs.GT q-bio.NC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages, 12 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order to understand the formation of social conventions we need to know\nthe specific role of control and learning in multi-agent systems. To advance in\nthis direction, we propose, within the framework of the Distributed Adaptive\nControl (DAC) theory, a novel Control-based Reinforcement Learning architecture\n(CRL) that can account for the acquisition of social conventions in multi-agent\npopulations that are solving a benchmark social decision-making problem. Our\nnew CRL architecture, as a concrete realization of DAC multi-agent theory,\nimplements a low-level sensorimotor control loop handling the agent's reactive\nbehaviors (pre-wired reflexes), along with a layer based on model-free\nreinforcement learning that maximizes long-term reward. We apply CRL in a\nmulti-agent game-theoretic task in which coordination must be achieved in order\nto find an optimal solution. We show that our CRL architecture is able to both\nfind optimal solutions in discrete and continuous time and reproduce human\nexperimental data on standard game-theoretic metrics such as efficiency in\nacquiring rewards, fairness in reward distribution and stability of convention\nformation."
    },
    "1802.10463": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dewangan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Parijat"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Phaniteja",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "K Madhava"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sarkar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhishek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ravindran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Balaraman"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "DiGrad: Multi-Task Reinforcement Learning with Shared Actions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Most reinforcement learning algorithms are inefficient for learning multiple\ntasks in complex robotic systems, where different tasks share a set of actions.\nIn such environments a compound policy may be learnt with shared neural network\nparameters, which performs multiple tasks concurrently. However such compound\npolicy may get biased towards a task or the gradients from different tasks\nnegate each other, making the learning unstable and sometimes less data\nefficient. In this paper, we propose a new approach for simultaneous training\nof multiple tasks sharing a set of common actions in continuous action spaces,\nwhich we call as DiGrad (Differential Policy Gradient). The proposed framework\nis based on differential policy gradients and can accommodate multi-task\nlearning in a single actor-critic network. We also propose a simple heuristic\nin the differential policy gradient update to further improve the learning. The\nproposed architecture was tested on 8 link planar manipulator and 27 degrees of\nfreedom(DoF) Humanoid for learning multi-goal reachability tasks for 3 and 2\nend effectors respectively. We show that our approach supports efficient\nmulti-task learning in complex robotic systems, outperforming related methods\nin continuous action spaces."
    },
    "1706.09838": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sirui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bert"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "New Fairness Metrics for Recommendation that Embrace Differences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study fairness in collaborative-filtering recommender systems, which are\nsensitive to discrimination that exists in historical data. Biased data can\nlead collaborative filtering methods to make unfair predictions against\nminority groups of users. We identify the insufficiency of existing fairness\nmetrics and propose four new metrics that address different forms of\nunfairness. These fairness metrics can be optimized by adding fairness terms to\nthe learning objective. Experiments on synthetic and real data show that our\nnew metrics can better measure fairness than the baseline, and that the\nfairness objectives effectively help reduce unfairness."
    },
    "1802.00048": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Anderson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Damien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stephenson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Togelius",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Salge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Levine",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Renz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jochen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deceptive Games",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages, accepted at EvoStar2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deceptive games are games where the reward structure or other aspects of the\ngame are designed to lead the agent away from a globally optimal policy. While\nmany games are already deceptive to some extent, we designed a series of games\nin the Video Game Description Language (VGDL) implementing specific types of\ndeception, classified by the cognitive biases they exploit. VGDL games can be\nrun in the General Video Game Artificial Intelligence (GVGAI) Framework, making\nit possible to test a variety of existing AI agents that have been submitted to\nthe GVGAI Competition on these deceptive games. Our results show that all\ntested agents are vulnerable to several kinds of deception, but that different\nagents have different weaknesses. This suggests that we can use deception to\nunderstand the capabilities of a game-playing algorithm, and game-playing\nalgorithms to characterize the deception displayed by a game."
    },
    "1711.00549": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anjishnu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arpit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tucker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hoffmeister",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bjorn"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dreyer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Markus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peshterliev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stanislav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gandhe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ankur"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Filiminov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Denis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rastrow",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ariya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Monson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Agnika"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Just ASK: Building an Architecture for Extensible Self-Service Spoken\n  Language Understanding",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.NE cs.SE",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at the 1st Workshop on Conversational AI at NIPS 2017\n  (NIPS-WCAI)",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68T50",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper presents the design of the machine learning architecture that\nunderlies the Alexa Skills Kit (ASK) a large scale Spoken Language\nUnderstanding (SLU) Software Development Kit (SDK) that enables developers to\nextend the capabilities of Amazon's virtual assistant, Alexa. At Amazon, the\ninfrastructure powers over 25,000 skills deployed through the ASK, as well as\nAWS's Amazon Lex SLU Service. The ASK emphasizes flexibility, predictability\nand a rapid iteration cycle for third party developers. It imposes inductive\nbiases that allow it to learn robust SLU models from extremely small and sparse\ndatasets and, in doing so, removes significant barriers to entry for software\ndevelopers and dialogue systems researchers."
    },
    "1803.07233": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Epstein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ziv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Payne",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Blakeley H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Judy Hanwen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dubey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhimanyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Felbo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bjarke"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Groh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Obradovich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nick"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cebrian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manuel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rahwan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iyad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Closing the AI Knowledge Gap",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 3 figures, under review",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "AI researchers employ not only the scientific method, but also methodology\nfrom mathematics and engineering. However, the use of the scientific method -\nspecifically hypothesis testing - in AI is typically conducted in service of\nengineering objectives. Growing interest in topics such as fairness and\nalgorithmic bias show that engineering-focused questions only comprise a subset\nof the important questions about AI systems. This results in the AI Knowledge\nGap: the number of unique AI systems grows faster than the number of studies\nthat characterize these systems' behavior. To close this gap, we argue that the\nstudy of AI could benefit from the greater inclusion of researchers who are\nwell positioned to formulate and test hypotheses about the behavior of AI\nsystems. We examine the barriers preventing social and behavioral scientists\nfrom conducting such studies. Our diagnosis suggests that accelerating the\nscientific study of AI systems requires new incentives for academia and\nindustry, mediated by new tools and institutions. To address these needs, we\npropose a two-sided marketplace called TuringBox. On one side, AI contributors\nupload existing and novel algorithms to be studied scientifically by others. On\nthe other side, AI examiners develop and post machine intelligence tasks\ndesigned to evaluate and characterize algorithmic behavior. We discuss this\nmarket's potential to democratize the scientific study of AI behavior, and thus\nnarrow the AI Knowledge Gap."
    },
    "1202.2770": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-02-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2012-06-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Salavati",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amir Hesam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Karbasi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multi-Level Error-Resilient Neural Networks with Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.IT math.IT",
        "http://arxiv.org/OAI/arXiv/:comments": "Part of this draft has been submitted to International Symposium on\n  Information Theory (ISIT) 2012",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The problem of neural network association is to retrieve a previously\nmemorized pattern from its noisy version using a network of neurons. An ideal\nneural network should include three components simultaneously: a learning\nalgorithm, a large pattern retrieval capacity and resilience against noise.\nPrior works in this area usually improve one or two aspects at the cost of the\nthird.\n  Our work takes a step forward in closing this gap. More specifically, we show\nthat by forcing natural constraints on the set of learning patterns, we can\ndrastically improve the retrieval capacity of our neural network. Moreover, we\ndevise a learning algorithm whose role is to learn those patterns satisfying\nthe above mentioned constraints. Finally we show that our neural network can\ncope with a fair amount of noise."
    },
    "1603.03795": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-03-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Volz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vanessa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rudolph",
                    "http://arxiv.org/OAI/arXiv/:forenames": "G\u00fcnter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Naujoks",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boris"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Demonstrating the Feasibility of Automatic Game Balancing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Game balancing is an important part of the (computer) game design process, in\nwhich designers adapt a game prototype so that the resulting gameplay is as\nentertaining as possible. In industry, the evaluation of a game is often based\non costly playtests with human players. It suggests itself to automate this\nprocess using surrogate models for the prediction of gameplay and outcome. In\nthis paper, the feasibility of automatic balancing using simulation- and\ndeck-based objectives is investigated for the card game top trumps.\nAdditionally, the necessity of a multi-objective approach is asserted by a\ncomparison with the only known (single-objective) method. We apply a\nmulti-objective evolutionary algorithm to obtain decks that optimise\nobjectives, e.g. win rate and average number of tricks, developed to express\nthe fairness and the excitement of a game of top trumps. The results are\ncompared with decks from published top trumps decks using simulation-based\nobjectives. The possibility to generate decks better or at least as good as\ndecks from published top trumps decks in terms of these objectives is\ndemonstrated. Our results indicate that automatic balancing with the presented\napproach is feasible even for more complex games such as real-time strategy\ngames."
    },
    "1303.2860": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "M\u00fchlenthaler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moritz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wanka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rolf"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness in Academic Course Timetabling",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DS",
        "http://arxiv.org/OAI/arXiv/:comments": "appeared in PATAT 2012, pp. 114-130",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.8; F.2.2",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s10479-014-1553-2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We consider the problem of creating fair course timetables in the setting of\na university. Our motivation is to improve the overall satisfaction of\nindividuals concerned (students, teachers, etc.) by providing a fair timetable\nto them. The central idea is that undesirable arrangements in the course\ntimetable, i.e., violations of soft constraints, should be distributed in a\nfair way among the individuals. We propose two formulations for the fair course\ntimetabling problem that are based on max-min fairness and Jain's fairness\nindex, respectively. Furthermore, we present and experimentally evaluate an\noptimization algorithm based on simulated annealing for solving max-min fair\ncourse timetabling problems. The new contribution is concerned with measuring\nthe energy difference between two timetables, i.e., how much worse a timetable\nis compared to another timetable with respect to max-min fairness. We introduce\nthree different energy difference measures and evaluate their impact on the\noverall algorithm performance. The second proposed problem formulation focuses\non the tradeoff between fairness and the total amount of soft constraint\nviolations. Our experimental evaluation shows that the known best solutions to\nthe ITC2007 curriculum-based course timetabling instances are quite fair with\nrespect to Jain's fairness index. However, the experiments also show that the\nfairness can be improved further for only a rather small increase in the total\namount of soft constraint violations."
    },
    "1705.10694": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rolnick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veit",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Belongie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shavit",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nir"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Learning is Robust to Massive Label Noise",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks trained on large supervised datasets have led to\nimpressive results in image classification and other tasks. However,\nwell-annotated datasets can be time-consuming and expensive to collect, lending\nincreased interest to larger but noisy datasets that are more easily obtained.\nIn this paper, we show that deep neural networks are capable of generalizing\nfrom training data for which true labels are massively outnumbered by incorrect\nlabels. We demonstrate remarkably high test performance after training on\ncorrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain\ntest accuracy above 90 percent even after each clean training example has been\ndiluted with 100 randomly-labeled examples. Such behavior holds across multiple\npatterns of label noise, even when erroneous labels are biased towards\nconfusing classes. We show that training in this regime requires a significant\nbut manageable increase in dataset size that is related to the factor by which\ncorrect labels have been diluted. Finally, we provide an analysis of our\nresults that shows how increasing noise decreases the effective batch size."
    },
    "1510.01344": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-10-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Havaei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Larochelle",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hugo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poulin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philippe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jodoin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre-Marc"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Within-Brain Classification for Brain Tumor Segmentation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s11548-015-1311-1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Purpose: In this paper, we investigate a framework for interactive brain\ntumor segmentation which, at its core, treats the problem of interactive brain\ntumor segmentation as a machine learning problem.\n  Methods: This method has an advantage over typical machine learning methods\nfor this task where generalization is made across brains. The problem with\nthese methods is that they need to deal with intensity bias correction and\nother MRI-specific noise. In this paper, we avoid these issues by approaching\nthe problem as one of within brain generalization. Specifically, we propose a\nsemi-automatic method that segments a brain tumor by training and generalizing\nwithin that brain only, based on some minimum user interaction.\n  Conclusion: We investigate how adding spatial feature coordinates (i.e. $i$,\n$j$, $k$) to the intensity features can significantly improve the performance\nof different classification methods such as SVM, kNN and random forests. This\nwould only be possible within an interactive framework. We also investigate the\nuse of a more appropriate kernel and the adaptation of hyper-parameters\nspecifically for each brain.\n  Results: As a result of these experiments, we obtain an interactive method\nwhose results reported on the MICCAI-BRATS 2013 dataset are the second most\naccurate compared to published methods, while using significantly less memory\nand processing power than most state-of-the-art methods."
    },
    "1807.02799": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-07-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shah",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haseeb"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Javed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Khurram"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shafait",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Faisal"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Distillation Techniques for Pseudo-rehearsal Based Incremental Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The ability to learn from incrementally arriving data is essential for any\nlife-long learning system. However, standard deep neural networks forget the\nknowledge about the old tasks, a phenomenon called catastrophic forgetting,\nwhen trained on incrementally arriving data. We discuss the biases in current\nGenerative Adversarial Networks (GAN) based approaches that learn the\nclassifier by knowledge distillation from previously trained classifiers. These\nbiases cause the trained classifier to perform poorly. We propose an approach\nto remove these biases by distilling knowledge from the classifier of AC-GAN.\nExperiments on MNIST and CIFAR10 show that this method is comparable to current\nstate of the art rehearsal based approaches. The code for this paper is\navailable at https://bit.ly/incremental-learning"
    },
    "1412.6614": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-12-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-04-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Neyshabur",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Behnam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tomioka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryota"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Srebro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nathan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "In Search of the Real Inductive Bias: On the Role of Implicit\n  Regularization in Deep Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present experiments demonstrating that some other form of capacity\ncontrol, different from network size, plays a central role in learning\nmultilayer feed-forward networks. We argue, partially through analogy to matrix\nfactorization, that this is an inductive bias that can help shed light on deep\nlearning."
    },
    "1401.0102": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-12-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-12-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zamani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mahdi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Movahedi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mahnush"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ebadzadeh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedram",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hossein"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A DDoS-Aware IDS Model Based on Danger Theory and Mobile Agents",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DC cs.AI cs.CR cs.MA",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 3 figure",
        "http://arxiv.org/OAI/arXiv/:acm-class": "C.2.1; C.2.2; I.2.11; C.2.0",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an artificial immune model for intrusion detection in distributed\nsystems based on a relatively recent theory in immunology called Danger theory.\nBased on Danger theory, immune response in natural systems is a result of\nsensing corruption as well as sensing unknown substances. In contrast,\ntraditional self-nonself discrimination theory states that immune response is\nonly initiated by sensing nonself (unknown) patterns. Danger theory solves many\nproblems that could only be partially explained by the traditional model.\nAlthough the traditional model is simpler, such problems result in high false\npositive rates in immune-inspired intrusion detection systems. We believe using\ndanger theory in a multi-agent environment that computationally emulates the\nbehavior of natural immune systems is effective in reducing false positive\nrates. We first describe a simplified scenario of immune response in natural\nsystems based on danger theory and then, convert it to a computational model as\na network protocol. In our protocol, we define several immune signals and model\ncell signaling via message passing between agents that emulate cells. Most\nmessages include application-specific patterns that must be meaningfully\nextracted from various system properties. We show how to model these messages\nin practice by performing a case study on the problem of detecting distributed\ndenial-of-service attacks in wireless sensor networks. We conduct a set of\nsystematic experiments to find a set of performance metrics that can accurately\ndistinguish malicious patterns. The results indicate that the system can be\nefficiently used to detect malicious patterns with a high level of accuracy."
    },
    "1806.06301": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sutton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lansdall-Welfare",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cristianini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nello"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Biased Embeddings from Wild Data: Measuring, Understanding and Removing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Author's original version",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many modern Artificial Intelligence (AI) systems make use of data embeddings,\nparticularly in the domain of Natural Language Processing (NLP). These\nembeddings are learnt from data that has been gathered \"from the wild\" and have\nbeen found to contain unwanted biases. In this paper we make three\ncontributions towards measuring, understanding and removing this problem. We\npresent a rigorous way to measure some of these biases, based on the use of\nword lists created for social psychology applications; we observe how gender\nbias in occupations reflects actual gender bias in the same occupations in the\nreal world; and finally we demonstrate how a simple projection can\nsignificantly reduce the effects of embedding bias. All this is part of an\nongoing effort to understand how trust can be built into AI systems."
    },
    "1810.01729": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Besse",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philippe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Castets-Renard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Celine"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garivier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aurelien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Loubes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jean-Michel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Can everyday AI be ethical. Fairness of Machine Learning Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.OT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "in French. L'IA du quotidien peut-elle \\^etre \\'ethique. Loyaut\\'e\n  des Algorithmes d'apprentissage automatique",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Combining big data and machine learning algorithms, the power of automatic\ndecision tools induces as much hope as fear. Many recently enacted European\nlegislation (GDPR) and French laws attempt to regulate the use of these tools.\nLeaving aside the well-identified problems of data confidentiality and\nimpediments to competition, we focus on the risks of discrimination, the\nproblems of transparency and the quality of algorithmic decisions. The detailed\nperspective of the legal texts, faced with the complexity and opacity of the\nlearning algorithms, reveals the need for important technological disruptions\nfor the detection or reduction of the discrimination risk, and for addressing\nthe right to obtain an explanation of the auto- matic decision. Since trust of\nthe developers and above all of the users (citizens, litigants, customers) is\nessential, algorithms exploiting personal data must be deployed in a strict\nethical framework. In conclusion, to answer this need, we list some ways of\ncontrols to be developed: institutional control, ethical charter, external\naudit attached to the issue of a label."
    },
    "1204.2248": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-04-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jun-Ming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bhargava",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniruddha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nowak",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaojin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Robust Spatio-Temporal Signal Recovery from Noisy Counts in Social Media",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.SI",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many real-world phenomena can be represented by a spatio-temporal signal:\nwhere, when, and how much. Social media is a tantalizing data source for those\nwho wish to monitor such signals. Unlike most prior work, we assume that the\ntarget phenomenon is known and we are given a method to count its occurrences\nin social media. However, counting is plagued by sample bias, incomplete data,\nand, paradoxically, data scarcity -- issues inadequately addressed by prior\nwork. We formulate signal recovery as a Poisson point process estimation\nproblem. We explicitly incorporate human population bias, time delays and\nspatial distortions, and spatio-temporal regularization into the model to\naddress the noisy count issues. We present an efficient optimization algorithm\nand discuss its theoretical properties. We show that our model is more accurate\nthan commonly-used baselines. Finally, we present a case study on wildlife\nroadkill monitoring, where our model produces qualitatively convincing results."
    },
    "1805.06549": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madhyastha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranava"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josiah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Specia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lucia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Defoiling Foiled Image Captions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address the task of detecting foiled image captions, i.e. identifying\nwhether a caption contains a word that has been deliberately replaced by a\nsemantically similar word, thus rendering it inaccurate with respect to the\nimage being described. Solving this problem should in principle require a\nfine-grained understanding of images to detect linguistically valid\nperturbations in captions. In such contexts, encoding sufficiently descriptive\nimage information becomes a key challenge. In this paper, we demonstrate that\nit is possible to solve this task using simple, interpretable yet powerful\nrepresentations based on explicit object information. Our models achieve\nstate-of-the-art performance on a standard dataset, with scores exceeding those\nachieved by humans on the task. We also measure the upper-bound performance of\nour models using gold standard annotations. Our analysis reveals that the\nsimpler model performs well even without image information, suggesting that the\ndataset contains strong linguistic bias."
    },
    "cs_0611104": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2006-11-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mouraud",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anthony",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "ISC, GRIMAAG"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paugam-Moisy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "H\u00e9l\u00e8ne",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "ISC"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning and discrimination through STDP in a top-down modulated\n  associative memory",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "ccsd hal-00115420",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of 14 European Symposium on Artificial Neural Networks\n  (ESANN 2006) (03/2006) 611-616",
        "http://arxiv.org/OAI/arXiv/:abstract": "This article underlines the learning and discrimination capabilities of a\nmodel of associative memory based on artificial networks of spiking neurons.\nInspired from neuropsychology and neurobiology, the model implements top-down\nmodulations, as in neocortical layer V pyramidal neurons, with a learning rule\nbased on synaptic plasticity (STDP), for performing a multimodal association\nlearning task. A temporal correlation method of analysis proves the ability of\nthe model to associate specific activity patterns to different samples of\nstimulation. Even in the absence of initial learning and with continuously\nvarying weights, the activity patterns become stable enough for discrimination."
    },
    "1712.04323": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gallicchio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Claudio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Micheli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Echo State Network (DeepESN): A Brief Survey",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The study of deep recurrent neural networks (RNNs) and, in particular, of\ndeep Reservoir Computing (RC) is gaining an increasing research attention in\nthe neural networks community. The recently introduced deep Echo State Network\n(deepESN) model opened the way to an extremely efficient approach for designing\ndeep neural networks for temporal data. At the same time, the study of deepESNs\nallowed to shed light on the intrinsic properties of state dynamics developed\nby hierarchical compositions of recurrent layers, i.e. on the bias of depth in\nRNNs architectural design. In this paper, we summarize the advancements in the\ndevelopment, analysis and applications of deepESNs."
    },
    "1705.09207": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lapata",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mirella"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Structured Text Representations",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "change to one-based indexing, published in Transactions of the\n  Association for Computational Linguistics (TACL),\n  https://transacl.org/ojs/index.php/tacl/article/view/1185/280",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we focus on learning structure-aware document representations\nfrom data without recourse to a discourse parser or additional annotations.\nDrawing inspiration from recent efforts to empower neural networks with a\nstructural bias, we propose a model that can encode a document while\nautomatically inducing rich structural dependencies. Specifically, we embed a\ndifferentiable non-projective parsing algorithm into a neural model and use\nattention mechanisms to incorporate the structural biases. Experimental\nevaluation across different tasks and datasets shows that the proposed model\nachieves state-of-the-art results on document modeling tasks while inducing\nintermediate structures which are both interpretable and meaningful."
    },
    "1809.07193": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-11-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xinghai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiechao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ji"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongsheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Han"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in\n  the Full Game",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Starcraft II (SC2) is widely considered as the most challenging Real Time\nStrategy (RTS) game. The underlying challenges include a large observation\nspace, a huge (continuous and infinite) action space, partial observations,\nsimultaneous move for all players, and long horizon delayed rewards for local\ndecisions. To push the frontier of AI research, Deepmind and Blizzard jointly\ndeveloped the StarCraft II Learning Environment (SC2LE) as a testbench of\ncomplex decision making systems. SC2LE provides a few mini games such as\nMoveToBeacon, CollectMineralShards, and DefeatRoaches, where some AI agents\nhave achieved the performance level of human professional players. However, for\nfull games, the current AI agents are still far from achieving human\nprofessional level performance. To bridge this gap, we present two full game AI\nagents in this paper - the AI agent TStarBot1 is based on deep reinforcement\nlearning over a flat action structure, and the AI agent TStarBot2 is based on\nhard-coded rules over a hierarchical action structure. Both TStarBot1 and\nTStarBot2 are able to defeat the built-in AI agents from level 1 to level 10 in\na full game (1v1 Zerg-vs-Zerg game on the AbyssalReef map), noting that level\n8, level 9, and level 10 are cheating agents with unfair advantages such as\nfull vision on the whole map and resource harvest boosting. To the best of our\nknowledge, this is the first public work to investigate AI agents that can\ndefeat the built-in AI in the StarCraft II full game."
    },
    "1811.03654": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saxena",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nripsuta"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "DeFilippis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Evan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Radanovic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Goran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parkes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "How Do Fairness Definitions Fare? Examining Public Attitudes Towards\n  Algorithmic Definitions of Fairness",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "What is the best way to define algorithmic fairness? There has been much\nrecent debate on algorithmic fairness. While many definitions of fairness have\nbeen proposed in the computer science literature, there is no clear agreement\nover a particular definition. In this work, we investigate ordinary people's\nperceptions of three of these fairness definitions. Across two online\nexperiments, we test which definitions people perceive to be the fairest in the\ncontext of loan decisions, and whether those fairness perceptions change with\nthe addition of sensitive information (i.e., race of the loan applicants). We\nfind a clear preference for one definition, and the general results seem to\nalign with the principle of affirmative action."
    },
    "1009.1446": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-09-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brahma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aseem"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Das",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanmay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Magdon-Ismail",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Malik"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Comparing Prediction Market Structures, With an Application to Market\n  Making",
        "http://arxiv.org/OAI/arXiv/:categories": "q-fin.TR cs.AI cs.CE",
        "http://arxiv.org/OAI/arXiv/:acm-class": "J.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Ensuring sufficient liquidity is one of the key challenges for designers of\nprediction markets. Various market making algorithms have been proposed in the\nliterature and deployed in practice, but there has been little effort to\nevaluate their benefits and disadvantages in a systematic manner. We introduce\na novel experimental design for comparing market structures in live trading\nthat ensures fair comparison between two different microstructures with the\nsame trading population. Participants trade on outcomes related to a\ntwo-dimensional random walk that they observe on their computer screens. They\ncan simultaneously trade in two markets, corresponding to the independent\nhorizontal and vertical random walks. We use this experimental design to\ncompare the popular inventory-based logarithmic market scoring rule (LMSR)\nmarket maker and a new information based Bayesian market maker (BMM). Our\nexperiments reveal that BMM can offer significant benefits in terms of price\nstability and expected loss when controlling for liquidity; the caveat is that,\nunlike LMSR, BMM does not guarantee bounded loss. Our investigation also\nelucidates some general properties of market makers in prediction markets. In\nparticular, there is an inherent tradeoff between adaptability to market shocks\nand convergence during market equilibrium."
    },
    "1810.07254": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Spielberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yitzhak"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Azaria",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Concept of Criticality in Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.MA stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Reinforcement learning methods carry a well known bias-variance trade-off in\nn-step algorithms for optimal control. Unfortunately, this has rarely been\naddressed in current research. This trade-off principle holds independent of\nthe choice of the algorithm, such as n-step SARSA, n-step Expected SARSA or\nn-step Tree backup. A small n results in a large bias, while a large n leads to\nlarge variance. The literature offers no straightforward recipe for the best\nchoice of this value. While currently all n-step algorithms use a fixed value\nof n over the state space we extend the framework of n-step updates by allowing\neach state to have its specific n.\n  We propose a solution to this problem within the context of human aided\nreinforcement learning. Our approach is based on the observation that a human\ncan learn more efficiently if she receives input regarding the criticality of a\ngiven state and thus the amount of attention she needs to invest into the\nlearning in that state. This observation is related to the idea that each state\nof the MDP has a certain measure of criticality which indicates how much the\nchoice of the action in that state influences the return. In our algorithm the\nRL agent utilizes the criticality measure, a function provided by a human\ntrainer, in order to locally choose the best stepnumber n for the update of the\nQ function."
    },
    "1710.01691": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kun Ho"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mac Aodha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oisin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perona",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pietro"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Context Embedding Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "CVPR 2018 spotlight",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Low dimensional embeddings that capture the main variations of interest in\ncollections of data are important for many applications. One way to construct\nthese embeddings is to acquire estimates of similarity from the crowd. However,\nsimilarity is a multi-dimensional concept that varies from individual to\nindividual. Existing models for learning embeddings from the crowd typically\nmake simplifying assumptions such as all individuals estimate similarity using\nthe same criteria, the list of criteria is known in advance, or that the crowd\nworkers are not influenced by the data that they see. To overcome these\nlimitations we introduce Context Embedding Networks (CENs). In addition to\nlearning interpretable embeddings from images, CENs also model worker biases\nfor different attributes along with the visual context i.e. the visual\nattributes highlighted by a set of images. Experiments on two noisy crowd\nannotated datasets show that modeling both worker bias and visual context\nresults in more interpretable embeddings compared to existing approaches."
    },
    "1308.0702": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-08-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Potapov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rodionov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergey"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Universal Empathy and Ethical Bias for Artificial General Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "AGI Impacts conference 2012 paper",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Rational agents are usually built to maximize rewards. However, AGI agents\ncan find undesirable ways of maximizing any prior reward function. Therefore\nvalue learning is crucial for safe AGI. We assume that generalized states of\nthe world are valuable - not rewards themselves, and propose an extension of\nAIXI, in which rewards are used only to bootstrap hierarchical value learning.\nThe modified AIXI agent is considered in the multi-agent environment, where\nother agents can be either humans or other \"mature\" agents, which values should\nbe revealed and adopted by the \"infant\" AGI agent. General framework for\ndesigning such empathic agent with ethical bias is proposed also as an\nextension of the universal intelligence model. Moreover, we perform experiments\nin the simple Markov environment, which demonstrate feasibility of our approach\nto value learning in safe AGI."
    },
    "1206.6852": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-06-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mansinghka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vikash"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kemp",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Griffiths",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Structured Priors for Structure Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2006-PG-324-331",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Traditional approaches to Bayes net structure learning typically assume\nlittle regularity in graph structure other than sparseness. However, in many\ncases, we expect more systematicity: variables in real-world systems often\ngroup into classes that predict the kinds of probabilistic dependencies they\nparticipate in. Here we capture this form of prior knowledge in a hierarchical\nBayesian framework, and exploit it to enable structure learning and type\ndiscovery from small datasets. Specifically, we present a nonparametric\ngenerative model for directed acyclic graphs as a prior for Bayes net structure\nlearning. Our model assumes that variables come in one or more classes and that\nthe prior probability of an edge existing between two variables is a function\nonly of their classes. We derive an MCMC algorithm for simultaneous inference\nof the number of classes, the class assignments of variables, and the Bayes net\nstructure over variables. For several realistic, sparse datasets, we show that\nthe bias towards systematicity of connections provided by our model yields more\naccurate learned networks than a traditional, uniform prior approach, and that\nthe classes found by our model are appropriate."
    },
    "1810.13329": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Doyun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yim",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Han Young"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanghyuck"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Changgwun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Inyup"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Convolutional Neural Network Quantization using Generalized Gamma\n  Distribution",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As edge applications using convolutional neural networks (CNN) models grow,\nit is becoming necessary to introduce dedicated hardware accelerators in which\nnetwork parameters and feature-map data are represented with limited precision.\nIn this paper we propose a novel quantization algorithm for energy-efficient\ndeployment of the hardware accelerators. For weights and biases, the optimal\nbit length of the fractional part is determined so that the quantization error\nis minimized over their distribution. For feature-map data, meanwhile, their\nsample distribution is well approximated with the generalized gamma\ndistribution (GGD), and accordingly the optimal quantization step size can be\nobtained through the asymptotical closed form solution of GGD. The proposed\nquantization algorithm has a higher signal-to-quantization-noise ratio (SQNR)\nthan other quantization schemes previously proposed for CNNs, and even can be\nmore improved by tuning the quantization parameters, resulting in efficient\nimplementation of the hardware accelerators for CNNs in terms of power\nconsumption and memory bandwidth."
    },
    "1801.09354": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zaidi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nayyar A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Webb",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Geoffrey I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Petitjean",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francois"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Forestier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Germain"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the Inter-relationships among Drift rate, Forgetting rate,\n  Bias/variance profile and Error",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose two general and falsifiable hypotheses about expectations on\ngeneralization error when learning in the context of concept drift. One posits\nthat as drift rate increases, the forgetting rate that minimizes generalization\nerror will also increase and vice versa. The other posits that as a learner's\nforgetting rate increases, the bias/variance profile that minimizes\ngeneralization error will have lower variance and vice versa. These hypotheses\nlead to the concept of the sweet path, a path through the 3-d space of\nalternative drift rates, forgetting rates and bias/variance profiles on which\ngeneralization error will be minimized, such that slow drift is coupled with\nlow forgetting and low bias, while rapid drift is coupled with fast forgetting\nand low variance. We present experiments that support the existence of such a\nsweet path. We also demonstrate that simple learners that select appropriate\nforgetting rates and bias/variance profiles are highly competitive with the\nstate-of-the-art in incremental learners for concept drift on real-world drift\nproblems."
    },
    "cs_0503044": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2005-03-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haixia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moore",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cristopher"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Strain",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Doug"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generating Hard Satisfiable Formulas by Hiding Solutions Deceptively",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cond-mat.other cond-mat.stat-mech",
        "http://arxiv.org/OAI/arXiv/:comments": "6 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:abstract": "To test incomplete search algorithms for constraint satisfaction problems\nsuch as 3-SAT, we need a source of hard, but satisfiable, benchmark instances.\nA simple way to do this is to choose a random truth assignment A, and then\nchoose clauses randomly from among those satisfied by A. However, this method\ntends to produce easy problems, since the majority of literals point toward the\n``hidden'' assignment A. Last year, Achlioptas, Jia and Moore proposed a\nproblem generator that cancels this effect by hiding both A and its complement.\nWhile the resulting formulas appear to be just as hard for DPLL algorithms as\nrandom 3-SAT formulas with no hidden assignment, they can be solved by WalkSAT\nin only polynomial time. Here we propose a new method to cancel the attraction\nto A, by choosing a clause with t > 0 literals satisfied by A with probability\nproportional to q^t for some q < 1. By varying q, we can generate formulas\nwhose variables have no bias, i.e., which are equally likely to be true or\nfalse; we can even cause the formula to ``deceptively'' point away from A. We\npresent theoretical and experimental results suggesting that these formulas are\nexponentially hard both for DPLL algorithms and for incomplete algorithms such\nas WalkSAT."
    },
    "1711.07111": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vasconcelos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marisa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cardonha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gon\u00e7alves",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernardo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling Epistemological Principles for Bias Mitigation in AI Systems:\n  An Illustration in Hiring Decisions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial Intelligence (AI) has been used extensively in automatic decision\nmaking in a broad variety of scenarios, ranging from credit ratings for loans\nto recommendations of movies. Traditional design guidelines for AI models focus\nessentially on accuracy maximization, but recent work has shown that\neconomically irrational and socially unacceptable scenarios of discrimination\nand unfairness are likely to arise unless these issues are explicitly\naddressed. This undesirable behavior has several possible sources, such as\nbiased datasets used for training that may not be detected in black-box models.\nAfter pointing out connections between such bias of AI and the problem of\ninduction, we focus on Popper's contributions after Hume's, which offer a\nlogical theory of preferences. An AI model can be preferred over others on\npurely rational grounds after one or more attempts at refutation based on\naccuracy and fairness. Inspired by such epistemological principles, this paper\nproposes a structured approach to mitigate discrimination and unfairness caused\nby bias in AI systems. In the proposed computational framework, models are\nselected and enhanced after attempts at refutation. To illustrate our\ndiscussion, we focus on hiring decision scenarios where an AI system filters in\nwhich job applicants should go to the interview phase."
    },
    "1810.00694": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zennaro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fabio Massimo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ivanovska",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Magdalena"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Counterfactually Fair Prediction Using Multiple Causal Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "18 pages, 5 figures, conference paper. arXiv admin note: text overlap\n  with arXiv:1805.09866",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper we study the problem of making predictions using multiple\nstructural casual models defined by different agents, under the constraint that\nthe prediction satisfies the criterion of counterfactual fairness. Relying on\nthe frameworks of causality, fairness and opinion pooling, we build upon and\nextend previous work focusing on the qualitative aggregation of causal Bayesian\nnetworks and causal models. In order to complement previous qualitative\nresults, we devise a method based on Monte Carlo simulations. This method\nenables a decision-maker to aggregate the outputs of the causal models provided\nby different experts while guaranteeing the counterfactual fairness of the\nresult. We demonstrate our approach on a simple, yet illustrative, toy case\nstudy."
    },
    "1004.1061": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-04-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuexian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tingxu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dawei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wenjie"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Tsallis Entropy Bias and Generalized Maximum Entropy Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cond-mat.stat-mech cs.AI cs.IT math.IT",
        "http://arxiv.org/OAI/arXiv/:comments": "29 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In density estimation task, maximum entropy model (Maxent) can effectively\nuse reliable prior information via certain constraints, i.e., linear\nconstraints without empirical parameters. However, reliable prior information\nis often insufficient, and the selection of uncertain constraints becomes\nnecessary but poses considerable implementation complexity. Improper setting of\nuncertain constraints can result in overfitting or underfitting. To solve this\nproblem, a generalization of Maxent, under Tsallis entropy framework, is\nproposed. The proposed method introduces a convex quadratic constraint for the\ncorrection of (expected) Tsallis entropy bias (TEB). Specifically, we\ndemonstrate that the expected Tsallis entropy of sampling distributions is\nsmaller than the Tsallis entropy of the underlying real distribution. This\nexpected entropy reduction is exactly the (expected) TEB, which can be\nexpressed by a closed-form formula and act as a consistent and unbiased\ncorrection. TEB indicates that the entropy of a specific sampling distribution\nshould be increased accordingly. This entails a quantitative re-interpretation\nof the Maxent principle. By compensating TEB and meanwhile forcing the\nresulting distribution to be close to the sampling distribution, our\ngeneralized TEBC Maxent can be expected to alleviate the overfitting and\nunderfitting. We also present a connection between TEB and Lidstone estimator.\nAs a result, TEB-Lidstone estimator is developed by analytically identifying\nthe rate of probability correction in Lidstone. Extensive empirical evaluation\nshows promising performance of both TEBC Maxent and TEB-Lidstone in comparison\nwith various state-of-the-art density estimation methods."
    },
    "1309.6824": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-09-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Claassen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mooij",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heskes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Sparse Causal Models is not NP-hard",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2013-PG-172-181",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper shows that causal model discovery is not an NP-hard problem, in\nthe sense that for sparse graphs bounded by node degree k the sound and\ncomplete causal model can be obtained in worst case order N^{2(k+2)}\nindependence tests, even when latent variables and selection bias may be\npresent. We present a modification of the well-known FCI algorithm that\nimplements the method for an independence oracle, and suggest improvements for\nsample/real-world data versions. It does not contradict any known hardness\nresults, and does not solve an NP-hard problem: it just proves that sparse\ncausal discovery is perhaps more complicated, but not as hard as learning\nminimal Bayesian networks."
    },
    "1802.03916": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-12",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lipton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zachary C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu-Xiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smola",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Detecting and Correcting for Label Shift with Black Box Predictors",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Faced with distribution shift between training and test set, we wish to\ndetect and quantify the shift, and to correct our classifiers without test set\nlabels. Motivated by medical diagnosis, where diseases (targets), cause\nsymptoms (observations), we focus on label shift, where the label marginal\n$p(y)$ changes but the conditional $p(x|y)$ does not. We propose Black Box\nShift Estimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploits\narbitrary black box predictors to reduce dimensionality prior to shift\ncorrection. While better predictors give tighter estimates, BBSE works even\nwhen predictors are biased, inaccurate, or uncalibrated, so long as their\nconfusion matrices are invertible. We prove BBSE's consistency, bound its\nerror, and introduce a statistical test that uses BBSE to detect shift. We also\nleverage BBSE to correct classifiers. Experiments demonstrate accurate\nestimates and improved prediction, even on high-dimensional datasets of natural\nimages."
    },
    "1804.08138": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Michieli",
                "http://arxiv.org/OAI/arXiv/:forenames": "Umberto"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Complex Network Analysis of Men Single ATP Tennis Matches",
        "http://arxiv.org/OAI/arXiv/:categories": "physics.soc-ph cs.AI cs.NI",
        "http://arxiv.org/OAI/arXiv/:comments": "Dataset:\n  https://drive.google.com/open?id=1mCxZfkkpIC9o-nxZ1yW3GBBdvBOPW6mQ 12 pages,\n  15 figures, 6 tables",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Who are the most significant players in the history of men tennis? Is the\nofficial ATP ranking system fair in evaluating players scores? Which players\ndeserved the most contemplation looking at their match records? Which players\nhave never faced yet and are likely to play against in the future? Those are\njust some of the questions developed in this paper supported by data updated at\nApril 2018. In order to give an answer to the aforementioned questions, complex\nnetwork science techniques have been applied to some representations of the\nnetwork of men singles tennis matches. Additionally, a new predictive algorithm\nis proposed in order to forecast the winner of a match."
    },
    "1803.03114": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abu-Khzam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Faisal N."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mouawi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rana H."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Concise Fuzzy Representation of Big Graphs: a Dimensionality Reduction\n  Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The enormous amount of data to be represented using large graphs exceeds in\nsome cases the resources of a conventional computer. Edges in particular can\ntake up a considerable amount of memory as compared to the number of nodes.\nHowever, rigorous edge storage might not always be essential to be able to draw\nthe needed conclusions. A similar problem takes records with many variables and\nattempts to extract the most discernible features. It is said that the\n\"dimension\" of this data is reduced. Following an approach with the same\nobjective in mind, we can map a graph representation to a k-dimensional space\nand answer queries of neighboring nodes by measuring Euclidean distances. The\naccuracy of our answers would decrease but would be compensated for by fuzzy\nlogic which gives an idea about the likelihood of error. This method allows for\nreasonable representation in memory while maintaining a fair amount of useful\ninformation. Promising preliminary results are obtained and reported by testing\nthe proposed approach on a number of Facebook graphs."
    },
    "1610.06067": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Albarghouthi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aws"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "D'Antoni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Loris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Drews",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Samuel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nori",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aditya"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness as a Program Property",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.PL cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We explore the following question: Is a decision-making program fair, for\nsome useful definition of fairness? First, we describe how several algorithmic\nfairness questions can be phrased as program verification problems. Second, we\ndiscuss an automated verification technique for proving or disproving fairness\nof decision-making programs with respect to a probabilistic model of the\npopulation."
    },
    "1804.10764": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wachinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Becker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benjamin Gutierrez"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rieckmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Detect, Quantify, and Incorporate Dataset Bias: A Neuroimaging Analysis\n  on 12,207 Individuals",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neuroimaging datasets keep growing in size to address increasingly complex\nmedical questions. However, even the largest datasets today alone are too small\nfor training complex models or for finding genome wide associations. A solution\nis to grow the sample size by merging data across several datasets. However,\nbias in datasets complicates this approach and includes additional sources of\nvariation in the data instead. In this work, we combine 15 large neuroimaging\ndatasets to study bias. First, we detect bias by demonstrating that scans can\nbe correctly assigned to a dataset with 73.3% accuracy. Next, we introduce\nmetrics to quantify the compatibility across datasets and to create embeddings\nof neuroimaging sites. Finally, we incorporate the presence of bias for the\nselection of a training set for predicting autism. For the quantification of\nthe dataset bias, we introduce two metrics: the Bhattacharyya distance between\ndatasets and the age prediction error. The presented embedding of neuroimaging\nsites provides an interesting new visualization about the similarity of\ndifferent sites. This could be used to guide the merging of data sources, while\nlimiting the introduction of unwanted variation. Finally, we demonstrate a\nclear performance increase when incorporating dataset bias for training set\nselection in autism prediction. Overall, we believe that the growing amount of\nneuroimaging data necessitates to incorporate data-driven methods for\nquantifying dataset bias in future analyses."
    },
    "cs_0604054": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2006-04-12",
        "http://arxiv.org/OAI/arXiv/:updated": "2008-05-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Armando",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bonacina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maria Paola"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ranise",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Silvio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schulz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stephan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "New results on rewrite-based satisfiability procedures",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in the ACM Transactions on Computational Logic, 49 pages",
        "http://arxiv.org/OAI/arXiv/:report-no": "RR 36/2005",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "ACM Transactions on Computational Logic, 10(1):129-179, January\n  2009",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/1459010.1459014",
        "http://arxiv.org/OAI/arXiv/:abstract": "Program analysis and verification require decision procedures to reason on\ntheories of data structures. Many problems can be reduced to the satisfiability\nof sets of ground literals in theory T. If a sound and complete inference\nsystem for first-order logic is guaranteed to terminate on T-satisfiability\nproblems, any theorem-proving strategy with that system and a fair search plan\nis a T-satisfiability procedure. We prove termination of a rewrite-based\nfirst-order engine on the theories of records, integer offsets, integer offsets\nmodulo and lists. We give a modularity theorem stating sufficient conditions\nfor termination on a combinations of theories, given termination on each. The\nabove theories, as well as others, satisfy these conditions. We introduce\nseveral sets of benchmarks on these theories and their combinations, including\nboth parametric synthetic benchmarks to test scalability, and real-world\nproblems to test performances on huge sets of literals. We compare the\nrewrite-based theorem prover E with the validity checkers CVC and CVC Lite.\nContrary to the folklore that a general-purpose prover cannot compete with\nreasoners with built-in theories, the experiments are overall favorable to the\ntheorem prover, showing that not only the rewriting approach is elegant and\nconceptually simple, but has important practical implications."
    },
    "1707.02729": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sch\u00fcller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Benz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mishal"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Best-Effort Inductive Logic Programming via Fine-grained Cost-based\n  Hypothesis Generation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG cs.LO",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to Machine Learning special issue on Inductive Logic\n  Programming",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We describe the Inspire system which participated in the first competition on\nInductive Logic Programming (ILP). Inspire is based on Answer Set Programming\n(ASP). The distinguishing feature of Inspire is an ASP encoding for hypothesis\nspace generation: given a set of facts representing the mode bias, and a set of\ncost configuration parameters, each answer set of this encoding represents a\nsingle rule that is considered for finding a hypothesis that entails the given\nexamples. Compared with state-of-the-art methods that use the length of the\nrule body as a metric for rule complexity, our approach permits a much more\nfine-grained specification of the shape of hypothesis candidate rules. The\nInspire system iteratively increases the rule cost limit and thereby increases\nthe search space until it finds a suitable hypothesis. The system searches for\na hypothesis that entails a single example at a time, utilizing an ASP encoding\nderived from the encoding used in XHAIL. We perform experiments with the\ndevelopment and test set of the ILP competition. For comparison we also adapted\nthe ILASP system to process competition instances. Experimental results show\nthat the cost parameters for the hypothesis search space are an important\nfactor for finding hypotheses to competition instances within tight resource\nbounds."
    },
    "1501.04242": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-01-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-12-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gauvrit",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zenil",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hector"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tegn\u00e9r",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jesper"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Information-theoretic and Algorithmic Approach to Human, Animal and\n  Artificial Cognition",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "22 pages. Forthcoming in Gordana Dodig-Crnkovic and Raffaela\n  Giovagnoli (eds). Representation and Reality: Humans, Animals and Machines,\n  Springer Verlag",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We survey concepts at the frontier of research connecting artificial, animal\nand human cognition to computation and information processing---from the Turing\ntest to Searle's Chinese Room argument, from Integrated Information Theory to\ncomputational and algorithmic complexity. We start by arguing that passing the\nTuring test is a trivial computational problem and that its pragmatic\ndifficulty sheds light on the computational nature of the human mind more than\nit does on the challenge of artificial intelligence. We then review our\nproposed algorithmic information-theoretic measures for quantifying and\ncharacterizing cognition in various forms. These are capable of accounting for\nknown biases in human behavior, thus vindicating a computational algorithmic\nview of cognition as first suggested by Turing, but this time rooted in the\nconcept of algorithmic probability, which in turn is based on computational\nuniversality while being independent of computational model, and which has the\nvirtue of being predictive and testable as a model theory of cognitive\nbehavior."
    },
    "1202.3711": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Claassen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heskes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Logical Characterization of Constraint-Based Causal Discovery",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2011-PG-135-144",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a novel approach to constraint-based causal discovery, that takes\nthe form of straightforward logical inference, applied to a list of simple,\nlogical statements about causal relations that are derived directly from\nobserved (in)dependencies. It is both sound and complete, in the sense that all\ninvariant features of the corresponding partial ancestral graph (PAG) are\nidentified, even in the presence of latent variables and selection bias. The\napproach shows that every identifiable causal relation corresponds to one of\njust two fundamental forms. More importantly, as the basic building blocks of\nthe method do not rely on the detailed (graphical) structure of the\ncorresponding PAG, it opens up a range of new opportunities, including more\nrobust inference, detailed accountability, and application to large models."
    },
    "1412.4736": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-12-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-02-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Helmbold",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Long",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philip M."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the Inductive Bias of Dropout",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Machine Learning Research, 16, 3403-3454 (2015). (See\n  http://jmlr.org/papers/volume16/helmbold15a/helmbold15a.pdf.)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Dropout is a simple but effective technique for learning in neural networks\nand other settings. A sound theoretical understanding of dropout is needed to\ndetermine when dropout should be applied and how to use it most effectively. In\nthis paper we continue the exploration of dropout as a regularizer pioneered by\nWager, et.al. We focus on linear classification where a convex proxy to the\nmisclassification loss (i.e. the logistic loss used in logistic regression) is\nminimized. We show: (a) when the dropout-regularized criterion has a unique\nminimizer, (b) when the dropout-regularization penalty goes to infinity with\nthe weights, and when it remains bounded, (c) that the dropout regularization\ncan be non-monotonic as individual weights increase from 0, and (d) that the\ndropout regularization penalty may not be convex. This last point is\nparticularly surprising because the combination of dropout regularization with\nany convex loss proxy is always a convex function.\n  In order to contrast dropout regularization with $L_2$ regularization, we\nformalize the notion of when different sources are more compatible with\ndifferent regularizers. We then exhibit distributions that are provably more\ncompatible with dropout regularization than $L_2$ regularization, and vice\nversa. These sources provide additional insight into how the inductive biases\nof dropout and $L_2$ regularization differ. We provide some similar results for\n$L_1$ regularization."
    },
    "1806.02380": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kusner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matt J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Russell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Loftus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Silva",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ricardo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Interventions for Fairness",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Most approaches in algorithmic fairness constrain machine learning methods so\nthe resulting predictions satisfy one of several intuitive notions of fairness.\nWhile this may help private companies comply with non-discrimination laws or\navoid negative publicity, we believe it is often too little, too late. By the\ntime the training data is collected, individuals in disadvantaged groups have\nalready suffered from discrimination and lost opportunities due to factors out\nof their control. In the present work we focus instead on interventions such as\na new public policy, and in particular, how to maximize their positive effects\nwhile improving the fairness of the overall system. We use causal methods to\nmodel the effects of interventions, allowing for potential interference--each\nindividual's outcome may depend on who else receives the intervention. We\ndemonstrate this with an example of allocating a budget of teaching resources\nusing a dataset of schools in New York City."
    },
    "1805.01960": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Brul\u00e9",
                "http://arxiv.org/OAI/arXiv/:forenames": "Joshua"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal programming: inference with structural causal models as finding\n  instances of a relation",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ME cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages, 9 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper proposes a causal inference relation and causal programming as\ngeneral frameworks for causal inference with structural causal models. A tuple,\n$\\langle M, I, Q, F \\rangle$, is an instance of the relation if a formula, $F$,\ncomputes a causal query, $Q$, as a function of known population probabilities,\n$I$, in every model entailed by a set of model assumptions, $M$. Many problems\nin causal inference can be viewed as the problem of enumerating instances of\nthe relation that satisfy given criteria. This unifies a number of previously\nstudied problems, including causal effect identification, causal discovery and\nrecovery from selection bias. In addition, the relation supports formalizing\nnew problems in causal inference with structural causal models, such as the\nproblem of research design. Causal programming is proposed as a further\ngeneralization of causal inference as the problem of finding optimal instances\nof the relation, with respect to a cost function."
    },
    "1810.04793": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-10",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jinghe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kowsari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kamran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harrison",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lobo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jennifer M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barnes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Laura E."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Patient2Vec: A Personalized Interpretable Deep Representation of the\n  Longitudinal Electronic Health Record",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.QM cs.AI cs.IR cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted by IEEE Access",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ACCESS.2018.2875677",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The wide implementation of electronic health record (EHR) systems facilitates\nthe collection of large-scale health data from real clinical settings. Despite\nthe significant increase in adoption of EHR systems, this data remains largely\nunexplored, but presents a rich data source for knowledge discovery from\npatient health histories in tasks such as understanding disease correlations\nand predicting health outcomes. However, the heterogeneity, sparsity, noise,\nand bias in this data present many complex challenges. This complexity makes it\ndifficult to translate potentially relevant information into machine learning\nalgorithms. In this paper, we propose a computational framework, Patient2Vec,\nto learn an interpretable deep representation of longitudinal EHR data which is\npersonalized for each patient. To evaluate this approach, we apply it to the\nprediction of future hospitalizations using real EHR data and compare its\npredictive performance with baseline methods. Patient2Vec produces a vector\nspace with meaningful structure and it achieves an AUC around 0.799\noutperforming baseline methods. In the end, the learned feature importance can\nbe visualized and interpreted at both the individual and population levels to\nbring clinical insights."
    },
    "1807.10615": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Madaan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nishtha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mehta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sameep"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mittal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shravika"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Suvarna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashima"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Judging a Book by its Description : Analyzing Gender Stereotypes in the\n  Man Bookers Prize Winning Fiction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: substantial text overlap with arXiv:1710.04117",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The presence of gender stereotypes in many aspects of society is a well-known\nphenomenon. In this paper, we focus on studying and quantifying such\nstereotypes and bias in the Man Bookers Prize winning fiction. We consider 275\nbooks shortlisted for Man Bookers Prize between 1969 and 2017. The gender bias\nis analyzed by semantic modeling of book descriptions on Goodreads. This\nreveals the pervasiveness of gender bias and stereotype in the books on\ndifferent features like occupation, introductions and actions associated to the\ncharacters in the book."
    },
    "1304.1529": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Spiegelhalter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Franklin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rodney C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bull",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kate"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Assessment, Criticism and Improvement of Imprecise Subjective\n  Probabilities for a Medical Expert System",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1989-PG-335-342",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Three paediatric cardiologists assessed nearly 1000 imprecise subjective\nconditional probabilities for a simple belief network representing congenital\nheart disease, and the quality of the assessments has been measured using\nprospective data on 200 babies. Quality has been assessed by a Brier scoring\nrule, which decomposes into terms measuring lack of discrimination and\nreliability. The results are displayed for each of 27 diseases and 24\nquestions, and generally the assessments are reliable although there was a\ntendency for the probabilities to be too extreme. The imprecision allows the\njudgements to be converted to implicit samples, and by combining with the\nobserved data the probabilities naturally adapt with experience. This appears\nto be a practical procedure even for reasonably large expert systems."
    },
    "1412.3773": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-12-11",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-12-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mooij",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joris M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peters",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Janzing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dominik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zscheischler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jakob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sch\u00f6lkopf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Distinguishing cause from effect using observational data: methods and\n  benchmarks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML stat.OT",
        "http://arxiv.org/OAI/arXiv/:comments": "101 pages, second revision submitted to Journal of Machine Learning\n  Research",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Machine Learning Research 17(32):1-102, 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The discovery of causal relationships from purely observational data is a\nfundamental problem in science. The most elementary form of such a causal\ndiscovery problem is to decide whether X causes Y or, alternatively, Y causes\nX, given joint observations of two variables X, Y. An example is to decide\nwhether altitude causes temperature, or vice versa, given only joint\nmeasurements of both variables. Even under the simplifying assumptions of no\nconfounding, no feedback loops, and no selection bias, such bivariate causal\ndiscovery problems are challenging. Nevertheless, several approaches for\naddressing those problems have been proposed in recent years. We review two\nfamilies of such methods: Additive Noise Methods (ANM) and Information\nGeometric Causal Inference (IGCI). We present the benchmark CauseEffectPairs\nthat consists of data for 100 different cause-effect pairs selected from 37\ndatasets from various domains (e.g., meteorology, biology, medicine,\nengineering, economy, etc.) and motivate our decisions regarding the \"ground\ntruth\" causal directions of all pairs. We evaluate the performance of several\nbivariate causal discovery methods on these real-world benchmark data and in\naddition on artificially simulated data. Our empirical results on real-world\ndata indicate that certain methods are indeed able to distinguish cause from\neffect using only purely observational data, although more benchmark data would\nbe needed to obtain statistically significant conclusions. One of the best\nperforming methods overall is the additive-noise method originally proposed by\nHoyer et al. (2009), which obtains an accuracy of 63+-10 % and an AUC of\n0.74+-0.05 on the real-world benchmark. As the main theoretical contribution of\nthis work we prove the consistency of that method."
    },
    "1705.11122": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qizhe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zihang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Du",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yulun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hovy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eduard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Neubig",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Graham"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Controllable Invariance through Adversarial Feature Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Learning meaningful representations that maintain the content necessary for a\nparticular task while filtering away detrimental variations is a problem of\ngreat interest in machine learning. In this paper, we tackle the problem of\nlearning representations invariant to a specific factor or trait of data. The\nrepresentation learning process is formulated as an adversarial minimax game.\nWe analyze the optimal equilibrium of such a game and find that it amounts to\nmaximizing the uncertainty of inferring the detrimental factor given the\nrepresentation while maximizing the certainty of making task-specific\npredictions. On three benchmark tasks, namely fair and bias-free\nclassification, language-independent generation, and lighting-independent image\nclassification, we show that the proposed framework induces an invariant\nrepresentation, and leads to better generalization evidenced by the improved\nperformance."
    },
    "1711.10401": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Misra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rajesh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ray",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kumar S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Modification of Particle Swarm Optimization using Random Walk",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Particle swarm optimization comes under lot of changes after James Kennedy\nand Russell Eberhart first proposes the idea in 1995. The changes has been done\nmainly on Inertia parameters in velocity updating equation so that the\nconvergence rate will be higher. We are proposing a novel approach where\nparticles movement will not be depend on its velocity rather it will be decided\nby constrained biased random walk of particles. In random walk every particles\nmovement based on two significant parameters, one is random process like toss\nof a coin and other is how much displacement a particle should have. In our\napproach we exploit this idea by performing a biased random operation and based\non the outcome of that random operation, PSO particles choose the direction of\nthe path and move non-uniformly into the solution space. This constrained,\nnon-uniform movement helps the random walking particle to converge quicker then\nclassical PSO. In our constrained biased random walking approach, we no longer\nneeded velocity term (Vi), rather we introduce a new parameter (K) which is a\nprobabilistic function. No global best particle (PGbest), local best particle\n(PLbest), Constriction parameter (W) are required rather we use a new term\ncalled Ptarg which is loosely influenced by PGbest.We test our algorithm on\nfive different benchmark functions, and also compare its performance with\nclassical PSO and Quantum Particle Swarm Optimization (QPSO).This new approach\nhave been shown significantly better than basic PSO and sometime outperform\nQPSO in terms of convergence, search space, number of iterations."
    },
    "1808.05344": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-08-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Szu-Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hwang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hsin-Te"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hsin-Min"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Quality-Net: An End-to-End Non-intrusive Speech Quality Assessment Model\n  based on BLSTM",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SD cs.AI eess.AS",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted in Interspeech2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Nowadays, most of the objective speech quality assessment tools (e.g.,\nperceptual evaluation of speech quality (PESQ)) are based on the comparison of\nthe degraded/processed speech with its clean counterpart. The need of a\n\"golden\" reference considerably restricts the practicality of such assessment\ntools in real-world scenarios since the clean reference usually cannot be\naccessed. On the other hand, human beings can readily evaluate the speech\nquality without any reference (e.g., mean opinion score (MOS) tests), implying\nthe existence of an objective and non-intrusive (no clean reference needed)\nquality assessment mechanism. In this study, we propose a novel end-to-end,\nnon-intrusive speech quality evaluation model, termed Quality-Net, based on\nbidirectional long short-term memory. The evaluation of utterance-level quality\nin Quality-Net is based on the frame-level assessment. Frame constraints and\nsensible initializations of forget gate biases are applied to learn meaningful\nframe-level quality assessment from the utterance-level quality label.\nExperimental results show that Quality-Net can yield high correlation to PESQ\n(0.9 for the noisy speech and 0.84 for the speech processed by speech\nenhancement). We believe that Quality-Net has potential to be used in a wide\nvariety of applications of speech signal processing."
    },
    "1512.07487": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-12-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nordio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tarable",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alberto"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Leonardi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emilio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Marsan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco Ajmone"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Selecting the top-quality item through crowd scoring",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To be published, ACM TOMPECS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We investigate crowdsourcing algorithms for finding the top-quality item\nwithin a large collection of objects with unknown intrinsic quality values.\nThis is an important problem with many relevant applications, for example in\nnetworked recommendation systems. The core of the algorithms is that objects\nare distributed to crowd workers, who return a noisy and biased evaluation. All\nreceived evaluations are then combined, to identify the top-quality object. We\nfirst present a simple probabilistic model for the system under investigation.\nThen, we devise and study a class of efficient adaptive algorithms to assign in\nan effective way objects to workers. We compare the performance of several\nalgorithms, which correspond to different choices of the design\nparameters/metrics. In the simulations we show that some of the algorithms\nachieve near optimal performance for a suitable setting of the system\nparameters."
    },
    "1702.07784": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chatzakou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Despoina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kourtellis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blackburn",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeremy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Cristofaro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emiliano"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stringhini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gianluca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vakali",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Athena"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Measuring #GamerGate: A Tale of Hate, Sexism, and Bullying",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "WWW Cybersafety Workshop 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Over the past few years, online aggression and abusive behaviors have\noccurred in many different forms and on a variety of platforms. In extreme\ncases, these incidents have evolved into hate, discrimination, and bullying,\nand even materialized into real-world threats and attacks against individuals\nor groups. In this paper, we study the Gamergate controversy. Started in August\n2014 in the online gaming world, it quickly spread across various social\nnetworking platforms, ultimately leading to many incidents of cyberbullying and\ncyberaggression. We focus on Twitter, presenting a measurement study of a\ndataset of 340k unique users and 1.6M tweets to study the properties of these\nusers, the content they post, and how they differ from random Twitter users. We\nfind that users involved in this \"Twitter war\" tend to have more friends and\nfollowers, are generally more engaged and post tweets with negative sentiment,\nless joy, and more hate than random users. We also perform preliminary\nmeasurements on how the Twitter suspension mechanism deals with such abusive\nbehaviors. While we focus on Gamergate, our methodology to collect and analyze\ntweets related to aggressive and bullying activities is of independent\ninterest."
    },
    "1407.5212": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-07-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khandwala",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kandarp"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sharma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rudra"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Snehal"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Context Aware Dynamic Traffic Signal Optimization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:report-no": "17586-8253",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Computer Applications 100(13):24-28,\n  August 2014",
        "http://arxiv.org/OAI/arXiv/:doi": "10.5120/17586-8253",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Conventional urban traffic control systems have been based on historical\ntraffic data. Later advancements made use of detectors, which enabled the\ngathering of real time traffic data, in order to reorganize and calibrate\ntraffic signalization programs. Further evolvement provided the ability to\nforecast traffic conditions, in order to develop traffic signalization programs\nand strategies precomputed and applied at the most appropriate time frame for\nthe optimal control of the current traffic conditions. We, propose the next\ngeneration of traffic control systems based on principles of Artificial\nIntelligence and Context Awareness. Most of the existing algorithms use average\nwaiting time or length of the queue to assess an algorithms performance.\nHowever, a low average waiting time may come at the cost of delaying other\nvehicles indefinitely. In our algorithm, besides the vehicle queue, we use\nfairness also as an important performance metric to assess an algorithms\nperformance."
    },
    "1004.3708": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-04-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ji",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongnan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Herve",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre-Yves"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aickelin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Uwe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pitiot",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alain"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Parcellation of fMRI Datasets with ICA and PLS-A Data Driven Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 5 figures, P12th International Conference of Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2009)",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 12th International Conference of Medical Image\n  Computing and Computer-Assisted Intervention (MICCAI 2009), Part I, Lecture\n  Notes in Computer Science 5761, London, UK, 2009",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Inter-subject parcellation of functional Magnetic Resonance Imaging (fMRI)\ndata based on a standard General Linear Model (GLM)and spectral clustering was\nrecently proposed as a means to alleviate the issues associated with spatial\nnormalization in fMRI. However, for all its appeal, a GLM-based parcellation\napproach introduces its own biases, in the form of a priori knowledge about the\nshape of Hemodynamic Response Function (HRF) and task-related signal changes,\nor about the subject behaviour during the task. In this paper, we introduce a\ndata-driven version of the spectral clustering parcellation, based on\nIndependent Component Analysis (ICA) and Partial Least Squares (PLS) instead of\nthe GLM. First, a number of independent components are automatically selected.\nSeed voxels are then obtained from the associated ICA maps and we compute the\nPLS latent variables between the fMRI signal of the seed voxels (which covers\nregional variations of the HRF) and the principal components of the signal\nacross all voxels. Finally, we parcellate all subjects data with a spectral\nclustering of the PLS latent variables. We present results of the application\nof the proposed method on both single-subject and multi-subject fMRI datasets.\nPreliminary experimental results, evaluated with intra-parcel variance of GLM\nt-values and PLS derived t-values, indicate that this data-driven approach\noffers improvement in terms of parcellation accuracy over GLM based techniques."
    },
    "1804.00499": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hosseini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hossein"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poovendran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semantic Adversarial Examples",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks are known to be vulnerable to adversarial examples,\ni.e., images that are maliciously perturbed to fool the model. Generating\nadversarial examples has been mostly limited to finding small perturbations\nthat maximize the model prediction error. Such images, however, contain\nartificial perturbations that make them somewhat distinguishable from natural\nimages. This property is used by several defense methods to counter adversarial\nexamples by applying denoising filters or training the model to be robust to\nsmall perturbations.\n  In this paper, we introduce a new class of adversarial examples, namely\n\"Semantic Adversarial Examples,\" as images that are arbitrarily perturbed to\nfool the model, but in such a way that the modified image semantically\nrepresents the same object as the original image. We formulate the problem of\ngenerating such images as a constrained optimization problem and develop an\nadversarial transformation based on the shape bias property of human cognitive\nsystem. In our method, we generate adversarial images by first converting the\nRGB image into the HSV (Hue, Saturation and Value) color space and then\nrandomly shifting the Hue and Saturation components, while keeping the Value\ncomponent the same. Our experimental results on CIFAR10 dataset show that the\naccuracy of VGG16 network on adversarial color-shifted images is 5.7%."
    },
    "1705.02667": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mukherjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subhabrata"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weikum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "People on Media: Jointly Identifying Credible News and Trustworthy\n  Citizen Journalists in Online Communities",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.IR cs.SI stat.ML",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/2806416.2806537",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Media seems to have become more partisan, often providing a biased coverage\nof news catering to the interest of specific groups. It is therefore essential\nto identify credible information content that provides an objective narrative\nof an event. News communities such as digg, reddit, or newstrust offer\nrecommendations, reviews, quality ratings, and further insights on journalistic\nworks. However, there is a complex interaction between different factors in\nsuch online communities: fairness and style of reporting, language clarity and\nobjectivity, topical perspectives (like political viewpoint), expertise and\nbias of community members, and more. This paper presents a model to\nsystematically analyze the different interactions in a news community between\nusers, news, and sources. We develop a probabilistic graphical model that\nleverages this joint interaction to identify 1) highly credible news articles,\n2) trustworthy news sources, and 3) expert users who perform the role of\n\"citizen journalists\" in the community. Our method extends CRF models to\nincorporate real-valued ratings, as some communities have very fine-grained\nscales that cannot be easily discretized without losing information. To the\nbest of our knowledge, this paper is the first full-fledged analysis of\ncredibility, trust, and expertise in news communities."
    },
    "1712.00377": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agrawal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aishwarya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kembhavi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniruddha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Don't Just Assume; Look and Answer: Overcoming Priors for Visual\n  Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 10 figures. To appear in IEEE Conference on Computer Vision\n  and Pattern Recognition (CVPR), 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A number of studies have found that today's Visual Question Answering (VQA)\nmodels are heavily driven by superficial correlations in the training data and\nlack sufficient image grounding. To encourage development of models geared\ntowards the latter, we propose a new setting for VQA where for every question\ntype, train and test sets have different prior distributions of answers.\nSpecifically, we present new splits of the VQA v1 and VQA v2 datasets, which we\ncall Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2\nrespectively). First, we evaluate several existing VQA models under this new\nsetting and show that their performance degrades significantly compared to the\noriginal VQA setting. Second, we propose a novel Grounded Visual Question\nAnswering model (GVQA) that contains inductive biases and restrictions in the\narchitecture specifically designed to prevent the model from 'cheating' by\nprimarily relying on priors in the training data. Specifically, GVQA explicitly\ndisentangles the recognition of visual concepts present in the image from the\nidentification of plausible answer space for a given question, enabling the\nmodel to more robustly generalize across different distributions of answers.\nGVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).\nOur experiments demonstrate that GVQA significantly outperforms SAN on both\nVQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more\npowerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in\nseveral cases. GVQA offers strengths complementary to SAN when trained and\nevaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more\ntransparent and interpretable than existing VQA models."
    },
    "0907.0598": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-07-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wesolkowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Slawomir"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mazurek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Whitacre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bender",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Axel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abbass",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hussein"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Robustness and Adaptiveness Analysis of Future Fleets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "SimtecT 2009 conference, Adelaide, Australia",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Making decisions about the structure of a future military fleet is a\nchallenging task. Several issues need to be considered such as the existence of\nmultiple competing objectives and the complexity of the operating environment.\nA particular challenge is posed by the various types of uncertainty that the\nfuture might hold. It is uncertain what future events might be encountered; how\nfleet design decisions will influence and shape the future; and how present and\nfuture decision makers will act based on available information, their personal\nbiases regarding the importance of different objectives, and their economic\npreferences. In order to assist strategic decision-making, an analysis of\nfuture fleet options needs to account for conditions in which these different\nclasses of uncertainty are exposed. It is important to understand what\nassumptions a particular fleet is robust to, what the fleet can readily adapt\nto, and what conditions present clear risks to the fleet. We call this the\nanalysis of a fleet's strategic positioning. This paper introduces how\nstrategic positioning can be evaluated using computer simulations. Our main aim\nis to introduce a framework for capturing information that can be useful to a\ndecision maker and for defining the concepts of robustness and adaptiveness in\nthe context of future fleet design. We demonstrate our conceptual framework\nusing simulation studies of an air transportation fleet. We capture uncertainty\nby employing an explorative scenario-based approach. Each scenario represents a\nsampling of different future conditions, different model assumptions, and\ndifferent economic preferences. Proposed changes to a fleet are then analysed\nbased on their influence on the fleet's robustness, adaptiveness, and risk to\ndifferent scenarios."
    },
    "1710.00490": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moreira",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Catarina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Haven",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emmanuel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sozzo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wichert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Dutch's Real World Financial Institute: Introducing Quantum-Like\n  Bayesian Networks as an Alternative Model to deal with Uncertainty",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI quant-ph",
        "http://arxiv.org/OAI/arXiv/:comments": "15 images, 33 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this work, we analyse and model a real life financial loan application\nbelonging to a sample bank in the Netherlands. The log is robust in terms of\ndata, containing a total of 262 200 event logs, belonging to 13 087 different\ncredit applications. The dataset is heterogeneous and consists of a mixture of\ncomputer generated automatic processes and manual human tasks. The goal is to\nwork out a decision model, which represents the underlying tasks that make up\nthe loan application service, and to assess potential areas of improvement of\nthe institution's internal processes. To this end we study the impact of\nincomplete event logs for the extraction and analysis of business processes. It\nis quite common that event logs are incomplete with several amounts of missing\ninformation (for instance, workers forget to register their tasks). Absence of\ndata is translated into a drastic decrease of precision and compromises the\ndecision models, leading to biased and unrepresentative results. We investigate\nhow classical probabilistic models are affected by incomplete event logs and we\nexplore quantum-like probabilistic inferences as an alternative mathematical\nmodel to classical probability. This work represents a first step towards\nsystematic investigation of the impact of quantum interference in a real life\nlarge scale decision scenario. The results obtained in this study indicate\nthat, under high levels of uncertainty, the quantum-like models generate\nquantum interference terms, which allow an additional non-linear\nparameterisation of the data. Experimental results attest the efficiency of the\nquantum-like Bayesian networks, since the application of interference terms is\nable to reduce the error percentage of inferences performed over quantum-like\nmodels when compared to inferences produced by classical models."
    },
    "1304.3083": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Dalkey",
                "http://arxiv.org/OAI/arXiv/:forenames": "Norman C."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Models vs. Inductive Inference for Dealing With Probabilistic Knowledge",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1986-PG-63-70",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Two different approaches to dealing with probabilistic knowledge are examined\n-models and inductive inference. Examples of the first are: influence diagrams\n[1], Bayesian networks [2], log-linear models [3, 4]. Examples of the second\nare: games-against nature [5, 6] varieties of maximum-entropy methods [7, 8,\n9], and the author's min-score induction [10]. In the modeling approach, the\nbasic issue is manageability, with respect to data elicitation and computation.\nThus, it is assumed that the pertinent set of users in some sense knows the\nrelevant probabilities, and the problem is to format that knowledge in a way\nthat is convenient to input and store and that allows computation of the\nanswers to current questions in an expeditious fashion. The basic issue for the\ninductive approach appears at first sight to be very different. In this\napproach it is presumed that the relevant probabilities are only partially\nknown, and the problem is to extend that incomplete information in a reasonable\nway to answer current questions. Clearly, this approach requires that some form\nof induction be invoked. Of course, manageability is an important additional\nconcern. Despite their seeming differences, the two approaches have a fair\namount in common, especially with respect to the structural framework they\nemploy. Roughly speaking, this framework involves identifying clusters of\nvariables which strongly interact, establishing marginal probability\ndistributions on the clusters, and extending the subdistributions to a more\ncomplete distribution, usually via a product formalism. The product extension\nis justified on the modeling approach in terms of assumed conditional\nindependence; in the inductive approach the product form arises from an\ninductive rule."
    },
    "1304.2368": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Loui",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ronald P."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evidential Reasoning in a Network Usage Prediction Testbed",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Fourth Conference on Uncertainty in\n  Artificial Intelligence (UAI1988)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1988-PG-257-265",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper reports on empirical work aimed at comparing evidential reasoning\ntechniques. While there is prima facie evidence for some conclusions, this i6\nwork in progress; the present focus is methodology, with the goal that\nsubsequent results be meaningful. The domain is a network of UNIX* cycle\nservers, and the task is to predict properties of the state of the network from\npartial descriptions of the state. Actual data from the network are taken and\nused for blindfold testing in a betting game that allows abstention. The focal\ntechnique has been Kyburg's method for reasoning with data of varying relevance\nto a particular query, though the aim is to be able eventually to compare\nvarious uncertainty calculi. The conclusions are not novel, but are\ninstructive. 1. All of the calculi performed better than human subjects, so\nunbiased access to sample experience is apparently of value. 2. Performance\ndepends on metric: (a) when trials are repeated, net = gains - losses favors\nmethods that place many bets, if the probability of placing a correct bet is\nsufficiently high; that is, it favors point-valued formalisms; (b) yield =\ngains/(gains + lossee) favors methods that bet only when sure to bet correctly;\nthat is, it favors interval-valued formalisms. 3. Among the calculi, there were\nno clear winners or losers. Methods are identified for eliminating the bias of\nthe net as a performance criterion and for separating the calculi effectively:\nin both cases by posting odds for the betting game in the appropriate way."
    },
    "1604.07928": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-05-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shandian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pengyuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kuang-chih"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zenglin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Qi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghahramani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zoubin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Distributed Flexible Nonlinear Tensor Factorization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.DC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Gaussian process, tensor factorization, multidimensional arrays,\n  large scale, spark, map-reduce",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.5.1; I.5.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Tensor factorization is a powerful tool to analyse multi-way data. Compared\nwith traditional multi-linear methods, nonlinear tensor factorization models\nare capable of capturing more complex relationships in the data. However, they\nare computationally expensive and may suffer severe learning bias in case of\nextreme data sparsity. To overcome these limitations, in this paper we propose\na distributed, flexible nonlinear tensor factorization model. Our model can\neffectively avoid the expensive computations and structural restrictions of the\nKronecker-product in existing TGP formulations, allowing an arbitrary subset of\ntensorial entries to be selected to contribute to the training. At the same\ntime, we derive a tractable and tight variational evidence lower bound (ELBO)\nthat enables highly decoupled, parallel computations and high-quality\ninference. Based on the new bound, we develop a distributed inference algorithm\nin the MapReduce framework, which is key-value-free and can fully exploit the\nmemory cache mechanism in fast MapReduce systems such as SPARK. Experimental\nresults fully demonstrate the advantages of our method over several\nstate-of-the-art approaches, in terms of both predictive performance and\ncomputational efficiency. Moreover, our approach shows a promising potential in\nthe application of Click-Through-Rate (CTR) prediction for online advertising."
    },
    "1811.03751": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jain",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Niharika"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Manikonda",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lydia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alberto Olmo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sengupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sailik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kambhampati",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subbarao"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Imagining an Engineer: On GAN-Based Data Augmentation Perpetuating\n  Biases",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "6 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The use of synthetic data generated by Generative Adversarial Networks (GANs)\nhas become quite a popular method to do data augmentation for many\napplications. While practitioners celebrate this as an economical way to get\nmore synthetic data that can be used to train downstream classifiers, it is not\nclear that they recognize the inherent pitfalls of this technique. In this\npaper, we aim to exhort practitioners against deriving any false sense of\nsecurity against data biases based on data augmentation. To drive this point\nhome, we show that starting with a dataset consisting of head-shots of\nengineering researchers, GAN-based augmentation \"imagines\" synthetic engineers,\nmost of whom have masculine features and white skin color (inferred from a\nhuman subject study conducted on Amazon Mechanical Turk). This demonstrates how\nbiases inherent in the training data are reinforced, and sometimes even\namplified, by GAN-based data augmentation; it should serve as a cautionary tale\nfor the lay practitioners."
    },
    "cs_0402019": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2004-02-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fruehwirth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abdennadher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Slim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Munich Rent Advisor: A Success for Logic Programming on the Internet",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DS",
        "http://arxiv.org/OAI/arXiv/:acm-class": "D.3.3;G.1.6",
        "http://arxiv.org/OAI/arXiv/:abstract": "Most cities in Germany regularly publish a booklet called the {\\em\nMietspiegel}. It basically contains a verbal description of an expert system.\nIt allows the calculation of the estimated fair rent for a flat. By hand, one\nmay need a weekend to do so. With our computerized version, the {\\em Munich\nRent Advisor}, the user just fills in a form in a few minutes and the rent is\ncalculated immediately. We also extended the functionality and applicability of\nthe {\\em Mietspiegel} so that the user need not answer all questions on the\nform. The key to computing with partial information using high-level\nprogramming was to use constraint logic programming. We rely on the internet,\nand more specifically the World Wide Web, to provide this service to a broad\nuser group. More than ten thousand people have used our service in the last\nthree years. This article describes the experiences in implementing and using\nthe {\\em Munich Rent Advisor}. Our results suggests that logic programming with\nconstraints can be an important ingredient in intelligent internet systems."
    },
    "1106.0666": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bartlett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "P. L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Baxter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weaver",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Experiments with Infinite-Horizon, Policy-Gradient Estimation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 15, pages\n  351-381, 2001",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.807",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we present algorithms that perform gradient ascent of the\naverage reward in a partially observable Markov decision process (POMDP). These\nalgorithms are based on GPOMDP, an algorithm introduced in a companion paper\n(Baxter and Bartlett, this volume), which computes biased estimates of the\nperformance gradient in POMDPs. The algorithm's chief advantages are that it\nuses only one free parameter beta, which has a natural interpretation in terms\nof bias-variance trade-off, it requires no knowledge of the underlying state,\nand it can be applied to infinite state, control and observation spaces. We\nshow how the gradient estimates produced by GPOMDP can be used to perform\ngradient ascent, both with a traditional stochastic-gradient algorithm, and\nwith an algorithm based on conjugate-gradients that utilizes gradient\ninformation to bracket maxima in line searches. Experimental results are\npresented illustrating both the theoretical results of (Baxter and Bartlett,\nthis volume) on a toy problem, and practical aspects of the algorithms on a\nnumber of more realistic problems."
    },
    "1802.08674": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Celis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L. Elisa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kapoor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sayash"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Salehi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Farnood"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vishnoi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nisheeth K."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Algorithmic Framework to Control Bias in Bandit-based Personalization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY cs.IR",
        "http://arxiv.org/OAI/arXiv/:comments": "A short version of this paper appeared in FAT/ML 2017\n  (arXiv:1707.02260)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Personalization is pervasive in the online space as it leads to higher\nefficiency and revenue by allowing the most relevant content to be served to\neach user. However, recent studies suggest that personalization methods can\npropagate societal or systemic biases and polarize opinions; this has led to\ncalls for regulatory mechanisms and algorithms to combat bias and inequality.\nAlgorithmically, bandit optimization has enjoyed great success in learning user\npreferences and personalizing content or feeds accordingly. We propose an\nalgorithmic framework that allows for the possibility to control bias or\ndiscrimination in such bandit-based personalization. Our model allows for the\nspecification of general fairness constraints on the sensitive types of the\ncontent that can be displayed to a user. The challenge, however, is to come up\nwith a scalable and low regret algorithm for the constrained optimization\nproblem that arises. Our main technical contribution is a provably fast and\nlow-regret algorithm for the fairness-constrained bandit optimization problem.\nOur proofs crucially leverage the special structure of our problem. Experiments\non synthetic and real-world data sets show that our algorithmic framework can\ncontrol bias with only a minor loss to revenue."
    },
    "1806.09597": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smith",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Samuel L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Duckworth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rezchikov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Semon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Le",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Quoc V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sohl-Dickstein",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jascha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Stochastic natural gradient descent draws posterior samples in function\n  space",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "11 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We prove that as the model predictions on the training set approach the true\nconditional distribution of labels given inputs, the noise inherent in\nminibatch gradients causes the stationary distribution of natural gradient\ndescent to approach a Bayesian posterior near local minima as the learning rate\n$\\epsilon \\rightarrow 0$. The temperature $T \\approx \\epsilon N/(2B)$ of this\nposterior is controlled by the learning rate, training set size $N$ and batch\nsize $B$. However minibatch NGD is not parameterisation invariant, and we\ntherefore introduce \"stochastic natural gradient descent\", which preserves\nparameterisation invariance by introducing a multiplicative bias to the\nstationary distribution. We identify this bias as the well known Jeffreys\nprior. To support our claims, we show that the distribution of samples from NGD\nis close to the Laplace approximation to the posterior when $T = 1$.\nFurthermore, the test loss of ensembles drawn using NGD falls rapidly as we\nincrease the batch size until $B \\approx \\epsilon N/2$, while above this point\nthe test loss is constant or rises slowly."
    },
    "1402.5991": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-02-24",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-03-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shams",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Issac"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ajorlou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Saeede"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kai"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A predictive analytics approach to reducing avoidable hospital\n  readmission",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.AP cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "30 pages, 4 figures, 7 tables",
        "http://arxiv.org/OAI/arXiv/:msc-class": "60J28, 62P10, 68T05, 62G86, 90B22",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.1; I.2.6; H.2.8",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Hospital readmission has become a critical metric of quality and cost of\nhealthcare. Medicare anticipates that nearly $17 billion is paid out on the 20%\nof patients who are readmitted within 30 days of discharge. Although several\ninterventions such as transition care management and discharge reengineering\nhave been practiced in recent years, the effectiveness and sustainability\ndepends on how well they can identify and target patients at high risk of\nrehospitalization. Based on the literature, most current risk prediction models\nfail to reach an acceptable accuracy level; none of them considers patient's\nhistory of readmission and impacts of patient attribute changes over time; and\nthey often do not discriminate between planned and unnecessary readmissions.\nTackling such drawbacks, we develop a new readmission metric based on\nadministrative data that can identify potentially avoidable readmissions from\nall other types of readmission. We further propose a tree based classification\nmethod to estimate the predicted probability of readmission that can directly\nincorporate patient's history of readmission and risk factors changes over\ntime. The proposed methods are validated with 2011-12 Veterans Health\nAdministration data from inpatients hospitalized for heart failure, acute\nmyocardial infarction, pneumonia, or chronic obstructive pulmonary disease in\nthe State of Michigan. Results shows improved discrimination power compared to\nthe literature (c-statistics>80%) and good calibration."
    },
    "1806.01261": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Battaglia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamrick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jessica B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bapst",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sanchez-Gonzalez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alvaro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zambaldi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vinicius"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Malinowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mateusz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tacchetti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raposo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Santoro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Faulkner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gulcehre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Caglar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ballard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gilmer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Justin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dahl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "George"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vaswani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Allen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kelsey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nash",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Langston",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victoria"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dyer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heess",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wierstra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Botvinick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matt"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vinyals",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oriol"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yujia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pascanu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Razvan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Relational inductive biases, deep learning, and graph networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence (AI) has undergone a renaissance recently, making\nmajor progress in key domains such as vision, language, control, and\ndecision-making. This has been due, in part, to cheap data and cheap compute\nresources, which have fit the natural strengths of deep learning. However, many\ndefining characteristics of human intelligence, which developed under much\ndifferent pressures, remain out of reach for current approaches. In particular,\ngeneralizing beyond one's experiences--a hallmark of human intelligence from\ninfancy--remains a formidable challenge for modern AI.\n  The following is part position paper, part review, and part unification. We\nargue that combinatorial generalization must be a top priority for AI to\nachieve human-like abilities, and that structured representations and\ncomputations are key to realizing this objective. Just as biology uses nature\nand nurture cooperatively, we reject the false choice between\n\"hand-engineering\" and \"end-to-end\" learning, and instead advocate for an\napproach which benefits from their complementary strengths. We explore how\nusing relational inductive biases within deep learning architectures can\nfacilitate learning about entities, relations, and rules for composing them. We\npresent a new building block for the AI toolkit with a strong relational\ninductive bias--the graph network--which generalizes and extends various\napproaches for neural networks that operate on graphs, and provides a\nstraightforward interface for manipulating structured knowledge and producing\nstructured behaviors. We discuss how graph networks can support relational\nreasoning and combinatorial generalization, laying the foundation for more\nsophisticated, interpretable, and flexible patterns of reasoning."
    },
    "1304.1499": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Cohen",
                "http://arxiv.org/OAI/arXiv/:forenames": "Marvin S."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Decision Making \"Biases\" and Support for Assumption-Based Higher-Order\n  Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Fifth Conference on Uncertainty in\n  Artificial Intelligence (UAI1989)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1989-PG-71-80",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Unaided human decision making appears to systematically violate consistency\nconstraints imposed by normative theories; these biases in turn appear to\njustify the application of formal decision-analytic models. It is argued that\nboth claims are wrong. In particular, we will argue that the \"confirmation\nbias\" is premised on an overly narrow view of how conflicting evidence is and\nought to be handled. Effective decision aiding should focus on supporting the\ncontral processes by means of which knowledge is extended into novel situations\nand in which assumptions are adopted, utilized, and revised. The Non- Monotonic\nProbabilist represents initial work toward such an aid."
    },
    "1301.7407": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-01-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peot",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark Alan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shachter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ross D."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning From What You Don't Observe",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Fourteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI1998)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1998-PG-439-446",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The process of diagnosis involves learning about the state of a system from\nvarious observations of symptoms or findings about the system. Sophisticated\nBayesian (and other) algorithms have been developed to revise and maintain\nbeliefs about the system as observations are made. Nonetheless, diagnostic\nmodels have tended to ignore some common sense reasoning exploited by human\ndiagnosticians; In particular, one can learn from which observations have not\nbeen made, in the spirit of conversational implicature. There are two concepts\nthat we describe to extract information from the observations not made. First,\nsome symptoms, if present, are more likely to be reported before others.\nSecond, most human diagnosticians and expert systems are economical in their\ndata-gathering, searching first where they are more likely to find symptoms\npresent. Thus, there is a desirable bias toward reporting symptoms that are\npresent. We develop a simple model for these concepts that can significantly\nimprove diagnostic inference."
    },
    "1301.2310": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-01-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Shelton",
                "http://arxiv.org/OAI/arXiv/:forenames": "Christian R."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Policy Improvement for POMDPs Using Normalized Importance Sampling",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2001-PG-496-503",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a new method for estimating the expected return of a POMDP from\nexperience. The method does not assume any knowledge of the POMDP and allows\nthe experience to be gathered from an arbitrary sequence of policies. The\nreturn is estimated for any new policy of the POMDP. We motivate the estimator\nfrom function-approximation and importance sampling points-of-view and derive\nits theoretical properties. Although the estimator is biased, it has low\nvariance and the bias is often irrelevant when the estimator is used for\npair-wise comparisons. We conclude by extending the estimator to policies with\nmemory and compare its performance in a greedy search algorithm to REINFORCE\nalgorithms showing an order of magnitude reduction in the number of trials\nrequired."
    },
    "1404.7734": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-04-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Baumann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ringo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dvor\u00e1k",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wolfgang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Linsbichler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Strass",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hannes"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Woltran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Compact Argumentation Frameworks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Contribution to the 15th International Workshop on Non-Monotonic\n  Reasoning, 2014, Vienna",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Abstract argumentation frameworks (AFs) are one of the most studied\nformalisms in AI. In this work, we introduce a certain subclass of AFs which we\ncall compact. Given an extension-based semantics, the corresponding compact AFs\nare characterized by the feature that each argument of the AF occurs in at\nleast one extension. This not only guarantees a certain notion of fairness;\ncompact AFs are thus also minimal in the sense that no argument can be removed\nwithout changing the outcome. We address the following questions in the paper:\n(1) How are the classes of compact AFs related for different semantics? (2)\nUnder which circumstances can AFs be transformed into equivalent compact ones?\n(3) Finally, we show that compact AFs are indeed a non-trivial subclass, since\nthe verification problem remains coNP-hard for certain semantics."
    },
    "1607.05845": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-07-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Reps",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jenna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhaoyang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haoyue"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aickelin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Uwe"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Identifying Candidate Risk Factors for Prescription Drug Side Effects\n  using Causal Contrast Set Mining",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Health Information Science (4th International Conference, HIS 2015,\n  Melbourne, Australia, May 28-30), pp. 45-55, Lecture Notes in Computer\n  Science, 2015",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Big longitudinal observational databases present the opportunity to extract\nnew knowledge in a cost effective manner. Unfortunately, the ability of these\ndatabases to be used for causal inference is limited due to the passive way in\nwhich the data are collected resulting in various forms of bias. In this paper\nwe investigate a method that can overcome these limitations and determine\ncausal contrast set rules efficiently from big data. In particular, we present\na new methodology for the purpose of identifying risk factors that increase a\npatients likelihood of experiencing the known rare side effect of renal failure\nafter ingesting aminosalicylates. The results show that the methodology was\nable to identify previously researched risk factors such as being prescribed\ndiuretics and highlighted that patients with a higher than average risk of\nrenal failure may be even more susceptible to experiencing it as a side effect\nafter ingesting aminosalicylates."
    },
    "1809.03260": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lohia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranay"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nagar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seema"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kuntal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diptikalyan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automated Test Generation to Detect Individual Discrimination in AI\n  Models",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Dependability on AI models is of utmost importance to ensure full acceptance\nof the AI systems. One of the key aspects of the dependable AI system is to\nensure that all its decisions are fair and not biased towards any individual.\nIn this paper, we address the problem of detecting whether a model has an\nindividual discrimination. Such a discrimination exists when two individuals\nwho differ only in the values of their protected attributes (such as,\ngender/race) while the values of their non-protected ones are exactly the same,\nget different decisions. Measuring individual discrimination requires an\nexhaustive testing, which is infeasible for a non-trivial system. In this\npaper, we present an automated technique to generate test inputs, which is\ngeared towards finding individual discrimination. Our technique combines the\nwell-known technique called symbolic execution along with the local\nexplainability for generation of effective test cases. Our experimental results\nclearly demonstrate that our technique produces 3.72 times more successful test\ncases than the existing state-of-the-art across all our chosen benchmarks."
    },
    "1610.08936": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Al-Shedivat",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maruan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wilson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew Gordon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saatchi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Scalable Deep Kernels with Recurrent Structure",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "37 pages, 7 figures, 5 tables. Updated to the final version that\n  appears in JMLR, 18(82):1-37, 2017",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Machine Learning Research (JMLR), JMLR 18(82):1-37,\n  2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many applications in speech, robotics, finance, and biology deal with\nsequential data, where ordering matters and recurrent structures are common.\nHowever, this structure cannot be easily captured by standard kernel functions.\nTo model such structure, we propose expressive closed-form kernel functions for\nGaussian processes. The resulting model, GP-LSTM, fully encapsulates the\ninductive biases of long short-term memory (LSTM) recurrent networks, while\nretaining the non-parametric probabilistic advantages of Gaussian processes. We\nlearn the properties of the proposed kernels by optimizing the Gaussian process\nmarginal likelihood using a new provably convergent semi-stochastic gradient\nprocedure and exploit the structure of these kernels for scalable training and\nprediction. This approach provides a practical representation for Bayesian\nLSTMs. We demonstrate state-of-the-art performance on several benchmarks, and\nthoroughly investigate a consequential autonomous driving application, where\nthe predictive uncertainties provided by GP-LSTM are uniquely valuable."
    },
    "1506.02850": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Basilico",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicola"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Nittis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giuseppe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gatti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicola"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adversarial patrolling with spatially uncertain alarm signals",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.GT",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "When securing complex infrastructures or large environments, constant\nsurveillance of every area is not affordable. To cope with this issue, a common\ncountermeasure is the usage of cheap but wide-ranged sensors, able to detect\nsuspicious events that occur in large areas, supporting patrollers to improve\nthe effectiveness of their strategies. However, such sensors are commonly\naffected by uncertainty. In the present paper, we focus on spatially uncertain\nalarm signals. That is, the alarm system is able to detect an attack but it is\nuncertain on the exact position where the attack is taking place. This is\ncommon when the area to be secured is wide such as in border patrolling and\nfair site surveillance. We propose, to the best of our knowledge, the first\nPatrolling Security Game model where a Defender is supported by a spatially\nuncertain alarm system which non-deterministically generates signals once a\ntarget is under attack. We show that finding the optimal strategy in arbitrary\ngraphs is APX-hard even in zero-sum games and we provide two (exponential time)\nexact algorithms and two (polynomial time) approximation algorithms.\nFurthermore, we analyse what happens in environments with special topologies,\nshowing that in linear and cycle graphs the optimal patrolling strategy can be\nfound in polynomial time, de facto allowing our algorithms to be used in\nreal-life scenarios, while in trees the problem is NP-hard. Finally, we show\nthat without false positives and missed detections, the best patrolling\nstrategy reduces to stay in a place, wait for a signal, and respond to it at\nbest. This strategy is optimal even with non-negligible missed detection rates,\nwhich, unfortunately, affect every commercial alarm system. We evaluate our\nmethods in simulation, assessing both quantitative and qualitative aspects."
    },
    "1611.03451": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Thomas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philip S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brunskill",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emma"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Importance Sampling with Unequal Support",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Importance sampling is often used in machine learning when training and\ntesting data come from different distributions. In this paper we propose a new\nvariant of importance sampling that can reduce the variance of importance\nsampling-based estimates by orders of magnitude when the supports of the\ntraining and testing distributions differ. After motivating and presenting our\nnew importance sampling estimator, we provide a detailed theoretical analysis\nthat characterizes both its bias and variance relative to the ordinary\nimportance sampling estimator (in various settings, which include cases where\nordinary importance sampling is biased, while our new estimator is not, and\nvice versa). We conclude with an example of how our new importance sampling\nestimator can be used to improve estimates of how well a new treatment policy\nfor diabetes will work for an individual, using only data from when the\nindividual used a previous treatment policy."
    },
    "1509.01978": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-09-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brodic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Darko"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amelio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alessia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Milivojevic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zoran N."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Approach to the Analysis of the South Slavic Medieval Labels Using\n  Image Texture",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 9 figures, 3rd Workshop on Recognition and Action for Scene\n  Understanding (REACTS 2015)",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.4; I.2.7",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The paper presents a new script classification method for the discrimination\nof the South Slavic medieval labels. It consists in the textural analysis of\nthe script types. In the first step, each letter is coded by the equivalent\nscript type, which is defined by its typographical features. Obtained coded\ntext is subjected to the run-length statistical analysis and to the adjacent\nlocal binary pattern analysis in order to extract the features. The result\nshows a diversity between the extracted features of the scripts, which makes\nthe feature classification more effective. It is the basis for the\nclassification process of the script identification by using an extension of a\nstate-of-the-art approach for document clustering. The proposed method is\nevaluated on an example of hand-engraved in stone and hand-printed in paper\nlabels in old Cyrillic, angular and round Glagolitic. Experiments demonstrate\nvery positive results, which prove the effectiveness of the proposed method."
    },
    "1710.10824": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-03-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Feng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shuliang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Feilong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shenglan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Rough extreme learning machine: a new classification method based on\n  uncertainty measure",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "23 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Extreme learning machine (ELM) is a new single hidden layer feedback neural\nnetwork. The weights of the input layer and the biases of neurons in hidden\nlayer are randomly generated, the weights of the output layer can be\nanalytically determined. ELM has been achieved good results for a large number\nof classification tasks. In this paper, a new extreme learning machine called\nrough extreme learning machine (RELM) was proposed. RELM uses rough set to\ndivide data into upper approximation set and lower approximation set, and the\ntwo approximation sets are utilized to train upper approximation neurons and\nlower approximation neurons. In addition, an attribute reduction is executed in\nthis algorithm to remove redundant attributes. The experimental results showed,\ncomparing with the comparison algorithms, RELM can get a better accuracy and\nrepeatability in most cases, RELM can not only maintain the advantages of fast\nspeed, but also effectively cope with the classification task for\nhigh-dimensional data."
    },
    "1408.6908": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-08-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-08-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez-Orallo",
                "http://arxiv.org/OAI/arXiv/:forenames": "Jose"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "AI Evaluation: past, present and future",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "34 pages. This paper is largely superseded by the following paper:\n  \"Evaluation in artificial intelligence: from task-oriented to\n  ability-oriented measurement\" Journal of Artificial Intelligence Review\n  (2016). doi:10.1007/s10462-016-9505-7,\n  \\url{http://dx.doi.org/10.1007/s10462-016-9505-7}. Please check and refer to\n  the journal paper",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence develops techniques and systems whose performance\nmust be evaluated on a regular basis in order to certify and foster progress in\nthe discipline. We will describe and critically assess the different ways AI\nsystems are evaluated. We first focus on the traditional task-oriented\nevaluation approach. We see that black-box (behavioural evaluation) is becoming\nmore and more common, as AI systems are becoming more complex and\nunpredictable. We identify three kinds of evaluation: Human discrimination,\nproblem benchmarks and peer confrontation. We describe the limitations of the\nmany evaluation settings and competitions in these three categories and propose\nseveral ideas for a more systematic and robust evaluation. We then focus on a\nless customary (and challenging) ability-oriented evaluation approach, where a\nsystem is characterised by its (cognitive) abilities, rather than by the tasks\nit is designed to solve. We discuss several possibilities: the adaptation of\ncognitive tests used for humans and animals, the development of tests derived\nfrom algorithmic information theory or more general approaches under the\nperspective of universal psychometrics."
    },
    "1810.00031": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Noriega-Campero",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alejandro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bakker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michiel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garcia-Bulle",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pentland",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Active Fairness in Algorithmic Decision Making",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.LG stat.AP",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Society increasingly relies on machine learning models for automated decision\nmaking. Yet, efficiency gains from automation have come paired with concern for\nalgorithmic discrimination that can systematize inequality. Substantial work in\nalgorithmic fairness has surged, focusing on either post-processing trained\nmodels, constraining learning processes, or pre-processing training data.\nRecent work has proposed optimal post-processing methods that randomize\nclassification decisions on a fraction of individuals in order to achieve\nfairness measures related to parity in errors and calibration. These methods,\nhowever, have raised concern due to the information inefficiency, intra-group\nunfairness, and Pareto sub-optimality they entail. The present work proposes an\nalternative active framework for fair classification, where, in deployment, a\ndecision-maker adaptively acquires information according to the needs of\ndifferent groups or individuals, towards balancing disparities in\nclassification performance. We propose two such methods, where information\ncollection is adapted to group- and individual-level needs respectively. We\nshow on real-world datasets that these can achieve: 1) calibration and single\nerror parity (e.g., equal opportunity); and 2) parity in both false positive\nand false negative rates (i.e., equal odds). Moreover, we show that, by\nleveraging their additional degree of freedom, active approaches can outperform\nrandomization-based classifiers previously considered optimal, while also\navoiding limitations such as intra-group unfairness."
    },
    "1611.05546": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Teney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Damien"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hengel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anton van den"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Zero-Shot Visual Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Part of the appeal of Visual Question Answering (VQA) is its promise to\nanswer new questions about previously unseen images. Most current methods\ndemand training questions that illustrate every possible concept, and will\ntherefore never achieve this capability, since the volume of required training\ndata would be prohibitive. Answering general questions about images requires\nmethods capable of Zero-Shot VQA, that is, methods able to answer questions\nbeyond the scope of the training questions. We propose a new evaluation\nprotocol for VQA methods which measures their ability to perform Zero-Shot VQA,\nand in doing so highlights significant practical deficiencies of current\napproaches, some of which are masked by the biases in current datasets. We\npropose and evaluate several strategies for achieving Zero-Shot VQA, including\nmethods based on pretrained word embeddings, object classifiers with semantic\nembeddings, and test-time retrieval of example images. Our extensive\nexperiments are intended to serve as baselines for Zero-Shot VQA, and they also\nachieve state-of-the-art performance in the standard VQA evaluation setting."
    },
    "1803.02509": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tse-Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yen-Lung"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Application of HodgeRank to Online Peer Assessment",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages. To appear in MLRec 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bias and heterogeneity in peer assessment can lead to the issue of unfair\nscoring in the educational field. To deal with this problem, we propose a\nreference ranking method for an online peer assessment system using HodgeRank.\nSuch a scheme provides instructors with an objective scoring reference based on\nmathematics."
    },
    "1809.04198": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cotter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Heinrich"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serena"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Narayan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Taman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "You",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seungil"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sridharan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthik"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Optimization with Non-Differentiable Constraints with Applications to\n  Fairness, Recall, Churn, and Other Goals",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.GT math.OC stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We show that many machine learning goals, such as improved fairness metrics,\ncan be expressed as constraints on the model's predictions, which we call rate\nconstraints. We study the problem of training non-convex models subject to\nthese rate constraints (or any non-convex and non-differentiable constraints).\nIn the non-convex setting, the standard approach of Lagrange multipliers may\nfail. Furthermore, if the constraints are non-differentiable, then one cannot\noptimize the Lagrangian with gradient-based methods. To solve these issues, we\nintroduce the proxy-Lagrangian formulation. This new formulation leads to an\nalgorithm that produces a stochastic classifier by playing a two-player\nnon-zero-sum game solving for what we call a semi-coarse correlated\nequilibrium, which in turn corresponds to an approximately optimal and feasible\nsolution to the constrained optimization problem. We then give a procedure\nwhich shrinks the randomized solution down to one that is a mixture of at most\n$m+1$ deterministic solutions, given $m$ constraints. This culminates in\nalgorithms that can solve non-convex constrained optimization problems with\npossibly non-differentiable and non-convex constraints with theoretical\nguarantees. We provide extensive experimental results enforcing a wide range of\npolicy goals including different fairness metrics, and other goals on accuracy,\ncoverage, recall, and churn."
    },
    "1710.06636": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deceased Organ Matching in Australia",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of 5th International Conference on Algorithmic Decision\n  Theory (ADT 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Despite efforts to increase the supply of organs from living donors, most\nkidney transplants performed in Australia still come from deceased donors. The\nage of these donated organs has increased substantially in recent decades as\nthe rate of fatal accidents on roads has fallen. The Organ and Tissue Authority\nin Australia is therefore looking to design a new mechanism that better matches\nthe age of the organ to the age of the patient. I discuss the design,\naxiomatics and performance of several candidate mechanisms that respect the\nspecial online nature of this fair division problem."
    },
    "1805.10582": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mahdi Milani"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maya"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Metric-Optimized Example Weights",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Real-world machine learning applications often have complex test metrics, and\nmay have training and test data that follow different distributions. We propose\naddressing these issues by using a weighted loss function with a standard\nconvex loss, but with weights on the training examples that are learned to\noptimize the test metric of interest on the validation set. These\nmetric-optimized example weights can be learned for any test metric, including\nblack box losses and customized metrics for specific applications. We\nillustrate the performance of our proposal with public benchmark datasets and\nreal-world applications with domain shift and custom loss functions that\nbalance multiple objectives, impose fairness policies, and are non-convex and\nnon-decomposable."
    },
    "1702.05222": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Noshad",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Morteza"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sekeh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Salimeh Yasaei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hero",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alfred O.",
                    "http://arxiv.org/OAI/arXiv/:suffix": "III"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Direct Estimation of Information Divergence Using Nearest Neighbor\n  Ratios",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IT cs.AI math.IT stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "2017 IEEE International Symposium on Information Theory (ISIT)",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "In Information Theory (ISIT), 2017 IEEE International Symposium on\n  (pp. 903-907). IEEE",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ISIT.2017.8006659",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a direct estimation method for R\\'{e}nyi and f-divergence measures\nbased on a new graph theoretical interpretation. Suppose that we are given two\nsample sets $X$ and $Y$, respectively with $N$ and $M$ samples, where\n$\\eta:=M/N$ is a constant value. Considering the $k$-nearest neighbor ($k$-NN)\ngraph of $Y$ in the joint data set $(X,Y)$, we show that the average powered\nratio of the number of $X$ points to the number of $Y$ points among all $k$-NN\npoints is proportional to R\\'{e}nyi divergence of $X$ and $Y$ densities. A\nsimilar method can also be used to estimate f-divergence measures. We derive\nbias and variance rates, and show that for the class of $\\gamma$-H\\\"{o}lder\nsmooth functions, the estimator achieves the MSE rate of\n$O(N^{-2\\gamma/(\\gamma+d)})$. Furthermore, by using a weighted ensemble\nestimation technique, for density functions with continuous and bounded\nderivatives of up to the order $d$, and some extra conditions at the support\nset boundary, we derive an ensemble estimator that achieves the parametric MSE\nrate of $O(1/N)$. Our estimators are more computationally tractable than other\ncompeting estimators, which makes them appealing in many practical\napplications."
    },
    "1703.10121": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Glauner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Patrick"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Du",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manxing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Paraschiv",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boytsov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Andrade",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Isabel Lopez"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meira",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jorge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Valtchev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Petko"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "State",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Top 10 Topics in Machine Learning Revisited: A Quantitative\n  Meta-Study",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 25th European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning (ESANN 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Which topics of machine learning are most commonly addressed in research?\nThis question was initially answered in 2007 by doing a qualitative survey\namong distinguished researchers. In our study, we revisit this question from a\nquantitative perspective. Concretely, we collect 54K abstracts of papers\npublished between 2007 and 2016 in leading machine learning journals and\nconferences. We then use machine learning in order to determine the top 10\ntopics in machine learning. We not only include models, but provide a holistic\nview across optimization, data, features, etc. This quantitative approach\nallows reducing the bias of surveys. It reveals new and up-to-date insights\ninto what the 10 most prolific topics in machine learning research are. This\nallows researchers to identify popular topics as well as new and rising topics\nfor their research."
    },
    "1609.05796": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-09-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-11-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ravanbakhsh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siamak"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lanusse",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francois"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mandelbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rachel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schneider",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeff"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poczos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Barnabas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Enabling Dark Energy Science with Deep Generative Models of Galaxy\n  Images",
        "http://arxiv.org/OAI/arXiv/:categories": "astro-ph.IM astro-ph.CO cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Understanding the nature of dark energy, the mysterious force driving the\naccelerated expansion of the Universe, is a major challenge of modern\ncosmology. The next generation of cosmological surveys, specifically designed\nto address this issue, rely on accurate measurements of the apparent shapes of\ndistant galaxies. However, shape measurement methods suffer from various\nunavoidable biases and therefore will rely on a precise calibration to meet the\naccuracy requirements of the science analysis. This calibration process remains\nan open challenge as it requires large sets of high quality galaxy images. To\nthis end, we study the application of deep conditional generative models in\ngenerating realistic galaxy images. In particular we consider variations on\nconditional variational autoencoder and introduce a new adversarial objective\nfor training of conditional generative networks. Our results suggest a reliable\nalternative to the acquisition of expensive high quality observations for\ngenerating the calibration data needed by the next generation of cosmological\nsurveys."
    },
    "cs_0403038": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2004-03-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Legg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shane"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hutter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Akshat"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Tournament versus Fitness Uniform Selection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 8 figures",
        "http://arxiv.org/OAI/arXiv/:report-no": "IDSIA-04-04",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2; I.2.6; I.2.8; F.2",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proc. 2004 Congress on Evolutionary Computation (CEC-2004), pages\n  2144--2151",
        "http://arxiv.org/OAI/arXiv/:abstract": "In evolutionary algorithms a critical parameter that must be tuned is that of\nselection pressure. If it is set too low then the rate of convergence towards\nthe optimum is likely to be slow. Alternatively if the selection pressure is\nset too high the system is likely to become stuck in a local optimum due to a\nloss of diversity in the population. The recent Fitness Uniform Selection\nScheme (FUSS) is a conceptually simple but somewhat radical approach to\naddressing this problem - rather than biasing the selection towards higher\nfitness, FUSS biases selection towards sparsely populated fitness levels. In\nthis paper we compare the relative performance of FUSS with the well known\ntournament selection scheme on a range of problems."
    },
    "1811.06032": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuxin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pineau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joelle"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Natural Environment Benchmarks for Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "12 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While current benchmark reinforcement learning (RL) tasks have been useful to\ndrive progress in the field, they are in many ways poor substitutes for\nlearning with real-world data. By testing increasingly complex RL algorithms on\nlow-complexity simulation environments, we often end up with brittle RL\npolicies that generalize poorly beyond the very specific domain. To combat\nthis, we propose three new families of benchmark RL domains that contain some\nof the complexity of the natural world, while still supporting fast and\nextensive data acquisition. The proposed domains also permit a characterization\nof generalization through fair train/test separation, and easy comparison and\nreplication of results. Through this work, we challenge the RL research\ncommunity to develop more robust algorithms that meet high standards of\nevaluation."
    },
    "1811.08186": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mart\u00ednez-Plumed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fernando"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hern\u00e1ndez-Orallo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jos\u00e9"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Analysing Results from AI Benchmarks: Key Indicators and How to Obtain\n  Them",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "This contribution has been accepted for publication at IEEE\n  Transactions on Games (to appear)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Item response theory (IRT) can be applied to the analysis of the evaluation\nof results from AI benchmarks. The two-parameter IRT model provides two\nindicators (difficulty and discrimination) on the side of the item (or AI\nproblem) while only one indicator (ability) on the side of the respondent (or\nAI agent). In this paper we analyse how to make this set of indicators dual, by\nadding a fourth indicator, generality, on the side of the respondent.\nGenerality is meant to be dual to discrimination, and it is based on\ndifficulty. Namely, generality is defined as a new metric that evaluates\nwhether an agent is consistently good at easy problems and bad at difficult\nones. With the addition of generality, we see that this set of four key\nindicators can give us more insight on the results of AI benchmarks. In\nparticular, we explore two popular benchmarks in AI, the Arcade Learning\nEnvironment (Atari 2600 games) and the General Video Game AI competition. We\nprovide some guidelines to estimate and interpret these indicators for other AI\nbenchmarks and competitions."
    },
    "1805.08522": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "P\u00e9rez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guillermo Valle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Camargo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chico Q."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Louis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ard A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep learning generalizes because the parameter-function map is biased\n  towards simple functions",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Deep neural networks generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime. This success\nsuggests that some form of implicit regularization must be at work. By applying\na modified version of the coding theorem from algorithmic information theory\nand by performing extensive empirical analysis of random neural networks, we\nargue that the parameter function map of deep neural networks is exponentially\nbiased towards functions with lower descriptional complexity. We show\nexplicitly for supervised learning of Boolean functions that the intrinsic\nsimplicity bias of deep neural networks means that they generalize\nsignificantly better than an unbiased learning algorithm does. The superior\ngeneralization due to simplicity bias can be explained using PAC-Bayes theory,\nwhich yields useful generalization error bounds for learning Boolean functions\nwith a wide range of complexities. Finally, we provide evidence that deeper\nneural networks trained on the CIFAR10 data set exhibit stronger simplicity\nbias than shallow networks do, which may help explain why deeper networks\ngeneralize better than shallow ones do."
    },
    "1712.10179": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Merelo-Guerv\u00f3s",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Juan J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fern\u00e1ndez-Ares",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Caballero",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio \u00c1lvarez"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garc\u00eda-S\u00e1nchez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pablo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rivas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "RedDwarfData: a simplified dataset of StarCraft matches",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:report-no": "GeNeura 2017-12-01",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The game Starcraft is one of the most interesting arenas to test new machine\nlearning and computational intelligence techniques; however, StarCraft matches\ntake a long time and creating a good dataset for training can be hard. Besides,\nanalyzing match logs to extract the main characteristics can also be done in\nmany different ways to the point that extracting and processing data itself can\ntake an inordinate amount of time and of course, depending on what you choose,\ncan bias learning algorithms. In this paper we present a simplified dataset\nextracted from the set of matches published by Robinson and Watson, which we\nhave called RedDwarfData, containing several thousand matches processed to\nframes, so that temporal studies can also be undertaken. This dataset is\navailable from GitHub under a free license. An initial analysis and appraisal\nof these matches is also made."
    },
    "1710.08191": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zanzotto",
                "http://arxiv.org/OAI/arXiv/:forenames": "Fabio Massimo"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Human-in-the-loop Artificial Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2; I.2.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Little by little, newspapers are revealing the bright future that Artificial\nIntelligence (AI) is building. Intelligent machines will help everywhere.\nHowever, this bright future has a dark side: a dramatic job market contraction\nbefore its unpredictable transformation. Hence, in a near future, large numbers\nof job seekers will need financial support while catching up with these novel\nunpredictable jobs. This possible job market crisis has an antidote inside. In\nfact, the rise of AI is sustained by the biggest knowledge theft of the recent\nyears. Learning AI machines are extracting knowledge from unaware skilled or\nunskilled workers by analyzing their interactions. By passionately doing their\njobs, these workers are digging their own graves.\n  In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI)\nas a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward\naware and unaware knowledge producers with a different scheme: decisions of AI\nsystems generating revenues will repay the legitimate owners of the knowledge\nused for taking those decisions. As modern Robin Hoods, HIT-AI researchers\nshould fight for a fairer Artificial Intelligence that gives back what it\nsteals."
    },
    "1803.06174": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Veale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Binns",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Reuben"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Van Kleek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Max"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Some HCI Priorities for GDPR-Compliant Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 0 figures, The General Data Protection Regulation: An\n  Opportunity for the CHI Community? (CHI-GDPR 2018), Workshop at ACM CHI'18,\n  22 April 2018, Montreal, Canada",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this short paper, we consider the roles of HCI in enabling the better\ngovernance of consequential machine learning systems using the rights and\nobligations laid out in the recent 2016 EU General Data Protection Regulation\n(GDPR)---a law which involves heavy interaction with people and systems.\nFocussing on those areas that relate to algorithmic systems in society, we\npropose roles for HCI in legal contexts in relation to fairness, bias and\ndiscrimination; data protection by design; data protection impact assessments;\ntransparency and explanations; the mitigation and understanding of automation\nbias; and the communication of envisaged consequences of processing."
    },
    "1106.3655": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-18",
        "http://arxiv.org/OAI/arXiv/:updated": "2011-11-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dimitrakakis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rothkopf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Constantin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian multitask inverse reinforcement learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Corrected version. 13 pages, 8 figures",
        "http://arxiv.org/OAI/arXiv/:msc-class": "62C10, 91B08, 91B10",
        "http://arxiv.org/OAI/arXiv/:acm-class": "G.3",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Recent Advances in Reinforcement Learning LNCS 7188, pp. 273-284,\n  2012",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/978-3-642-29946-9_27",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We generalise the problem of inverse reinforcement learning to multiple\ntasks, from multiple demonstrations. Each one may represent one expert trying\nto solve a different task, or as different experts trying to solve the same\ntask. Our main contribution is to formalise the problem as statistical\npreference elicitation, via a number of structured priors, whose form captures\nour biases about the relatedness of different tasks or expert policies. In\ndoing so, we introduce a prior on policy optimality, which is more natural to\nspecify. We show that our framework allows us not only to learn to efficiently\nfrom multiple experts but to also effectively differentiate between the goals\nof each. Possible applications include analysing the intrinsic motivations of\nsubjects in behavioural experiments and learning from multiple teachers."
    },
    "1209.2620": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hutter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lloyd",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kee Siong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Uther",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William T. B."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Probabilities on Sentences in an Expressive Logic",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LO cs.AI cs.LG math.LO math.PR",
        "http://arxiv.org/OAI/arXiv/:comments": "52 LaTeX pages, 64 definiton/theorems/etc, presented at conference\n  Progic 2011 in New York",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automated reasoning about uncertain knowledge has many applications. One\ndifficulty when developing such systems is the lack of a completely\nsatisfactory integration of logic and probability. We address this problem\ndirectly. Expressive languages like higher-order logic are ideally suited for\nrepresenting and reasoning about structured knowledge. Uncertain knowledge can\nbe modeled by using graded probabilities rather than binary truth-values. The\nmain technical problem studied in this paper is the following: Given a set of\nsentences, each having some probability of being true, what probability should\nbe ascribed to other (query) sentences? A natural wish-list, among others, is\nthat the probability distribution (i) is consistent with the knowledge base,\n(ii) allows for a consistent inference procedure and in particular (iii)\nreduces to deductive logic in the limit of probabilities being 0 and 1, (iv)\nallows (Bayesian) inductive reasoning and (v) learning in the limit and in\nparticular (vi) allows confirmation of universally quantified\nhypotheses/sentences. We translate this wish-list into technical requirements\nfor a prior probability and show that probabilities satisfying all our criteria\nexist. We also give explicit constructions and several general\ncharacterizations of probabilities that satisfy some or all of the criteria and\nvarious (counter) examples. We also derive necessary and sufficient conditions\nfor extending beliefs about finitely many sentences to suitable probabilities\nover all sentences, and in particular least dogmatic or least biased ones. We\nconclude with a brief outlook on how the developed theory might be used and\napproximated in autonomous reasoning agents. Our theory is a step towards a\nglobally consistent and empirically satisfactory unification of probability and\nlogic."
    },
    "1106.1804": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dahlman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Howe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A. E."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Critical Assessment of Benchmark Comparison in Planning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 17, pages\n  1-33, 2002",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.935",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent trends in planning research have led to empirical comparison becoming\ncommonplace. The field has started to settle into a methodology for such\ncomparisons, which for obvious practical reasons requires running a subset of\nplanners on a subset of problems. In this paper, we characterize the\nmethodology and examine eight implicit assumptions about the problems, planners\nand metrics used in many of these comparisons. The problem assumptions are:\nPR1) the performance of a general purpose planner should not be\npenalized/biased if executed on a sampling of problems and domains, PR2) minor\nsyntactic differences in representation do not affect performance, and PR3)\nproblems should be solvable by STRIPS capable planners unless they require ADL.\nThe planner assumptions are: PL1) the latest version of a planner is the best\none to use, PL2) default parameter settings approximate good performance, and\nPL3) time cut-offs do not unduly bias outcome. The metrics assumptions are: M1)\nperformance degrades similarly for each planner when run on degraded runtime\nenvironments (e.g., machine platform) and M2) the number of plan steps\ndistinguishes performance. We find that most of these assumptions are not\nsupported empirically; in particular, that planners are affected differently by\nthese assumptions. We conclude with a call to the community to devote research\nresources to improving the state of the practice and especially to enhancing\nthe available benchmark problems."
    },
    "1711.01024": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sodsong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wasuwee"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scholz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernhard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chawla",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanjay"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "SPARK: Static Program Analysis Reasoning and Retrieving Knowledge",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.PL cs.AI cs.CR",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Program analysis is a technique to reason about programs without executing\nthem, and it has various applications in compilers, integrated development\nenvironments, and security. In this work, we present a machine learning\npipeline that induces a security analyzer for programs by example. The security\nanalyzer determines whether a program is either secure or insecure based on\nsymbolic rules that were deduced by our machine learning pipeline. The machine\npipeline is two-staged consisting of a Recurrent Neural Networks (RNN) and an\nExtractor that converts an RNN to symbolic rules.\n  To evaluate the quality of the learned symbolic rules, we propose a\nsampling-based similarity measurement between two infinite regular languages.\nWe conduct a case study using real-world data. In this work, we discuss the\nlimitations of existing techniques and possible improvements in the future. The\nresults show that with sufficient training data and a fair distribution of\nprogram paths it is feasible to deducing symbolic security rules for the\nOpenJDK library with millions lines of code."
    },
    "1708.07149": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lowe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Noseworthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Serban",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iulian V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Angelard-Gontier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pineau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joelle"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards an Automatic Turing Test: Learning to Evaluate Dialogue\n  Responses",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "ACL 2017",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 55th annual meeting on Association for\n  Computational Linguistics (2017), pp. 1116-1126",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automatically evaluating the quality of dialogue responses for unstructured\ndomains is a challenging problem. Unfortunately, existing automatic evaluation\nmetrics are biased and correlate very poorly with human judgements of response\nquality. Yet having an accurate automatic evaluation procedure is crucial for\ndialogue research, as it allows rapid prototyping and testing of new models\nwith fewer expensive human evaluations. In response to this challenge, we\nformulate automatic dialogue evaluation as a learning problem. We present an\nevaluation model (ADEM) that learns to predict human-like scores to input\nresponses, using a new dataset of human response scores. We show that the ADEM\nmodel's predictions correlate significantly, and at a level much higher than\nword-overlap metrics such as BLEU, with human judgements at both the utterance\nand system-level. We also show that ADEM can generalize to evaluating dialogue\nmodels unseen during training, an important step for automatic dialogue\nevaluation."
    },
    "1802.08138": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sayin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Muhammed O."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chung-Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shiraishi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shinichi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ba\u015far",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tamer"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Reliable Intersection Control in Non-cooperative Environments",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.GT cs.SY",
        "http://arxiv.org/OAI/arXiv/:comments": "Extended version (including proofs of theorems and lemmas) of the\n  paper: M. O. Sayin, C.-W. Lin, S. Shiraishi, and T. Basar, \"Reliable\n  intersection control in non-cooperative environments\", to appear in the\n  Proceedings of American Control Conference, 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a reliable intersection control mechanism for strategic autonomous\nand connected vehicles (agents) in non-cooperative environments. Each agent has\naccess to his/her earliest possible and desired passing times, and reports a\npassing time to the intersection manager, who allocates the intersection\ntemporally to the agents in a First-Come-First-Serve basis. However, the agents\nmight have conflicting interests and can take actions strategically. To this\nend, we analyze the strategic behaviors of the agents and formulate Nash\nequilibria for all possible scenarios. Furthermore, among all Nash equilibria\nwe identify a socially optimal equilibrium that leads to a fair intersection\nallocation, and correspondingly we describe a strategy-proof intersection\nmechanism, which achieves reliable intersection control such that the strategic\nagents do not have any incentive to misreport their passing times\nstrategically."
    },
    "1509.05742": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-09-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haohan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ganapathiraju",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Madhavi K."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evaluation of Protein-protein Interaction Predictors with Noisy\n  Partially Labeled Data Sets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "preprint version, 9 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Protein-protein interaction (PPI) prediction is an important problem in\nmachine learning and computational biology. However, there is no data set for\ntraining or evaluation purposes, where all the instances are accurately\nlabeled. Instead, what is available are instances of positive class (with\npossibly noisy labels) and no instances of negative class. The non-availability\nof negative class data is typically handled with the observation that randomly\nchosen protein-pairs have a nearly 100% chance of being negative class, as only\n1 in 1,500 protein pairs expected is expected to be an interacting pair. In\nthis paper, we focused on the problem that non-availability of accurately\nlabeled testing data sets in the domain of protein-protein interaction (PPI)\nprediction may lead to biased evaluation results. We first showed that not\nacknowledging the inherent skew in the interactome (i.e. rare occurrence of\npositive instances) leads to an over-estimated accuracy of the predictor. Then\nwe show that, with the belief that positive interactions are a rare category,\nsampling random pairs of proteins excluding known interacting proteins set as\nthe negative testing data set could lead to an under-estimated evaluation\nresult. We formalized those two problems to validate the above claim, and based\non the formalization, we proposed a balancing method to cancel out the\nover-estimation with under-estimation. Finally, our experiments validated the\ntheoretical aspects and showed that this balancing evaluation could evaluate\nthe exact performance without availability of golden standard data sets."
    },
    "1802.06521": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chang-Shing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mei-Hui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ko",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Li-Wei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kubota",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Naoyuki"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lu-An"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kitaoka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shinya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu-Te"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shun-Feng"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Human and Smart Machine Co-Learning with Brain Computer Interface",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "This article will be published in IEEE SMC Magazine, vol. 4, no. 2,\n  2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/MSMC.2017.2785441",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning has become a very popular approach for cybernetics systems,\nand it has always been considered important research in the Computational\nIntelligence area. Nevertheless, when it comes to smart machines, it is not\njust about the methodologies. We need to consider systems and cybernetics as\nwell as include human in the loop. The purpose of this article is as follows:\n(1) To integrate the open source Facebook AI Research (FAIR) DarkForest program\nof Facebook with Item Response Theory (IRT), to the new open learning system,\nnamely, DDF learning system; (2) To integrate DDF Go with Robot namely Robotic\nDDF Go system; (3) To invite the professional Go players to attend the activity\nto play Go games on site with a smart machine. The research team will apply\nthis technology to education, such as, playing games to enhance the children\nconcentration on learning mathematics, languages, and other topics. With the\ndetected brainwaves, the robot will be able to speak some words that are very\nmuch to the point for the students and to assist the teachers in classroom in\nthe future."
    },
    "1203.5443": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-03-24",
        "http://arxiv.org/OAI/arXiv/:updated": "2012-06-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pelikan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hauschild",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lanzi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pier Luca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Transfer Learning, Soft Distance-Based Bias, and the Hierarchical BOA",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Parallel Problem Solving from Nature (PPSN XII), 10\n  pages. arXiv admin note: substantial text overlap with arXiv:1201.2241",
        "http://arxiv.org/OAI/arXiv/:report-no": "MEDAL Report No. 2012004",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6; I.2.8; G.1.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "An automated technique has recently been proposed to transfer learning in the\nhierarchical Bayesian optimization algorithm (hBOA) based on distance-based\nstatistics. The technique enables practitioners to improve hBOA efficiency by\ncollecting statistics from probabilistic models obtained in previous hBOA runs\nand using the obtained statistics to bias future hBOA runs on similar problems.\nThe purpose of this paper is threefold: (1) test the technique on several\nclasses of NP-complete problems, including MAXSAT, spin glasses and minimum\nvertex cover; (2) demonstrate that the technique is effective even when\nprevious runs were done on problems of different size; (3) provide empirical\nevidence that combining transfer learning with other efficiency enhancement\ntechniques can often yield nearly multiplicative speedups."
    },
    "1707.02033": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaohui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Qiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Youming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shengyu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Networked Fairness in Cake Cutting",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DS cs.AI cs.GT",
        "http://arxiv.org/OAI/arXiv/:comments": "A preliminary version of this paper appears at IJCAI 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce a graphical framework for fair division in cake cutting, where\ncomparisons between agents are limited by an underlying network structure. We\ngeneralize the classical fairness notions of envy-freeness and proportionality\nto this graphical setting. Given a simple undirected graph G, an allocation is\nenvy-free on G if no agent envies any of her neighbor's share, and is\nproportional on G if every agent values her own share no less than the average\namong her neighbors, with respect to her own measure. These generalizations\nopen new research directions in developing simple and efficient algorithms that\ncan produce fair allocations under specific graph structures.\n  On the algorithmic frontier, we first propose a moving-knife algorithm that\noutputs an envy-free allocation on trees. The algorithm is significantly\nsimpler than the discrete and bounded envy-free algorithm recently designed by\nAziz and Mackenzie for complete graphs. Next, we give a discrete and bounded\nalgorithm for computing a proportional allocation on descendant graphs, a class\nof graphs by taking a rooted tree and connecting all its ancestor-descendant\npairs."
    },
    "1705.02668": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mukherjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Subhabrata"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dutta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sourav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weikum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Credible Review Detection with Limited Information using Consistency\n  Analysis",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.IR cs.SI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Online reviews provide viewpoints on the strengths and shortcomings of\nproducts/services, influencing potential customers' purchasing decisions.\nHowever, the proliferation of non-credible reviews -- either fake (promoting/\ndemoting an item), incompetent (involving irrelevant aspects), or biased --\nentails the problem of identifying credible reviews. Prior works involve\nclassifiers harnessing rich information about items/users -- which might not be\nreadily available in several domains -- that provide only limited\ninterpretability as to why a review is deemed non-credible. This paper presents\na novel approach to address the above issues. We utilize latent topic models\nleveraging review texts, item ratings, and timestamps to derive consistency\nfeatures without relying on item/user histories, unavailable for \"long-tail\"\nitems/users. We develop models, for computing review credibility scores to\nprovide interpretable evidence for non-credible reviews, that are also\ntransferable to other domains -- addressing the scarcity of labeled data.\nExperiments on real-world datasets demonstrate improvements over\nstate-of-the-art baselines."
    },
    "1301.2295": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-01-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Morris",
                "http://arxiv.org/OAI/arXiv/:forenames": "Quaid"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Recognition Networks for Approximate Inference in BN20 Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2001-PG-370-377",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose using recognition networks for approximate inference inBayesian\nnetworks (BNs). A recognition network is a multilayerperception (MLP) trained\nto predict posterior marginals given observedevidence in a particular BN. The\ninput to the MLP is a vector of thestates of the evidential nodes. The activity\nof an output unit isinterpreted as a prediction of the posterior marginal of\nthecorresponding variable. The MLP is trained using samples generated fromthe\ncorresponding BN.We evaluate a recognition network that was trained to do\ninference ina large Bayesian network, similar in structure and complexity to\ntheQuick Medical Reference, Decision Theoretic (QMR-DT). Our networkis a\nbinary, two-layer, noisy-OR network containing over 4000 potentially observable\nnodes and over 600 unobservable, hidden nodes. Inreal medical diagnosis, most\nobservables are unavailable, and there isa complex and unknown bias that\nselects which ones are provided. Weincorporate a very basic type of selection\nbias in our network: a knownpreference that available observables are positive\nrather than negative.Even this simple bias has a significant effect on the\nposterior. We compare the performance of our recognition network\ntostate-of-the-art approximate inference algorithms on a large set oftest\ncases. In order to evaluate the effect of our simplistic modelof the selection\nbias, we evaluate algorithms using a variety ofincorrectly modeled observation\nbiases. Recognition networks performwell using both correct and incorrect\nobservation biases."
    },
    "1802.00748": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Gallicchio",
                "http://arxiv.org/OAI/arXiv/:forenames": "Claudio"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Short-term Memory of Deep RNN",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI math.DS stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "This is a pre-print (pre-review) version of the paper accepted for\n  presentation at the 26th European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning (ESANN), Bruges (Belgium),\n  25-27 April 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The extension of deep learning towards temporal data processing is gaining an\nincreasing research interest. In this paper we investigate the properties of\nstate dynamics developed in successive levels of deep recurrent neural networks\n(RNNs) in terms of short-term memory abilities. Our results reveal interesting\ninsights that shed light on the nature of layering as a factor of RNN design.\nNoticeably, higher layers in a hierarchically organized RNN architecture\nresults to be inherently biased towards longer memory spans even prior to\ntraining of the recurrent connections. Moreover, in the context of Reservoir\nComputing framework, our analysis also points out the benefit of a layered\nrecurrent organization as an efficient approach to improve the memory skills of\nreservoir models."
    },
    "1405.3713": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-05-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-05-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pereira",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lu\u00eds Moniz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dietz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emmanuelle-Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "H\u00f6lldobler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steffen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Contextual Abductive Reasoning with Side-Effects",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, no figures, 1 table",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1017/S1471068414000258",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The belief bias effect is a phenomenon which occurs when we think that we\njudge an argument based on our reasoning, but are actually influenced by our\nbeliefs and prior knowledge. Evans, Barston and Pollard carried out a\npsychological syllogistic reasoning task to prove this effect. Participants\nwere asked whether they would accept or reject a given syllogism. We discuss\none specific case which is commonly assumed to be believable but which is\nactually not logically valid. By introducing abnormalities, abduction and\nbackground knowledge, we adequately model this case under the weak completion\nsemantics. Our formalization reveals new questions about possible extensions in\nabductive reasoning. For instance, observations and their explanations might\ninclude some relevant prior abductive contextual information concerning some\nside-effect or leading to a contestable or refutable side-effect. A weaker\nnotion indicates the support of some relevant consequences by a prior abductive\ncontext. Yet another definition describes jointly supported relevant\nconsequences, which captures the idea of two observations containing mutually\nsupportive side-effects. Though motivated with and exemplified by the running\npsychology application, the various new general abductive context definitions\nare introduced here and given a declarative semantics for the first time, and\nhave a much wider scope of application. Inspection points, a concept introduced\nby Pereira and Pinto, allows us to express these definitions syntactically and\nintertwine them into an operational semantics."
    },
    "1801.04378": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghassami",
                    "http://arxiv.org/OAI/arXiv/:forenames": "AmirEmad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khodadadian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sajad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kiyavash",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Negar"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness in Supervised Learning: An Information Theoretic Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.IT math.IT stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Automated decision making systems are increasingly being used in real-world\napplications. In these systems for the most part, the decision rules are\nderived by minimizing the training error on the available historical data.\nTherefore, if there is a bias related to a sensitive attribute such as gender,\nrace, religion, etc. in the data, say, due to cultural/historical\ndiscriminatory practices against a certain demographic, the system could\ncontinue discrimination in decisions by including the said bias in its decision\nrule. We present an information theoretic framework for designing fair\npredictors from data, which aim to prevent discrimination against a specified\nsensitive attribute in a supervised learning setting. We use equalized odds as\nthe criterion for discrimination, which demands that the prediction should be\nindependent of the protected attribute conditioned on the actual label. To\nensure fairness and generalization simultaneously, we compress the data to an\nauxiliary variable, which is used for the prediction task. This auxiliary\nvariable is chosen such that it is decontaminated from the discriminatory\nattribute in the sense of equalized odds. The final predictor is obtained by\napplying a Bayesian decision rule to the auxiliary variable."
    },
    "1703.07022": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhiting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chuang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xing",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Recurrent Topic-Transition GAN for Visual Paragraph Generation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, 6 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A natural image usually conveys rich semantic content and can be viewed from\ndifferent angles. Existing image description methods are largely restricted by\nsmall sets of biased visual paragraph annotations, and fail to cover rich\nunderlying semantics. In this paper, we investigate a semi-supervised paragraph\ngenerative framework that is able to synthesize diverse and semantically\ncoherent paragraph descriptions by reasoning over local semantic regions and\nexploiting linguistic knowledge. The proposed Recurrent Topic-Transition\nGenerative Adversarial Network (RTT-GAN) builds an adversarial framework\nbetween a structured paragraph generator and multi-level paragraph\ndiscriminators. The paragraph generator generates sentences recurrently by\nincorporating region-based visual and language attention mechanisms at each\nstep. The quality of generated paragraph sentences is assessed by multi-level\nadversarial discriminators from two aspects, namely, plausibility at sentence\nlevel and topic-transition coherence at paragraph level. The joint adversarial\ntraining of RTT-GAN drives the model to generate realistic paragraphs with\nsmooth logical transition between sentence topics. Extensive quantitative\nexperiments on image and video paragraph datasets demonstrate the effectiveness\nof our RTT-GAN in both supervised and semi-supervised settings. Qualitative\nresults on telling diverse stories for an image also verify the\ninterpretability of RTT-GAN."
    },
    "1805.09866": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zennaro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fabio Massimo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ivanovska",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Magdalena"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Pooling of Causal Models under Counterfactual Fairness via Causal\n  Judgement Aggregation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 4 figures, workshop paper",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper we consider the problem of combining multiple probabilistic\ncausal models, provided by different experts, under the requirement that the\naggregated model satisfy the criterion of counterfactual fairness. We build\nupon the work on causal models and fairness in machine learning, and we express\nthe problem of combining multiple models within the framework of opinion\npooling. We propose two simple algorithms, grounded in the theory of\ncounterfactual fairness and causal judgment aggregation, that are guaranteed to\ngenerate aggregated probabilistic causal models respecting the criterion of\nfairness, and we compare their behaviors on a toy case study."
    },
    "1203.3503": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-03-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Pearl",
                "http://arxiv.org/OAI/arXiv/:forenames": "Judea"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "On a Class of Bias-Amplifying Variables that Endanger Effect Estimates",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ME cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2010-PG-417-424",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This note deals with a class of variables that, if conditioned on, tends to\namplify confounding bias in the analysis of causal effects. This class,\nindependently discovered by Bhattacharya and Vogt (2007) and Wooldridge (2009),\nincludes instrumental variables and variables that have greater influence on\ntreatment selection than on the outcome. We offer a simple derivation and an\nintuitive explanation of this phenomenon and then extend the analysis to non\nlinear models. We show that: 1. the bias-amplifying potential of instrumental\nvariables extends over to non-linear models, though not as sweepingly as in\nlinear models; 2. in non-linear models, conditioning on instrumental variables\nmay introduce new bias where none existed before; 3. in both linear and\nnon-linear models, instrumental variables have no effect on selection-induced\nbias."
    },
    "1703.10476": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shetty",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rakshith"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rohrbach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marcus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hendricks",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lisa Anne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fritz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mario"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schiele",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernt"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Speaking the Same Language: Matching Machine to Human Captions by\n  Adversarial Training",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages, Published in ICCV 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While strong progress has been made in image captioning over the last years,\nmachine and human captions are still quite distinct. A closer look reveals that\nthis is due to the deficiencies in the generated word distribution, vocabulary\nsize, and strong bias in the generators towards frequent captions. Furthermore,\nhumans -- rightfully so -- generate multiple, diverse captions, due to the\ninherent ambiguity in the captioning task which is not considered in today's\nsystems.\n  To address these challenges, we change the training objective of the caption\ngenerator from reproducing groundtruth captions to generating a set of captions\nthat is indistinguishable from human generated captions. Instead of\nhandcrafting such a learning target, we employ adversarial training in\ncombination with an approximate Gumbel sampler to implicitly match the\ngenerated distribution to the human one. While our method achieves comparable\nperformance to the state-of-the-art in terms of the correctness of the\ncaptions, we generate a set of diverse captions, that are significantly less\nbiased and match the word statistics better in several aspects."
    },
    "1306.6843": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-06-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2013-09-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Pe\u00f1a",
                "http://arxiv.org/OAI/arXiv/:forenames": "Jose M."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Error AMP Chain Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings of the 12th Scandinavian Conference on Artificial\n  Intelligence (SCAI 2013), to appear. Changes from v1 to v2: Minor correction\n  in Theorem 1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Any regular Gaussian probability distribution that can be represented by an\nAMP chain graph (CG) can be expressed as a system of linear equations with\ncorrelated errors whose structure depends on the CG. However, the CG represents\nthe errors implicitly, as no nodes in the CG correspond to the errors. We\npropose in this paper to add some deterministic nodes to the CG in order to\nrepresent the errors explicitly. We call the result an EAMP CG. We will show\nthat, as desired, every AMP CG is Markov equivalent to its corresponding EAMP\nCG under marginalization of the error nodes. We will also show that every EAMP\nCG under marginalization of the error nodes is Markov equivalent to some LWF CG\nunder marginalization of the error nodes, and that the latter is Markov\nequivalent to some directed and acyclic graph (DAG) under marginalization of\nthe error nodes and conditioning on some selection nodes. This is important\nbecause it implies that the independence model represented by an AMP CG can be\naccounted for by some data generating process that is partially observed and\nhas selection bias. Finally, we will show that EAMP CGs are closed under\nmarginalization. This is a desirable feature because it guarantees parsimonious\nmodels under marginalization."
    },
    "1702.07031": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Challita",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ursula"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Li"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saad",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Walid"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Proactive Resource Management in LTE-U Systems: A Deep Learning\n  Perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IT cs.AI cs.GT math.IT",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "LTE in unlicensed spectrum (LTE-U) is a promising approach to overcome the\nwireless spectrum scarcity. However, to reap the benefits of LTE-U, a fair\ncoexistence mechanism with other incumbent WiFi deployments is required. In\nthis paper, a novel deep learning approach is proposed for modeling the\nresource allocation problem of LTE-U small base stations (SBSs). The proposed\napproach enables multiple SBSs to proactively perform dynamic channel\nselection, carrier aggregation, and fractional spectrum access while\nguaranteeing fairness with existing WiFi networks and other LTE-U operators.\nAdopting a proactive coexistence mechanism enables future delay-intolerant\nLTE-U data demands to be served within a given prediction window ahead of their\nactual arrival time thus avoiding the underutilization of the unlicensed\nspectrum during off-peak hours while maximizing the total served LTE-U traffic\nload. To this end, a noncooperative game model is formulated in which SBSs are\nmodeled as Homo Egualis agents that aim at predicting a sequence of future\nactions and thus achieving long-term equal weighted fairness with WLAN and\nother LTE-U operators over a given time horizon. The proposed deep learning\nalgorithm is then shown to reach a mixed-strategy Nash equilibrium (NE), when\nit converges. Simulation results using real data traces show that the proposed\nscheme can yield up to 28% and 11% gains over a conventional reactive approach\nand a proportional fair coexistence mechanism, respectively. The results also\nshow that the proposed framework prevents WiFi performance degradation for a\ndensely deployed LTE-U network."
    },
    "1806.04959": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heidari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hoda"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ferrari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Claudio"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gummadi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Krishna P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krause",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated\n  Decision Making",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Conference: Thirty-second Conference on Neural Information Processing\n  Systems (NIPS 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We draw attention to an important, yet largely overlooked aspect of\nevaluating fairness for automated decision making systems---namely risk and\nwelfare considerations. Our proposed family of measures corresponds to the\nlong-established formulations of cardinal social welfare in economics, and is\njustified by the Rawlsian conception of fairness behind a veil of ignorance.\nThe convex formulation of our welfare-based measures of fairness allows us to\nintegrate them as a constraint into any convex loss minimization pipeline. Our\nempirical analysis reveals interesting trade-offs between our proposal and (a)\nprediction accuracy, (b) group discrimination, and (c) Dwork et al.'s notion of\nindividual fairness. Furthermore and perhaps most importantly, our work\nprovides both heuristic justification and empirical evidence suggesting that a\nlower-bound on our measures often leads to bounded inequality in algorithmic\noutcomes; hence presenting the first computationally feasible mechanism for\nbounding individual-level inequality."
    },
    "1608.07187": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Caliskan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aylin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bryson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joanna J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Narayanan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arvind"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semantics derived automatically from language corpora contain human-like\n  biases",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL cs.CY cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, 3 figures",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1126/science.aal4230",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence and machine learning are in a period of astounding\ngrowth. However, there are concerns that these technologies may be used, either\nwith or without intention, to perpetuate the prejudice and unfairness that\nunfortunately characterizes many human institutions. Here we show for the first\ntime that human-like semantic biases result from the application of standard\nmachine learning to ordinary language---the same sort of language humans are\nexposed to every day. We replicate a spectrum of standard human biases as\nexposed by the Implicit Association Test and other well-known psychological\nstudies. We replicate these using a widely used, purely statistical\nmachine-learning model---namely, the GloVe word embedding---trained on a corpus\nof text from the Web. Our results indicate that language itself contains\nrecoverable and accurate imprints of our historic biases, whether these are\nmorally neutral as towards insects or flowers, problematic as towards race or\ngender, or even simply veridical, reflecting the {\\em status quo} for the\ndistribution of gender with respect to careers or first names. These\nregularities are captured by machine learning along with the rest of semantics.\nIn addition to our empirical findings concerning language, we also contribute\nnew methods for evaluating bias in text, the Word Embedding Association Test\n(WEAT) and the Word Embedding Factual Association Test (WEFAT). Our results\nhave implications not only for AI and machine learning, but also for the fields\nof psychology, sociology, and human ethics, since they raise the possibility\nthat mere exposure to everyday language can account for the biases we replicate\nhere."
    },
    "1810.03608": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chendi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Unified Dynamic Approach to Sparse Model Selection",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 21st International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Sparse model selection is ubiquitous from linear regression to graphical\nmodels where regularization paths, as a family of estimators upon the\nregularization parameter varying, are computed when the regularization\nparameter is unknown or decided data-adaptively. Traditional computational\nmethods rely on solving a set of optimization problems where the regularization\nparameters are fixed on a grid that might be inefficient. In this paper, we\nintroduce a simple iterative regularization path, which follows the dynamics of\na sparse Mirror Descent algorithm or a generalization of Linearized Bregman\nIterations with nonlinear loss. Its performance is competitive to\n\\texttt{glmnet} with a further bias reduction. A path consistency theory is\npresented that under the Restricted Strong Convexity (RSC) and the\nIrrepresentable Condition (IRR), the path will first evolve in a subspace with\nno false positives and reach an estimator that is sign-consistent or of minimax\noptimal $\\ell_2$ error rate. Early stopping regularization is required to\nprevent overfitting. Application examples are given in sparse logistic\nregression and Ising models for NIPS coauthorship."
    },
    "1109.1314": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-09-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schaul",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tom"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Togelius",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schmidhuber",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J\u00fcrgen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Measuring Intelligence through Games",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial general intelligence (AGI) refers to research aimed at tackling\nthe full problem of artificial intelligence, that is, create truly intelligent\nagents. This sets it apart from most AI research which aims at solving\nrelatively narrow domains, such as character recognition, motion planning, or\nincreasing player satisfaction in games. But how do we know when an agent is\ntruly intelligent? A common point of reference in the AGI community is Legg and\nHutter's formal definition of universal intelligence, which has the appeal of\nsimplicity and generality but is unfortunately incomputable. Games of various\nkinds are commonly used as benchmarks for \"narrow\" AI research, as they are\nconsidered to have many important properties. We argue that many of these\nproperties carry over to the testing of general intelligence as well. We then\nsketch how such testing could practically be carried out. The central part of\nthis sketch is an extension of universal intelligence to deal with finite time,\nand the use of sampling of the space of games expressed in a suitably biased\ngame description language."
    },
    "1803.07067": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mahmood",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A. Rupam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Korenkevych",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dmytro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Komer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brent J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bergstra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Setting up a Reinforcement Learning Task with a Real-World Robot",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to 2018 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Reinforcement learning is a promising approach to developing hard-to-engineer\nadaptive solutions for complex and diverse robotic tasks. However, learning\nwith real-world robots is often unreliable and difficult, which resulted in\ntheir low adoption in reinforcement learning research. This difficulty is\nworsened by the lack of guidelines for setting up learning tasks with robots.\nIn this work, we develop a learning task with a UR5 robotic arm to bring to\nlight some key elements of a task setup and study their contributions to the\nchallenges with robots. We find that learning performance can be highly\nsensitive to the setup, and thus oversights and omissions in setup details can\nmake effective learning, reproducibility, and fair comparison hard. Our study\nsuggests some mitigating steps to help future experimenters avoid difficulties\nand pitfalls. We show that highly reliable and repeatable experiments can be\nperformed in our setup, indicating the possibility of reinforcement learning\nresearch extensively based on real-world robots."
    },
    "1807.04458": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-12",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-07-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gedda",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Magnus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lagerkvist",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mikael Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Butler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Monte Carlo Methods for the Game Kingdomino",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To be published in IEEE Conference on Computational Intelligence and\n  Games 2018 (IEEE CIG 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Kingdomino is introduced as an interesting game for studying game playing:\nthe game is multiplayer (4 independent players per game); it has a limited game\ndepth (13 moves per player); and it has limited but not insignificant\ninteraction among players.\n  Several strategies based on locally greedy players, Monte Carlo Evaluation\n(MCE), and Monte Carlo Tree Search (MCTS) are presented with variants. We\nexamine a variation of UCT called progressive win bias and a playout policy\n(Player-greedy) focused on selecting good moves for the player. A thorough\nevaluation is done showing how the strategies perform and how to choose\nparameters given specific time constraints. The evaluation shows that\nsurprisingly MCE is stronger than MCTS for a game like Kingdomino.\n  All experiments use a cloud-native design, with a game server in a Docker\ncontainer, and agents communicating using a REST-style JSON protocol. This\nenables a multi-language approach to separating the game state, the strategy\nimplementations, and the coordination layer."
    },
    "1806.06972": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wadhwa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Soumya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chandu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Khyathi Raghavi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nyberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eric"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Comparative Analysis of Neural QA models on SQuAD",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Workshop on Machine Reading for Question Answering\n  (MRQA), ACL 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The task of Question Answering has gained prominence in the past few decades\nfor testing the ability of machines to understand natural language. Large\ndatasets for Machine Reading have led to the development of neural models that\ncater to deeper language understanding compared to information retrieval tasks.\nDifferent components in these neural architectures are intended to tackle\ndifferent challenges. As a first step towards achieving generalization across\nmultiple domains, we attempt to understand and compare the peculiarities of\nexisting end-to-end neural models on the Stanford Question Answering Dataset\n(SQuAD) by performing quantitative as well as qualitative analysis of the\nresults attained by each of them. We observed that prediction errors reflect\ncertain model-specific biases, which we further discuss in this paper."
    },
    "1810.08678": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-19",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhenpeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kearnes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Steven"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Li"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zare",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard N."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Patrick"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Optimization of Molecules via Deep Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Adds Supporting Information",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a framework, which we call Molecule Deep $Q$-Networks (MolDQN),\nfor molecule optimization by combining domain knowledge of chemistry and\nstate-of-the-art reinforcement learning techniques (prioritized experience\nreplay, double $Q$-learning, and randomized value functions). We directly\ndefine modifications on molecules, thereby ensuring 100% chemical validity.\nFurther, we operate without pre-training on any dataset to avoid possible bias\nfrom the choice of that set. As a result, our model outperforms several other\nstate-of-the-art algorithms by having a higher success rate of acquiring\nmolecules with better properties. Inspired by problems faced during medicinal\nchemistry lead optimization, we extend our model with multi-objective\nreinforcement learning, which maximizes drug-likeness while maintaining\nsimilarity to the original molecule. We further show the path through chemical\nspace to achieve optimization for a molecule to understand how the model works."
    },
    "1803.10937": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grover",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aditya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Markov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Todor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Attia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Norman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perkins",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicholas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cheong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bryan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Harris",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stephen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chueh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ermon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefano"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Best arm identification in multi-armed bandits with delayed feedback",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "AISTATS 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a generalization of the best arm identification problem in\nstochastic multi-armed bandits (MAB) to the setting where every pull of an arm\nis associated with delayed feedback. The delay in feedback increases the\neffective sample complexity of standard algorithms, but can be offset if we\nhave access to partial feedback received before a pull is completed. We propose\na general framework to model the relationship between partial and delayed\nfeedback, and as a special case we introduce efficient algorithms for settings\nwhere the partial feedback are biased or unbiased estimators of the delayed\nfeedback. Additionally, we propose a novel extension of the algorithms to the\nparallel MAB setting where an agent can control a batch of arms. Our\nexperiments in real-world settings, involving policy search and hyperparameter\noptimization in computational sustainability domains for fast charging of\nbatteries and wildlife corridor construction, demonstrate that exploiting the\nstructure of partial feedback can lead to significant improvements over\nbaselines in both sequential and parallel MAB."
    },
    "cs_0610170": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2006-10-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Szita",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Istvan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lorincz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andras"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Low-complexity modular policies: learning to play Pac-Man and a new\n  framework beyond MDPs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "23 pages",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper we propose a method that learns to play Pac-Man. We define a\nset of high-level observation and action modules. Actions are temporally\nextended, and multiple action modules may be in effect concurrently. A decision\nof the agent is represented as a rule-based policy. For learning, we apply the\ncross-entropy method, a recent global optimization algorithm. The learned\npolicies reached better score than the hand-crafted policy, and neared the\nscore of average human players. We argue that learning is successful mainly\nbecause (i) the policy space includes the combination of individual actions and\nthus it is sufficiently rich, (ii) the search is biased towards low-complexity\npolicies and low complexity solutions can be found quickly if they exist. Based\non these principles, we formulate a new theoretical framework, which can be\nfound in the Appendix as supporting material."
    },
    "1811.03532": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "McElfresh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Duncan C"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bidkhori",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hoda"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dickerson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John P"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Scalable Robust Kidney Exchange",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at AAAI19",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2; G.1.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In barter exchanges, participants directly trade their endowed goods in a\nconstrained economic setting without money. Transactions in barter exchanges\nare often facilitated via a central clearinghouse that must match participants\neven in the face of uncertainty---over participants, existence and quality of\npotential trades, and so on. Leveraging robust combinatorial optimization\ntechniques, we address uncertainty in kidney exchange, a real-world barter\nmarket where patients swap (in)compatible paired donors. We provide two\nscalable robust methods to handle two distinct types of uncertainty in kidney\nexchange---over the quality and the existence of a potential match. The latter\ncase directly addresses a weakness in all stochastic-optimization-based methods\nto the kidney exchange clearing problem, which all necessarily require explicit\nestimates of the probability of a transaction existing---a still-unsolved\nproblem in this nascent market. We also propose a novel, scalable kidney\nexchange formulation that eliminates the need for an exponential-time\nconstraint generation process in competing formulations, maintains provable\noptimality, and serves as a subsolver for our robust approach. For each type of\nuncertainty we demonstrate the benefits of robustness on real data from a\nlarge, fielded kidney exchange in the United States. We conclude by drawing\nparallels between robustness and notions of fairness in the kidney exchange\nsetting."
    },
    "1403.1353": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-03-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jarich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vansteenberge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mukunoki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Masayuki"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Minoh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michihiko"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Collaborative Representation for Classification, Sparse or Non-sparse?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 1 figure",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Sparse representation based classification (SRC) has been proved to be a\nsimple, effective and robust solution to face recognition. As it gets popular,\ndoubts on the necessity of enforcing sparsity starts coming up, and primary\nexperimental results showed that simply changing the $l_1$-norm based\nregularization to the computationally much more efficient $l_2$-norm based\nnon-sparse version would lead to a similar or even better performance. However,\nthat's not always the case. Given a new classification task, it's still unclear\nwhich regularization strategy (i.e., making the coefficients sparse or\nnon-sparse) is a better choice without trying both for comparison. In this\npaper, we present as far as we know the first study on solving this issue,\nbased on plenty of diverse classification experiments. We propose a scoring\nfunction for pre-selecting the regularization strategy using only the dataset\nsize, the feature dimensionality and a discrimination score derived from a\ngiven feature representation. Moreover, we show that when dictionary learning\nis taking into account, non-sparse representation has a more significant\nsuperiority to sparse representation. This work is expected to enrich our\nunderstanding of sparse/non-sparse collaborative representation for\nclassification and motivate further research activities."
    },
    "1811.06747": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scantamburlo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Teresa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Charlesworth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cristianini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nello"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Machine Decisions and Human Consequences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As we increasingly delegate decision-making to algorithms, whether directly\nor indirectly, important questions emerge in circumstances where those\ndecisions have direct consequences for individual rights and personal\nopportunities, as well as for the collective good. A key problem for\npolicymakers is that the social implications of these new methods can only be\ngrasped if there is an adequate comprehension of their general technical\nunderpinnings. The discussion here focuses primarily on the case of enforcement\ndecisions in the criminal justice system, but draws on similar situations\nemerging from other algorithms utilised in controlling access to opportunities,\nto explain how machine learning works and, as a result, how decisions are made\nby modern intelligent algorithms or 'classifiers'. It examines the key aspects\nof the performance of classifiers, including how classifiers learn, the fact\nthat they operate on the basis of correlation rather than causation, and that\nthe term 'bias' in machine learning has a different meaning to common usage.An\nexample of a real world 'classifier', the Harm Assessment Risk Tool (HART), is\nexamined, through identification of its technical features: the classification\nmethod, the training data and the test data, the features and the labels,\nvalidation and performance measures. Four normative benchmarks are then\nconsidered by reference to HART: (a) prediction accuracy (b) fairness and\nequality before the law (c) transparency and accountability (d) informational\nprivacy and freedom of expression, in order to demonstrate how its technical\nfeatures have important normative dimensions that bear directly on the extent\nto which the system can be regarded as a viable and legitimate support for, or\neven alternative to, existing human decision-makers."
    },
    "1212.1100": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-12-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smith",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J. E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Caleb-Solly",
                    "http://arxiv.org/OAI/arXiv/:forenames": "P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tahir",
                    "http://arxiv.org/OAI/arXiv/:forenames": "M. A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sannen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "van-Brussel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "H."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Making Early Predictions of the Accuracy of Machine Learning\n  Applications",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "35 pagers, 12 figures",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.6; I.5.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The accuracy of machine learning systems is a widely studied research topic.\nEstablished techniques such as cross-validation predict the accuracy on unseen\ndata of the classifier produced by applying a given learning method to a given\ntraining data set. However, they do not predict whether incurring the cost of\nobtaining more data and undergoing further training will lead to higher\naccuracy. In this paper we investigate techniques for making such early\npredictions. We note that when a machine learning algorithm is presented with a\ntraining set the classifier produced, and hence its error, will depend on the\ncharacteristics of the algorithm, on training set's size, and also on its\nspecific composition. In particular we hypothesise that if a number of\nclassifiers are produced, and their observed error is decomposed into bias and\nvariance terms, then although these components may behave differently, their\nbehaviour may be predictable.\n  We test our hypothesis by building models that, given a measurement taken\nfrom the classifier created from a limited number of samples, predict the\nvalues that would be measured from the classifier produced when the full data\nset is presented. We create separate models for bias, variance and total error.\nOur models are built from the results of applying ten different machine\nlearning algorithms to a range of data sets, and tested with \"unseen\"\nalgorithms and datasets. We analyse the results for various numbers of initial\ntraining samples, and total dataset sizes. Results show that our predictions\nare very highly correlated with the values observed after undertaking the extra\ntraining. Finally we consider the more complex case where an ensemble of\nheterogeneous classifiers is trained, and show how we can accurately estimate\nan upper bound on the accuracy achievable after further training."
    },
    "1802.09158": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-25",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yiling"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Surrogate Scoring Rules and a Dominant Truth Serum for Information\n  Elicitation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study information elicitation without verification (IEWV) and ask the\nfollowing question: Can we achieve truthfulness in dominant strategy in IEWV?\nThis paper considers two elicitation settings. The first setting is when the\nmechanism designer has access to a random variable that is a noisy or proxy\nversion of the ground truth, with known biases. The second setting is the\nstandard peer prediction setting where agents' reports are the only source of\ninformation that the mechanism designer has. We introduce surrogate scoring\nrules (SSR) for the first setting, which use the noisy ground truth to evaluate\nquality of elicited information, and show that SSR achieve truthful elicitation\nin dominant strategy. Built upon SSR, we develop a multi-task mechanism,\ndominant truth serum (DTS), to achieve truthful elicitation in dominant\nstrategy when the mechanism designer only has access to agents' reports (the\nsecond setting). The method relies on an estimation procedure to accurately\nestimate the average bias in the reports of other agents. With the accurate\nestimation, a random peer agent's report serves as a noisy ground truth and SSR\ncan then be applied to achieve truthfulness in dominant strategy. A salient\nfeature of SSR and DTS is that they both quantify the quality or value of\ninformation despite lack of ground truth, just as proper scoring rules do for\nthe with verification setting. Our work complements both the strictly proper\nscoring rule literature by solving the case where the mechanism designer only\nhas access to a noisy or proxy version of the ground truth, and the peer\nprediction literature by achieving truthful elicitation in dominant strategy."
    },
    "1203.3535": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-03-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yeung",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dit-Yan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Multi-Domain Collaborative Filtering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2010-PG-725-732",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Collaborative filtering is an effective recommendation approach in which the\npreference of a user on an item is predicted based on the preferences of other\nusers with similar interests. A big challenge in using collaborative filtering\nmethods is the data sparsity problem which often arises because each user\ntypically only rates very few items and hence the rating matrix is extremely\nsparse. In this paper, we address this problem by considering multiple\ncollaborative filtering tasks in different domains simultaneously and\nexploiting the relationships between domains. We refer to it as a multi-domain\ncollaborative filtering (MCF) problem. To solve the MCF problem, we propose a\nprobabilistic framework which uses probabilistic matrix factorization to model\nthe rating problem in each domain and allows the knowledge to be adaptively\ntransferred across different domains by automatically learning the correlation\nbetween domains. We also introduce the link function for different domains to\ncorrect their biases. Experiments conducted on several real-world applications\ndemonstrate the effectiveness of our methods when compared with some\nrepresentative methods."
    },
    "1710.10057": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Celis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L. Elisa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lingxiao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vishnoi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nisheeth K."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Group Fairness in Multiwinner Voting",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.DS",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study multiwinner voting problems when there is an additional requirement\nthat the selected committee should be fair with respect to attributes such as\ngender, ethnicity, or political parties. Every setting of an attribute gives\nrise to a group, and the goal is to ensure that each group is neither over nor\nunder represented in the selected committee. Prior work has largely focused on\ndesigning specialized score functions that lead to a precise level of\nrepresentation with respect to disjoint attributes (e.g., only political\naffiliation). Here we propose a general algorithmic framework that allows the\nuse of any score function and can guarantee flexible notions of fairness with\nrespect to multiple, non-disjoint attributes (e.g., political affiliation and\ngender). Technically, we study the complexity of this constrained multiwinner\nvoting problem subject to group-fairness constraints for monotone submodular\nscore functions. We present approximation algorithms and hardness of\napproximation results for various attribute set structures and score functions."
    },
    "1207.1389": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-07-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Eberhardt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Frederick"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Glymour",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Clark"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scheines",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the Number of Experiments Sufficient and in the Worst Case Necessary\n  to Identify All Causal Relations Among N Variables",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ME",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2005-PG-178-184",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We show that if any number of variables are allowed to be simultaneously and\nindependently randomized in any one experiment, log2(N) + 1 experiments are\nsufficient and in the worst case necessary to determine the causal relations\namong N >= 2 variables when no latent variables, no sample selection bias and\nno feedback cycles are present. For all K, 0 < K < 1/(2N) we provide an upper\nbound on the number experiments required to determine causal structure when\neach experiment simultaneously randomizes K variables. For large N, these\nbounds are significantly lower than the N - 1 bound required when each\nexperiment randomizes at most one variable. For kmax < N/2, we show that\n(N/kmax-1)+N/(2kmax)log2(kmax) experiments aresufficient and in the worst case\nnecessary. We over a conjecture as to the minimal number of experiments that\nare in the worst case sufficient to identify all causal relations among N\nobserved variables that are a subset of the vertices of a DAG."
    },
    "1307.2579": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-07-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Piech",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhenghao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Do",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chuong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Koller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daphne"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Tuned Models of Peer Assessment in MOOCs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.HC stat.AP stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of The 6th International Conference on Educational Data\n  Mining (EDM 2013)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In massive open online courses (MOOCs), peer grading serves as a critical\ntool for scaling the grading of complex, open-ended assignments to courses with\ntens or hundreds of thousands of students. But despite promising initial\ntrials, it does not always deliver accurate results compared to human experts.\nIn this paper, we develop algorithms for estimating and correcting for grader\nbiases and reliabilities, showing significant improvement in peer grading\naccuracy on real data with 63,199 peer grades from Coursera's HCI course\nofferings --- the largest peer grading networks analysed to date. We relate\ngrader biases and reliabilities to other student factors such as student\nengagement, performance as well as commenting style. We also show that our\nmodel can lead to more intelligent assignment of graders to gradees."
    },
    "1806.09936": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedreschi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dino"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Giannotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fosca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guidotti",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Riccardo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Monreale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pappalardo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Luca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ruggieri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Salvatore"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Turini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franco"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Open the Black Box Data-Driven Explanation of Black Box Decision Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Black box systems for automated decision making, often based on machine\nlearning over (big) data, map a user's features into a class or a score without\nexposing the reasons why. This is problematic not only for lack of\ntransparency, but also for possible biases hidden in the algorithms, due to\nhuman prejudices and collection artifacts hidden in the training data, which\nmay lead to unfair or wrong decisions. We introduce the local-to-global\nframework for black box explanation, a novel approach with promising early\nresults, which paves the road for a wide spectrum of future developments along\nthree dimensions: (i) the language for expressing explanations in terms of\nhighly expressive logic-based rules, with a statistical and causal\ninterpretation; (ii) the inference of local explanations aimed at revealing the\nlogic of the decision adopted for a specific instance by querying and auditing\nthe black box in the vicinity of the target instance; (iii), the bottom-up\ngeneralization of the many local explanations into simple global ones, with\nalgorithms that optimize the quality and comprehensibility of explanations."
    },
    "1604.08934": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dumancic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastijan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blockeel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hendrik"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An expressive dissimilarity measure for relational clustering using\n  neighbourhood trees",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 3 figures, 4 tables, submitted to ECMLPKDD 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s10994-017-5644-6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Clustering is an underspecified task: there are no universal criteria for\nwhat makes a good clustering. This is especially true for relational data,\nwhere similarity can be based on the features of individuals, the relationships\nbetween them, or a mix of both. Existing methods for relational clustering have\nstrong and often implicit biases in this respect. In this paper, we introduce a\nnovel similarity measure for relational data. It is the first measure to\nincorporate a wide variety of types of similarity, including similarity of\nattributes, similarity of relational context, and proximity in a hypergraph. We\nexperimentally evaluate how using this similarity affects the quality of\nclustering on very different types of datasets. The experiments demonstrate\nthat (a) using this similarity in standard clustering methods consistently\ngives good results, whereas other measures work well only on datasets that\nmatch their bias; and (b) on most datasets, the novel similarity outperforms\neven the best among the existing ones."
    },
    "1710.06879": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-18",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Guolei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiangliang"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Graph Embedding with Rich Information through Heterogeneous Network",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.SI",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 7 figures, 4 tables",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Graph embedding has attracted increasing attention due to its critical\napplication in social network analysis. Most existing algorithms for graph\nembedding only rely on the typology information and fail to use the copious\ninformation in nodes as well as edges. As a result, their performance for many\ntasks may not be satisfactory. In this paper, we proposed a novel and general\nframework of representation learning for graph with rich text information\nthrough constructing a bipartite heterogeneous network. Specially, we designed\na biased random walk to explore the constructed heterogeneous network with the\nnotion of flexible neighborhood. The efficacy of our method is demonstrated by\nextensive comparison experiments with several baselines on various datasets. It\nimproves the Micro-F1 and Macro-F1 of node classification by 10% and 7% on Cora\ndataset."
    },
    "1304.2756": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Elsaesser",
                "http://arxiv.org/OAI/arXiv/:forenames": "Christopher"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explanation of Probabilistic Inference for Decision Support Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Third Conference on Uncertainty in\n  Artificial Intelligence (UAI1987)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1987-PG-394-403",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "An automated explanation facility for Bayesian conditioning aimed at\nimproving user acceptance of probability-based decision support systems has\nbeen developed. The domain-independent facility is based on an information\nprocessing perspective on reasoning about conditional evidence that accounts\nboth for biased and normative inferences. Experimental results indicate that\nthe facility is both acceptable to naive users and effective in improving\nunderstanding."
    },
    "1809.07806": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Thiagarajan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jayaraman J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rajan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Deepta"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sattigeri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Prasanna"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Can Deep Clinical Models Handle Real-World Domain Shifts?",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The hypothesis that computational models can be reliable enough to be adopted\nin prognosis and patient care is revolutionizing healthcare. Deep learning, in\nparticular, has been a game changer in building predictive models, thereby\nleading to community-wide data curation efforts. However, due to the inherent\nvariabilities in population characteristics and biological systems, these\nmodels are often biased to the training datasets. This can be limiting when\nmodels are deployed in new environments, particularly when there are systematic\ndomain shifts not known a priori. In this paper, we formalize these challenges\nby emulating a large class of domain shifts that can occur in clinical\nsettings, and argue that evaluating the behavior of predictive models in light\nof those shifts is an effective way of quantifying the reliability of clinical\nmodels. More specifically, we develop an approach for building challenging\nscenarios, based on analysis of \\textit{disease landscapes}, and utilize\nunsupervised domain adaptation to compensate for the domain shifts. Using the\nopenly available MIMIC-III EHR dataset for phenotyping, we generate a large\nclass of scenarios and evaluate the ability of deep clinical models in those\ncases. For the first time, our work sheds light into data regimes where deep\nclinical models can fail to generalize, due to significant changes in the\ndisease landscapes between the source and target landscapes. This study\nemphasizes the need for sophisticated evaluation mechanisms driven by\nreal-world domain shifts to build effective AI solutions for healthcare."
    },
    "1610.08606": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-07-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tiep"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Monga",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vishal"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fast Low-rank Shared Dictionary Learning for Image Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted version",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/TIP.2017.2729885",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Despite the fact that different objects possess distinct class-specific\nfeatures, they also usually share common patterns. This observation has been\nexploited partially in a recently proposed dictionary learning framework by\nseparating the particularity and the commonality (COPAR). Inspired by this, we\npropose a novel method to explicitly and simultaneously learn a set of common\npatterns as well as class-specific features for classification with more\nintuitive constraints. Our dictionary learning framework is hence characterized\nby both a shared dictionary and particular (class-specific) dictionaries. For\nthe shared dictionary, we enforce a low-rank constraint, i.e. claim that its\nspanning subspace should have low dimension and the coefficients corresponding\nto this dictionary should be similar. For the particular dictionaries, we\nimpose on them the well-known constraints stated in the Fisher discrimination\ndictionary learning (FDDL). Further, we develop new fast and accurate\nalgorithms to solve the subproblems in the learning step, accelerating its\nconvergence. The said algorithms could also be applied to FDDL and its\nextensions. The efficiencies of these algorithms are theoretically and\nexperimentally verified by comparing their complexities and running time with\nthose of other well-known dictionary learning methods. Experimental results on\nwidely used image datasets establish the advantages of our method over\nstate-of-the-art dictionary learning methods."
    },
    "cs_0504042": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2005-04-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schetinin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fieldsend",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J. E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Partridge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krzanowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "W. J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Everson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "R. M."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bailey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "T. C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hernandez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Bayesian Decision Tree Technique with a Sweeping Strategy",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:abstract": "The uncertainty of classification outcomes is of crucial importance for many\nsafety critical applications including, for example, medical diagnostics. In\nsuch applications the uncertainty of classification can be reliably estimated\nwithin a Bayesian model averaging technique that allows the use of prior\ninformation. Decision Tree (DT) classification models used within such a\ntechnique gives experts additional information by making this classification\nscheme observable. The use of the Markov Chain Monte Carlo (MCMC) methodology\nof stochastic sampling makes the Bayesian DT technique feasible to perform.\nHowever, in practice, the MCMC technique may become stuck in a particular DT\nwhich is far away from a region with a maximal posterior. Sampling such DTs\ncauses bias in the posterior estimates, and as a result the evaluation of\nclassification uncertainty may be incorrect. In a particular case, the negative\neffect of such sampling may be reduced by giving additional prior information\non the shape of DTs. In this paper we describe a new approach based on sweeping\nthe DTs without additional priors on the favorite shape of DTs. The\nperformances of Bayesian DT techniques with the standard and sweeping\nstrategies are compared on a synthetic data as well as on real datasets.\nQuantitatively evaluating the uncertainty in terms of entropy of class\nposterior probabilities, we found that the sweeping strategy is superior to the\nstandard strategy."
    },
    "1412.6749": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-12-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Ibraheem",
                "http://arxiv.org/OAI/arXiv/:forenames": "Abdulrahman Oladipupo"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "SENNS: Sparse Extraction Neural NetworkS for Feature Extraction",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.NE math.OC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Eighteen pages in all, but much of the central ideas are covered in\n  the first five and a half pages; most of the remaining pages are devoted to\n  straightforward mathematical derivations, and the presentation of three\n  algorithms. Manuscript contains no figures at this time",
        "http://arxiv.org/OAI/arXiv/:msc-class": "90-08",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "By drawing on ideas from optimisation theory, artificial neural networks\n(ANN), graph embeddings and sparse representations, I develop a novel\ntechnique, termed SENNS (Sparse Extraction Neural NetworkS), aimed at\naddressing the feature extraction problem. The proposed method uses (preferably\ndeep) ANNs for projecting input attribute vectors to an output space wherein\npairwise distances are maximized for vectors belonging to different classes,\nbut minimized for those belonging to the same class, while simultaneously\nenforcing sparsity on the ANN outputs. The vectors that result from the\nprojection can then be used as features in any classifier of choice.\nMathematically, I formulate the proposed method as the minimisation of an\nobjective function which can be interpreted, in the ANN output space, as a\nnegative factor of the sum of the squares of the pair-wise distances between\noutput vectors belonging to different classes, added to a positive factor of\nthe sum of squares of the pair-wise distances between output vectors belonging\nto the same classes, plus sparsity and weight decay terms. To derive an\nalgorithm for minimizing the objective function via gradient descent, I use the\nmulti-variate version of the chain rule to obtain the partial derivatives of\nthe function with respect to ANN weights and biases, and find that each of the\nrequired partial derivatives can be expressed as a sum of six terms. As it\nturns out, four of those six terms can be computed using the standard back\npropagation algorithm; the fifth can be computed via a slight modification of\nthe standard backpropagation algorithm; while the sixth one can be computed via\nsimple arithmetic. Finally, I propose experiments on the ARABASE Arabic corpora\nof digits and letters, the CMU PIE database of faces, the MNIST digits\ndatabase, and other standard machine learning databases."
    },
    "1511.03722": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-11-11",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-05-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lihong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Doubly Robust Off-policy Value Evaluation for Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.SY stat.ME stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages; 4 figures; ICML 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study the problem of off-policy value evaluation in reinforcement learning\n(RL), where one aims to estimate the value of a new policy based on data\ncollected by a different policy. This problem is often a critical step when\napplying RL in real-world problems. Despite its importance, existing general\nmethods either have uncontrolled bias or suffer high variance. In this work, we\nextend the doubly robust estimator for bandits to sequential decision-making\nproblems, which gets the best of both worlds: it is guaranteed to be unbiased\nand can have a much lower variance than the popular importance sampling\nestimators. We demonstrate the estimator's accuracy in several benchmark\nproblems, and illustrate its use as a subroutine in safe policy improvement. We\nalso provide theoretical results on the hardness of the problem, and show that\nour estimator can match the lower bound in certain scenarios."
    },
    "1008.1566": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-08-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2012-12-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhemin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hiemstra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Djoerd"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Apers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wombacher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andreas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Separate Training for Conditional Random Fields Using Co-occurrence Rate\n  Factorization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10pages",
        "http://arxiv.org/OAI/arXiv/:report-no": "TR-CTIT-12-29",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The standard training method of Conditional Random Fields (CRFs) is very slow\nfor large-scale applications. As an alternative, piecewise training divides the\nfull graph into pieces, trains them independently, and combines the learned\nweights at test time. In this paper, we present \\emph{separate} training for\nundirected models based on the novel Co-occurrence Rate Factorization (CR-F).\nSeparate training is a local training method. In contrast to MEMMs, separate\ntraining is unaffected by the label bias problem. Experiments show that\nseparate training (i) is unaffected by the label bias problem; (ii) reduces the\ntraining time from weeks to seconds; and (iii) obtains competitive results to\nthe standard and piecewise training on linear-chain CRFs."
    },
    "1806.05112": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Komiyama",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Junpei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shimao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hajime"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Comparing Fairness Criteria Based on Social Outcome",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fairness in algorithmic decision-making processes is attracting increasing\nconcern. When an algorithm is applied to human-related decision-making an\nestimator solely optimizing its predictive power can learn biases on the\nexisting data, which motivates us the notion of fairness in machine learning.\nwhile several different notions are studied in the literature, little studies\nare done on how these notions affect the individuals. We demonstrate such a\ncomparison between several policies induced by well-known fairness criteria,\nincluding the color-blind (CB), the demographic parity (DP), and the equalized\nodds (EO). We show that the EO is the only criterion among them that removes\ngroup-level disparity. Empirical studies on the social welfare and disparity of\nthese policies are conducted."
    },
    "1708.09032": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "MacFie",
                "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Plausibility and probability in deductive reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We consider the problem of rational uncertainty about unproven mathematical\nstatements, which G\\\"odel and others have remarked on. Using Bayesian-inspired\narguments we build a normative model of fair bets under deductive uncertainty\nwhich draws from both probability and the theory of algorithms. We comment on\nconnections to Zeilberger's notion of \"semi-rigorous proofs\", particularly that\ninherent subjectivity is an obstacle."
    },
    "1806.01203": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamrick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jessica B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Allen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kelsey R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bapst",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "McKee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Battaglia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter W."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Relational inductive bias for physical construction in humans and\n  machines",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "In Proceedings of the Annual Meeting of the Cognitive Science Society\n  (CogSci 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While current deep learning systems excel at tasks such as object\nclassification, language processing, and gameplay, few can construct or modify\na complex system such as a tower of blocks. We hypothesize that what these\nsystems lack is a \"relational inductive bias\": a capacity for reasoning about\ninter-object relations and making choices over a structured description of a\nscene. To test this hypothesis, we focus on a task that involves gluing pairs\nof blocks together to stabilize a tower, and quantify how well humans perform.\nWe then introduce a deep reinforcement learning agent which uses object- and\nrelation-centric scene and policy representations and apply it to the task. Our\nresults show that these structured representations allow the agent to\noutperform both humans and more naive approaches, suggesting that relational\ninductive bias is an important component in solving structured reasoning\nproblems and for building more intelligent, flexible machines."
    },
    "1803.07616": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riochet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ronan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Castro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mario Ynocente"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bernard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mathieu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lerer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fergus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Izard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "V\u00e9ronique"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dupoux",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emmanuel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "IntPhys: A Framework and Benchmark for Visual Intuitive Physics\n  Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In order to reach human performance on complex visual tasks, artificial\nsystems need to incorporate a significant amount of understanding of the world\nin terms of macroscopic objects, movements, forces, etc. Inspired by work on\nintuitive physics in infants, we propose an evaluation framework which\ndiagnoses how much a given system understands about physics by testing whether\nit can tell apart well matched videos of possible versus impossible events. The\ntest requires systems to compute a physical plausibility score over an entire\nvideo. It is free of bias and can test a range of specific physical reasoning\nskills. We then describe the first release of a benchmark dataset aimed at\nlearning intuitive physics in an unsupervised way, using videos constructed\nwith a game engine. We describe two Deep Neural Network baseline systems\ntrained with a future frame prediction objective and tested on the possible\nversus impossible discrimination task. The analysis of their results compared\nto human data gives novel insights in the potentials and limitations of next\nframe prediction architectures."
    },
    "1710.11386": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kilcher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yannic"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Becigneul",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gary"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hofmann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Parametrizing filters of a CNN with a GAN",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "It is commonly agreed that the use of relevant invariances as a good\nstatistical bias is important in machine-learning. However, most approaches\nthat explicitly incorporate invariances into a model architecture only make use\nof very simple transformations, such as translations and rotations. Hence,\nthere is a need for methods to model and extract richer transformations that\ncapture much higher-level invariances. To that end, we introduce a tool\nallowing to parametrize the set of filters of a trained convolutional neural\nnetwork with the latent space of a generative adversarial network. We then show\nthat the method can capture highly non-linear invariances of the data by\nvisualizing their effect in the data space."
    },
    "1806.07857": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Arjona-Medina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jose A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gillhofer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Widrich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Unterthiner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hochreiter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sepp"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "RUDDER: Return Decomposition for Delayed Rewards",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI math.OC stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "9 Pages plus appendix. For the code\n  https://github.com/ml-jku/baselines-rudder. For videos https://goo.gl/EQerZV",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a novel reinforcement learning approach for finite Markov decision\nprocesses (MDPs) with delayed rewards. In this work, biases of temporal\ndifference (TD) estimates are proved to be corrected only exponentially slowly\nin the number of delay steps. Furthermore, variances of Monte Carlo (MC)\nestimates are proved to increase the variance of other estimates, the number of\nwhich can exponentially grow in the number of delay steps. We introduce RUDDER,\na return decomposition method, which creates a new MDP with same optimal\npolicies as the original MDP but with redistributed rewards that have largely\nreduced delays. If the return decomposition is optimal, then the new MDP does\nnot have delayed rewards and TD estimates are unbiased. In this case, the\nrewards track Q-values so that the future expected reward is always zero. We\nexperimentally confirm our theoretical results on bias and variance of TD and\nMC estimates. On artificial tasks with different lengths of reward delays, we\nshow that RUDDER is exponentially faster than TD, MC, and MC Tree Search\n(MCTS). RUDDER outperforms rainbow, A3C, DDQN, Distributional DQN, Dueling\nDDQN, Noisy DQN, and Prioritized DDQN on the delayed reward Atari game Venture\nin only a fraction of the learning time. RUDDER considerably improves the\nstate-of-the-art on the delayed reward Atari game Bowling in much less learning\ntime. Source code is available at https://github.com/ml-jku/baselines-rudder,\nwith demonstration videos at https://goo.gl/EQerZV."
    },
    "1411.4023": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-11-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ahmed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Umair Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chatterjee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Krishnendu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gulwani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sumit"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Automatic Generation of Alternative Starting Positions for Simple\n  Traditional Board Games",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "A conference version of the paper will appear in AAAI 2015",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Simple board games, like Tic-Tac-Toe and CONNECT-4, play an important role\nnot only in the development of mathematical and logical skills, but also in the\nemotional and social development. In this paper, we address the problem of\ngenerating targeted starting positions for such games. This can facilitate new\napproaches for bringing novice players to mastery, and also leads to discovery\nof interesting game variants. We present an approach that generates starting\nstates of varying hardness levels for player~$1$ in a two-player board game,\ngiven rules of the board game, the desired number of steps required for\nplayer~$1$ to win, and the expertise levels of the two players. Our approach\nleverages symbolic methods and iterative simulation to efficiently search the\nextremely large state space. We present experimental results that include\ndiscovery of states of varying hardness levels for several simple grid-based\nboard games. The presence of such states for standard game variants like $4\n\\times 4$ Tic-Tac-Toe opens up new games to be played that have never been\nplayed as the default start state is heavily biased."
    },
    "1209.1885": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-09-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kramer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sack",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Parametric Constructive Kripke-Semantics for Standard Multi-Agent Belief\n  and Knowledge (Knowledge As Unbiased Belief)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LO cs.AI cs.DC cs.MA",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose parametric constructive Kripke-semantics for multi-agent\nKD45-belief and S5-knowledge in terms of elementary set-theoretic constructions\nof two basic functional building blocks, namely bias (or viewpoint) and\nvisibility, functioning also as the parameters of the doxastic and epistemic\naccessibility relation. The doxastic accessibility relates two possible worlds\nwhenever the application of the composition of bias with visibility to the\nfirst world is equal to the application of visibility to the second world. The\nepistemic accessibility is the transitive closure of the union of our doxastic\naccessibility and its converse. Therefrom, accessibility relations for common\nand distributed belief and knowledge can be constructed in a standard way. As a\nresult, we obtain a general definition of knowledge in terms of belief that\nenables us to view S5-knowledge as accurate (unbiased and thus true)\nKD45-belief, negation-complete belief and knowledge as exact KD45-belief and\nS5-knowledge, respectively, and perfect S5-knowledge as precise (exact and\naccurate) KD45-belief, and all this generically for arbitrary functions of bias\nand visibility. Our results can be seen as a semantic complement to previous\nfoundational results by Halpern et al. about the (un)definability and\n(non-)reducibility of knowledge in terms of and to belief, respectively."
    },
    "1805.01627": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Basu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Debabrota"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Senellart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bressan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "St\u00e9phane"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "BelMan: Bayesian Bandits on the Belief--Reward Manifold",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a generic, Bayesian, information geometric approach to the\nexploration--exploitation trade-off in multi-armed bandit problems. Our\napproach, BelMan, uniformly supports pure exploration,\nexploration--exploitation, and two-phase bandit problems. The knowledge on\nbandit arms and their reward distributions is summarised by the barycentre of\nthe joint distributions of beliefs and rewards of the arms, the\n\\emph{pseudobelief-reward}, within the beliefs-rewards manifold. BelMan\nalternates \\emph{information projection} and \\emph{reverse information\nprojection}, i.e., projection of the pseudobelief-reward onto beliefs-rewards\nto choose the arm to play, and projection of the resulting beliefs-rewards onto\nthe pseudobelief-reward. It introduces a mechanism that infuses an exploitative\nbias by means of a \\emph{focal distribution}, i.e., a reward distribution that\ngradually concentrates on higher rewards. Comparative performance evaluation\nwith state-of-the-art algorithms shows that BelMan is not only competitive but\ncan also outperform other approaches in specific setups, for instance involving\nmany arms and continuous rewards."
    },
    "1001.3745": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-01-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2010-08-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Medo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wakeling",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joseph Rushton"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The effect of discrete vs. continuous-valued ratings on reputation and\n  ranking systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.DB physics.soc-ph",
        "http://arxiv.org/OAI/arXiv/:comments": "6 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:acm-class": "H.2.8; K.4.4; H.3.5",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "EPL 91, 48004, 2010",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1209/0295-5075/91/48004",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "When users rate objects, a sophisticated algorithm that takes into account\nability or reputation may produce a fairer or more accurate aggregation of\nratings than the straightforward arithmetic average. Recently a number of\nauthors have proposed different co-determination algorithms where estimates of\nuser and object reputation are refined iteratively together, permitting\naccurate measures of both to be derived directly from the rating data. However,\nsimulations demonstrating these methods' efficacy assumed a continuum of rating\nvalues, consistent with typical physical modelling practice, whereas in most\nactual rating systems only a limited range of discrete values (such as a 5-star\nsystem) is employed. We perform a comparative test of several co-determination\nalgorithms with different scales of discrete ratings and show that this\nseemingly minor modification in fact has a significant impact on algorithms'\nperformance. Paradoxically, where rating resolution is low, increased noise in\nusers' ratings may even improve the overall performance of the system."
    },
    "1806.01242": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sanchez-Gonzalez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alvaro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Heess",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Springenberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jost Tobias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Merel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Riedmiller",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hadsell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Raia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Battaglia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Graph networks as learnable physics engines for inference and control",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "ICML 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Understanding and interacting with everyday physical scenes requires rich\nknowledge about the structure of the world, represented either implicitly in a\nvalue or policy function, or explicitly in a transition model. Here we\nintroduce a new class of learnable models--based on graph networks--which\nimplement an inductive bias for object- and relation-centric representations of\ncomplex, dynamical systems. Our results show that as a forward model, our\napproach supports accurate predictions from real and simulated data, and\nsurprisingly strong and efficient generalization, across eight distinct\nphysical systems which we varied parametrically and structurally. We also found\nthat our inference model can perform system identification. Our models are also\ndifferentiable, and support online planning via gradient-based trajectory\noptimization, as well as offline policy optimization. Our framework offers new\nopportunities for harnessing and exploiting rich knowledge about the world, and\ntakes a key step toward building machines with more human-like representations\nof the world."
    },
    "1810.10182": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Baosong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhaopeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Derek F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fandong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lidia S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling Localness for Self-Attention Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "EMNLP 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Self-attention networks have proven to be of profound value for its strength\nof capturing global dependencies. In this work, we propose to model localness\nfor self-attention networks, which enhances the ability of capturing useful\nlocal context. We cast localness modeling as a learnable Gaussian bias, which\nindicates the central and scope of the local region to be paid more attention.\nThe bias is then incorporated into the original attention distribution to form\na revised distribution. To maintain the strength of capturing long distance\ndependencies and enhance the ability of capturing short-range dependencies, we\nonly apply localness modeling to lower layers of self-attention networks.\nQuantitative and qualitative analyses on Chinese-English and English-German\ntranslation tasks demonstrate the effectiveness and universality of the\nproposed approach."
    },
    "1711.05401": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ravishankar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Srinivas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chandrahas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Talukdar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Partha Pratim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Revisiting Simple Neural Networks for Learning Representations of\n  Knowledge Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, submitted to and accepted in Automated Knowledge Base\n  Construction (AKBC) Workshop 2017, at NIPS 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address the problem of learning vector representations for entities and\nrelations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This\nproblem has received significant attention in the past few years and multiple\nmethods have been proposed. Most of the existing methods in the literature use\na predefined characteristic scoring function for evaluating the correctness of\nKG triples. These scoring functions distinguish correct triples (high score)\nfrom incorrect ones (low score). However, their performance vary across\ndifferent datasets. In this work, we demonstrate that a simple neural network\nbased score function can consistently achieve near start-of-the-art performance\non multiple datasets. We also quantitatively demonstrate biases in standard\nbenchmark datasets, and highlight the need to perform evaluation spanning\nvarious datasets."
    },
    "1106.0665": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bartlett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "P. L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Baxter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Infinite-Horizon Policy-Gradient Estimation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 15, pages\n  319-350, 2001",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.806",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Gradient-based approaches to direct policy search in reinforcement learning\nhave received much recent attention as a means to solve problems of partial\nobservability and to avoid some of the problems associated with policy\ndegradation in value-function methods. In this paper we introduce GPOMDP, a\nsimulation-based algorithm for generating a biased estimate of the gradient of\nthe average reward in Partially Observable Markov Decision Processes POMDPs\ncontrolled by parameterized stochastic policies. A similar algorithm was\nproposed by (Kimura et al. 1995). The algorithm's chief advantages are that it\nrequires storage of only twice the number of policy parameters, uses one free\nbeta (which has a natural interpretation in terms of bias-variance trade-off),\nand requires no knowledge of the underlying state. We prove convergence of\nGPOMDP, and show how the correct choice of the parameter beta is related to the\nmixing time of the controlled POMDP. We briefly describe extensions of GPOMDP\nto controlled Markov chains, continuous state, observation and control spaces,\nmultiple-agents, higher-order derivatives, and a version for training\nstochastic policies with internal states. In a companion paper (Baxter et al.,\nthis volume) we show how the gradient estimates generated by GPOMDP can be used\nin both a traditional stochastic gradient algorithm and a conjugate-gradient\nprocedure to find local optima of the average reward."
    },
    "1510.06335": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-10-21",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-04-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Venanzi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matteo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guiver",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jennings",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nick"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Time-Sensitive Bayesian Information Aggregation for Crowdsourcing\n  Systems",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Crowdsourcing systems commonly face the problem of aggregating multiple\njudgments provided by potentially unreliable workers. In addition, several\naspects of the design of efficient crowdsourcing processes, such as defining\nworker's bonuses, fair prices and time limits of the tasks, involve knowledge\nof the likely duration of the task at hand. Bringing this together, in this\nwork we introduce a new time--sensitive Bayesian aggregation method that\nsimultaneously estimates a task's duration and obtains reliable aggregations of\ncrowdsourced judgments. Our method, called BCCTime, builds on the key insight\nthat the time taken by a worker to perform a task is an important indicator of\nthe likely quality of the produced judgment. To capture this, BCCTime uses\nlatent variables to represent the uncertainty about the workers' completion\ntime, the tasks' duration and the workers' accuracy. To relate the quality of a\njudgment to the time a worker spends on a task, our model assumes that each\ntask is completed within a latent time window within which all workers with a\npropensity to genuinely attempt the labelling task (i.e., no spammers) are\nexpected to submit their judgments. In contrast, workers with a lower\npropensity to valid labeling, such as spammers, bots or lazy labelers, are\nassumed to perform tasks considerably faster or slower than the time required\nby normal workers. Specifically, we use efficient message-passing Bayesian\ninference to learn approximate posterior probabilities of (i) the confusion\nmatrix of each worker, (ii) the propensity to valid labeling of each worker,\n(iii) the unbiased duration of each task and (iv) the true label of each task.\nUsing two real-world public datasets for entity linking tasks, we show that\nBCCTime produces up to 11% more accurate classifications and up to 100% more\ninformative estimates of a task's duration compared to state-of-the-art\nmethods."
    },
    "1306.4999": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-06-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                "http://arxiv.org/OAI/arXiv/:forenames": "Lizi"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Safeguarding E-Commerce against Advisor Cheating Behaviors: Towards More\n  Robust Trust Models for Handling Unfair Ratings",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In electronic marketplaces, after each transaction buyers will rate the\nproducts provided by the sellers. To decide the most trustworthy sellers to\ntransact with, buyers rely on trust models to leverage these ratings to\nevaluate the reputation of sellers. Although the high effectiveness of\ndifferent trust models for handling unfair ratings have been claimed by their\ndesigners, recently it is argued that these models are vulnerable to more\nintelligent attacks, and there is an urgent demand that the robustness of the\nexisting trust models has to be evaluated in a more comprehensive way. In this\nwork, we classify the existing trust models into two broad categories and\npropose an extendable e-marketplace testbed to evaluate their robustness\nagainst different unfair rating attacks comprehensively. On top of highlighting\nthe robustness of the existing trust models for handling unfair ratings is far\nfrom what they were claimed to be, we further propose and validate a novel\ncombination mechanism for the existing trust models, Discount-then-Filter, to\nnotably enhance their robustness against the investigated attacks."
    },
    "1711.11443": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stock",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cisse",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Moustapha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "ConvNets and ImageNet Beyond Accuracy: Explanations, Bias Detection,\n  Adversarial Examples and Model Criticism",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.CY stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "submitted",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "ConvNets and Imagenet have driven the recent success of deep learning for\nimage classification. However, the marked slowdown in performance improvement,\nthe recent studies on the lack of robustness of neural networks to adversarial\nexamples and their tendency to exhibit undesirable biases (e.g racial biases)\nquestioned the reliability and the sustained development of these methods. This\nwork investigates these questions from the perspective of the end-user by using\nhuman subject studies and explanations. We experimentally demonstrate that the\naccuracy and robustness of ConvNets measured on Imagenet are underestimated. We\nshow that explanations can mitigate the impact of misclassified adversarial\nexamples from the perspective of the end-user and we introduce a novel tool for\nuncovering the undesirable biases learned by a model. These contributions also\nshow that explanations are a promising tool for improving our understanding of\nConvNets' predictions and for designing more reliable models"
    },
    "1810.04528": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Santana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brenda Salenave"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Woloszyn",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vinicius"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wives",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leandro Krug"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Is there Gender bias and stereotype in Portuguese Word Embeddings?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "The 13th edition of the International Conference on the\n  Computational Processing of Portuguese (PROPOR 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this work, we propose an analysis of the presence of gender bias\nassociated with professions in Portuguese word embeddings. The objective of\nthis work is to study gender implications related to stereotyped professions\nfor women and men in the context of the Portuguese language."
    },
    "1804.08117": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Tsuchiya",
                "http://arxiv.org/OAI/arXiv/:forenames": "Masatoshi"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Performance Impact Caused by Hidden Bias of Training Data for\n  Recognizing Textual Entailment",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of the 11th International Conference on Language\n  Resources and Evaluation (LREC2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The quality of training data is one of the crucial problems when a\nlearning-centered approach is employed. This paper proposes a new method to\ninvestigate the quality of a large corpus designed for the recognizing textual\nentailment (RTE) task. The proposed method, which is inspired by a statistical\nhypothesis test, consists of two phases: the first phase is to introduce the\npredictability of textual entailment labels as a null hypothesis which is\nextremely unacceptable if a target corpus has no hidden bias, and the second\nphase is to test the null hypothesis using a Naive Bayes model. The\nexperimental result of the Stanford Natural Language Inference (SNLI) corpus\ndoes not reject the null hypothesis. Therefore, it indicates that the SNLI\ncorpus has a hidden bias which allows prediction of textual entailment labels\nfrom hypothesis sentences even if no context information is given by a premise\nsentence. This paper also presents the performance impact of NN models for RTE\ncaused by this hidden bias."
    },
    "1802.05382": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abdollahpouri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Himan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Burke",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mobasher",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bamshad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Value-Aware Item Weighting for Long-Tail Recommendation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many recommender systems suffer from the popularity bias problem: popular\nitems are being recommended frequently while less popular, niche products, are\nrecommended rarely if not at all. However, those ignored products are exactly\nthe products that businesses need to find customers for and their\nrecommendations would be more beneficial. In this paper, we examine an item\nweighting approach to improve long-tail recommendation. Our approach works as a\nsimple yet powerful add-on to existing recommendation algorithms for making a\ntunable trade-off between accuracy and long-tail coverage."
    },
    "1502.07571": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-02-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-02-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aleksandrov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Martin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aziz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gaspers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Online Fair Division: analysing a Food Bank problem",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI cs.MA",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, 2 figures, 1 table",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study an online model of fair division designed to capture features of a\nreal world charity problem. We consider two simple mechanisms for this model in\nwhich agents simply declare what items they like. We analyse several axiomatic\nproperties of these mechanisms like strategy-proofness and envy-freeness.\nFinally, we perform a competitive analysis and compute the price of anarchy."
    },
    "1606.06126": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-06-20",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hanna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josiah P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stone",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Niekum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Scott"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bootstrapping with Models: Confidence Intervals for Off-Policy\n  Evaluation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Published in proceedings of the 16th International Conference on\n  Autonomous Agents and Multi-agent Systems. Updated with the camera-ready\n  version",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "For an autonomous agent, executing a poor policy may be costly or even\ndangerous. For such agents, it is desirable to determine confidence interval\nlower bounds on the performance of any given policy without executing said\npolicy. Current methods for exact high confidence off-policy evaluation that\nuse importance sampling require a substantial amount of data to achieve a tight\nlower bound. Existing model-based methods only address the problem in discrete\nstate spaces. Since exact bounds are intractable for many domains we trade off\nstrict guarantees of safety for more data-efficient approximate bounds. In this\ncontext, we propose two bootstrapping off-policy evaluation methods which use\nlearned MDP transition models in order to estimate lower confidence bounds on\npolicy performance with limited data in both continuous and discrete state\nspaces. Since direct use of a model may introduce bias, we derive a theoretical\nupper bound on model bias for when the model transition function is estimated\nwith i.i.d. trajectories. This bound broadens our understanding of the\nconditions under which model-based methods have high bias. Finally, we\nempirically evaluate our proposed methods and analyze the settings in which\ndifferent bootstrapping off-policy confidence interval methods succeed and\nfail."
    },
    "1801.04271": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Hitawala",
                "http://arxiv.org/OAI/arXiv/:forenames": "Saifuddin"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Comparative Study on Generative Adversarial Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent years, there have been tremendous advancements in the field of\nmachine learning. These advancements have been made through both academic as\nwell as industrial research. Lately, a fair amount of research has been\ndedicated to the usage of generative models in the field of computer vision and\nimage classification. These generative models have been popularized through a\nnew framework called Generative Adversarial Networks. Moreover, many modified\nversions of this framework have been proposed in the last two years. We study\nthe original model proposed by Goodfellow et al. as well as modifications over\nthe original model and provide a comparative analysis of these models."
    },
    "1807.00553": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-07-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dobbe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dean",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sarah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gilbert",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nitin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Broader View on Bias in Automated Decision-Making: Reflecting on\n  Epistemology and Dynamics",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.SY math.DS stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at the 2018 Workshop on Fairness, Accountability and\n  Transparency in Machine Learning during ICML 2018, Stockholm, Sweden",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning (ML) is increasingly deployed in real world contexts,\nsupplying actionable insights and forming the basis of automated\ndecision-making systems. While issues resulting from biases pre-existing in\ntraining data have been at the center of the fairness debate, these systems are\nalso affected by technical and emergent biases, which often arise as\ncontext-specific artifacts of implementation. This position paper interprets\ntechnical bias as an epistemological problem and emergent bias as a dynamical\nfeedback phenomenon. In order to stimulate debate on how to change machine\nlearning practice to effectively address these issues, we explore this broader\nview on bias, stress the need to reflect on epistemology, and point to\nvalue-sensitive design methodologies to revisit the design and implementation\nprocess of automated decision-making systems."
    },
    "1206.3239": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-06-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zhihong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kuroki",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manabu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Identifying Total Effects in the Presence of Latent Variables and\n  Selection bias",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ME cs.AI stat.AP",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2008-PG-62-69",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Assume that cause-effect relationships between variables can be described as\na directed acyclic graph and the corresponding linear structural equation\nmodel.We consider the identification problem of total effects in the presence\nof latent variables and selection bias between a treatment variable and a\nresponse variable. Pearl and his colleagues provided the back door criterion,\nthe front door criterion (Pearl, 2000) and the conditional instrumental\nvariable method (Brito and Pearl, 2002) as identifiability criteria for total\neffects in the presence of latent variables, but not in the presence of\nselection bias. In order to solve this problem, we propose new graphical\nidentifiability criteria for total effects based on the identifiable factor\nmodels. The results of this paper are useful to identify total effects in\nobservational studies and provide a new viewpoint to the identification\nconditions of factor models."
    },
    "1803.01901": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yongkai"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xintao"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Discrimination Discovery and Removal in Ranked Data using Causal\n  Graph",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Predictive models learned from historical data are widely used to help\ncompanies and organizations make decisions. However, they may digitally\nunfairly treat unwanted groups, raising concerns about fairness and\ndiscrimination. In this paper, we study the fairness-aware ranking problem\nwhich aims to discover discrimination in ranked datasets and reconstruct the\nfair ranking. Existing methods in fairness-aware ranking are mainly based on\nstatistical parity that cannot measure the true discriminatory effect since\ndiscrimination is causal. On the other hand, existing methods in causal-based\nanti-discrimination learning focus on classification problems and cannot be\ndirectly applied to handle the ranked data. To address these limitations, we\npropose to map the rank position to a continuous score variable that represents\nthe qualification of the candidates. Then, we build a causal graph that\nconsists of both the discrete profile attributes and the continuous score. The\npath-specific effect technique is extended to the mixed-variable causal graph\nto identify both direct and indirect discrimination. The relationship between\nthe path-specific effects for the ranked data and those for the binary decision\nis theoretically analyzed. Finally, algorithms for discovering and removing\ndiscrimination from a ranked dataset are developed. Experiments using the real\ndataset show the effectiveness of our approaches."
    },
    "1806.00852": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Havaei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chartrand",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gabriel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chouaib",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hassan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vincent",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jesson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chapados",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Matwin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the Importance of Attention in Meta-Learning for Few-Shot Text\n  Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "13 pages, 4 figures, submitted to NIPS",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Current deep learning based text classification methods are limited by their\nability to achieve fast learning and generalization when the data is scarce. We\naddress this problem by integrating a meta-learning procedure that uses the\nknowledge learned across many tasks as an inductive bias towards better natural\nlanguage understanding. Based on the Model-Agnostic Meta-Learning framework\n(MAML), we introduce the Attentive Task-Agnostic Meta-Learning (ATAML)\nalgorithm for text classification. The essential difference between MAML and\nATAML is in the separation of task-agnostic representation learning and\ntask-specific attentive adaptation. The proposed ATAML is designed to encourage\ntask-agnostic representation learning by way of task-agnostic parameterization\nand facilitate task-specific adaptation via attention mechanisms. We provide\nevidence to show that the attention mechanism in ATAML has a synergistic effect\non learning performance. In comparisons with models trained from random\ninitialization, pretrained models and meta trained MAML, our proposed ATAML\nmethod generalizes better on single-label and multi-label classification tasks\nin miniRCV1 and miniReuters-21578 datasets."
    },
    "1808.05385": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-08-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ding",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lizhong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the Decision Boundary of Deep Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "While deep learning models and techniques have achieved great empirical\nsuccess, our understanding of the source of success in many aspects remains\nvery limited. In an attempt to bridge the gap, we investigate the decision\nboundary of a production deep learning architecture with weak assumptions on\nboth the training data and the model. We demonstrate, both theoretically and\nempirically, that the last weight layer of a neural network converges to a\nlinear SVM trained on the output of the last hidden layer, for both the binary\ncase and the multi-class case with the commonly used cross-entropy loss.\nFurthermore, we show empirically that training a neural network as a whole,\ninstead of only fine-tuning the last weight layer, may result in better bias\nconstant for the last weight layer, which is important for generalization. In\naddition to facilitating the understanding of deep learning, our result can be\nhelpful for solving a broad range of practical problems of deep learning, such\nas catastrophic forgetting and adversarial attacking. The experiment codes are\navailable at https://github.com/lykaust15/NN_decision_boundary"
    },
    "1710.09867": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hill",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Felix"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hermann",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karl Moritz"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Blunsom",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Phil"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Clark",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stephen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Understanding Grounded Language Learning Agents",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neural network-based systems can now learn to locate the referents of words\nand phrases in images, answer questions about visual scenes, and even execute\nsymbolic instructions as first-person actors in partially-observable worlds. To\nachieve this so-called grounded language learning, models must overcome certain\nwell-studied learning challenges that are also fundamental to infants learning\ntheir first words. While it is notable that models with no meaningful prior\nknowledge overcome these learning obstacles, AI researchers and practitioners\ncurrently lack a clear understanding of exactly how they do so. Here we address\nthis question as a way of achieving a clearer general understanding of grounded\nlanguage learning, both to inform future research and to improve confidence in\nmodel predictions. For maximum control and generality, we focus on a simple\nneural network-based language learning agent trained via policy-gradient\nmethods to interpret synthetic linguistic instructions in a simulated 3D world.\nWe apply experimental paradigms from developmental psychology to this agent,\nexploring the conditions under which established human biases and learning\neffects emerge. We further propose a novel way to visualise and analyse\nsemantic representation in grounded language learning agents that yields a\nplausible computational account of the observed effects."
    },
    "1802.03493": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-09",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Farajtabar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mehrdad"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chow",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yinlam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghavamzadeh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "More Robust Doubly Robust Off-policy Evaluation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study the problem of off-policy evaluation (OPE) in reinforcement learning\n(RL), where the goal is to estimate the performance of a policy from the data\ngenerated by another policy(ies). In particular, we focus on the doubly robust\n(DR) estimators that consist of an importance sampling (IS) component and a\nperformance model, and utilize the low (or zero) bias of IS and low variance of\nthe model at the same time. Although the accuracy of the model has a huge\nimpact on the overall performance of DR, most of the work on using the DR\nestimators in OPE has been focused on improving the IS part, and not much on\nhow to learn the model. In this paper, we propose alternative DR estimators,\ncalled more robust doubly robust (MRDR), that learn the model parameter by\nminimizing the variance of the DR estimator. We first present a formulation for\nlearning the DR model in RL. We then derive formulas for the variance of the DR\nestimator in both contextual bandits and RL, such that their gradients\nw.r.t.~the model parameters can be estimated from the samples, and propose\nmethods to efficiently minimize the variance. We prove that the MRDR estimators\nare strongly consistent and asymptotically optimal. Finally, we evaluate MRDR\nin bandits and RL benchmark problems, and compare its performance with the\nexisting methods."
    },
    "1806.09777": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mianjy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Poorya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Arora",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Raman"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vidal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rene"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "On the Implicit Bias of Dropout",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "17 pages, 3 figures, In Proceedings of the Thirty-fifth International\n  Conference on Machine Learning (ICML), 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Algorithmic approaches endow deep learning systems with implicit bias that\nhelps them generalize even in over-parametrized settings. In this paper, we\nfocus on understanding such a bias induced in learning through dropout, a\npopular technique to avoid overfitting in deep learning. For single\nhidden-layer linear neural networks, we show that dropout tends to make the\nnorm of incoming/outgoing weight vectors of all the hidden nodes equal. In\naddition, we provide a complete characterization of the optimization landscape\ninduced by dropout."
    },
    "1806.02510": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mhamdi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "El Mahdi El"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guerraoui",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rachid"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hoang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L\u00ea Nguy\u00ean"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Maurer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexandre"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Removing Algorithmic Discrimination (With Minimal Individual Error)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We address the problem of correcting group discriminations within a score\nfunction, while minimizing the individual error. Each group is described by a\nprobability density function on the set of profiles. We first solve the problem\nanalytically in the case of two populations, with a uniform bonus-malus on the\nzones where each population is a majority. We then address the general case of\nn populations, where the entanglement of populations does not allow a similar\nanalytical solution. We show that an approximate solution with an arbitrarily\nhigh level of precision can be computed with linear programming. Finally, we\naddress the inverse problem where the error should not go beyond a certain\nvalue and we seek to minimize the discrimination."
    },
    "1801.09496": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gaurav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Thomas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shawe-Taylor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Improving Active Learning in Systematic Reviews",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.DL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages, many figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Systematic reviews are essential to summarizing the results of different\nclinical and social science studies. The first step in a systematic review task\nis to identify all the studies relevant to the review. The task of identifying\nrelevant studies for a given systematic review is usually performed manually,\nand as a result, involves substantial amounts of expensive human resource.\nLately, there have been some attempts to reduce this manual effort using active\nlearning. In this work, we build upon some such existing techniques, and\nvalidate by experimenting on a larger and comprehensive dataset than has been\nattempted until now. Our experiments provide insights on the use of different\nfeature extraction models for different disciplines. More importantly, we\nidentify that a naive active learning based screening process is biased in\nfavour of selecting similar documents. We aimed to improve the performance of\nthe screening process using a novel active learning algorithm with success.\nAdditionally, we propose a mechanism to choose the best feature extraction\nmethod for a given review."
    },
    "1611.04660": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yadav",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pranjul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Prunelli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lisiane"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hoff",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Steinbach",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Westra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bonnie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vipin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Simon",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gyorgy"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Inference in Observational Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.AP",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Our aging population increasingly suffers from multiple chronic diseases\nsimultaneously, necessitating the comprehensive treatment of these conditions.\nFinding the optimal set of drugs for a combinatorial set of diseases is a\ncombinatorial pattern exploration problem. Association rule mining is a popular\ntool for such problems, but the requirement of health care for finding causal,\nrather than associative, patterns renders association rule mining unsuitable.\nTo address this issue, we propose a novel framework based on the Rubin-Neyman\ncausal model for extracting causal rules from observational data, correcting\nfor a number of common biases. Specifically, given a set of interventions and a\nset of items that define subpopulations (e.g., diseases), we wish to find all\nsubpopulations in which effective intervention combinations exist and in each\nsuch subpopulation, we wish to find all intervention combinations such that\ndropping any intervention from this combination will reduce the efficacy of the\ntreatment. A key aspect of our framework is the concept of closed intervention\nsets which extend the concept of quantifying the effect of a single\nintervention to a set of concurrent interventions. We also evaluated our causal\nrule mining framework on the Electronic Health Records (EHR) data of a large\ncohort of patients from Mayo Clinic and showed that the patterns we extracted\nare sufficiently rich to explain the controversial findings in the medical\nliterature regarding the effect of a class of cholesterol drugs on Type-II\nDiabetes Mellitus (T2DM)."
    },
    "1801.08116": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-24",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Leibo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joel Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "d'Autume",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cyprien de Masson"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zoran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Beattie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Anderson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Keith"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Casta\u00f1eda",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio Garc\u00eda"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sanchez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manuel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Green",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gruslys",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Audrunas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Legg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shane"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hassabis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Demis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Botvinick",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matthew M."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.NE q-bio.NC",
        "http://arxiv.org/OAI/arXiv/:comments": "28 pages, 11 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Psychlab is a simulated psychology laboratory inside the first-person 3D game\nworld of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations\nof classical laboratory psychological experiments so that they work with both\nhuman and artificial agents. Psychlab has a simple and flexible API that\nenables users to easily create their own tasks. As examples, we are releasing\nPsychlab implementations of several classical experimental paradigms including\nvisual search, change detection, random dot motion discrimination, and multiple\nobject tracking. We also contribute a study of the visual psychophysics of a\nspecific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg\net al. 2016). This study leads to the surprising conclusion that UNREAL learns\nmore quickly about larger target stimuli than it does about smaller stimuli. In\nturn, this insight motivates a specific improvement in the form of a simple\nmodel of foveal vision that turns out to significantly boost UNREAL's\nperformance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By\nopen-sourcing Psychlab we hope to facilitate a range of future such studies\nthat simultaneously advance deep reinforcement learning and improve its links\nwith cognitive science."
    },
    "1703.10545": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Srijan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hooi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bryan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Makhija",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Disha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Faloutsos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christos"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Subrahamanian",
                    "http://arxiv.org/OAI/arXiv/:forenames": "V. S."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "FairJudge: Trustworthy User Prediction in Rating Platforms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SI cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Rating platforms enable large-scale collection of user opinion about items\n(products, other users, etc.). However, many untrustworthy users give\nfraudulent ratings for excessive monetary gains. In the paper, we present\nFairJudge, a system to identify such fraudulent users. We propose three\nmetrics: (i) the fairness of a user that quantifies how trustworthy the user is\nin rating the products, (ii) the reliability of a rating that measures how\nreliable the rating is, and (iii) the goodness of a product that measures the\nquality of the product. Intuitively, a user is fair if it provides reliable\nratings that are close to the goodness of the product. We formulate a mutually\nrecursive definition of these metrics, and further address cold start problems\nand incorporate behavioral properties of users and products in the formulation.\nWe propose an iterative algorithm, FairJudge, to predict the values of the\nthree metrics. We prove that FairJudge is guaranteed to converge in a bounded\nnumber of iterations, with linear time complexity. By conducting five different\nexperiments on five rating platforms, we show that FairJudge significantly\noutperforms nine existing algorithms in predicting fair and unfair users. We\nreported the 100 most unfair users in the Flipkart network to their review\nfraud investigators, and 80 users were correctly identified (80% accuracy). The\nFairJudge algorithm is already being deployed at Flipkart."
    },
    "1403.1893": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-03-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Smith",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Martinez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tony"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Becoming More Robust to Label Noise with Classifier Diversity",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "37 pages, 10 tables, 2 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "It is widely known in the machine learning community that class noise can be\n(and often is) detrimental to inducing a model of the data. Many current\napproaches use a single, often biased, measurement to determine if an instance\nis noisy. A biased measure may work well on certain data sets, but it can also\nbe less effective on a broader set of data sets. In this paper, we present\nnoise identification using classifier diversity (NICD) -- a method for deriving\na less biased noise measurement and integrating it into the learning process.\nTo lessen the bias of the noise measure, NICD selects a diverse set of\nclassifiers (based on their predictions of novel instances) to determine which\ninstances are noisy. We examine NICD as a technique for filtering, instance\nweighting, and selecting the base classifiers of a voting ensemble. We compare\nNICD with several other noise handling techniques that do not consider\nclassifier diversity on a set of 54 data sets and 5 learning algorithms. NICD\nsignificantly increases the classification accuracy over the other considered\napproaches and is effective across a broad set of data sets and learning\nalgorithms."
    },
    "1807.06813": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Di Palma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefano"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lanzi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pier Luca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Traditional Wisdom and Monte Carlo Tree Search Face-to-Face in the Card\n  Game Scopone",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Preprint. Accepted for publication in the IEEE Transaction on Games",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "IEEE Transactions on Games 2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/TG.2018.2834618",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present the design of a competitive artificial intelligence for Scopone, a\npopular Italian card game. We compare rule-based players using the most\nestablished strategies (one for beginners and two for advanced players) against\nplayers using Monte Carlo Tree Search (MCTS) and Information Set Monte Carlo\nTree Search (ISMCTS) with different reward functions and simulation strategies.\nMCTS requires complete information about the game state and thus implements a\ncheating player while ISMCTS can deal with incomplete information and thus\nimplements a fair player. Our results show that, as expected, the cheating MCTS\noutperforms all the other strategies; ISMCTS is stronger than all the\nrule-based players implementing well-known and most advanced strategies and it\nalso turns out to be a challenging opponent for human players."
    },
    "cs_0103015": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2001-03-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Hutter",
                "http://arxiv.org/OAI/arXiv/:forenames": "Marcus"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fitness Uniform Selection to Preserve Genetic Diversity",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DC cs.LG q-bio",
        "http://arxiv.org/OAI/arXiv/:comments": "13 LaTeX pages, 1 eps figure",
        "http://arxiv.org/OAI/arXiv/:report-no": "IDSIA-01-01",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2; I.2.6; I.2.8; F.2",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 2002 Congress on Evolutionary Computation\n  (CEC-2002) 783-788",
        "http://arxiv.org/OAI/arXiv/:abstract": "In evolutionary algorithms, the fitness of a population increases with time\nby mutating and recombining individuals and by a biased selection of more fit\nindividuals. The right selection pressure is critical in ensuring sufficient\noptimization progress on the one hand and in preserving genetic diversity to be\nable to escape from local optima on the other. We propose a new selection\nscheme, which is uniform in the fitness values. It generates selection pressure\ntowards sparsely populated fitness regions, not necessarily towards higher\nfitness, as is the case for all other selection schemes. We show that the new\nselection scheme can be much more effective than standard selection schemes."
    },
    "1505.00401": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-05-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Powers",
                "http://arxiv.org/OAI/arXiv/:forenames": "David M. W."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Visualization of Tradeoff in Evaluation: from Precision-Recall & PN to\n  LIFT, ROC & BIRD",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.IR stat.ME stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "23 pages, 12 equations, 2 figures, 2 tables, 1 sidebar",
        "http://arxiv.org/OAI/arXiv/:report-no": "KIT-14-002",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Evaluation often aims to reduce the correctness or error characteristics of a\nsystem down to a single number, but that always involves trade-offs. Another\nway of dealing with this is to quote two numbers, such as Recall and Precision,\nor Sensitivity and Specificity. But it can also be useful to see more than\nthis, and a graphical approach can explore sensitivity to cost, prevalence,\nbias, noise, parameters and hyper-parameters.\n  Moreover, most techniques are implicitly based on two balanced classes, and\nour ability to visualize graphically is intrinsically two dimensional, but we\noften want to visualize in a multiclass context. We review the dichotomous\napproaches relating to Precision, Recall, and ROC as well as the related LIFT\nchart, exploring how they handle unbalanced and multiclass data, and deriving\nnew probabilistic and information theoretic variants of LIFT that help deal\nwith the issues associated with the handling of multiple and unbalanced\nclasses."
    },
    "1711.10907": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-29",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Popova",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mariya"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Isayev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Olexandr"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tropsha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Reinforcement Learning for De-Novo Drug Design",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a novel computational strategy for de novo design of molecules\nwith desired properties termed ReLeaSE (Reinforcement Learning for Structural\nEvolution). Based on deep and reinforcement learning approaches, ReLeaSE\nintegrates two deep neural networks - generative and predictive - that are\ntrained separately but employed jointly to generate novel targeted chemical\nlibraries. ReLeaSE employs simple representation of molecules by their SMILES\nstrings only. Generative models are trained with stack-augmented memory network\nto produce chemically feasible SMILES strings, and predictive models are\nderived to forecast the desired properties of the de novo generated compounds.\nIn the first phase of the method, generative and predictive models are trained\nseparately with a supervised learning algorithm. In the second phase, both\nmodels are trained jointly with the reinforcement learning approach to bias the\ngeneration of new chemical structures towards those with the desired physical\nand/or biological properties. In the proof-of-concept study, we have employed\nthe ReLeaSE method to design chemical libraries with a bias toward structural\ncomplexity or biased toward compounds with either maximal, minimal, or specific\nrange of physical properties such as melting point or hydrophobicity, as well\nas to develop novel putative inhibitors of JAK2. The approach proposed herein\ncan find a general use for generating targeted chemical libraries of novel\ncompounds optimized for either a single desired property or multiple\nproperties."
    },
    "1701.06233": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-01-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haoyuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nguyen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thuy-vy Thi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Luo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiebo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "What the Language You Tweet Says About Your Occupation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at the 10th International AAAI Conference on Web and Social\n  Media (ICWSM-16)",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many aspects of people's lives are proven to be deeply connected to their\njobs. In this paper, we first investigate the distinct characteristics of major\noccupation categories based on tweets. From multiple social media platforms, we\ngather several types of user information. From users' LinkedIn webpages, we\nlearn their proficiencies. To overcome the ambiguity of self-reported\ninformation, a soft clustering approach is applied to extract occupations from\ncrowd-sourced data. Eight job categories are extracted, including Marketing,\nAdministrator, Start-up, Editor, Software Engineer, Public Relation, Office\nClerk, and Designer. Meanwhile, users' posts on Twitter provide cues for\nunderstanding their linguistic styles, interests, and personalities. Our\nresults suggest that people of different jobs have unique tendencies in certain\nlanguage styles and interests. Our results also clearly reveal distinctive\nlevels in terms of Big Five Traits for different jobs. Finally, a classifier is\nbuilt to predict job types based on the features extracted from tweets. A high\naccuracy indicates a strong discrimination power of language features for job\nprediction task."
    },
    "1806.05502": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-14",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fuchs",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Fabian B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Groth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Oliver"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kosiorek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adam R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bewley",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alex"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wulfmeier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Markus"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vedaldi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Posner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ingmar"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Neural Stethoscopes: Unifying Analytic, Auxiliary and Adversarial\n  Network Probing",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Model interpretability and systematic, targeted model adaptation present\ncentral tenets in machine learning for addressing limited or biased datasets.\nIn this paper, we introduce neural stethoscopes as a framework for quantifying\nthe degree of importance of specific factors of influence in deep networks as\nwell as for actively promoting and suppressing information as appropriate. In\ndoing so we unify concepts from multitask learning as well as training with\nauxiliary and adversarial losses. We showcase the efficacy of neural\nstethoscopes in an intuitive physics domain. Specifically, we investigate the\nchallenge of visually predicting stability of block towers and demonstrate that\nthe network uses visual cues which makes it susceptible to biases in the\ndataset. Through the use of stethoscopes we interrogate the accessibility of\nspecific information throughout the network stack and show that we are able to\nactively de-bias network predictions as well as enhance performance via\nsuitable auxiliary and adversarial stethoscope losses."
    },
    "1805.06248": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nakahashi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ryo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yamada",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Seiji"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling Human Inference of Others' Intentions in Complex Situations\n  with Plan Predictability Bias",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Cogsci 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A recent approach based on Bayesian inverse planning for the \"theory of mind\"\nhas shown good performance in modeling human cognition. However, perfect\ninverse planning differs from human cognition during one kind of complex tasks\ndue to human bounded rationality. One example is an environment in which there\nare many available plans for achieving a specific goal. We propose a \"plan\npredictability oriented model\" as a model of inferring other peoples' goals in\ncomplex environments. This model adds the bias that people prefer predictable\nplans. This bias is calculated with simple plan prediction. We tested this\nmodel with a behavioral experiment in which humans observed the partial path of\ngoal-directed actions. Our model had a higher correlation with human inference.\nWe also confirmed the robustness of our model with complex tasks and determined\nthat it can be improved by taking account of individual differences in \"bounded\nrationality\"."
    },
    "1408.4901": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-08-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aziz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cahan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Casey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gretton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Charles"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kilby",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Phillip"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mattei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicholas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Study of Proxies for Shapley Allocations of Transport Costs",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI cs.MA math.OC",
        "http://arxiv.org/OAI/arXiv/:comments": "51 Pages: 1-35 Main Document, 36-51 Appendices A--E",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose and evaluate a number of solutions to the problem of calculating\nthe cost to serve each location in a single-vehicle transport setting. Such\ncost to serve analysis has application both strategically and operationally in\ntransportation. The problem is formally given by the traveling salesperson game\n(TSG), a cooperative total utility game in which agents correspond to locations\nin a traveling salesperson problem (TSP). The cost to serve a location is an\nallocated portion of the cost of an optimal tour. The Shapley value is one of\nthe most important normative division schemes in cooperative games, giving a\nprincipled and fair allocation both for the TSG and more generally. We consider\na number of direct and sampling-based procedures for calculating the Shapley\nvalue, and present the first proof that approximating the Shapley value of the\nTSG within a constant factor is NP-hard. Treating the Shapley value as an ideal\nbaseline allocation, we then develop six proxies for that value which are\nrelatively easy to compute. We perform an experimental evaluation using\nSynthetic Euclidean games as well as games derived from real-world tours\ncalculated for fast-moving consumer goods scenarios. Our experiments show that\nseveral computationally tractable allocation techniques correspond to good\nproxies for the Shapley value."
    },
    "1604.03912": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Herman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gindele",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tobias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wagner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "J\u00f6rg"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schmitt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Felix"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Burgard",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wolfram"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Inverse Reinforcement Learning with Simultaneous Estimation of Rewards\n  and Dynamics",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG cs.SY stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "accepted to appear in AISTATS 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Inverse Reinforcement Learning (IRL) describes the problem of learning an\nunknown reward function of a Markov Decision Process (MDP) from observed\nbehavior of an agent. Since the agent's behavior originates in its policy and\nMDP policies depend on both the stochastic system dynamics as well as the\nreward function, the solution of the inverse problem is significantly\ninfluenced by both. Current IRL approaches assume that if the transition model\nis unknown, additional samples from the system's dynamics are accessible, or\nthe observed behavior provides enough samples of the system's dynamics to solve\nthe inverse problem accurately. These assumptions are often not satisfied. To\novercome this, we present a gradient-based IRL approach that simultaneously\nestimates the system's dynamics. By solving the combined optimization problem,\nour approach takes into account the bias of the demonstrations, which stems\nfrom the generating policy. The evaluation on a synthetic MDP and a transfer\nlearning task shows improvements regarding the sample efficiency as well as the\naccuracy of the estimated reward functions and transition models."
    },
    "1811.00692": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuanpeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Zero-Shot Transfer VQA Dataset",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Acquiring a large vocabulary is an important aspect of human intelligence.\nOnecommon approach for human to populating vocabulary is to learn words\nduringreading or listening, and then use them in writing or speaking. This\nability totransfer from input to output is natural for human, but it is\ndifficult for machines.Human spontaneously performs this knowledge transfer in\ncomplicated multimodaltasks, such as Visual Question Answering (VQA). In order\nto approach human-levelArtificial Intelligence, we hope to equip machines with\nsuch ability. Therefore, toaccelerate this research, we propose a newzero-shot\ntransfer VQA(ZST-VQA)dataset by reorganizing the existing VQA v1.0 dataset in\nthe way that duringtraining, some words appear only in one module (i.e.\nquestions) but not in theother (i.e. answers). In this setting, an intelligent\nmodel should understand andlearn the concepts from one module (i.e. questions),\nand at test time, transfer themto the other (i.e. predict the concepts as\nanswers). We conduct evaluation on thisnew dataset using three existing\nstate-of-the-art VQA neural models. Experimentalresults show a significant drop\nin performance on this dataset, indicating existingmethods do not address the\nzero-shot transfer problem. Besides, our analysis findsthat this may be caused\nby the implicit bias learned during training."
    },
    "1803.03639": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-08",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tatbul",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nesime"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tae Jun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zdonik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gottschlich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Justin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A New Model for Evaluating Range-Based Anomaly Detection Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Classical anomaly detection (AD) is principally concerned with point-based\nanomalies, anomalies that occur at a single point in time. While point-based\nanomalies are useful, many real-world anomalies are range-based, meaning they\noccur over a period of time. Therefore, applying classical point-based accuracy\nmeasures to range-based AD systems can be misleading. In this paper, we present\na new mathematical model that more accurately gauges the classification\ncorrectness of AD systems for range-based anomalies. Unlike prior work, our\nmathematical definitions are a superset of the classical AD definitions,\nenabling our system to also subsume point-based anomalies. Moreover, our system\nis broadly generalizable and provides a number of specialization functions that\ncan control the application's bias along a multi-dimensional axis."
    },
    "1711.01711": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-05",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zenil",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hector"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Badillo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Liliana"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hern\u00e1ndez-Orozco",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Santiago"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hern\u00e1ndez-Quiroz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francisco"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Coding-theorem Like Behaviour and Emergence of the Universal\n  Distribution from Resource-bounded Algorithmic Probability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IT cs.AI cs.CC math.IT",
        "http://arxiv.org/OAI/arXiv/:comments": "27 pages main text, 39 pages including supplement. Online complexity\n  calculator: http://complexitycalculator.com/",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Parallel, Emergent and Distributed\n  Systems, DOI: 10.1080/17445760.2018.1448932",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Previously referred to as `miraculous' in the scientific literature because\nof its powerful properties and its wide application as optimal solution to the\nproblem of induction/inference, (approximations to) Algorithmic Probability\n(AP) and the associated Universal Distribution are (or should be) of the\ngreatest importance in science. Here we investigate the emergence, the rates of\nemergence and convergence, and the Coding-theorem like behaviour of AP in\nTuring-subuniversal models of computation. We investigate empirical\ndistributions of computing models in the Chomsky hierarchy. We introduce\nmeasures of algorithmic probability and algorithmic complexity based upon\nresource-bounded computation, in contrast to previously thoroughly investigated\ndistributions produced from the output distribution of Turing machines. This\napproach allows for numerical approximations to algorithmic\n(Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a\ncomputational hierarchy. We demonstrate that all these estimations are\ncorrelated in rank and that they converge both in rank and values as a function\nof computational power, despite fundamental differences between computational\nmodels. In the context of natural processes that operate below the Turing\nuniversal level because of finite resources and physical degradation, the\ninvestigation of natural biases stemming from algorithmic rules may shed light\non the distribution of outcomes. We show that up to 60\\% of the\nsimplicity/complexity bias in distributions produced even by the weakest of the\ncomputational models can be accounted for by Algorithmic Probability in its\napproximation to the Universal Distribution."
    },
    "1312.6546": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-12-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-06-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aziz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gaspers",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Serge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mackenzie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fair assignment of indivisible objects under ordinal preferences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "extended version of a paper presented at AAMAS 2014",
        "http://arxiv.org/OAI/arXiv/:msc-class": "91A12, 68Q15",
        "http://arxiv.org/OAI/arXiv/:acm-class": "F.2; J.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We consider the discrete assignment problem in which agents express ordinal\npreferences over objects and these objects are allocated to the agents in a\nfair manner. We use the stochastic dominance relation between fractional or\nrandomized allocations to systematically define varying notions of\nproportionality and envy-freeness for discrete assignments. The computational\ncomplexity of checking whether a fair assignment exists is studied for these\nfairness notions. We also characterize the conditions under which a fair\nassignment is guaranteed to exist. For a number of fairness concepts,\npolynomial-time algorithms are presented to check whether a fair assignment\nexists. Our algorithmic results also extend to the case of unequal entitlements\nof agents. Our NP-hardness result, which holds for several variants of\nenvy-freeness, answers an open question posed by Bouveret, Endriss, and Lang\n(ECAI 2010). We also propose fairness concepts that always suggest a non-empty\nset of assignments with meaningful fairness properties. Among these concepts,\noptimal proportionality and optimal weak proportionality appear to be desirable\nfairness concepts."
    },
    "1611.02385": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peysakhovich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexander"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lada",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Akos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Combining observational and experimental data to find heterogeneous\n  treatment effects",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Every design choice will have different effects on different units. However\ntraditional A/B tests are often underpowered to identify these heterogeneous\neffects. This is especially true when the set of unit-level attributes is\nhigh-dimensional and our priors are weak about which particular covariates are\nimportant. However, there are often observational data sets available that are\norders of magnitude larger. We propose a method to combine these two data\nsources to estimate heterogeneous treatment effects. First, we use\nobservational time series data to estimate a mapping from covariates to\nunit-level effects. These estimates are likely biased but under some conditions\nthe bias preserves unit-level relative rank orderings. If these conditions\nhold, we only need sufficient experimental data to identify a monotonic,\none-dimensional transformation from observationally predicted treatment effects\nto real treatment effects. This reduces power demands greatly and makes the\ndetection of heterogeneous effects much easier. As an application, we show how\nour method can be used to improve Facebook page recommendations."
    },
    "1702.07134": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-08-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ahmed",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Faez"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dickerson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fuge",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Diverse Weighted Bipartite b-Matching",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.DS cs.AI",
        "http://arxiv.org/OAI/arXiv/:doi": "10.24963/ijcai.2017/6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bipartite matching, where agents on one side of a market are matched to\nagents or items on the other, is a classical problem in computer science and\neconomics, with widespread application in healthcare, education, advertising,\nand general resource allocation. A practitioner's goal is typically to maximize\na matching market's economic efficiency, possibly subject to some fairness\nrequirements that promote equal access to resources. A natural balancing act\nexists between fairness and efficiency in matching markets, and has been the\nsubject of much research.\n  In this paper, we study a complementary goal---balancing diversity and\nefficiency---in a generalization of bipartite matching where agents on one side\nof the market can be matched to sets of agents on the other. Adapting a\nclassical definition of the diversity of a set, we propose a quadratic\nprogramming-based approach to solving a supermodular minimization problem that\nbalances diversity and total weight of the solution. We also provide a scalable\ngreedy algorithm with theoretical performance bounds. We then define the price\nof diversity, a measure of the efficiency loss due to enforcing diversity, and\ngive a worst-case theoretical bound. Finally, we demonstrate the efficacy of\nour methods on three real-world datasets, and show that the price of diversity\nis not bad in practice."
    },
    "1711.02326": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ke",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nan Rosemary"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goyal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anirudh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bilaniuk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Olexa"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Binas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jonathan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Charlin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Laurent"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yoshua"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent\n  Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A major drawback of backpropagation through time (BPTT) is the difficulty of\nlearning long-term dependencies, coming from having to propagate credit\ninformation backwards through every single step of the forward computation.\nThis makes BPTT both computationally impractical and biologically implausible.\nFor this reason, full backpropagation through time is rarely used on long\nsequences, and truncated backpropagation through time is used as a heuristic.\nHowever, this usually leads to biased estimates of the gradient in which longer\nterm dependencies are ignored. Addressing this issue, we propose an alternative\nalgorithm, Sparse Attentive Backtracking, which might also be related to\nprinciples used by brains to learn long-term dependencies. Sparse Attentive\nBacktracking learns an attention mechanism over the hidden states of the past\nand selectively backpropagates through paths with high attention weights. This\nallows the model to learn long term dependencies while only backtracking for a\nsmall number of time steps, not just from the recent past but also from\nattended relevant past states."
    },
    "1202.3764": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-02-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Textor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Johannes"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liskiewicz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maciej"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adjustment Criteria in Causal Diagrams: An Algorithmic Perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2011-PG-681-688",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Identifying and controlling bias is a key problem in empirical sciences.\nCausal diagram theory provides graphical criteria for deciding whether and how\ncausal effects can be identified from observed (nonexperimental) data by\ncovariate adjustment. Here we prove equivalences between existing as well as\nnew criteria for adjustment and we provide a new simplified but still\nequivalent notion of d-separation. These lead to efficient algorithms for two\nimportant tasks in causal diagram analysis: (1) listing minimal covariate\nadjustments (with polynomial delay); and (2) identifying the subdiagram\ninvolved in biasing paths (in linear time). Our results improve upon existing\nexponential-time solutions for these problems, enabling users to assess the\neffects of covariate adjustment on diagrams with tens to hundreds of variables\ninteractively in real time."
    },
    "1507.00407": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-07-01",
        "http://arxiv.org/OAI/arXiv/:updated": "2015-12-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Syrgkanis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vasilis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alekh"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Luo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haipeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schapire",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Robert E."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fast Convergence of Regularized Learning in Games",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We show that natural classes of regularized learning algorithms with a form\nof recency bias achieve faster convergence rates to approximate efficiency and\nto coarse correlated equilibria in multiplayer normal form games. When each\nplayer in a game uses an algorithm from our class, their individual regret\ndecays at $O(T^{-3/4})$, while the sum of utilities converges to an approximate\noptimum at $O(T^{-1})$--an improvement upon the worst case $O(T^{-1/2})$ rates.\nWe show a black-box reduction for any algorithm in the class to achieve\n$\\tilde{O}(T^{-1/2})$ rates against an adversary, while maintaining the faster\nrates against algorithms in the class. Our results extend those of [Rakhlin and\nShridharan 2013] and [Daskalakis et al. 2014], who only analyzed two-player\nzero-sum games for specific algorithms."
    },
    "1002.4522": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2010-02-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jakaite",
                    "http://arxiv.org/OAI/arXiv/:forenames": "L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schetinin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "V."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Maple",
                    "http://arxiv.org/OAI/arXiv/:forenames": "C."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Feature Importance in Bayesian Assessment of Newborn Brain Maturity from\n  EEG",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of the 9th WSEAS International Conference on Artificial\n  Intelligence, Knowledge Engineering and Data Bases (AIKED), University of\n  Cambridge, UK, 2010, edited by L. A. Zadeh et al, pp 191 - 195",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 9th WSEAS International Conference on\n  Artificial Intelligence, Knowledge Engineering and Data Bases (AIKED),\n  University of Cambridge, UK, 2010, edited by L. A. Zadeh et al, pp 191 - 195",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The methodology of Bayesian Model Averaging (BMA) is applied for assessment\nof newborn brain maturity from sleep EEG. In theory this methodology provides\nthe most accurate assessments of uncertainty in decisions. However, the\nexisting BMA techniques have been shown providing biased assessments in the\nabsence of some prior information enabling to explore model parameter space in\ndetails within a reasonable time. The lack in details leads to disproportional\nsampling from the posterior distribution. In case of the EEG assessment of\nbrain maturity, BMA results can be biased because of the absence of information\nabout EEG feature importance. In this paper we explore how the posterior\ninformation about EEG features can be used in order to reduce a negative impact\nof disproportional sampling on BMA performance. We use EEG data recorded from\nsleeping newborns to test the efficiency of the proposed BMA technique."
    },
    "1712.10050": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anqi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fathony",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rizal"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ziebart",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Brian D."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Kernel Robust Bias-Aware Prediction under Covariate Shift",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Under covariate shift, training (source) data and testing (target) data\ndiffer in input space distribution, but share the same conditional label\ndistribution. This poses a challenging machine learning task. Robust Bias-Aware\n(RBA) prediction provides the conditional label distribution that is robust to\nthe worstcase logarithmic loss for the target distribution while matching\nfeature expectation constraints from the source distribution. However,\nemploying RBA with insufficient feature constraints may result in high\ncertainty predictions for much of the source data, while leaving too much\nuncertainty for target data predictions. To overcome this issue, we extend the\nrepresenter theorem to the RBA setting, enabling minimization of regularized\nexpected target risk by a reweighted kernel expectation under the source\ndistribution. By applying kernel methods, we establish consistency guarantees\nand demonstrate better performance of the RBA classifier than competing methods\non synthetically biased UCI datasets as well as datasets that have natural\ncovariate shift."
    },
    "1407.3130": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-07-11",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-07-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Allocation in Practice",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CC cs.GT",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Proc. of 37th edition of the German Conference on\n  Artificial Intelligence (KI 2014), Springer LNCS",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "How do we allocate scarcere sources? How do we fairly allocate costs? These\nare two pressing challenges facing society today. I discuss two recent projects\nat NICTA concerning resource and cost allocation. In the first, we have been\nworking with FoodBank Local, a social startup working in collaboration with\nfood bank charities around the world to optimise the logistics of collecting\nand distributing donated food. Before we can distribute this food, we must\ndecide how to allocate it to different charities and food kitchens. This gives\nrise to a fair division problem with several new dimensions, rarely considered\nin the literature. In the second, we have been looking at cost allocation\nwithin the distribution network of a large multinational company. This also has\nseveral new dimensions rarely considered in the literature."
    },
    "1604.01734": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-04-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bouveret",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sylvain",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Toulouse"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lema\u00eetre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michel",
                    "http://arxiv.org/OAI/arXiv/:affiliation": "Toulouse"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficiency and Sequenceability in Fair Division of Indivisible Goods\n  with Additive Preferences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "COMSOC-2016, Jun 2016, Toulouse, France",
        "http://arxiv.org/OAI/arXiv/:proxy": "ccsd",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is the\nfollowing: at each stage, a designated agent picks one object among those that\nremain. This paper, restricted to the case where the agents have numerical\nadditive preferences over objects, revisits to some extent the seminal paper by\nBrams and King [9] which was specific to ordinal and linear order preferences\nover items. We point out similarities and differences with this latter context.\nIn particular, we show that any Pareto-optimal allocation (under additive\npreferences) is sequenceable, but that the converse is not true anymore. This\nasymmetry leads naturally to the definition of a \"scale of efficiency\" having\nthree steps: Pareto-optimality, sequenceability without Pareto-optimality, and\nnon-sequenceability. Finally, we investigate the links between these efficiency\nproperties and the \"scale of fairness\" we have described in an earlier work\n[7]: we first show that an allocation can be envy-free and non-sequenceable,\nbut that every competitive equilibrium with equal incomes is sequenceable. Then\nwe experimentally explore the links between the scales of efficiency and\nfairness."
    },
    "1709.09450": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Halawani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohammad K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Forsyth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rob"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lord",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Phillip"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Literature Based Approach to Define the Scope of Biomedical\n  Ontologies: A Case Study on a Rehabilitation Therapy Ontology",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.DL",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at the International Conference for Biomedical Ontologies\n  2017(ICBO 2017), 4 pages, 3 figures, 1 table",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this article, we investigate our early attempts at building an ontology\ndescribing rehabilitation therapies following brain injury. These therapies are\nwide-ranging, involving interventions of many different kinds. As a result,\nthese therapies are hard to describe. As well as restricting actual practice,\nthis is also a major impediment to evidence-based medicine as it is hard to\nmeaningfully compare two treatment plans.\n  Ontology development requires significant effort from both ontologists and\ndomain experts. Knowledge elicited from domain experts forms the scope of the\nontology. The process of knowledge elicitation is expensive, consumes experts'\ntime and might have biases depending on the selection of the experts. Various\nmethodologies and techniques exist for enabling this knowledge elicitation,\nincluding community groups and open development practices. A related problem is\nthat of defining scope. By defining the scope, we can decide whether a concept\n(i.e. term) should be represented in the ontology. This is the opposite of\nknowledge elicitation, in the sense that it defines what should not be in the\nontology. This can be addressed by pre-defining a set of competency questions.\n  These approaches are, however, expensive and time-consuming. Here, we\ndescribe our work toward an alternative approach, bootstrapping the ontology\nfrom an initially small corpus of literature that will define the scope of the\nontology, expanding this to a set covering the domain, then using information\nextraction to define an initial terminology to provide the basis and the\ncompetencies for the ontology. Here, we discuss four approaches to building a\nsuitable corpus that is both sufficiently covering and precise."
    },
    "1807.06777": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Aminof",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benjamin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "De Giacomo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giuseppe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Murano",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aniello"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rubin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sasha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Planning and Synthesis Under Assumptions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LO cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In Reasoning about Action and Planning, one synthesizes the agent plan by\ntaking advantage of the assumption on how the environment works (that is, one\nexploits the environment's effects, its fairness, its trajectory constraints).\nIn this paper we study this form of synthesis in detail. We consider\nassumptions as constraints on the possible strategies that the environment can\nhave in order to respond to the agent's actions. Such constraints may be given\nin the form of a planning domain (or action theory), as linear-time formulas\nover infinite or finite runs, or as a combination of the two (e.g., FOND under\nfairness). We argue though that not all assumption specifications are\nmeaningful: they need to be consistent, which means that there must exist an\nenvironment strategy fulfilling the assumption in spite of the agent actions.\nFor such assumptions, we study how to do synthesis/planning for agent goals,\nranging from a classical reachability to goal on traces specified in LTL and\nLTLf/LDLf, characterizing the problem both mathematically and algorithmically."
    },
    "1802.09728": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-02-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zafari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Moser",
                    "http://arxiv.org/OAI/arXiv/:forenames": "I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Baarslag",
                    "http://arxiv.org/OAI/arXiv/:forenames": "T."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modelling and Analysis of Temporal Preference Drifts Using A\n  Component-Based Factorised Latent Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The changes in user preferences can originate from substantial reasons, like\npersonality shift, or transient and circumstantial ones, like seasonal changes\nin item popularities. Disregarding these temporal drifts in modelling user\npreferences can result in unhelpful recommendations. Moreover, different\ntemporal patterns can be associated with various preference domains, and\npreference components and their combinations. These components comprise\npreferences over features, preferences over feature values, conditional\ndependencies between features, socially-influenced preferences, and bias. For\nexample, in the movies domain, the user can change his rating behaviour (bias\nshift), her preference for genre over language (feature preference shift), or\nstart favouring drama over comedy (feature value preference shift). In this\npaper, we first propose a novel latent factor model to capture the\ndomain-dependent component-specific temporal patterns in preferences. The\ncomponent-based approach followed in modelling the aspects of preferences and\ntheir temporal effects enables us to arbitrarily switch components on and off.\nWe evaluate the proposed method on three popular recommendation datasets and\nshow that it significantly outperforms the most accurate state-of-the-art\nstatic models. The experiments also demonstrate the greater robustness and\nstability of the proposed dynamic model in comparison with the most successful\nmodels to date. We also analyse the temporal behaviour of different preference\ncomponents and their combinations and show that the dynamic behaviour of\npreference components is highly dependent on the preference dataset and domain.\nTherefore, the results also highlight the importance of modelling temporal\neffects but also underline the advantages of a component-based architecture\nthat is better suited to capture domain-specific balances in the contributions\nof the aspects."
    },
    "1811.05577": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saleiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pedro"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kuester",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benedict"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stevens",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abby"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Anisfeld",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ari"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hinkson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Loren"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "London",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jesse"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rayid"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Aequitas: A Bias and Fairness Audit Toolkit",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "Aequitas website: http://dsapp.uchicago.edu/aequitas",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent work has raised concerns on the risk of unintended bias in algorithmic\ndecision making systems being used nowadays that can affect individuals\nunfairly based on race, gender or religion, among other possible\ncharacteristics. While a lot of bias metrics and fairness definitions have been\nproposed in recent years, there is no consensus on which metric/definition\nshould be used and there are very few available resources to operationalize\nthem. Therefore, despite recent awareness, auditing for bias and fairness when\ndeveloping and deploying algorithmic decision making systems is not yet a\nstandard practice. We present Aequitas, an open source bias and fairness audit\ntoolkit that is an intuitive and easy to use addition to the machine learning\nworkflow, enabling users to seamlessly test models for several bias and\nfairness metrics in relation to multiple population sub-groups. We believe\nAequitas will facilitate informed and equitable decisions around developing and\ndeploying algorithmic decision making systems for both data scientists, machine\nlearning researchers and policymakers."
    },
    "1805.03379": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Manqing"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lina"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xianzhi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Benatallah",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boualem"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chaoran"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ning",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaodong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Opinion Fraud Detection via Neural Autoencoder Decision Forest",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Online reviews play an important role in influencing buyers' daily purchase\ndecisions. However, fake and meaningless reviews, which cannot reflect users'\ngenuine purchase experience and opinions, widely exist on the Web and pose\ngreat challenges for users to make right choices. Therefore,it is desirable to\nbuild a fair model that evaluates the quality of products by distinguishing\nspamming reviews. We present an end-to-end trainable unified model to leverage\nthe appealing properties from Autoencoder and random forest. A stochastic\ndecision tree model is implemented to guide the global parameter learning\nprocess. Extensive experiments were conducted on a large Amazon review dataset.\nThe proposed model consistently outperforms a series of compared methods."
    },
    "1610.07045": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julie Yixuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Huichu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Victor O. K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Han",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiawei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "pg-Causality: Identifying Spatiotemporal Causal Pathways for Air\n  Pollutants with Urban Big Data",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many countries are suffering from severe air pollution. Understanding how\ndifferent air pollutants accumulate and propagate is critical to making\nrelevant public policies. In this paper, we use urban big data (air quality\ndata and meteorological data) to identify the \\emph{spatiotemporal (ST) causal\npathways} for air pollutants. This problem is challenging because: (1) there\nare numerous noisy and low-pollution periods in the raw air quality data, which\nmay lead to unreliable causality analysis, (2) for large-scale data in the ST\nspace, the computational complexity of constructing a causal structure is very\nhigh, and (3) the \\emph{ST causal pathways} are complex due to the interactions\nof multiple pollutants and the influence of environmental factors. Therefore,\nwe present \\emph{p-Causality}, a novel pattern-aided causality analysis\napproach that combines the strengths of \\emph{pattern mining} and\n\\emph{Bayesian learning} to efficiently and faithfully identify the \\emph{ST\ncausal pathways}. First, \\emph{Pattern mining} helps suppress the noise by\ncapturing frequent evolving patterns (FEPs) of each monitoring sensor, and\ngreatly reduce the complexity by selecting the pattern-matched sensors as\n\"causers\". Then, \\emph{Bayesian learning} carefully encodes the local and ST\ncausal relations with a Gaussian Bayesian network (GBN)-based graphical model,\nwhich also integrates environmental influences to minimize biases in the final\nresults. We evaluate our approach with three real-world data sets containing\n982 air quality sensors, in three regions of China from 01-Jun-2013 to\n19-Dec-2015. Results show that our approach outperforms the traditional causal\nstructure learning methods in time efficiency, inference accuracy and\ninterpretability."
    },
    "1810.01566": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-02",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunzhu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiajun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tedrake",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Russ"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tenenbaum",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua B."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Torralba",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Antonio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning Particle Dynamics for Manipulating Rigid Bodies, Deformable\n  Objects, and Fluids",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO physics.comp-ph stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Real-life control tasks involve matter of various substances---rigid or soft\nbodies, liquid, gas---each with distinct physical behaviors. This poses\nchallenges to traditional rigid-body physics engines. Particle-based simulators\nhave been developed to model the dynamics of these complex scenes; however,\nrelying on approximation techniques, their simulation often deviates from real\nworld physics, especially in the long term. In this paper, we propose to learn\na particle-based simulator for complex control tasks. Combining learning with\nparticle-based systems brings in two major benefits: first, the learned\nsimulator, just like other particle-based systems, acts widely on objects of\ndifferent materials; second, the particle-based representation poses strong\ninductive bias for learning: particles of the same type have the same dynamics\nwithin. This enables the model to quickly adapt to new environments of unknown\ndynamics within a few observations. Using the learned simulator, robots have\nachieved success in complex manipulation tasks, such as manipulating fluids and\ndeformable foam. The effectiveness of our method has also been demonstrated in\nthe real world. Our study helps lay the foundation for robot learning of\ndynamic scenes with particle-based representations."
    },
    "1311.0541": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-11-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bialkowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Otte",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Frazzoli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emilio"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Free-configuration Biased Sampling for Motion Planning: Errata",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This document contains improved and updated proofs of convergence for the\nsampling method presented in our paper \"Free-configuration Biased Sampling for\nMotion Planning\"."
    },
    "1612.00837": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-02",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goyal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yash"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Khot",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tejas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Summers-Stay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Douglas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in\n  Visual Question Answering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.CL cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Problems at the intersection of vision and language are of significant\nimportance both as challenging research questions and for the rich set of\napplications they enable. However, inherent structure in our world and bias in\nour language tend to be a simpler signal for learning than visual modalities,\nresulting in models that ignore visual information, leading to an inflated\nsense of their capability.\n  We propose to counter these language priors for the task of Visual Question\nAnswering (VQA) and make vision (the V in VQA) matter! Specifically, we balance\nthe popular VQA dataset by collecting complementary images such that every\nquestion in our balanced dataset is associated with not just a single image,\nbut rather a pair of similar images that result in two different answers to the\nquestion. Our dataset is by construction more balanced than the original VQA\ndataset and has approximately twice the number of image-question pairs. Our\ncomplete balanced dataset is publicly available at www.visualqa.org as part of\nthe 2nd iteration of the Visual Question Answering Dataset and Challenge (VQA\nv2.0).\n  We further benchmark a number of state-of-art VQA models on our balanced\ndataset. All models perform significantly worse on our balanced dataset,\nsuggesting that these models have indeed learned to exploit language priors.\nThis finding provides the first concrete empirical evidence for what seems to\nbe a qualitative sense among practitioners.\n  Finally, our data collection protocol for identifying complementary images\nenables us to develop a novel interpretable model, which in addition to\nproviding an answer to the given (image, question) pair, also provides a\ncounter-example based explanation. Specifically, it identifies an image that is\nsimilar to the original image, but it believes has a different answer to the\nsame question. This can help in building trust for machines among their users."
    },
    "1608.02193": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-08-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-08-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Burgess",
                "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Spacetimes with Semantics (III) - The Structure of Functional Knowledge\n  Representation and Artificial Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.SY",
        "http://arxiv.org/OAI/arXiv/:comments": "122 pages, builiding on parts I and II Minor updates and corrections\n  added to current version",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.11; F.4.1; I.2.4; G.2.2",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Using the previously developed concepts of semantic spacetime, I explore the\ninterpretation of knowledge representations, and their structure, as a semantic\nsystem, within the framework of promise theory. By assigning interpretations to\nphenomena, from observers to observed, we may approach a simple description of\nknowledge-based functional systems, with direct practical utility. The focus is\nespecially on the interpretation of concepts, associative knowledge, and\ncontext awareness. The inference seems to be that most if not all of these\nconcepts emerge from purely semantic spacetime properties, which opens the\npossibility for a more generalized understanding of what constitutes a\nlearning, or even `intelligent' system.\n  Some key principles emerge for effective knowledge representation: 1)\nseparation of spacetime scales, 2) the recurrence of four irreducible types of\nassociation, by which intent propagates: aggregation, causation, cooperation,\nand similarity, 3) the need for discrimination of identities (discrete), which\nis assisted by distinguishing timeline simultaneity from sequential events, and\n4) the ability to learn (memory). It is at least plausible that emergent\nknowledge abstraction capabilities have their origin in basic spacetime\nstructures.\n  These notes present a unified view of mostly well-known results; they allow\nus to see information models, knowledge representations, machine learning, and\nsemantic networking (transport and information base) in a common framework. The\nnotion of `smart spaces' thus encompasses artificial systems as well as living\nsystems, across many different scales, e.g. smart cities and organizations."
    },
    "1702.03767": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-07-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Glauner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Patrick"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Migliosi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Angelo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meira",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jorge"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Valtchev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Petko"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "State",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Radu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bettinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Franck"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Is Big Data Sufficient for a Reliable Detection of Non-Technical Losses?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Proceedings of the 19th International Conference on Intelligent\n  System Applications to Power Systems (ISAP 2017)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Non-technical losses (NTL) occur during the distribution of electricity in\npower grids and include, but are not limited to, electricity theft and faulty\nmeters. In emerging countries, they may range up to 40% of the total\nelectricity distributed. In order to detect NTLs, machine learning methods are\nused that learn irregular consumption patterns from customer data and\ninspection results. The Big Data paradigm followed in modern machine learning\nreflects the desire of deriving better conclusions from simply analyzing more\ndata, without the necessity of looking at theory and models. However, the\nsample of inspected customers may be biased, i.e. it does not represent the\npopulation of all customers. As a consequence, machine learning models trained\non these inspection results are biased as well and therefore lead to unreliable\npredictions of whether customers cause NTL or not. In machine learning, this\nissue is called covariate shift and has not been addressed in the literature on\nNTL detection yet. In this work, we present a novel framework for quantifying\nand visualizing covariate shift. We apply it to a commercial data set from\nBrazil that consists of 3.6M customers and 820K inspection results. We show\nthat some features have a stronger covariate shift than others, making\npredictions less reliable. In particular, previous inspections were focused on\ncertain neighborhoods or customer classes and that they were not sufficiently\nspread among the population of customers. This framework is about to be\ndeployed in a commercial product for NTL detection."
    },
    "1805.01217": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lippi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Palka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Przemyslaw"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Contissa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giuseppe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lagioia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Micklitz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hans-Wolfgang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sartor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giovanni"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Torroni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paolo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "CLAUDETTE: an Automated Detector of Potentially Unfair Clauses in Online\n  Terms of Service",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Terms of service of on-line platforms too often contain clauses that are\npotentially unfair to the consumer. We present an experimental study where\nmachine learning is employed to automatically detect such potentially unfair\nclauses. Results show that the proposed system could provide a valuable tool\nfor lawyers and consumers alike."
    },
    "0902.0798": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2009-02-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Diaz-Aviles",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ernesto"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Alleviating Media Bias Through Intelligent Agent Blogging",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.11; J.4; H.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Consumers of mass media must have a comprehensive, balanced and plural\nselection of news to get an unbiased perspective; but achieving this goal can\nbe very challenging, laborious and time consuming. News stories development\nover time, its (in)consistency, and different level of coverage across the\nmedia outlets are challenges that a conscientious reader has to overcome in\norder to alleviate bias.\n  In this paper we present an intelligent agent framework currently\nfacilitating analysis of the main sources of on-line news in El Salvador. We\nshow how prior tools of text analysis and Web 2.0 technologies can be combined\nwith minimal manual intervention to help individuals on their rational decision\nprocess, while holding media outlets accountable for their work."
    },
    "1602.05352": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-02-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-05-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schnabel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tobias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Swaminathan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adith"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashudeep"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chandak",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Navin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Joachims",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thorsten"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Recommendations as Treatments: Debiasing Learning and Evaluation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.IR",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages in ICML 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Most data for evaluating and training recommender systems is subject to\nselection biases, either through self-selection by the users or through the\nactions of the recommendation system itself. In this paper, we provide a\nprincipled approach to handling selection biases, adapting models and\nestimation techniques from causal inference. The approach leads to unbiased\nperformance estimators despite biased data, and to a matrix factorization\nmethod that provides substantially improved prediction performance on\nreal-world data. We theoretically and empirically characterize the robustness\nof the approach, finding that it is highly practical and scalable."
    },
    "1612.05048": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-12-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Karaletsos",
                "http://arxiv.org/OAI/arXiv/:forenames": "Theofanis"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adversarial Message Passing For Graphical Models",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "(12 pages, 2 figures) Presented at NIPS Advances In Approximate\n  Inference 2016 (AABI 2016)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bayesian inference on structured models typically relies on the ability to\ninfer posterior distributions of underlying hidden variables. However,\ninference in implicit models or complex posterior distributions is hard. A\npopular tool for learning implicit models are generative adversarial networks\n(GANs) which learn parameters of generators by fooling discriminators.\nTypically, GANs are considered to be models themselves and are not understood\nin the context of inference. Current techniques rely on inefficient global\ndiscrimination of joint distributions to perform learning, or only consider\ndiscriminating a single output variable. We overcome these limitations by\ntreating GANs as a basis for likelihood-free inference in generative models and\ngeneralize them to Bayesian posterior inference over factor graphs. We propose\nlocal learning rules based on message passing minimizing a global divergence\ncriterion involving cooperating local adversaries used to sidestep explicit\nlikelihood evaluations. This allows us to compose models and yields a unified\ninference and learning framework for adversarial learning. Our framework treats\nmodel specification and inference separately and facilitates richly structured\nmodels within the family of Directed Acyclic Graphs, including components such\nas intractable likelihoods, non-differentiable models, simulators and generally\ncumbersome models. A key result of our treatment is the insight that Bayesian\ninference on structured models can be performed only with sampling and\ndiscrimination when using nonparametric variational families, without access to\nexplicit distributions. As a side-result, we discuss the link to likelihood\nmaximization. These approaches hold promise to be useful in the toolbox of\nprobabilistic modelers and enrich the gamut of current probabilistic\nprogramming applications."
    },
    "1511.05897": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-11-18",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-03-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Edwards",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Harrison"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Storkey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Censoring Representations with an Adversary",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Paper accepted to ICLR",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In practice, there are often explicit constraints on what representations or\ndecisions are acceptable in an application of machine learning. For example it\nmay be a legal requirement that a decision must not favour a particular group.\nAlternatively it can be that that representation of data must not have\nidentifying information. We address these two related issues by learning\nflexible representations that minimize the capability of an adversarial critic.\nThis adversary is trying to predict the relevant sensitive variable from the\nrepresentation, and so minimizing the performance of the adversary ensures\nthere is little or no information in the representation about the sensitive\nvariable. We demonstrate this adversarial approach on two problems: making\ndecisions free from discrimination and removing private information from\nimages. We formulate the adversarial model as a minimax problem, and optimize\nthat minimax objective using a stochastic gradient alternate min-max optimizer.\nWe demonstrate the ability to provide discriminant free representations for\nstandard test problems, and compare with previous state of the art methods for\nfairness, showing statistically significant improvement across most cases. The\nflexibility of this method is shown via a novel problem: removing annotations\nfrom images, from unaligned training examples of annotated and unannotated\nimages, and with no a priori knowledge of the form of annotation provided to\nthe model."
    },
    "1409.2821": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-09-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghaffari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Meysam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghadiri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nasser"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Ambiguity-Driven Fuzzy C-Means Clustering: How to Detect Uncertain\n  Clustered Records",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CV",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s10489-016-0759-1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As a well-known clustering algorithm, Fuzzy C-Means (FCM) allows each input\nsample to belong to more than one cluster, providing more flexibility than\nnon-fuzzy clustering methods. However, the accuracy of FCM is subject to false\ndetections caused by noisy records, weak feature selection and low certainty of\nthe algorithm in some cases. The false detections are very important in some\ndecision-making application domains like network security and medical\ndiagnosis, where weak decisions based on such false detections may lead to\ncatastrophic outcomes. They are mainly emerged from making decisions about a\nsubset of records that do not provide enough evidence to make a good decision.\nIn this paper, we propose a method for detecting such ambiguous records in FCM\nby introducing a certainty factor to decrease invalid detections. This approach\nenables us to send the detected ambiguous records to another discrimination\nmethod for a deeper investigation, thus increasing the accuracy by lowering the\nerror rate. Most of the records are still processed quickly and with low error\nrate which prevents performance loss compared to similar hybrid methods.\nExperimental results of applying the proposed method on several datasets from\ndifferent domains show a significant decrease in error rate as well as improved\nsensitivity of the algorithm."
    },
    "1804.06876": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jieyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianlu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yatskar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ordonez",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vicente"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kai-Wei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "NAACL '18 Camera Ready",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce a new benchmark, WinoBias, for coreference resolution focused on\ngender bias. Our corpus contains Winograd-schema style sentences with entities\ncorresponding to people referred by their occupation (e.g. the nurse, the\ndoctor, the carpenter). We demonstrate that a rule-based, a feature-rich, and a\nneural coreference system all link gendered pronouns to pro-stereotypical\nentities with higher accuracy than anti-stereotypical entities, by an average\ndifference of 21.1 in F1 score. Finally, we demonstrate a data-augmentation\napproach that, in combination with existing word-embedding debiasing\ntechniques, removes the bias demonstrated by these systems in WinoBias without\nsignificantly affecting their performance on existing coreference benchmark\ndatasets. Our dataset and code are available at http://winobias.org."
    },
    "1709.02256": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "De Lara",
                "http://arxiv.org/OAI/arXiv/:forenames": "Michel",
                "http://arxiv.org/OAI/arXiv/:affiliation": "CERMICS"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Rationally Biased Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI math.OC",
        "http://arxiv.org/OAI/arXiv/:proxy": "ccsd",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Are human perception and decision biases grounded in a form of rationality?\nYou return to your camp after hunting or gathering. You see the grass moving.\nYou do not know the probability that a snake is in the grass. Should you cross\nthe grass - at the risk of being bitten by a snake - or make a long, hence\ncostly, detour? Based on this storyline, we consider a rational decision maker\nmaximizing expected discounted utility with learning. We show that his optimal\nbehavior displays three biases: status quo, salience, overestimation of small\nprobabilities. Biases can be the product of rational behavior."
    },
    "1803.05752": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Weihao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stork",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Johannes A."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kragic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Danica"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael Y."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kaiyu"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Rearrangement with Nonprehensile Manipulation Using Deep Reinforcement\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "2018 International Conference on Robotics and Automation",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Rearranging objects on a tabletop surface by means of nonprehensile\nmanipulation is a task which requires skillful interaction with the physical\nworld. Usually, this is achieved by precisely modeling physical properties of\nthe objects, robot, and the environment for explicit planning. In contrast, as\nexplicitly modeling the physical environment is not always feasible and\ninvolves various uncertainties, we learn a nonprehensile rearrangement strategy\nwith deep reinforcement learning based on only visual feedback. For this, we\nmodel the task with rewards and train a deep Q-network. Our potential\nfield-based heuristic exploration strategy reduces the amount of collisions\nwhich lead to suboptimal outcomes and we actively balance the training set to\navoid bias towards poor examples. Our training process leads to quicker\nlearning and better performance on the task as compared to uniform exploration\nand standard experience replay. We demonstrate empirical evidence from\nsimulation that our method leads to a success rate of 85%, show that our system\ncan cope with sudden changes of the environment, and compare our performance\nwith human level performance."
    },
    "1106.1818": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Nock",
                "http://arxiv.org/OAI/arXiv/:forenames": "R."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Inducing Interpretable Voting Classifiers without Trading Accuracy for\n  Simplicity: Theoretical Results, Approximation Algorithms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 17, pages\n  137-170, 2002",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.986",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent advances in the study of voting classification algorithms have brought\nempirical and theoretical results clearly showing the discrimination power of\nensemble classifiers. It has been previously argued that the search of this\nclassification power in the design of the algorithms has marginalized the need\nto obtain interpretable classifiers. Therefore, the question of whether one\nmight have to dispense with interpretability in order to keep classification\nstrength is being raised in a growing number of machine learning or data mining\npapers. The purpose of this paper is to study both theoretically and\nempirically the problem. First, we provide numerous results giving insight into\nthe hardness of the simplicity-accuracy tradeoff for voting classifiers. Then\nwe provide an efficient \"top-down and prune\" induction heuristic, WIDC, mainly\nderived from recent results on the weak learning and boosting frameworks. It is\nto our knowledge the first attempt to build a voting classifier as a base\nformula using the weak learning framework (the one which was previously highly\nsuccessful for decision tree induction), and not the strong learning framework\n(as usual for such classifiers with boosting-like approaches). While it uses a\nwell-known induction scheme previously successful in other classes of concept\nrepresentations, thus making it easy to implement and compare, WIDC also relies\non recent or new results we give about particular cases of boosting known as\npartition boosting and ranking loss boosting. Experimental results on\nthirty-one domains, most of which readily available, tend to display the\nability of WIDC to produce small, accurate, and interpretable decision\ncommittees."
    },
    "1707.05729": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Martinez-Cantin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ruben"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "McCourt",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Robust Bayesian Optimization with Student-t Likelihood",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Bayesian optimization has recently attracted the attention of the automatic\nmachine learning community for its excellent results in hyperparameter tuning.\nBO is characterized by the sample efficiency with which it can optimize\nexpensive black-box functions. The efficiency is achieved in a similar fashion\nto the learning to learn methods: surrogate models (typically in the form of\nGaussian processes) learn the target function and perform intelligent sampling.\nThis surrogate model can be applied even in the presence of noise; however, as\nwith most regression methods, it is very sensitive to outlier data. This can\nresult in erroneous predictions and, in the case of BO, biased and inefficient\nexploration. In this work, we present a GP model that is robust to outliers\nwhich uses a Student-t likelihood to segregate outliers and robustly conduct\nBayesian optimization. We present numerical results evaluating the proposed\nmethod in both artificial functions and real problems."
    },
    "1605.03269": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Junpei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Novianto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rony"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mingjun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xinzheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cangelosi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Angelo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Hierarchical Emotion Regulated Sensorimotor Model: Case Studies",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at The 5th International Conference on Data-Driven Control\n  and Learning Systems. 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Inspired by the hierarchical cognitive architecture and the perception-action\nmodel (PAM), we propose that the internal status acts as a kind of\ncommon-coding representation which affects, mediates and even regulates the\nsensorimotor behaviours. These regulation can be depicted in the Bayesian\nframework, that is why cognitive agents are able to generate behaviours with\nsubtle differences according to their emotion or recognize the emotion by\nperception. A novel recurrent neural network called recurrent neural network\nwith parametric bias units (RNNPB) runs in three modes, constructing a\ntwo-level emotion regulated learning model, was further applied to testify this\ntheory in two different cases."
    },
    "1406.2464": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-06-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kopparapu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sunil Kumar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pandharipande",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Meghna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sita",
                    "http://arxiv.org/OAI/arXiv/:forenames": "G"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Music and Vocal Separation Using Multi-Band Modulation Based Features",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SD cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 5 figures, 2010 IEEE Symposium on Industrial Electronics\n  Applications (ISIEA)",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/ISIEA.2010.5679370",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The potential use of non-linear speech features has not been investigated for\nmusic analysis although other commonly used speech features like Mel Frequency\nCeptral Coefficients (MFCC) and pitch have been used extensively. In this\npaper, we assume an audio signal to be a sum of modulated sinusoidal and then\nuse the energy separation algorithm to decompose the audio into amplitude and\nfrequency modulation components using the non-linear Teager-Kaiser energy\noperator. We first identify the distribution of these non-linear features for\nmusic only and voice only segments in the audio signal in different Mel spaced\nfrequency bands and show that they have the ability to discriminate. The\nproposed method based on Kullback-Leibler divergence measure is evaluated using\na set of Indian classical songs from three different artists. Experimental\nresults show that the discrimination ability is evident in certain low and mid\nfrequency bands (200 - 1500 Hz)."
    },
    "1508.04633": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-08-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Textor",
                "http://arxiv.org/OAI/arXiv/:forenames": "Johannes"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Drawing and Analyzing Causal DAGs with DAGitty",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "15 pages, 2 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "DAGitty is a software for drawing and analyzing causal diagrams, also known\nas directed acyclic graphs (DAGs). Functions include identification of minimal\nsufficient adjustment sets for estimating causal effects, diagnosis of\ninsufficient or invalid adjustment via the identification of biasing paths,\nidentification of instrumental variables, and derivation of testable\nimplications. DAGitty is provided in the hope that it is useful for researchers\nand students in Epidemiology, Sociology, Psychology, and other empirical\ndisciplines. The software should run in any web browser that supports modern\nJavaScript, HTML, and SVG. This is the user manual for DAGitty version 2.3. The\nmanual is updated with every release of a new stable version. DAGitty is\navailable at dagitty.net."
    },
    "1504.00854": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-04-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Powers",
                "http://arxiv.org/OAI/arXiv/:forenames": "David M. W."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evaluation Evaluation a Monte Carlo study",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "5 pages, 14 Equations, 2 Figures, 1 Table, as submitted to European\n  Conference on Artificial Intelligence (shorter version published with 2\n  pages, 4 Equations, 0 Figures, 1 Table)",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "ECAI 2008, pp.843-844",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Over the last decade there has been increasing concern about the biases\nembodied in traditional evaluation methods for Natural Language\nProcessing/Learning, particularly methods borrowed from Information Retrieval.\nWithout knowledge of the Bias and Prevalence of the contingency being tested,\nor equivalently the expectation due to chance, the simple conditional\nprobabilities Recall, Precision and Accuracy are not meaningful as evaluation\nmeasures, either individually or in combinations such as F-factor. The\nexistence of bias in NLP measures leads to the 'improvement' of systems by\nincreasing their bias, such as the practice of improving tagging and parsing\nscores by using most common value (e.g. water is always a Noun) rather than the\nattempting to discover the correct one. The measures Cohen Kappa and Powers\nInformedness are discussed as unbiased alternative to Recall and related to the\npsychologically significant measure DeltaP. In this paper we will analyze both\nbiased and unbiased measures theoretically, characterizing the precise\nrelationship between all these measures as well as evaluating the evaluation\nmeasures themselves empirically using a Monte Carlo simulation."
    },
    "1706.07068": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Elgammal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ahmed"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bingchen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Elhoseiny",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohamed"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mazzone",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "CAN: Creative Adversarial Networks, Generating \"Art\" by Learning About\n  Styles and Deviating from Style Norms",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "This paper is an extended version of a paper published on the eighth\n  International Conference on Computational Creativity (ICCC), held in Atlanta,\n  GA, June 20th-June 22nd, 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a new system for generating art. The system generates art by\nlooking at art and learning about style; and becomes creative by increasing the\narousal potential of the generated art by deviating from the learned styles. We\nbuild over Generative Adversarial Networks (GAN), which have shown the ability\nto learn to generate novel images simulating a given distribution. We argue\nthat such networks are limited in their ability to generate creative products\nin their original design. We propose modifications to its objective to make it\ncapable of generating creative art by maximizing deviation from established\nstyles and minimizing deviation from art distribution. We conducted experiments\nto compare the response of human subjects to the generated art with their\nresponse to art created by artists. The results show that human subjects could\nnot distinguish art generated by the proposed system from art generated by\ncontemporary artists and shown in top art fairs. Human subjects even rated the\ngenerated images higher on various scales."
    },
    "1802.08535": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Evans",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saxton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Amos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kohli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pushmeet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Grefenstette",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Can Neural Networks Understand Logical Entailment?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Published at ICLR 2018 (main conference)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce a new dataset of logical entailments for the purpose of\nmeasuring models' ability to capture and exploit the structure of logical\nexpressions against an entailment prediction task. We use this task to compare\na series of architectures which are ubiquitous in the sequence-processing\nliterature, in addition to a new model class---PossibleWorldNets---which\ncomputes entailment as a \"convolution over possible worlds\". Results show that\nconvolutional networks present the wrong inductive bias for this class of\nproblems relative to LSTM RNNs, tree-structured neural networks outperform LSTM\nRNNs due to their enhanced ability to exploit the syntax of logic, and\nPossibleWorldNets outperform all benchmarks."
    },
    "1810.08648": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kyriakides",
                    "http://arxiv.org/OAI/arXiv/:forenames": "George"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Margaritis",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Konstantinos"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards automated neural design: An open source, distributed neural\n  architecture research framework",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "NORD (Neural Operations Research & Development) is an open source distributed\ndeep learning architectural research framework, based on PyTorch, MPI and\nHorovod. It aims to make research of deep architectures easier for experts of\ndifferent domains, in order to accelerate the process of finding better\narchitectures, as well as study the best architectures generated for different\ndatasets. Although currently under heavy development, the framework aims to\nallow the easy implementation of different design and optimization method\nfamilies (optimization algorithms, meta-heuristics, reinforcement learning\netc.) as well as the fair comparison between them. Furthermore, due to the\ncomputational resources required in order to optimize and evaluate network\narchitectures, it leverage the use of distributed computing, while aiming to\nminimize the researcher's overhead required to implement it. Moreover, it\nstrives to make the creation of architectures more intuitive, by implementing\nnetwork descriptors, allowing to separately define the architecture's nodes and\nconnections. In this paper, we present the framework's current state of\ndevelopment, while presenting its basic concepts, providing simple examples as\nwell as their experimental results."
    },
    "1811.07516": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fourati",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rahma"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ammar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Boudour"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sanchez-Medina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Javier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Alimi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adel M."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unsupervised Learning in Reservoir Computing for EEG-based Emotion\n  Recognition",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In real-world applications such as emotion recognition from recorded brain\nactivity, data are captured from electrodes over time. These signals constitute\na multidimensional time series. In this paper, Echo State Network (ESN), a\nrecurrent neural network with a great success in time series prediction and\nclassification, is optimized with different neural plasticity rules for\nclassification of emotions based on electroencephalogram (EEG) time series.\nActually, the neural plasticity rules are a kind of unsupervised learning\nadapted for the reservoir, i.e. the hidden layer of ESN. More specifically, an\ninvestigation of Oja's rule, BCM rule and gaussian intrinsic plasticity rule\nwas carried out in the context of EEG-based emotion recognition. The study,\nalso, includes a comparison of the offline and online training of the ESN. When\ntesting on the well-known affective benchmark \"DEAP dataset\" which contains EEG\nsignals from 32 subjects, we find that pretraining ESN with gaussian intrinsic\nplasticity enhanced the classification accuracy and outperformed the results\nachieved with an ESN pretrained with synaptic plasticity. Four classification\nproblems were conducted in which the system complexity is increased and the\ndiscrimination is more challenging, i.e. inter-subject emotion discrimination.\nOur proposed method achieves higher performance over the state of the art\nmethods."
    },
    "1807.06286": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Joppen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tobias"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wirth",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "F\u00fcrnkranz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Johannes"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Preference-Based Monte Carlo Tree Search",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To be published",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the 41st German Conference on Artificial\n  Intelligence (KI-18), 2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/978-3-030-00111-7_28",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Monte Carlo tree search (MCTS) is a popular choice for solving sequential\nanytime problems. However, it depends on a numeric feedback signal, which can\nbe difficult to define. Real-time MCTS is a variant which may only rarely\nencounter states with an explicit, extrinsic reward. To deal with such cases,\nthe experimenter has to supply an additional numeric feedback signal in the\nform of a heuristic, which intrinsically guides the agent. Recent work has\nshown evidence that in different areas the underlying structure is ordinal and\nnot numerical. Hence erroneous and biased heuristics are inevitable, especially\nin such domains. In this paper, we propose a MCTS variant which only depends on\nqualitative feedback, and therefore opens up new applications for MCTS. We also\nfind indications that translating absolute into ordinal feedback may be\nbeneficial. Using a puzzle domain, we show that our preference-based MCTS\nvariant, wich only receives qualitative feedback, is able to reach a\nperformance level comparable to a regular MCTS baseline, which obtains\nquantitative feedback."
    },
    "1304.3116": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wise",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ben P."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Experimentally Comparing Uncertain Inference Systems to Probability",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Second Conference on Uncertainty in\n  Artificial Intelligence (UAI1986)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1986-PG-319-332",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper examines the biases and performance of several uncertain inference\nsystems: Mycin, a variant of Mycin. and a simplified version of probability\nusing conditional independence assumptions. We present axiomatic arguments for\nusing Minimum Cross Entropy inference as the best way to do uncertain\ninference. For Mycin and its variant we found special situations where its\nperformance was very good, but also situations where performance was worse than\nrandom guessing, or where data was interpreted as having the opposite of its\ntrue import We have found that all three of these systems usually gave accurate\nresults, and that the conditional independence assumptions gave the most robust\nresults. We illustrate how the Importance of biases may be quantitatively\nassessed and ranked. Considerations of robustness might be a critical factor is\nselecting UlS's for a given application."
    },
    "1811.07078": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-16",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peixiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Di"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Miao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chunyan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An Affect-Rich Neural Conversational Model with Biased Attention and\n  Weighted Cross-Entropy Loss",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "AAAI-19",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Affect conveys important implicit information in human communication. Having\nthe capability to correctly express affect during human-machine conversations\nis one of the major milestones in artificial intelligence. In recent years,\nextensive research on open-domain neural conversational models has been\nconducted. However, embedding affect into such models is still under explored.\nIn this paper, we propose an end-to-end affect-rich open-domain neural\nconversational model that produces responses not only appropriate in syntax and\nsemantics, but also with rich affect. Our model extends the Seq2Seq model and\nadopts VAD (Valence, Arousal and Dominance) affective notations to embed each\nword with affects. In addition, our model considers the effect of negators and\nintensifiers via a novel affective attention mechanism, which biases attention\ntowards affect-rich words in input sentences. Lastly, we train our model with\nan affect-incorporated objective function to encourage the generation of\naffect-rich words in the output responses. Evaluations based on both perplexity\nand human evaluations show that our model outperforms the state-of-the-art\nbaseline model of comparable size in producing natural and affect-rich\nresponses."
    },
    "1302.3988": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-02-16",
        "http://arxiv.org/OAI/arXiv/:updated": "2013-09-09",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Capraro",
                "http://arxiv.org/OAI/arXiv/:forenames": "Valerio"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "A solution concept for games with altruism and cooperation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Over the years, numerous experiments have been accumulated to show that\ncooperation is not casual and depends on the payoffs of the game. These\nfindings suggest that humans have attitude to cooperation by nature and the\nsame person may act more or less cooperatively depending on the particular\npayoffs. In other words, people do not act a priori as single agents, but they\nforecast how the game would be played if they formed coalitions and then they\nplay according to their best forecast. In this paper we formalize this idea and\nwe define a new solution concept for one-shot normal form games. We prove that\nthis \\emph{cooperative equilibrium} exists for all finite games and it explains\na number of different experimental findings, such as (1) the rate of\ncooperation in the Prisoner's dilemma depends on the cost-benefit ratio; (2)\nthe rate of cooperation in the Traveler's dilemma depends on the bonus/penalty;\n(3) the rate of cooperation in the Publig Goods game depends on the pro-capite\nmarginal return and on the numbers of players; (4) the rate of cooperation in\nthe Bertrand competition depends on the number of players; (5) players tend to\nbe fair in the bargaining problem; (6) players tend to be fair in the Ultimatum\ngame; (7) players tend to be altruist in the Dictator game; (8) offers in the\nUltimatum game are larger than offers in the Dictator game."
    },
    "1806.02215": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pfau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Petersen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stig"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ashish"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barrett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stachenfeld",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kim"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Spectral Inference Networks: Unifying Spectral Methods With Deep\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present Spectral Inference Networks, a framework for learning\neigenfunctions of linear operators by stochastic optimization. Spectral\nInference Networks generalize Slow Feature Analysis to generic symmetric\noperators, and are closely related to Variational Monte Carlo methods from\ncomputational physics. As such, they can be a powerful tool for unsupervised\nrepresentation learning from video or pairs of data. We derive a training\nalgorithm for Spectral Inference Networks that addresses the bias in the\ngradients due to finite batch size and allows for online learning of multiple\neigenfunctions. We show results of training Spectral Inference Networks on\nproblems in quantum mechanics and feature learning for videos on synthetic\ndatasets as well as the Arcade Learning Environment. Our results demonstrate\nthat Spectral Inference Networks accurately recover eigenfunctions of linear\noperators, can discover interpretable representations from video and find\nmeaningful subgoals in reinforcement learning environments."
    },
    "1807.08934": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chauhan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Vinod Kumar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sharma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anuj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dahiya",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kalpana"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "SAAGs: Biased Stochastic Variance Reduction Methods",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "66 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Stochastic optimization is one of the effective approach to deal with the\nlarge-scale machine learning problems and the recent research has focused on\nreduction of variance, caused by the noisy approximations of the gradients, and\nmomentum acceleration. In this paper, we have proposed simple variants of\nSAAG-I and II (Stochastic Average Adjusted Gradient) \\cite{Chauhan2017Saag},\ncalled SAAG-III and IV, respectively. Unlike SAAG-I, starting point is set to\naverage of previous epoch in SAAG-III, and unlike SAAG-II, the snap point and\nstarting point are set to average and last iterate of previous epoch,\nrespectively. To determine the step size, we introduce Stochastic\nBacktracking-Armijo line Search (SBAS) which performs line search only on\nselected mini-batch of data points. Since backtracking line search is not\nsuitable for large-scale problems and the constants used to find the step size,\nlike Lipschitz constant, are not always available so SBAS could be very\neffective in such cases. We also extend SAAGs (I, II, III, IV), to solve\nnon-smooth problems and design two update rules for smooth and non-smooth\nproblems. Moreover, our theoretical results prove linear convergence of SAAG-IV\nfor all the four combinations of smoothness and strong-convexity, in\nexpectation. Finally, our experimental studies prove the efficacy of proposed\nmethods against the state-of-art techniques, like, SVRG and VR-SGD."
    },
    "1209.4290": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-09-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Potapov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rodionov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergey"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Myasnikov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrew"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Begimov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Galymzhan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Cognitive Bias for Universal Algorithmic Intelligence",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "10 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Existing theoretical universal algorithmic intelligence models are not\npractically realizable. More pragmatic approach to artificial general\nintelligence is based on cognitive architectures, which are, however,\nnon-universal in sense that they can construct and use models of the\nenvironment only from Turing-incomplete model spaces. We believe that the way\nto the real AGI consists in bridging the gap between these two approaches. This\nis possible if one considers cognitive functions as a \"cognitive bias\" (priors\nand search heuristics) that should be incorporated into the models of universal\nalgorithmic intelligence without violating their universality. Earlier reported\nresults suiting this approach and its overall feasibility are discussed on the\nexample of perception, planning, knowledge representation, attention, theory of\nmind, language, and some others."
    },
    "1811.04896": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Codella",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Noel C. F."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hind",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ramamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karthikeyan Natesan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Campbell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Murray"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dhurandhar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Amit"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Varshney",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kush R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wei",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dennis"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mojsilovic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aleksandra"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "TED: Teaching AI to Explain its Decisions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "This article leverages some content from arXiv:1805.11648",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Artificial intelligence systems are being increasingly deployed due to their\npotential to increase the efficiency, scale, consistency, fairness, and\naccuracy of decisions. However, as many of these systems are opaque in their\noperation, there is a growing demand for such systems to provide explanations\nfor their decisions. Conventional approaches to this problem attempt to expose\nor discover the inner workings of a machine learning model with the hope that\nthe resulting explanations will be meaningful to the consumer. In contrast,\nthis paper suggests a new approach to this problem. It introduces a simple,\npractical framework, called Teaching Explanations for Decisions (TED), that\nprovides meaningful explanations that match the mental model of the consumer.\nWe illustrate the generality and effectiveness of this approach with two\ndifferent examples, resulting in highly accurate explanations with no loss of\nprediction accuracy for these two examples."
    },
    "1705.08804": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-24",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sirui"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bert"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Beyond Parity: Fairness Objectives for Collaborative Filtering",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.IR cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study fairness in collaborative-filtering recommender systems, which are\nsensitive to discrimination that exists in historical data. Biased data can\nlead collaborative-filtering methods to make unfair predictions for users from\nminority groups. We identify the insufficiency of existing fairness metrics and\npropose four new metrics that address different forms of unfairness. These\nfairness metrics can be optimized by adding fairness terms to the learning\nobjective. Experiments on synthetic and real data show that our new metrics can\nbetter measure fairness than the baseline, and that the fairness objectives\neffectively help reduce unfairness."
    },
    "1811.07255": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Foulds",
                    "http://arxiv.org/OAI/arXiv/:forenames": "James"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Islam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rashidul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Keya",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kamrun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shimei"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Bayesian Modeling of Intersectional Fairness: The Variance of Bias",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Intersectionality is a framework that analyzes how interlocking systems of\npower and oppression affect individuals along overlapping dimensions including\nrace, gender, sexual orientation, class, and disability. Intersectionality\ntheory therefore implies it is important that fairness in artificial\nintelligence systems be protected with regard to multi-dimensional protected\nattributes. However, the measurement of fairness becomes statistically\nchallenging in the multi-dimensional setting due to data sparsity, which\nincreases rapidly in the number of dimensions, and in the values per dimension.\nWe present a Bayesian probabilistic modeling approach for the reliable,\ndata-efficient estimation of fairness with multi-dimensional protected\nattributes, which we apply to novel intersectional fairness metrics.\nExperimental results on census data and the COMPAS criminal justice recidivism\ndataset demonstrate the utility of our methodology, and show that Bayesian\nmethods are valuable for the modeling and measurement of fairness in an\nintersectional context."
    },
    "1805.09657": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hupkes",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dieuwke"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Singh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Anand"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Korrel",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kruszewski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "German"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bruni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Elia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning compositionally through attentive guidance",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this paper, we introduce Attentive Guidance (AG), a new mechanism to\ndirect a sequence to sequence model equipped with attention to find more\ncompositional solutions that generalise even in cases where the training and\ntesting distribution strongly diverge. We test AG on two tasks, devised\nprecisely to asses the composi- tional capabilities of neural models and show\nhow vanilla sequence to sequence models with attention overfit the training\ndistribution, while the guided versions come up with compositional solutions\nthat, in some cases, fit the training and testing distributions equally well.\nAG is a simple and intuitive method to provide a learning bias to a sequence to\nsequence model without the need of including extra components, that we believe\nallows to inject a component in the training process which is also present in\nhuman learning: guidance."
    },
    "1707.01195": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-07-04",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Miconi",
                "http://arxiv.org/OAI/arXiv/:forenames": "Thomas"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The impossibility of \"fairness\": a generalized impossibility result for\n  decisions",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.AP cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Various measures can be used to estimate bias or unfairness in a predictor.\nPrevious work has already established that some of these measures are\nincompatible with each other. Here we show that, when groups differ in\nprevalence of the predicted event, several intuitive, reasonable measures of\nfairness (probability of positive prediction given occurrence or\nnon-occurrence; probability of occurrence given prediction or non-prediction;\nand ratio of predictions over occurrences for each group) are all mutually\nexclusive: if one of them is equal among groups, the other two must differ. The\nonly exceptions are for perfect, or trivial (always-positive or\nalways-negative) predictors. As a consequence, any non-perfect, non-trivial\npredictor must necessarily be \"unfair\" under two out of three reasonable sets\nof criteria. This result readily generalizes to a wide range of well-known\nstatistical quantities (sensitivity, specificity, false positive rate,\nprecision, etc.), all of which can be divided into three mutually exclusive\ngroups. Importantly, The results applies to all predictors, whether algorithmic\nor human. We conclude with possible ways to handle this effect when assessing\nand designing prediction methods."
    },
    "1810.06284": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-10-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Colas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "C\u00e9dric"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fournier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sigaud",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Olivier"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Oudeyer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pierre-Yves"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "CURIOUS: Intrinsically Motivated Multi-Task, Multi-Goal Reinforcement\n  Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In open-ended and changing environments, agents face a wide range of\npotential tasks that may or may not come with associated reward functions. Such\nautonomous learning agents must be able to generate their own tasks through a\nprocess of intrinsically motivated exploration, some of which might prove easy,\nothers impossible. For this reason, they should be able to actively select\nwhich task to practice at any given moment, to maximize their overall mastery\non the set of learnable tasks. This paper proposes CURIOUS, an extension of\nUniversal Value Function Approximators that enables intrinsically motivated\nagents to learn to achieve both multiple tasks and multiple goals within a\nunique policy, leveraging hindsight learning. Agents focus on achievable tasks\nfirst, using an automated curriculum learning mechanism that biases their\nattention towards tasks maximizing the absolute learning progress. This\nmechanism provides robustness to catastrophic forgetting (by refocusing on\ntasks where performance decreases) and distracting tasks (by avoiding tasks\nwith no absolute learning progress). Furthermore, we show that having two\nlevels of parameterization (tasks and goals within tasks) enables more\nefficient learning of skills in an environment with a modular physical\nstructure (e.g. multiple objects) as compared to flat, goal-parameterized RL\nwith hindsight experience replay."
    },
    "1805.05859": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Loftus",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joshua R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Russell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kusner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Matt J."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Silva",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ricardo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Causal Reasoning for Algorithmic Fairness",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this work, we argue for the importance of causal reasoning in creating\nfair algorithms for decision making. We give a review of existing approaches to\nfairness, describe work in causality necessary for the understanding of causal\napproaches, argue why causality is necessary for any approach that wishes to be\nfair, and give a detailed analysis of the many recent approaches to\ncausality-based fairness."
    },
    "1806.05250": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sylvester",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jared"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Raff",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "What About Applied Fairness?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted at Machine Learning: The Debates (ML-D), at ICML Stockholm,\n  Sweden, 2018. 5 pages",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Machine Learning: The Debates (ML-D), at ICML Stockholm, Sweden,\n  2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Machine learning practitioners are often ambivalent about the ethical aspects\nof their products. We believe anything that gets us from that current state to\none in which our systems are achieving some degree of fairness is an\nimprovement that should be welcomed. This is true even when that progress does\nnot get us 100% of the way to the goal of \"complete\" fairness or perfectly\nalign with our personal belief on which measure of fairness is used. Some\nmeasure of fairness being built would still put us in a better position than\nthe status quo. Impediments to getting fairness and ethical concerns applied in\nreal applications, whether they are abstruse philosophical debates or technical\noverhead such as the introduction of ever more hyper-parameters, should be\navoided. In this paper we further elaborate on our argument for this viewpoint\nand its importance."
    },
    "1809.05807": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Long",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunfei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ma",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mingyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chu-Ren"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Dual Memory Network Model for Biased Product Review Classification",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in 2018 EMNLP 9th Workshop on Computational Approaches to\n  Subjectivity, Sentiment and Social Media Analysis",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In sentiment analysis (SA) of product reviews, both user and product\ninformation are proven to be useful. Current tasks handle user profile and\nproduct information in a unified model which may not be able to learn salient\nfeatures of users and products effectively. In this work, we propose a dual\nuser and product memory network (DUPMN) model to learn user profiles and\nproduct reviews using separate memory networks. Then, the two representations\nare used jointly for sentiment prediction. The use of separate models aims to\ncapture user profiles and product information more effectively. Compared to\nstate-of-the-art unified prediction models, the evaluations on three benchmark\ndatasets, IMDB, Yelp13, and Yelp14, show that our dual learning model gives\nperformance gain of 0.6%, 1.2%, and 0.9%, respectively. The improvements are\nalso deemed very significant measured by p-values."
    },
    "1706.07269": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-22",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Miller",
                "http://arxiv.org/OAI/arXiv/:forenames": "Tim"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explanation in Artificial Intelligence: Insights from the Social\n  Sciences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There has been a recent resurgence in the area of explainable artificial\nintelligence as researchers and practitioners seek to make their algorithms\nmore understandable. Much of this research is focused on explicitly explaining\ndecisions or actions to a human observer, and it should not be controversial to\nsay that looking at how humans explain to each other can serve as a useful\nstarting point for explanation in artificial intelligence. However, it is fair\nto say that most work in explainable artificial intelligence uses only the\nresearchers' intuition of what constitutes a `good' explanation. There exists\nvast and valuable bodies of research in philosophy, psychology, and cognitive\nscience of how people define, generate, select, evaluate, and present\nexplanations, which argues that people employ certain cognitive biases and\nsocial expectations towards the explanation process. This paper argues that the\nfield of explainable artificial intelligence should build on this existing\nresearch, and reviews relevant papers from philosophy, cognitive\npsychology/science, and social psychology, which study these topics. It draws\nout some important findings, and discusses ways that these can be infused with\nwork on explainable artificial intelligence."
    },
    "1205.3380": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-02-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Bakman",
                "http://arxiv.org/OAI/arXiv/:forenames": "Yefim"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Unfair items detection in educational measurement",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, 5 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Measurement professionals cannot come to an agreement on the definition of\nthe term 'item fairness'. In this paper a continuous measure of item unfairness\nis proposed. The more the unfairness measure deviates from zero, the less fair\nthe item is. If the measure exceeds the cutoff value, the item is identified as\ndefinitely unfair. The new approach can identify unfair items that would not be\nidentified with conventional procedures. The results are in accord with\nexperts' judgments on the item qualities. Since no assumptions about scores\ndistributions and/or correlations are assumed, the method is applicable to any\neducational test. Its performance is illustrated through application to scores\nof a real test."
    },
    "1807.00124": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boag",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Willie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Suresh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Harini"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Celi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leo Anthony"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Szolovits",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghassemi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marzyeh"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Modeling Mistrust in End-of-Life Care",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In this work, we characterize the doctor-patient relationship using a machine\nlearning-derived trust score. We show that this score has statistically\nsignificant racial associations, and that by modeling trust directly we find\nstronger disparities in care than by stratifying on race. We further\ndemonstrate that mistrust is indicative of worse outcomes, but is only weakly\nassociated with physiologically-created severity scores. Finally, we describe\nsentiment analysis experiments indicating patients with higher levels of\nmistrust have worse experiences and interactions with their caregivers. This\nwork is a step towards measuring fairer machine learning in the healthcare\ndomain."
    },
    "1711.07621": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-11-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siddharth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Biswas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arpita"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Krishnamurthy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sanath Kumar"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Narahari",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Y."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Groupwise Maximin Fair Allocation of Indivisible Goods",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "19 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study the problem of allocating indivisible goods among n agents in a fair\nmanner. For this problem, maximin share (MMS) is a well-studied solution\nconcept which provides a fairness threshold. Specifically, maximin share is\ndefined as the minimum utility that an agent can guarantee for herself when\nasked to partition the set of goods into n bundles such that the remaining\n(n-1) agents pick their bundles adversarially. An allocation is deemed to be\nfair if every agent gets a bundle whose valuation is at least her maximin\nshare.\n  Even though maximin shares provide a natural benchmark for fairness, it has\nits own drawbacks and, in particular, it is not sufficient to rule out\nunsatisfactory allocations. Motivated by these considerations, in this work we\ndefine a stronger notion of fairness, called groupwise maximin share guarantee\n(GMMS). In GMMS, we require that the maximin share guarantee is achieved not\njust with respect to the grand bundle, but also among all the subgroups of\nagents. Hence, this solution concept strengthens MMS and provides an ex-post\nfairness guarantee. We show that in specific settings, GMMS allocations always\nexist. We also establish the existence of approximate GMMS allocations under\nadditive valuations, and develop a polynomial-time algorithm to find such\nallocations. Moreover, we establish a scale of fairness wherein we show that\nGMMS implies approximate envy freeness.\n  Finally, we empirically demonstrate the existence of GMMS allocations in a\nlarge set of randomly generated instances. For the same set of instances, we\nadditionally show that our algorithm achieves an approximation factor better\nthan the established, worst-case bound."
    },
    "1805.08877": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-22",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Arachie",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chidubem"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bert"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adversarial Labeling for Learning without Labels",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We consider the task of training classifiers without labels. We propose a\nweakly supervised method---adversarial label learning---that trains classifiers\nto perform well against an adversary that chooses labels for training data. The\nweak supervision constrains what labels the adversary can choose. The method\ntherefore minimizes an upper bound of the classifier's error rate using\nprojected primal-dual subgradient descent. Minimizing this bound protects\nagainst bias and dependencies in the weak supervision. Experiments on three\nreal datasets show that our method can train without labels and outperforms\nother approaches for weakly supervised learning."
    },
    "1411.5878": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-11-18",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Borji",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ali"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ming-Ming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qibin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jiang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Huaizu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Salient Object Detection: A Survey",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI q-bio.NC",
        "http://arxiv.org/OAI/arXiv/:comments": "21 pages, 12 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Detecting and segmenting salient objects in natural scenes, often referred to\nas salient object detection, has attracted a lot of interest in computer\nvision. While many models have been proposed and several applications have\nemerged, yet a deep understanding of achievements and issues is lacking. We aim\nto provide a comprehensive review of the recent progress in salient object\ndetection and situate this field among other closely related areas such as\ngeneric scene segmentation, object proposal generation, and saliency for\nfixation prediction. Covering 228 publications, we survey i) roots, key\nconcepts, and tasks, ii) core techniques and main modeling trends, and iii)\ndatasets and evaluation metrics in salient object detection. We also discuss\nopen problems such as evaluation metrics and dataset bias in model performance\nand suggest future research directions."
    },
    "1702.05437": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-17",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Albarghouthi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aws"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "D'Antoni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Loris"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Drews",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Samuel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nori",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aditya"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Quantifying Program Bias",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.PL cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "With the range and sensitivity of algorithmic decisions expanding at a\nbreak-neck speed, it is imperative that we aggressively investigate whether\nprograms are biased. We propose a novel probabilistic program analysis\ntechnique and apply it to quantifying bias in decision-making programs.\nSpecifically, we (i) present a sound and complete automated verification\ntechnique for proving quantitative properties of probabilistic programs; (ii)\nshow that certain notions of bias, recently proposed in the fairness\nliterature, can be phrased as quantitative correctness properties; and (iii)\npresent FairSquare, the first verification tool for quantifying program bias,\nand evaluate it on a range of decision-making programs."
    },
    "1702.02258": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-08-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jahangiri",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ehsan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yuille",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alan L."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Generating Multiple Diverse Hypotheses for Human 3D Pose Consistent with\n  2D Joint Detections",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.MM stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "accepted to ICCV 2017 (PeopleCap)",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a method to generate multiple diverse and valid human pose\nhypotheses in 3D all consistent with the 2D detection of joints in a monocular\nRGB image. We use a novel generative model uniform (unbiased) in the space of\nanatomically plausible 3D poses. Our model is compositional (produces a pose by\ncombining parts) and since it is restricted only by anatomical constraints it\ncan generalize to every plausible human 3D pose. Removing the model bias\nintrinsically helps to generate more diverse 3D pose hypotheses. We argue that\ngenerating multiple pose hypotheses is more reasonable than generating only a\nsingle 3D pose based on the 2D joint detection given the depth ambiguity and\nthe uncertainty due to occlusion and imperfect 2D joint detection. We hope that\nthe idea of generating multiple consistent pose hypotheses can give rise to a\nnew line of future work that has not received much attention in the literature.\nWe used the Human3.6M dataset for empirical evaluation."
    },
    "quant-ph_0011122": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2000-11-30",
        "http://arxiv.org/OAI/arXiv/:updated": "2000-12-20",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Schmidhuber",
                "http://arxiv.org/OAI/arXiv/:forenames": "Juergen"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Algorithmic Theories of Everything",
        "http://arxiv.org/OAI/arXiv/:categories": "quant-ph cs.AI cs.CC cs.LG hep-th math-ph math.MP physics.comp-ph",
        "http://arxiv.org/OAI/arXiv/:comments": "10 theorems, 50 pages, 100 refs, 20000 words. Minor revisions: added\n  references; improved readability",
        "http://arxiv.org/OAI/arXiv/:report-no": "IDSIA-20-00 (Version 2.0)",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Sections 1-5 in: Hierarchies of generalized Kolmogorov\n  complexities and nonenumerable universal measures computable in the limit.\n  International Journal of Foundations of Computer Science 13(4):587-612\n  (2002). Section 6 in: The Speed Prior: A New Simplicity Measure Yielding\n  Near-Optimal Computable Predictions. In J. Kivinen and R. H. Sloan, editors,\n  Proceedings of the 15th Annual Conference on Computational Learning Theory\n  (COLT 2002), Sydney, Australia, Lecture Notes in Artificial Intelligence,\n  pages 216--228. Springer, 2002.",
        "http://arxiv.org/OAI/arXiv/:abstract": "The probability distribution P from which the history of our universe is\nsampled represents a theory of everything or TOE. We assume P is formally\ndescribable. Since most (uncountably many) distributions are not, this imposes\na strong inductive bias. We show that P(x) is small for any universe x lacking\na short description, and study the spectrum of TOEs spanned by two Ps, one\nreflecting the most compact constructive descriptions, the other the fastest\nway of computing everything. The former derives from generalizations of\ntraditional computability, Solomonoff's algorithmic probability, Kolmogorov\ncomplexity, and objects more random than Chaitin's Omega, the latter from\nLevin's universal search and a natural resource-oriented postulate: the\ncumulative prior probability of all x incomputable within time t by this\noptimal algorithm should be 1/t. Between both Ps we find a universal\ncumulatively enumerable measure that dominates traditional enumerable measures;\nany such CEM must assign low probability to any universe lacking a short\nenumerating program. We derive P-specific consequences for evolving observers,\ninductive reasoning, quantum physics, philosophy, and the expected duration of\nour universe."
    },
    "1611.02654": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-11-08",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-12-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Logeswaran",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lajanugen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Honglak"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Radev",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dragomir"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Sentence Ordering and Coherence Modeling using Recurrent Neural Networks",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Modeling the structure of coherent texts is a key NLP problem. The task of\ncoherently organizing a given set of sentences has been commonly used to build\nand evaluate models that understand such structure. We propose an end-to-end\nunsupervised deep learning approach based on the set-to-sequence framework to\naddress this problem. Our model strongly outperforms prior methods in the order\ndiscrimination task and a novel task of ordering abstracts from scientific\narticles. Furthermore, our work shows that useful text representations can be\nobtained by learning to order sentences. Visualizing the learned sentence\nrepresentations shows that the model captures high-level logical structure in\nparagraphs. Our representations perform comparably to state-of-the-art\npre-training methods on sentence similarity and paraphrase detection tasks."
    },
    "1301.2315": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-01-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weaver",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lex"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nigel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Optimal Reward Baseline for Gradient-Based Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Seventeenth Conference on Uncertainty\n  in Artificial Intelligence (UAI2001)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2001-PG-538-545",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There exist a number of reinforcement learning algorithms which learnby\nclimbing the gradient of expected reward. Their long-runconvergence has been\nproved, even in partially observableenvironments with non-deterministic\nactions, and without the need fora system model. However, the variance of the\ngradient estimator hasbeen found to be a significant practical problem. Recent\napproacheshave discounted future rewards, introducing a bias-variance\ntrade-offinto the gradient estimate. We incorporate a reward baseline into\nthelearning system, and show that it affects variance without\nintroducingfurther bias. In particular, as we approach the\nzero-bias,high-variance parameterization, the optimal (or variance\nminimizing)constant reward baseline is equal to the long-term average\nexpectedreward. Modified policy-gradient algorithms are presented, and anumber\nof experiments demonstrate their improvement over previous work."
    },
    "1810.06748": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Di"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barros",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pablo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parisi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "German I."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haiyan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Magg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sven"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wermter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stefan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Assessing the Contribution of Semantic Congruency to Multisensory\n  Integration and Conflict Resolution",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC q-bio.NC",
        "http://arxiv.org/OAI/arXiv/:comments": "Workshop on Crossmodal Learning for Intelligent Robotics at IROS'18,\n  Madrid, Spain",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The efficient integration of multisensory observations is a key property of\nthe brain that yields the robust interaction with the environment. However,\nartificial multisensory perception remains an open issue especially in\nsituations of sensory uncertainty and conflicts. In this work, we extend\nprevious studies on audio-visual (AV) conflict resolution in complex\nenvironments. In particular, we focus on quantitatively assessing the\ncontribution of semantic congruency during an AV spatial localization task. In\naddition to conflicts in the spatial domain (i.e. spatially misaligned\nstimuli), we consider gender-specific conflicts with male and female avatars.\nOur results suggest that while semantically related stimuli affect the\nmagnitude of the visual bias (perceptually shifting the location of the sound\ntowards a semantically congruent visual cue), humans still strongly rely on\nenvironmental statistics to solve AV conflicts. Together with previously\nreported results, this work contributes to a better understanding of how\nmultisensory integration and conflict resolution can be modelled in artificial\nagents and robots operating in real-world environments."
    },
    "1301.0611": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-12-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Wakker",
                "http://arxiv.org/OAI/arXiv/:forenames": "Peter P."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Decision Principles to justify Carnap's Updating Method and to Suggest\n  Corrections of Probability Judgments (Invited Talks)",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Eighteenth Conference on Uncertainty in\n  Artificial Intelligence (UAI2002)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2002-PG-544-551",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper uses decision-theoretic principles to obtain new insights into the\nassessment and updating of probabilities. First, a new foundation of\nBayesianism is given. It does not require infinite atomless uncertainties as\ndid Savage s classical result, AND can therefore be applied TO ANY finite\nBayesian network.It neither requires linear utility AS did de Finetti s\nclassical result, AND r ntherefore allows FOR the empirically AND normatively\ndesirable risk r naversion.Finally, BY identifying AND fixing utility IN an\nelementary r nmanner, our result can readily be applied TO identify methods OF\nr nprobability updating.Thus, a decision - theoretic foundation IS given r nto\nthe computationally efficient method OF inductive reasoning r ndeveloped BY\nRudolf Carnap.Finally, recent empirical findings ON r nprobability assessments\nare discussed.It leads TO suggestions FOR r ncorrecting biases IN probability\nassessments, AND FOR an alternative r nto the Dempster - Shafer belief\nfunctions that avoids the reduction TO r ndegeneracy after multiple updatings.r\nn"
    },
    "1712.00846": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-12-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hundman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kyle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gowda",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thamme"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kejriwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mayank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Boecking",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Benedikt"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Always Lurking: Understanding and Mitigating Bias in Online Human\n  Trafficking Detection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to 2018 AAAI 1st conference on AI, Ethics, and Society.\n  Awaiting review",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "AAAI/ACM First conference on Artificial Intelligence, Ethics, and\n  Society, New Orleans, USA, February 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Web-based human trafficking activity has increased in recent years but it\nremains sparsely dispersed among escort advertisements and difficult to\nidentify due to its often-latent nature. The use of intelligent systems to\ndetect trafficking can thus have a direct impact on investigative resource\nallocation and decision-making, and, more broadly, help curb a widespread\nsocial problem. Trafficking detection involves assigning a normalized score to\na set of escort advertisements crawled from the Web -- a higher score indicates\na greater risk of trafficking-related (involuntary) activities. In this paper,\nwe define and study the problem of trafficking detection and present a\ntrafficking detection pipeline architecture developed over three years of\nresearch within the DARPA Memex program. Drawing on multi-institutional data,\nsystems, and experiences collected during this time, we also conduct post hoc\nbias analyses and present a bias mitigation plan. Our findings show that, while\nautomatic trafficking detection is an important application of AI for social\ngood, it also provides cautionary lessons for deploying predictive machine\nlearning algorithms without appropriate de-biasing. This ultimately led to\nintegration of an interpretable solution into a search system that contains\nover 100 million advertisements and is used by over 200 law enforcement\nagencies to investigate leads."
    },
    "1806.09455": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Geffner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tomas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Geffner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Hector"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Compact Policies for Fully-Observable Non-Deterministic Planning as SAT",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proc. ICAPS 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fully observable non-deterministic (FOND) planning is becoming increasingly\nimportant as an approach for computing proper policies in probabilistic\nplanning, extended temporal plans in LTL planning, and general plans in\ngeneralized planning. In this work, we introduce a SAT encoding for FOND\nplanning that is compact and can produce compact strong cyclic policies. Simple\nvariations of the encodings are also introduced for strong planning and for\nwhat we call, dual FOND planning, where some non-deterministic actions are\nassumed to be fair (e.g., probabilistic) and others unfair (e.g., adversarial).\nThe resulting FOND planners are compared empirically with existing planners\nover existing and new benchmarks. The notion of \"probabilistic interesting\nproblems\" is also revisited to yield a more comprehensive picture of the\nstrengths and limitations of current FOND planners and the proposed SAT\napproach."
    },
    "1705.04885": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Fontanari",
                "http://arxiv.org/OAI/arXiv/:forenames": "Jos\u00e9 F."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Awareness improves problem-solving performance",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Cogn Syst Res, 45C (2017) 52-58",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.cogsys.2017.05.003",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The brain's self-monitoring of activities, including internal activities -- a\nfunctionality that we refer to as awareness -- has been suggested as a key\nelement of consciousness. Here we investigate whether the presence of an\ninner-eye-like process (monitor) that supervises the activities of a number of\nsubsystems (operative agents) engaged in the solution of a problem can improve\nthe problem-solving efficiency of the system. The problem is to find the global\nmaximum of a NK fitness landscape and the performance is measured by the time\nrequired to find that maximum. The operative agents explore blindly the fitness\nlandscape and the monitor provides them with feedback on the quality (fitness)\nof the proposed solutions. This feedback is then used by the operative agents\nto bias their searches towards the fittest regions of the landscape. We find\nthat a weak feedback between the monitor and the operative agents improves the\nperformance of the system, regardless of the difficulty of the problem, which\nis gauged by the number of local maxima in the landscape. For easy problems\n(i.e., landscapes without local maxima), the performance improves monotonically\nas the feedback strength increases, but for difficult problems, there is an\noptimal value of the feedback strength beyond which the system performance\ndegrades very rapidly."
    },
    "1709.09093": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-26",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-10-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Geiger",
                "http://arxiv.org/OAI/arXiv/:forenames": "R. Stuart"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Beyond opening up the black box: Investigating the role of algorithmic\n  systems in Wikipedian organizational culture",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "14 pages, typo fixed in v2",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Big Data & Society 4(2). 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1177/2053951717730735",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Scholars and practitioners across domains are increasingly concerned with\nalgorithmic transparency and opacity, interrogating the values and assumptions\nembedded in automated, black-boxed systems, particularly in user-generated\ncontent platforms. I report from an ethnography of infrastructure in Wikipedia\nto discuss an often understudied aspect of this topic: the local, contextual,\nlearned expertise involved in participating in a highly automated\nsocial-technical environment. Today, the organizational culture of Wikipedia is\ndeeply intertwined with various data-driven algorithmic systems, which\nWikipedians rely on to help manage and govern the \"anyone can edit\"\nencyclopedia at a massive scale. These bots, scripts, tools, plugins, and\ndashboards make Wikipedia more efficient for those who know how to work with\nthem, but like all organizational culture, newcomers must learn them if they\nwant to fully participate. I illustrate how cultural and organizational\nexpertise is enacted around algorithmic agents by discussing two\nautoethnographic vignettes, which relate my personal experience as a veteran in\nWikipedia. I present thick descriptions of how governance and gatekeeping\npractices are articulated through and in alignment with these automated\ninfrastructures. Over the past 15 years, Wikipedian veterans and administrators\nhave made specific decisions to support administrative and editorial workflows\nwith automation in particular ways and not others. I use these cases of\nWikipedia's bot-supported bureaucracy to discuss several issues in the fields\nof critical algorithms studies, critical data studies, and fairness,\naccountability, and transparency in machine learning -- most principally\narguing that scholarship and practice must go beyond trying to \"open up the\nblack box\" of such systems and also examine sociocultural processes like\nnewcomer socialization."
    },
    "1810.07460": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zackova",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Eva"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Romportl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "What might matter in autonomous cars adoption: first person versus third\n  person scenarios",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The discussion between the automotive industry, governments, ethicists,\npolicy makers and general public about autonomous cars' moral agency is\nwidening, and therefore we see the need to bring more insight into what\nmeta-factors might actually influence the outcomes of such discussions, surveys\nand plebiscites. In our study, we focus on the psychological (personality\ntraits), practical (active driving experience), gender and rhetoric/framing\nfactors that might impact and even determine respondents' a priori preferences\nof autonomous cars' operation. We conducted an online survey (N=430) to collect\ndata that show that the third person scenario is less biased than the first\nperson scenario when presenting ethical dilemma related to autonomous cars.\nAccording to our analysis, gender bias should be explored in more extensive\nfuture studies as well. We recommend any participatory technology assessment\ndiscourse to use the third person scenario and to direct attention to the way\nany autonomous car related debate is introduced, especially in terms of\nlinguistic and communication aspects and gender."
    },
    "1704.08509": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-04-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yi-Hsin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wei-Yu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu-Ting"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bo-Cheng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yu-Chiang Frank"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Min"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "No More Discrimination: Cross City Adaptation of Road Scene Segmenters",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "13 pages, 10 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Despite the recent success of deep-learning based semantic segmentation,\ndeploying a pre-trained road scene segmenter to a city whose images are not\npresented in the training set would not achieve satisfactory performance due to\ndataset biases. Instead of collecting a large number of annotated images of\neach city of interest to train or refine the segmenter, we propose an\nunsupervised learning approach to adapt road scene segmenters across different\ncities. By utilizing Google Street View and its time-machine feature, we can\ncollect unannotated images for each road scene at different times, so that the\nassociated static-object priors can be extracted accordingly. By advancing a\njoint global and class-specific domain adversarial learning framework,\nadaptation of pre-trained segmenters to that city can be achieved without the\nneed of any user annotation or interaction. We show that our method improves\nthe performance of semantic segmentation in multiple cities across continents,\nwhile it performs favorably against state-of-the-art approaches requiring\nannotated training data."
    },
    "1801.09848": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-01-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Nobandegani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ardavan S."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Castanheira",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin da Silva"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Otto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "A. Ross"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shultz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Thomas R."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Over-representation of Extreme Events in Decision-Making: A Rational\n  Metacognitive Account",
        "http://arxiv.org/OAI/arXiv/:categories": "q-bio.NC cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The Availability bias, manifested in the over-representation of extreme\neventualities in decision-making, is a well-known cognitive bias, and is\ngenerally taken as evidence of human irrationality. In this work, we present\nthe first rational, metacognitive account of the Availability bias, formally\narticulated at Marr's algorithmic level of analysis. Concretely, we present a\nnormative, metacognitive model of how a cognitive system should over-represent\nextreme eventualities, depending on the amount of time available at its\ndisposal for decision-making. Our model also accounts for two well-known\nframing effects in human decision-making under risk---the fourfold pattern of\nrisk preferences in outcome probability (Tversky & Kahneman, 1992) and in\noutcome magnitude (Markovitz, 1952)---thereby providing the first\nmetacognitively-rational basis for those effects. Empirical evidence,\nfurthermore, confirms an important prediction of our model. Surprisingly, our\nmodel is unimaginably robust with respect to its focal parameter. We discuss\nthe implications of our work for studies on human decision-making, and conclude\nby presenting a counterintuitive prediction of our model, which, if confirmed,\nwould have intriguing implications for human decision-making under risk. To our\nknowledge, our model is the first metacognitive, resource-rational process\nmodel of cognitive biases in decision-making."
    },
    "1709.09882": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pasquale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giulia"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ciliberto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carlo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Odone",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesca"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rosasco",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lorenzo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Natale",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lorenzo"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Are we Done with Object Recognition? The iCub robot's Perspective",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "21 pages + supplementary material",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.9; I.2.10; I.2.11; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2;\n  I.5.4; I.5.5",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We report on an extensive study of the current benefits and limitations of\ndeep learning approaches to robot vision and introduce a novel dataset used for\nour investigation. To avoid the biases in currently available datasets, we\nconsider a human-robot interaction setting to design a data-acquisition\nprotocol for visual object recognition on the iCub humanoid robot. Considering\nthe performance of off-the-shelf models trained on off-line large-scale image\nretrieval datasets, we show the necessity for knowledge transfer. Indeed, we\nanalyze different ways in which this last step can be done, and identify the\nmajor bottlenecks in robotics scenarios. By studying both object categorization\nand identification tasks, we highlight the key differences between object\nrecognition in robotics and in image retrieval tasks, for which the considered\ndeep learning approaches have been originally designed. In a nutshell, our\nresults confirm also in the considered setting the remarkable improvements\nyield by deep learning, while pointing to specific open challenges that need to\nbe addressed for seamless deployment in robotics."
    },
    "1305.0751": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-05-03",
        "http://arxiv.org/OAI/arXiv/:updated": "2014-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Pe\u00f1a",
                "http://arxiv.org/OAI/arXiv/:forenames": "Jose M."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Marginal AMP Chain Graphs",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Changes from v1 to v2: Discussion section got extended. Changes from\n  v2 to v3: New Sections 3 and 5. Changes from v3 to v4: Example 4 added to\n  discussion section. Changes from v4 to v5: None. Changes from v5 to v6: Some\n  minor and major errors have been corrected. The latter include the\n  definitions of descending route and pairwise separation base, and the proofs\n  of Theorems 5 and 6",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "International Journal of Approximate Reasoning, 55 (5), 1185-1206,\n  2014",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present a new family of models that is based on graphs that may have\nundirected, directed and bidirected edges. We name these new models marginal\nAMP (MAMP) chain graphs because each of them is Markov equivalent to some AMP\nchain graph under marginalization of some of its nodes. However, MAMP chain\ngraphs do not only subsume AMP chain graphs but also multivariate regression\nchain graphs. We describe global and pairwise Markov properties for MAMP chain\ngraphs and prove their equivalence for compositional graphoids. We also\ncharacterize when two MAMP chain graphs are Markov equivalent.\n  For Gaussian probability distributions, we also show that every MAMP chain\ngraph is Markov equivalent to some directed and acyclic graph with\ndeterministic nodes under marginalization and conditioning on some of its\nnodes. This is important because it implies that the independence model\nrepresented by a MAMP chain graph can be accounted for by some data generating\nprocess that is partially observed and has selection bias. Finally, we modify\nMAMP chain graphs so that they are closed under marginalization for Gaussian\nprobability distributions. This is a desirable feature because it guarantees\nparsimonious models under marginalization."
    },
    "1709.04176": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-13",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lupia",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Mendicelli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Angelo"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ribichini",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Andrea"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Scarcello",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesco"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schaerf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marco"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Computing the Shapley Value in Allocation Problems: Approximations and\n  Bounds, with an Application to the Italian VQR Research Assessment Program",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In allocation problems, a given set of goods are assigned to agents in such a\nway that the social welfare is maximised, that is, the largest possible global\nworth is achieved. When goods are indivisible, it is possible to use money\ncompensation to perform a fair allocation taking into account the actual\ncontribution of all agents to the social welfare. Coalitional games provide a\nformal mathematical framework to model such problems, in particular the Shapley\nvalue is a solution concept widely used for assigning worths to agents in a\nfair way. Unfortunately, computing this value is a $\\#{\\rm P}$-hard problem, so\nthat applying this good theoretical notion is often quite difficult in\nreal-world problems.\n  We describe useful properties that allow us to greatly simplify the instances\nof allocation problems, without affecting the Shapley value of any player.\nMoreover, we propose algorithms for computing lower bounds and upper bounds of\nthe Shapley value, which in some cases provide the exact result and that can be\ncombined with approximation algorithms.\n  The proposed techniques have been implemented and tested on a real-world\napplication of allocation problems, namely, the Italian research assessment\nprogram, known as VQR. For the large university considered in the experiments,\nthe problem involves thousands of agents and goods (here, researchers and their\nresearch products). The algorithms described in the paper are able to compute\nthe Shapley value for most of those agents, and to get a good approximation of\nthe Shapley value for all of them."
    },
    "1505.07434": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-05-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2016-12-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ye",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qing Chuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yingqian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dekker",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rommert"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fair task allocation in transportation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.GT",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Ye QC, et al. Fair task allocation in transportation. Omega\n  (2016), http://dx.doi.org/10.1016/j.omega.2016.05.005",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1016/j.omega.2016.05.005",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Task allocation problems have traditionally focused on cost optimization.\nHowever, more and more attention is being given to cases in which cost should\nnot always be the sole or major consideration. In this paper we study a fair\ntask allocation problem in transportation where an optimal allocation not only\nhas low cost but more importantly, it distributes tasks as even as possible\namong heterogeneous participants who have different capacities and costs to\nexecute tasks. To tackle this fair minimum cost allocation problem we analyze\nand solve it in two parts using two novel polynomial-time algorithms. We show\nthat despite the new fairness criterion, the proposed algorithms can solve the\nfair minimum cost allocation problem optimally in polynomial time. In addition,\nwe conduct an extensive set of experiments to investigate the trade-off between\ncost minimization and fairness. Our experimental results demonstrate the\nbenefit of factoring fairness into task allocation. Among the majority of test\ninstances, fairness comes with a very small price in terms of cost."
    },
    "1610.02391": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-10-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-03-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Selvaraju",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramprasaath R."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cogswell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Das",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhishek"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vedantam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramakrishna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Batra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhruv"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based\n  Localization",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "24 pages, 22 figures. Adds bias experiments, and robustness to\n  adversarial noise",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a technique for producing \"visual explanations\" for decisions from\na large class of CNN-based models, making them more transparent. Our approach -\nGradient-weighted Class Activation Mapping (Grad-CAM), uses the gradients of\nany target concept, flowing into the final convolutional layer to produce a\ncoarse localization map highlighting the important regions in the image for\npredicting the concept. Unlike previous approaches, GradCAM is applicable to a\nwide variety of CNN model-families: (1) CNNs with fully-connected layers (e.g.\nVGG), (2) CNNs used for structured outputs (e.g. captioning), (3) CNNs used in\ntasks with multimodal inputs (e.g. VQA) or reinforcement learning, without any\narchitectural changes or re-training. We combine GradCAM with fine-grained\nvisualizations to create a high-resolution class-discriminative visualization\nand apply it to off-the-shelf image classification, captioning, and visual\nquestion answering (VQA) models, including ResNet-based architectures. In the\ncontext of image classification models, our visualizations (a) lend insights\ninto their failure modes (showing that seemingly unreasonable predictions have\nreasonable explanations), (b) are robust to adversarial images, (c) outperform\nprevious methods on weakly-supervised localization, (d) are more faithful to\nthe underlying model and (e) help achieve generalization by identifying dataset\nbias. For captioning and VQA, our visualizations show that even non-attention\nbased models can localize inputs. Finally, we conduct human studies to measure\nif GradCAM explanations help users establish trust in predictions from deep\nnetworks and show that GradCAM helps untrained users successfully discern a\n\"stronger\" deep network from a \"weaker\" one. Our code is available at\nhttps://github.com/ramprs/grad-cam. A demo and a video of the demo can be found\nat http://gradcam.cloudcv.org and youtu.be/COjUB9Izk6E."
    },
    "cs_0504072": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2005-04-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barthelemy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Marc"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chow",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edmond"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Eliassi-Rad",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tina"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Knowledge Representation Issues in Semantic Graphs for Relationship\n  Detection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI physics.soc-ph",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages, 2 tables, 7 figures",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Papers from the 2005 AAAI Spring Symposium, AAAI Press, 2005, pp.\n  91-98",
        "http://arxiv.org/OAI/arXiv/:abstract": "An important task for Homeland Security is the prediction of threat\nvulnerabilities, such as through the detection of relationships between\nseemingly disjoint entities. A structure used for this task is a \"semantic\ngraph\", also known as a \"relational data graph\" or an \"attributed relational\ngraph\". These graphs encode relationships as \"typed\" links between a pair of\n\"typed\" nodes. Indeed, semantic graphs are very similar to semantic networks\nused in AI. The node and link types are related through an ontology graph (also\nknown as a schema). Furthermore, each node has a set of attributes associated\nwith it (e.g., \"age\" may be an attribute of a node of type \"person\").\nUnfortunately, the selection of types and attributes for both nodes and links\ndepends on human expertise and is somewhat subjective and even arbitrary. This\nsubjectiveness introduces biases into any algorithm that operates on semantic\ngraphs. Here, we raise some knowledge representation issues for semantic graphs\nand provide some possible solutions using recently developed ideas in the field\nof complex networks. In particular, we use the concept of transitivity to\nevaluate the relevance of individual links in the semantic graph for detecting\nrelationships. We also propose new statistical measures for semantic graphs and\nillustrate these semantic measures on graphs constructed from movies and\nterrorism data."
    },
    "1807.07049": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gupta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhinav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Murali",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Adithyavairavan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gandhi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dhiraj"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pinto",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lerrel"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Robot Learning in Homes: Improving Generalization and Reducing Dataset\n  Bias",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.RO cs.AI cs.CV cs.LG",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Data-driven approaches to solving robotic tasks have gained a lot of traction\nin recent years. However, most existing policies are trained on large-scale\ndatasets collected in curated lab settings. If we aim to deploy these models in\nunstructured visual environments like people's homes, they will be unable to\ncope with the mismatch in data distribution. In such light, we present the\nfirst systematic effort in collecting a large dataset for robotic grasping in\nhomes. First, to scale and parallelize data collection, we built a low cost\nmobile manipulator assembled for under 3K USD. Second, data collected using low\ncost robots suffer from noisy labels due to imperfect execution and calibration\nerrors. To handle this, we develop a framework which factors out the noise as a\nlatent variable. Our model is trained on 28K grasps collected in several houses\nunder an array of different environmental conditions. We evaluate our models by\nphysically executing grasps on a collection of novel objects in multiple unseen\nhomes. The models trained with our home dataset showed a marked improvement of\n43.7% over a baseline model trained with data collected in lab. Our\narchitecture which explicitly models the latent noise in the dataset also\nperformed 10% better than one that did not factor out the noise. We hope this\neffort inspires the robotics community to look outside the lab and embrace\nlearning based approaches to handle inaccurate cheap robots."
    },
    "1401.5390": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-01-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Branavan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "S. R. K."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Silver",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barzilay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Regina"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Learning to Win by Reading Manuals in a Monte-Carlo Framework",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 43, pages\n  661-704, 2012",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.3484",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Domain knowledge is crucial for effective performance in autonomous control\nsystems. Typically, human effort is required to encode this knowledge into a\ncontrol algorithm. In this paper, we present an approach to language grounding\nwhich automatically interprets text in the context of a complex control\napplication, such as a game, and uses domain knowledge extracted from the text\nto improve control performance. Both text analysis and control strategies are\nlearned jointly using only a feedback signal inherent to the application. To\neffectively leverage textual information, our method automatically extracts the\ntext segment most relevant to the current game state, and labels it with a\ntask-centric predicate structure. This labeled text is then used to bias an\naction selection policy for the game, guiding it towards promising regions of\nthe action space. We encode our model for text analysis and game playing in a\nmulti-layer neural network, representing linguistic decisions via latent\nvariables in the hidden layers, and game action quality via the output layer.\nOperating within the Monte-Carlo Search framework, we estimate model parameters\nusing feedback from simulated games. We apply our approach to the complex\nstrategy game Civilization II using the official game manual as the text guide.\nOur results show that a linguistically-informed game-playing agent\nsignificantly outperforms its language-unaware counterpart, yielding a 34%\nabsolute improvement and winning over 65% of games when playing against the\nbuilt-in AI of Civilization."
    },
    "0709.0178": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2007-09-03",
        "http://arxiv.org/OAI/arXiv/:updated": "2008-10-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Sanderson",
                "http://arxiv.org/OAI/arXiv/:forenames": "Yasmine B."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Effective Generation of Subjectively Random Binary Sequences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Introduction and Section 6 revised",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.10; I.6.8; J.4; G.3",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We present an algorithm for effectively generating binary sequences which\nwould be rated by people as highly likely to have been generated by a random\nprocess, such as flipping a fair coin."
    },
    "1805.09460": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hechtlinger",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yotam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "P\u00f3czos",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Barnab\u00e1s"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wasserman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Larry"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Cautious Deep Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.CV cs.LG stat.ME",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Most classifiers operate by selecting the maximum of an estimate of the\nconditional distribution $p(y|x)$ where $x$ stands for the features of the\ninstance to be classified and $y$ denotes its label. This often results in a\nhubristic bias: overconfidence in the assignment of a definite label. Usually,\nthe observations are concentrated on a small volume but the classifier provides\ndefinite predictions for the entire space. We propose constructing conformal\nprediction sets [vovk2005algorithmic] which contain a set of labels rather than\na single label. These conformal prediction sets contain the true label with\nprobability $1-\\alpha$. Our construction is based on $p(x|y)$ rather than\n$p(y|x)$ which results in a classifier that is very cautious: it outputs the\nnull set - meaning `I don't know' --- when the object does not resemble the\ntraining examples. An important property of our approach is that classes can be\nadded or removed without having to retrain the classifier. We demonstrate the\nperformance on the ImageNet ILSVRC dataset using high dimensional features\nobtained from state of the art convolutional neural networks."
    },
    "1802.08554": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-23",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Stay",
                "http://arxiv.org/OAI/arXiv/:forenames": "Douglas Summers"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Semantic Vector Spaces for Broadening Consideration of Consequences",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "A book chapter from Autonomy and Artificial Intelligence: A Threat or\n  Savior?",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Autonomy and Artificial Intelligence: A Threat or Savior? Editors\n  W.F. Lawless, Ranjeev Mittu, Donald Sofge, Stephen Russell Springer, 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Reasoning systems with too simple a model of the world and human intent are\nunable to consider potential negative side effects of their actions and modify\ntheir plans to avoid them (e.g., avoiding potential errors). However,\nhand-encoding the enormous and subtle body of facts that constitutes common\nsense into a knowledge base has proved too difficult despite decades of work.\nDistributed semantic vector spaces learned from large text corpora, on the\nother hand, can learn representations that capture shades of meaning of\ncommon-sense concepts and perform analogical and associational reasoning in\nways that knowledge bases are too rigid to perform, by encoding concepts and\nthe relations between them as geometric structures. These have, however, the\ndisadvantage of being unreliable, poorly understood, and biased in their view\nof the world by the source material. This chapter will discuss how these\napproaches may be combined in a way that combines the best properties of each\nfor understanding the world and human intentions in a richer way."
    },
    "1808.00089": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Srivastava",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Biplav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rossi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Francesca"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Towards Composable Bias Rating of AI Services",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "7 pages, appeared in 2018 ACM/AAAI Conference on AI Ethics and\n  Society (AIES 2018)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A new wave of decision-support systems are being built today using AI\nservices that draw insights from data (like text and video) and incorporate\nthem in human-in-the-loop assistance. However, just as we expect humans to be\nethical, the same expectation needs to be met by automated systems that\nincreasingly get delegated to act on their behalf. A very important aspect of\nan ethical behavior is to avoid (intended, perceived, or accidental) bias. Bias\noccurs when the data distribution is not representative enough of the natural\nphenomenon one wants to model and reason about. The possibly biased behavior of\na service is hard to detect and handle if the AI service is merely being used\nand not developed from scratch, since the training data set is not available.\nIn this situation, we envisage a 3rd party rating agency that is independent of\nthe API producer or consumer and has its own set of biased and unbiased data,\nwith customizable distributions. We propose a 2-step rating approach that\ngenerates bias ratings signifying whether the AI service is unbiased\ncompensating, data-sensitive biased, or biased. The approach also works on\ncomposite services. We implement it in the context of text translation and\nreport interesting results."
    },
    "1703.01671": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-05",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-01-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Landeiro",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Virgile"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Culotta",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aron"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Controlling for Unobserved Confounds in Classification Using\n  Correlational Constraints",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CL",
        "http://arxiv.org/OAI/arXiv/:comments": "9 pages",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "As statistical classifiers become integrated into real-world applications, it\nis important to consider not only their accuracy but also their robustness to\nchanges in the data distribution. In this paper, we consider the case where\nthere is an unobserved confounding variable $z$ that influences both the\nfeatures $\\mathbf{x}$ and the class variable $y$. When the influence of $z$\nchanges from training to testing data, we find that the classifier accuracy can\ndegrade rapidly. In our approach, we assume that we can predict the value of\n$z$ at training time with some error. The prediction for $z$ is then fed to\nPearl's back-door adjustment to build our model. Because of the attenuation\nbias caused by measurement error in $z$, standard approaches to controlling for\n$z$ are ineffective. In response, we propose a method to properly control for\nthe influence of $z$ by first estimating its relationship with the class\nvariable $y$, then updating predictions for $z$ to match that estimated\nrelationship. By adjusting the influence of $z$, we show that we can build a\nmodel that exceeds competing baselines on accuracy as well as on robustness\nover a range of confounding relationships."
    },
    "1405.7192": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-05-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Walsh",
                "http://arxiv.org/OAI/arXiv/:forenames": "Toby"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The PeerRank Method for Peer Assessment",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.DS",
        "http://arxiv.org/OAI/arXiv/:comments": "To appear in Proc. of ECAI 2014",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose the PeerRank method for peer assessment. This constructs a grade\nfor an agent based on the grades proposed by the agents evaluating the agent.\nSince the grade of an agent is a measure of their ability to grade correctly,\nthe PeerRank method weights grades by the grades of the grading agent. The\nPeerRank method also provides an incentive for agents to grade correctly. As\nthe grades of an agent depend on the grades of the grading agents, and as these\ngrades themselves depend on the grades of other agents, we define the PeerRank\nmethod by a fixed point equation similar to the PageRank method for ranking\nweb-pages. We identify some formal properties of the PeerRank method (for\nexample, it satisfies axioms of unanimity, no dummy, no discrimination and\nsymmetry), discuss some examples, compare with related work and evaluate the\nperformance on some synthetic data. Our results show considerable promise,\nreducing the error in grade predictions by a factor of 2 or more in many cases\nover the natural baseline of averaging peer grades."
    },
    "1811.02959": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-11-07",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-11-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sinha",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Koustuv"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sodhani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shagun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hamilton",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pineau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joelle"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Compositional Language Understanding with Text-based Relational\n  Reasoning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "4 pages of main content, to be presented at Relational Representation\n  Learning Workshop, NIPS 2018, Montreal",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neural networks for natural language reasoning have largely focused on\nextractive, fact-based question-answering (QA) and common-sense inference.\nHowever, it is also crucial to understand the extent to which neural networks\ncan perform relational reasoning and combinatorial generalization from natural\nlanguage---abilities that are often obscured by annotation artifacts and the\ndominance of language modeling in standard QA benchmarks. In this work, we\npresent a novel benchmark dataset for language understanding that isolates\nperformance on relational reasoning. We also present a neural message-passing\nbaseline and show that this model, which incorporates a relational inductive\nbias, is superior at combinatorial generalization compared to a traditional\nrecurrent neural network approach."
    },
    "1708.05688": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-08-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Jasberg",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sizov",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergej"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Human Uncertainty and Ranking Error -- The Secret of Successful\n  Evaluation in Predictive Data Mining",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.HC cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "One of the most crucial issues in data mining is to model human behaviour in\norder to provide personalisation, adaptation and recommendation. This usually\ninvolves implicit or explicit knowledge, either by observing user interactions,\nor by asking users directly. But these sources of information are always\nsubject to the volatility of human decisions, making utilised data uncertain to\na particular extent. In this contribution, we elaborate on the impact of this\nhuman uncertainty when it comes to comparative assessments of different data\nmining approaches. In particular, we reveal two problems: (1) biasing effects\non various metrics of model-based prediction and (2) the propagation of\nuncertainty and its thus induced error probabilities for algorithm rankings.\nFor this purpose, we introduce a probabilistic view and prove the existence of\nthose problems mathematically, as well as provide possible solution strategies.\nWe exemplify our theory mainly in the context of recommender systems along with\nthe metric RMSE as a prominent example of precision quality measures."
    },
    "1209.3734": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-09-17",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rodler",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Patrick"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shchekotykhin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kostyantyn"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fleiss",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philipp"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Friedrich",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gerhard"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "RIO: Minimizing User Interaction in Ontology Debugging",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by-nc-sa/3.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Efficient ontology debugging is a cornerstone for many activities in the\ncontext of the Semantic Web, especially when automatic tools produce (parts of)\nontologies such as in the field of ontology matching. The best currently known\ninteractive debugging systems rely upon some meta information in terms of fault\nprobabilities, which can speed up the debugging procedure in the good case, but\ncan also have negative impact on the performance in the bad case. The problem\nis that assessment of the meta information is only possible a-posteriori.\nConsequently, as long as the actual fault is unknown, there is always some risk\nof suboptimal interactive diagnoses discrimination. As an alternative, one\nmight prefer to rely on a tool which pursues a no-risk strategy. In this case,\nhowever, possibly well-chosen meta information cannot be exploited, resulting\nagain in inefficient debugging actions. In this work we present a reinforcement\nlearning strategy that continuously adapts its behavior depending on the\nperformance achieved and minimizes the risk of using low-quality meta\ninformation. Therefore, this method is suitable for application scenarios where\nreliable a-priori fault estimates are difficult to obtain. Using problematic\nontologies in the field of ontology matching, we show that the proposed\nrisk-aware query strategy outperforms both active learning approaches and\nno-risk strategies on average in terms of required amount of user interaction."
    },
    "1804.09521": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siddharth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Biswas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Arpita"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fair Division Under Cardinality Constraints",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "16 pages. Accepted at the 27th International Joint Conference on\n  Artificial Intelligence (IJCAI), 2018",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We consider the problem of fairly allocating indivisible goods, among agents,\nunder cardinality constraints and additive valuations. In this setting, we are\ngiven a partition of the entire set of goods---i.e., the goods are\ncategorized---and a limit is specified on the number of goods that can be\nallocated from each category to any agent. The objective here is to find a fair\nallocation in which the subset of goods assigned to any agent satisfies the\ngiven cardinality constraints. This problem naturally captures a number of\nresource-allocation applications, and is a generalization of the well-studied\n(unconstrained) fair division problem.\n  The two central notions of fairness, in the context of fair division of\nindivisible goods, are envy freeness up to one good (EF1) and the (approximate)\nmaximin share guarantee (MMS). We show that the existence and algorithmic\nguarantees established for these solution concepts in the unconstrained setting\ncan essentially be achieved under cardinality constraints. Specifically, we\ndevelop efficient algorithms which compute EF1 and approximately MMS\nallocations in the constrained setting.\n  Furthermore, focusing on the case wherein all the agents have the same\nadditive valuation, we establish that EF1 locations exist even under matroid\nconstraints."
    },
    "1309.6856": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-09-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perny",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Patrice"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goldsmith",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Judy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hanna",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Josiah"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Approximation of Lorenz-Optimal Solutions in Multiobjective Markov\n  Decision Processes",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2013-PG-508-517",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper is devoted to fair optimization in Multiobjective Markov Decision\nProcesses (MOMDPs). A MOMDP is an extension of the MDP model for planning under\nuncertainty while trying to optimize several reward functions simultaneously.\nThis applies to multiagent problems when rewards define individual utility\nfunctions, or in multicriteria problems when rewards refer to different\nfeatures. In this setting, we study the determination of policies leading to\nLorenz-non-dominated tradeoffs. Lorenz dominance is a refinement of Pareto\ndominance that was introduced in Social Choice for the measurement of\ninequalities. In this paper, we introduce methods to efficiently approximate\nthe sets of Lorenz-non-dominated solutions of infinite-horizon, discounted\nMOMDPs. The approximations are polynomial-sized subsets of those solutions."
    },
    "1702.08286": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-02-27",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-09-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "McElfresh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Duncan C."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dickerson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John P."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Balancing Lexicographic Fairness and a Utilitarian Objective with\n  Application to Kidney Exchange",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.11; J.4; G.1.6",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Balancing fairness and efficiency in resource allocation is a classical\neconomic and computational problem. The price of fairness measures the\nworst-case loss of economic efficiency when using an inefficient but fair\nallocation rule; for indivisible goods in many settings, this price is\nunacceptably high. One such setting is kidney exchange, where needy patients\nswap willing but incompatible kidney donors. In this work, we close an open\nproblem regarding the theoretical price of fairness in modern kidney exchanges.\nWe then propose a general hybrid fairness rule that balances a strict\nlexicographic preference ordering over classes of agents, and a utilitarian\nobjective that maximizes economic efficiency. We develop a utility function for\nthis rule that favors disadvantaged groups lexicographically; but if cost to\noverall efficiency becomes too high, it switches to a utilitarian objective.\nThis rule has only one parameter which is proportional to a bound on the price\nof fairness, and can be adjusted by policymakers. We apply this rule to real\ndata from a large kidney exchange and show that our hybrid rule produces more\nreliable outcomes than other fairness rules."
    },
    "1810.03025": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-06",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Schulam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Saria",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Suchi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Discretizing Logged Interaction Data Biases Learning for Decision-Making",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG cs.SY",
        "http://arxiv.org/OAI/arXiv/:comments": "This is a standalone short paper describing a new type of bias that\n  can arise when learning from time series data for sequential decision-making\n  problems",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Time series data that are not measured at regular intervals are commonly\ndiscretized as a preprocessing step. For example, data about customer arrival\ntimes might be simplified by summing the number of arrivals within hourly\nintervals, which produces a discrete-time time series that is easier to model.\nIn this abstract, we show that discretization introduces a bias that affects\nmodels trained for decision-making. We refer to this phenomenon as\ndiscretization bias, and show that we can avoid it by using continuous-time\nmodels instead."
    },
    "1810.08540": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Patel",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ansh"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness for Whom? Critically reframing fairness with Nash Welfare\n  Product",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Submitted to FAT* 2019",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recent studies on disparate impact in machine learning applications have\nsparked a debate around the concept of fairness along with attempts to\nformalize its different criteria. Many of these approaches focus on reducing\nprediction errors while maximizing sole utility of the institution. This work\nseeks to reconceptualize and critically frame the existing discourse on\nfairness by underlining the implicit biases embedded in common understandings\nof fairness in the literature and how they contrast with its corresponding\neconomic and legal definitions. This paper expands the concept of utility and\nfairness by bringing in concepts from established literature in welfare\neconomics and game theory. We then translate these concepts for the algorithmic\nprediction domain by defining a formalization of Nash Welfare Product that\nseeks to expand utility by collapsing that of the institution using the\nprediction tool and the individual subject to the prediction into one function.\nWe then apply a modulating function that makes the fairness and welfare\ntrade-offs explicit based on designated policy goals and then apply it to a\ntemporal model to take into account the effects of decisions beyond the scope\nof one-shot predictions. We apply this on a binary classification problem and\npresent results of a multi-epoch simulation based on the UCI Adult Income\ndataset and a test case analysis of the ProPublica recidivism dataset that show\nthat expanding the concept of utility results in a fairer distribution\ncorrecting for the embedded biases in the dataset without sacrificing the\nclassifier accuracy."
    },
    "1811.02627": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-29",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yue"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Song",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Du",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Xiaojiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guizani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mohsen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Vehicle Tracking Using Surveillance with Multimodal Data Fusion",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages,6 figures,33 conferences",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/TITS.2017.2787101",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Vehicle location prediction or vehicle tracking is a significant topic within\nconnected vehicles. This task, however, is difficult if only a single modal\ndata is available, probably causing bias and impeding the accuracy. With the\ndevelopment of sensor networks in connected vehicles, multimodal data are\nbecoming accessible. Therefore, we propose a framework for vehicle tracking\nwith multimodal data fusion. Specifically, we fuse the results of two\nmodalities, images and velocity, in our vehicle-tracking task. Images, being\nprocessed in the module of vehicle detection, provide direct information about\nthe features of vehicles, whereas velocity estimation can further evaluate the\npossible location of the target vehicles, which reduces the number of features\nbeing compared, and decreases the time consumption and computational cost.\nVehicle detection is designed with a color-faster R-CNN, which takes both the\nshape and color of the vehicles into consideration. Meanwhile, velocity\nestimation is through the Kalman filter, which is a classical method for\ntracking. Finally, a multimodal data fusion method is applied to integrate\nthese outcomes so that vehicle-tracking tasks can be achieved. Experimental\nresults suggest the efficiency of our methods, which can track vehicles using a\nseries of surveillance cameras in urban areas."
    },
    "1709.07576": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jialong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qingfu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tsang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edward"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "EB-GLS: An Improved Guided Local Search Based on the Big Valley\n  Structure",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Memetic Computing, 2017: 1-18",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1007/s12293-017-0242-5",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Local search is a basic building block in memetic algorithms. Guided Local\nSearch (GLS) can improve the efficiency of local search. By changing the guide\nfunction, GLS guides a local search to escape from locally optimal solutions\nand find better solutions. The key component of GLS is its penalizing mechanism\nwhich determines which feature is selected to penalize when the search is\ntrapped in a locally optimal solution. The original GLS penalizing mechanism\nonly makes use of the cost and the current penalty value of each feature. It is\nwell known that many combinatorial optimization problems have a big valley\nstructure, i.e., the better a solution is, the more the chance it is closer to\na globally optimal solution. This paper proposes to use big valley structure\nassumption to improve the GLS penalizing mechanism. An improved GLS algorithm\ncalled Elite Biased GLS (EB-GLS) is proposed. EB-GLS records and maintains an\nelite solution as an estimate of the globally optimal solutions, and reduces\nthe chance of penalizing the features in this solution. We have systematically\ntested the proposed algorithm on the symmetric traveling salesman problem.\nExperimental results show that EB-GLS is significantly better than GLS."
    },
    "1203.3504": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2012-03-15",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Pearl",
                "http://arxiv.org/OAI/arXiv/:forenames": "Judea"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "On Measurement Bias in Causal Inference",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ME cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty\n  in Artificial Intelligence (UAI2010)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-2010-PG-425-432",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper addresses the problem of measurement errors in causal inference\nand highlights several algebraic and graphical methods for eliminating\nsystematic bias induced by such errors. In particulars, the paper discusses the\ncontrol of partially observable confounders in parametric and non parametric\nmodels and the computational problem of obtaining bias-free effect estimates in\nsuch models."
    },
    "1804.10669": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-04-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hetherly",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeff"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gamble",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Paul"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barrios",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maria"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Stephenson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cory"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ni",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Karl"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Speech Denoising with Vector Space Projections",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SD cs.AI eess.AS",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: text overlap with arXiv:1705.04662",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose an algorithm to denoise speakers from a single microphone in the\npresence of non-stationary and dynamic noise. Our approach is inspired by the\nrecent success of neural network models separating speakers from other speakers\nand singers from instrumental accompaniment. Unlike prior art, we leverage\nembedding spaces produced with source-contrastive estimation, a technique\nderived from negative sampling techniques in natural language processing, while\nsimultaneously obtaining a continuous inference mask. Our embedding space\ndirectly optimizes for the discrimination of speaker and noise by jointly\nmodeling their characteristics. This space is generalizable in that it is not\nspeaker or noise specific and is capable of denoising speech even if the model\nhas not seen the speaker in the training set. Parameters are trained with dual\nobjectives: one that promotes a selective bandpass filter that eliminates noise\nat time-frequency positions that exceed signal power, and another that\nproportionally splits time-frequency content between signal and noise. We\ncompare to state of the art algorithms as well as traditional sparse\nnon-negative matrix factorization solutions. The resulting algorithm avoids\nsevere computational burden by providing a more intuitive and easily optimized\napproach, while achieving competitive accuracy."
    },
    "1605.09782": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2016-05-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-04-03",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Donahue",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jeff"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kr\u00e4henb\u00fchl",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Philipp"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Darrell",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Trevor"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Adversarial Feature Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV cs.NE stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Published as a conference paper at ICLR 2017. Changelog: (v7) Table 2\n  results improved 1-2% due to averaging predictions over 10 crops at test\n  time, as done in Noroozi & Favaro; Table 3 VOC classification results\n  slightly improved due to minor bugfix. (See v6 changelog for previous\n  versions.)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning."
    },
    "1809.09147": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Agarwal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Akshat"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kumar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abhinau",
                    "http://arxiv.org/OAI/arXiv/:suffix": "V"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dunovan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kyle"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Peterson",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Erik"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Verstynen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timothy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sycara",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Katia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Better Safe than Sorry: Evidence Accumulation Allows for Safe\n  Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 3 figures. Code available at\n  https://github.com/agakshat/evidence-accumulation",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In the real world, agents often have to operate in situations with incomplete\ninformation, limited sensing capabilities, and inherently stochastic\nenvironments, making individual observations incomplete and unreliable.\nMoreover, in many situations it is preferable to delay a decision rather than\nrun the risk of making a bad decision. In such situations it is necessary to\naggregate information before taking an action; however, most state of the art\nreinforcement learning (RL) algorithms are biased towards taking actions\n\\textit{at every time step}, even if the agent is not particularly confident in\nits chosen action. This lack of caution can lead the agent to make critical\nmistakes, regardless of prior experience and acclimation to the environment.\nMotivated by theories of dynamic resolution of uncertainty during decision\nmaking in biological brains, we propose a simple accumulator module which\naccumulates evidence in favor of each possible decision, encodes uncertainty as\na dynamic competition between actions, and acts on the environment only when it\nis sufficiently confident in the chosen action. The agent makes no decision by\ndefault, and the burden of proof to make a decision falls on the policy to\naccrue evidence strongly in favor of a single decision. Our results show that\nthis accumulator module achieves near-optimal performance on a simple guessing\ngame, far outperforming deep recurrent networks using traditional, forced\naction selection policies."
    },
    "1705.01080": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kunanusont",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kamolwan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gaina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Raluca D."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jialin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Perez-Liebana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Diego"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lucas",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon M."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The N-Tuple Bandit Evolutionary Algorithm for Automatic Game Improvement",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 9 figure, 2 tables, CEC2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper describes a new evolutionary algorithm that is especially well\nsuited to AI-Assisted Game Design. The approach adopted in this paper is to use\nobservations of AI agents playing the game to estimate the game's quality. Some\nof best agents for this purpose are General Video Game AI agents, since they\ncan be deployed directly on a new game without game-specific tuning; these\nagents tend to be based on stochastic algorithms which give robust but noisy\nresults and tend to be expensive to run. This motivates the main contribution\nof the paper: the development of the novel N-Tuple Bandit Evolutionary\nAlgorithm, where a model is used to estimate the fitness of unsampled points\nand a bandit approach is used to balance exploration and exploitation of the\nsearch space. Initial results on optimising a Space Battle game variant suggest\nthat the algorithm offers far more robust results than the Random Mutation Hill\nClimber and a Biased Mutation variant, which are themselves known to offer\ncompetitive performance across a range of problems. Subjective observations are\nalso given by human players on the nature of the evolved games, which indicate\na preference towards games generated by the N-Tuple algorithm."
    },
    "1807.11919": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-07-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Beynier",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Aur\u00e9lie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bouveret",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sylvain"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lema\u00eetre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michel"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Maudet",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nicolas"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rey",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Simon"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficiency, Sequenceability and Deal-Optimality in Fair Division of\n  Indivisible Goods",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.MA",
        "http://arxiv.org/OAI/arXiv/:comments": "arXiv admin note: substantial text overlap with arXiv:1604.01734",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In fair division of indivisible goods, using sequences of sincere choices (or\npicking sequences) is a natural way to allocate the objects. The idea is as\nfollows: at each stage, a designated agent picks one object among those that\nremain. Another intuitive way to obtain an allocation is to give objects to\nagents in the first place, and to let agents exchange them as long as such\n\"deals\" are beneficial. This paper investigates these notions, when agents have\nadditive preferences over objects, and unveils surprising connections between\nthem, and with other efficiency and fairness notions. In particular, we show\nthat an allocation is sequenceable iff it is optimal for a certain type of\ndeals, namely cycle deals involving a single object. Furthermore, any\nPareto-optimal allocation is sequenceable, but not the converse. Regarding\nfairness, we show that an allocation can be envy-free and non-sequenceable, but\nthat every competitive equilibrium with equal incomes is sequenceable. To\ncomplete the picture, we show how some domain restrictions may affect the\nrelations between these notions. Finally, we experimentally explore the links\nbetween the scales of efficiency and fairness."
    },
    "1710.08315": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-10-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-11-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jinhua"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Du",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zidong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Huiying"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lei"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shengyuan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Xu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lingjie"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Cong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Haifeng"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rush",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Allen"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Willian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shaoli"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yunji"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tianshi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "BENCHIP: Benchmarking Intelligence Processors",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.PF cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "37pages, 14 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The increasing attention on deep learning has tremendously spurred the design\nof intelligence processing hardware. The variety of emerging intelligence\nprocessors requires standard benchmarks for fair comparison and system\noptimization (in both software and hardware). However, existing benchmarks are\nunsuitable for benchmarking intelligence processors due to their non-diversity\nand nonrepresentativeness. Also, the lack of a standard benchmarking\nmethodology further exacerbates this problem. In this paper, we propose\nBENCHIP, a benchmark suite and benchmarking methodology for intelligence\nprocessors. The benchmark suite in BENCHIP consists of two sets of benchmarks:\nmicrobenchmarks and macrobenchmarks. The microbenchmarks consist of\nsingle-layer networks. They are mainly designed for bottleneck analysis and\nsystem optimization. The macrobenchmarks contain state-of-the-art industrial\nnetworks, so as to offer a realistic comparison of different platforms. We also\npropose a standard benchmarking methodology built upon an industrial software\nstack and evaluation metrics that comprehensively reflect the various\ncharacteristics of the evaluated intelligence processors. BENCHIP is utilized\nfor evaluating various hardware platforms, including CPUs, GPUs, and\naccelerators. BENCHIP will be open-sourced soon."
    },
    "1802.06926": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Guo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shouyan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Huang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kaimin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jiaxin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gong",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Qian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bai",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Tong"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Overett",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gary"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Scale Optimization for Full-Image-CNN Vehicle Detection",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted by 2017 IEEE Intelligent Vehicles Symposium (IV). Link:\n  http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7995812",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many state-of-the-art general object detection methods make use of shared\nfull-image convolutional features (as in Faster R-CNN). This achieves a\nreasonable test-phase computation time while enjoys the discriminative power\nprovided by large Convolutional Neural Network (CNN) models. Such designs excel\non benchmarks which contain natural images but which have very unnatural\ndistributions, i.e. they have an unnaturally high-frequency of the target\nclasses and a bias towards a \"friendly\" or \"dominant\" object scale. In this\npaper we present further study of the use and adaptation of the Faster R-CNN\nobject detection method for datasets presenting natural scale distribution and\nunbiased real-world object frequency. In particular, we show that better\nalignment of the detector scale sensitivity to the extant distribution improves\nvehicle detection performance. We do this by modifying both the selection of\nRegion Proposals, and through using more scale-appropriate full-image\nconvolution features within the CNN model. By selecting better scales in the\nregion proposal input and by combining feature maps through careful design of\nthe convolutional neural network, we improve performance on smaller objects. We\nsignificantly increase detection AP for the KITTI dataset car class from 76.3%\non our baseline Faster R-CNN detector to 83.6% in our improved detector."
    },
    "1809.09444": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Barclay",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Iain"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Preece",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alun"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Taylor",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ian"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Defining the Collective Intelligence Supply Chain",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CY",
        "http://arxiv.org/OAI/arXiv/:comments": "Presented at AAAI FSS-18: Artificial Intelligence in Government and\n  Public Sector, Arlington, Virginia, USA",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Organisations are increasingly open to scrutiny, and need to be able to prove\nthat they operate in a fair and ethical way. Accountability should extend to\nthe production and use of the data and knowledge assets used in AI systems, as\nit would for any raw material or process used in production of physical goods.\nThis paper considers collective intelligence, comprising data and knowledge\ngenerated by crowd-sourced workforces, which can be used as core components of\nAI systems. A proposal is made for the development of a supply chain model for\ntracking the creation and use of crowdsourced collective intelligence assets,\nwith a blockchain based decentralised architecture identified as an appropriate\nmeans of providing validation, accountability and fairness."
    },
    "cs_9512101": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "1995-11-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Webb",
                "http://arxiv.org/OAI/arXiv/:forenames": "G. I."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "OPUS: An Efficient Admissible Algorithm for Unordered Search",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "See http://www.jair.org/ for any accompanying files",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Artificial Intelligence Research, Vol 3, (1995),\n  431-465",
        "http://arxiv.org/OAI/arXiv/:abstract": "OPUS is a branch and bound search algorithm that enables efficient admissible\nsearch through spaces for which the order of search operator application is not\nsignificant. The algorithm's search efficiency is demonstrated with respect to\nvery large machine learning search spaces. The use of admissible search is of\npotential value to the machine learning community as it means that the exact\nlearning biases to be employed for complex learning tasks can be precisely\nspecified and manipulated. OPUS also has potential for application in other\nareas of artificial intelligence, notably, truth maintenance."
    },
    "1709.03221": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-09-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Galhotra",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sainyam"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Brun",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yuriy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meliou",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alexandra"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fairness Testing: Testing Software for Discrimination",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SE cs.AI cs.CY cs.DB cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "Sainyam Galhotra, Yuriy Brun, and Alexandra Meliou. 2017. Fairness\n  Testing: Testing Software for Discrimination. In Proceedings of 2017 11th\n  Joint Meeting of the European Software Engineering Conference and the ACM\n  SIGSOFT Symposium on the Foundations of Software Engineering (ESEC/FSE),\n  Paderborn, Germany, September 4-8, 2017 (ESEC/FSE'17).\n  https://doi.org/10.1145/3106237.3106277, ESEC/FSE, 2017",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3106237.3106277",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This paper defines software fairness and discrimination and develops a\ntesting-based method for measuring if and how much software discriminates,\nfocusing on causality in discriminatory behavior. Evidence of software\ndiscrimination has been found in modern software systems that recommend\ncriminal sentences, grant access to financial products, and determine who is\nallowed to participate in promotions. Our approach, Themis, generates efficient\ntest suites to measure discrimination. Given a schema describing valid system\ninputs, Themis generates discrimination tests automatically and does not\nrequire an oracle. We evaluate Themis on 20 software systems, 12 of which come\nfrom prior work with explicit focus on avoiding discrimination. We find that\n(1) Themis is effective at discovering software discrimination, (2)\nstate-of-the-art techniques for removing discrimination from algorithms fail in\nmany situations, at times discriminating against as much as 98% of an input\nsubdomain, (3) Themis optimizations are effective at producing efficient test\nsuites for measuring discrimination, and (4) Themis is more efficient on\nsystems that exhibit more discrimination. We thus demonstrate that fairness\ntesting is a critical aspect of the software development cycle in domains with\npossible discrimination and provide initial tools for measuring software\ndiscrimination."
    },
    "1106.0245": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Baxter",
                "http://arxiv.org/OAI/arXiv/:forenames": "J."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Model of Inductive Bias Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 12, pages\n  149-198, 2000",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.731",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "A major problem in machine learning is that of inductive bias: how to choose\na learner's hypothesis space so that it is large enough to contain a solution\nto the problem being learnt, yet small enough to ensure reliable generalization\nfrom reasonably-sized training sets. Typically such bias is supplied by hand\nthrough the skill and insights of experts. In this paper a model for\nautomatically learning bias is investigated. The central assumption of the\nmodel is that the learner is embedded within an environment of related learning\ntasks. Within such an environment the learner can sample from multiple tasks,\nand hence it can search for a hypothesis space that contains good solutions to\nmany of the problems in the environment. Under certain restrictions on the set\nof all hypothesis spaces available to the learner, we show that a hypothesis\nspace that performs well on a sufficiently large number of training tasks will\nalso perform well when learning novel tasks in the same environment. Explicit\nbounds are also derived demonstrating that learning multiple tasks within an\nenvironment of related tasks can potentially give much better generalization\nthan learning a single task."
    },
    "1703.10579": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-03-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lyu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lingyu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kantardzic",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mehmed"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evaluating Complex Task through Crowdsourcing: Multiple Views Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.HC",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 13 figures, the paper is accepted by ICCSE 2016",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "With the popularity of massive open online courses, grading through\ncrowdsourcing has become a prevalent approach towards large scale classes.\nHowever, for getting grades for complex tasks, which require specific skills\nand efforts for grading, crowdsourcing encounters a restriction of insufficient\nknowledge of the workers from the crowd. Due to knowledge limitation of the\ncrowd graders, grading based on partial perspectives becomes a big challenge\nfor evaluating complex tasks through crowdsourcing. Especially for those tasks\nwhich not only need specific knowledge for grading, but also should be graded\nas a whole instead of being decomposed into smaller and simpler subtasks. We\npropose a framework for grading complex tasks via multiple views, which are\ndifferent grading perspectives defined by experts for the task, to provide\nuniformity. Aggregation algorithm based on graders variances are used to\ncombine the grades for each view. We also detect bias patterns of the graders,\nand debias them regarding each view of the task. Bias pattern determines how\nthe behavior is biased among graders, which is detected by a statistical\ntechnique. The proposed approach is analyzed on a synthetic data set. We show\nthat our model gives more accurate results compared to the grading approaches\nwithout different views and debiasing algorithm."
    },
    "1810.00428": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Najafi",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Saeed"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cherry",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Colin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kondrak",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Grzegorz"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Efficient Sequence Labeling with Actor-Critic Training",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CL stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Neural approaches to sequence labeling often use a Conditional Random Field\n(CRF) to model their output dependencies, while Recurrent Neural Networks (RNN)\nare used for the same purpose in other tasks. We set out to establish RNNs as\nan attractive alternative to CRFs for sequence labeling. To do so, we address\none of the RNN's most prominent shortcomings, the fact that it is not exposed\nto its own errors with the maximum-likelihood training. We frame the prediction\nof the output sequence as a sequential decision-making process, where we train\nthe network with an adjusted actor-critic algorithm (AC-RNN). We\ncomprehensively compare this strategy with maximum-likelihood training for both\nRNNs and CRFs on three structured-output tasks. The proposed AC-RNN efficiently\nmatches the performance of the CRF on NER and CCG tagging, and outperforms it\non Machine Transliteration. We also show that our training strategy is\nsignificantly better than other techniques for addressing RNN's exposure bias,\nsuch as Scheduled Sampling, and Self-Critical policy training."
    },
    "1302.7175": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-02-28",
        "http://arxiv.org/OAI/arXiv/:updated": "2013-03-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "van Hasselt",
                "http://arxiv.org/OAI/arXiv/:forenames": "Hado"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Estimating the Maximum Expected Value: An Analysis of (Nested) Cross\n  Validation and the Maximum Sample Average",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG stat.ME",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We investigate the accuracy of the two most common estimators for the maximum\nexpected value of a general set of random variables: a generalization of the\nmaximum sample average, and cross validation. No unbiased estimator exists and\nwe show that it is non-trivial to select a good estimator without knowledge\nabout the distributions of the random variables. We investigate and bound the\nbias and variance of the aforementioned estimators and prove consistency. The\nvariance of cross validation can be significantly reduced, but not without\nrisking a large bias. The bias and variance of different variants of cross\nvalidation are shown to be very problem-dependent, and a wrong choice can lead\nto very inaccurate estimates."
    },
    "1701.02870": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-01-11",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-07-31",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Vedantam",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ramakrishna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bengio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Samy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Murphy",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kevin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Parikh",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Devi"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Chechik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gal"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Context-aware Captions from Context-agnostic Supervision",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted to CVPR 2017 (Spotlight)",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We introduce an inference technique to produce discriminative context-aware\nimage captions (captions that describe differences between images or visual\nconcepts) using only generic context-agnostic training data (captions that\ndescribe a concept or an image in isolation). For example, given images and\ncaptions of \"siamese cat\" and \"tiger cat\", we generate language that describes\nthe \"siamese cat\" in a way that distinguishes it from \"tiger cat\". Our key\nnovelty is that we show how to do joint inference over a language model that is\ncontext-agnostic and a listener which distinguishes closely-related concepts.\nWe first apply our technique to a justification task, namely to describe why an\nimage contains a particular fine-grained category as opposed to another\nclosely-related category of the CUB-200-2011 dataset. We then study\ndiscriminative image captioning to generate language that uniquely refers to\none of two semantically-similar images in the COCO dataset. Evaluations with\ndiscriminative ground truth for justification and human studies for\ndiscriminative image captioning reveal that our approach outperforms baseline\ngenerative and speaker-listener approaches for discrimination."
    },
    "1806.05085": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-13",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Wang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jingyan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Shah",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nihar B."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Your 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in\n  Ratings",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.IT cs.LG math.IT",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Cardinal scores (numeric ratings) collected from people are well known to\nsuffer from miscalibrations. A popular approach to address this issue is to\nassume simplistic models of miscalibration (such as linear biases) to de-bias\nthe scores. This approach, however, often fares poorly because people's\nmiscalibrations are typically far more complex and not well understood. In the\nabsence of simplifying assumptions on the miscalibration, it is widely believed\nby the crowdsourcing community that the only useful information in the cardinal\nscores is the induced ranking. In this paper, inspired by the framework of\nStein's shrinkage, empirical Bayes, and the classic two-envelope problem, we\ncontest this widespread belief. Specifically, we consider cardinal scores with\narbitrary (or even adversarially chosen) miscalibrations which are only\nrequired to be consistent with the induced ranking. We design estimators which\ndespite making no assumptions on the miscalibration, strictly and uniformly\noutperform all possible estimators that rely on only the ranking. Our\nestimators are flexible in that they can be used as a plug-in for a variety of\napplications, and we provide a proof-of-concept for A/B testing and ranking.\nOur results thus provide novel insights in the eternal debate between cardinal\nand ordinal data."
    },
    "1810.05041": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Fitzsimons",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jack"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ali",
                    "http://arxiv.org/OAI/arXiv/:forenames": "AbdulRahman Al"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Osborne",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Roberts",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Stephen"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Equality Constrained Decision Trees: For the Algorithmic Enforcement of\n  Group Fairness",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 2 figures, 1 page references, 1 page appendix",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Fairness, through its many forms and definitions, has become an important\nissue facing the machine learning community. In this work, we consider how to\nincorporate group fairness constraints in kernel regression methods. More\nspecifically, we focus on examining the incorporation of these constraints in\ndecision tree regression when cast as a form of kernel regression, with direct\napplications to random forests and boosted trees amongst other widespread\npopular inference techniques. We show that order of complexity of memory and\ncomputation is preserved for such models and bounds the expected perturbations\nto the model in terms of the number of leaves of the trees. Importantly, the\napproach works on trained models and hence can be easily applied to models in\ncurrent use."
    },
    "1803.09967": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Maestre",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Roberto"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Duque",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Juan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Rubio",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alberto"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ar\u00e9valo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Juan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Reinforcement Learning for Fair Dynamic Pricing",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Unfair pricing policies have been shown to be one of the most negative\nperceptions customers can have concerning pricing, and may result in long-term\nlosses for a company. Despite the fact that dynamic pricing models help\ncompanies maximize revenue, fairness and equality should be taken into account\nin order to avoid unfair price differences between groups of customers. This\npaper shows how to solve dynamic pricing by using Reinforcement Learning (RL)\ntechniques so that prices are maximized while keeping a balance between revenue\nand fairness. We demonstrate that RL provides two main features to support\nfairness in dynamic pricing: on the one hand, RL is able to learn from recent\nexperience, adapting the pricing policy to complex market environments; on the\nother hand, it provides a trade-off between short and long-term objectives,\nhence integrating fairness into the model's core. Considering these two\nfeatures, we propose the application of RL for revenue optimization, with the\nadditional integration of fairness as part of the learning procedure by using\nJain's index as a metric. Results in a simulated environment show a significant\nimprovement in fairness while at the same time maintaining optimisation of\nrevenue."
    },
    "1808.09123": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-08-28",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sarah"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Adebayo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Julius"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Inkpen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kori"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kamar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ece"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Investigating Human + Machine Complementarity for Recidivism Predictions",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "When might human input help (or not) when assessing risk in fairness-related\ndomains? Dressel and Farid asked Mechanical Turk workers to evaluate a subset\nof individuals in the ProPublica COMPAS data set for risk of recidivism, and\nconcluded that COMPAS predictions were no more accurate or fair than\npredictions made by humans. We delve deeper into this claim in this paper. We\nconstruct a Human Risk Score based on the predictions made by multiple\nMechanical Turk workers on the same individual, study the agreement and\ndisagreement between COMPAS and Human Scores on subgroups of individuals, and\nconstruct hybrid Human+AI models to predict recidivism. Our key finding is that\non this data set, human and COMPAS decision making differed, but not in ways\nthat could be leveraged to significantly improve ground truth prediction. We\npresent the results of our analyses and suggestions for how machine and human\ninput may have complementary strengths to address challenges in the fairness\ndomain."
    },
    "1306.2558": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-06-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Cohen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "William W."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Redlawsk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pierce",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Douglas"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Effect of Biased Communications On Both Trusting and Suspicious\n  Voters",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In recent studies of political decision-making, apparently anomalous behavior\nhas been observed on the part of voters, in which negative information about a\ncandidate strengthens, rather than weakens, a prior positive opinion about the\ncandidate. This behavior appears to run counter to rational models of decision\nmaking, and it is sometimes interpreted as evidence of non-rational \"motivated\nreasoning\". We consider scenarios in which this effect arises in a model of\nrational decision making which includes the possibility of deceptive\ninformation. In particular, we will consider a model in which there are two\nclasses of voters, which we will call trusting voters and suspicious voters,\nand two types of information sources, which we will call unbiased sources and\nbiased sources. In our model, new data about a candidate can be efficiently\nincorporated by a trusting voter, and anomalous updates are impossible;\nhowever, anomalous updates can be made by suspicious voters, if the information\nsource mistakenly plans for an audience of trusting voters, and if the partisan\ngoals of the information source are known by the suspicious voter to be\n\"opposite\" to his own. Our model is based on a formalism introduced by the\nartificial intelligence community called \"multi-agent influence diagrams\",\nwhich generalize Bayesian networks to settings involving multiple agents with\ndistinct goals."
    },
    "1107.0054": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2011-06-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Birmingham",
                    "http://arxiv.org/OAI/arXiv/:forenames": "W. P."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Meek",
                    "http://arxiv.org/OAI/arXiv/:forenames": "C. J."
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "A Comprehensive Trainable Error Model for Sung Music Queries",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:proxy": "jair.org",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal Of Artificial Intelligence Research, Volume 22, pages\n  57-91, 2004",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1613/jair.1334",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We propose a model for errors in sung queries, a variant of the hidden Markov\nmodel (HMM). This is a solution to the problem of identifying the degree of\nsimilarity between a (typically error-laden) sung query and a potential target\nin a database of musical works, an important problem in the field of music\ninformation retrieval. Similarity metrics are a critical component of\nquery-by-humming (QBH) applications which search audio and multimedia databases\nfor strong matches to oral queries. Our model comprehensively expresses the\ntypes of error or variation between target and query: cumulative and\nnon-cumulative local errors, transposition, tempo and tempo changes,\ninsertions, deletions and modulation. The model is not only expressive, but\nautomatically trainable, or able to learn and generalize from query examples.\nWe present results of simulations, designed to assess the discriminatory\npotential of the model, and tests with real sung queries, to demonstrate\nrelevance to real-world applications."
    },
    "1810.09832": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-21",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Abebe",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Rediet"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Goldner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kira"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Mechanism Design for Social Good",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.GT cs.AI cs.CY cs.DS",
        "http://arxiv.org/OAI/arXiv/:comments": "AI Matters, 2018",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1145/3284751.328476",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Across various domains--such as health, education, and housing--improving\nsocietal welfare involves allocating resources, setting policies, targeting\ninterventions, and regulating activities. These solutions have an immense\nimpact on the day-to-day lives of individuals, whether in the form of access to\nquality healthcare, labor market outcomes, or how votes are accounted for in a\ndemocratic society. Problems that can have an out-sized impact on individuals\nwhose opportunities have historically been limited often pose conceptual and\ntechnical challenges, requiring insights from many disciplines. Conversely, the\nlack of interdisciplinary approach can leave these urgent needs unaddressed and\ncan even exacerbate underlying socioeconomic inequalities. To realize the\nopportunities in these domains, we need to correctly set objectives and reason\nabout human behavior and actions. Doing so requires a deep grounding in the\nfield of interest and collaboration with domain experts who understand the\nsocietal implications and feasibility of proposed solutions. These insights can\nplay an instrumental role in proposing algorithmically-informed policies.\n  In this article, we describe the Mechanism Design for Social Good (MD4SG)\nresearch agenda, which involves using insights from algorithms, optimization,\nand mechanism design to improve access to opportunity. The MD4SG research\ncommunity takes an interdisciplinary, multi-stakeholder approach to improve\nsocietal welfare. We discuss three exciting research avenues within MD4SG\nrelated to improving access to opportunity in the developing world, labor\nmarkets and discrimination, and housing. For each of these, we showcase ongoing\nwork, underline new directions, and discuss potential for implementing existing\nwork in practice."
    },
    "1803.02852": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-03-07",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Estrada",
                "http://arxiv.org/OAI/arXiv/:forenames": "Daniel"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Value Alignment, Fair Play, and the Rights of Service Robots",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CY cs.AI",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Ethics and safety research in artificial intelligence is increasingly framed\nin terms of \"alignment\" with human values and interests. I argue that Turing's\ncall for \"fair play for machines\" is an early and often overlooked contribution\nto the alignment literature. Turing's appeal to fair play suggests a need to\ncorrect human behavior to accommodate our machines, a surprising inversion of\nhow value alignment is treated today. Reflections on \"fair play\" motivate a\nnovel interpretation of Turing's notorious \"imitation game\" as a condition not\nof intelligence but instead of value alignment: a machine demonstrates a\nminimal degree of alignment (with the norms of conversation, for instance) when\nit can go undetected when interrogated by a human. I carefully distinguish this\ninterpretation from the Moral Turing Test, which is not motivated by a\nprinciple of fair play, but instead depends on imitation of human moral\nbehavior. Finally, I consider how the framework of fair play can be used to\nsituate the debate over robot rights within the alignment literature. I argue\nthat extending rights to service robots operating in public spaces is \"fair\" in\nprecisely the sense that it encourages an alignment of interests between humans\nand machines."
    },
    "1805.04025": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yuille",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Alan L."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Liu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Chenxi"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Deep Nets: What have they ever done for Vision?",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CV cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "MIT CBMM Memo No. 088",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "This is an opinion paper about the strengths and weaknesses of Deep Nets.\nThey are at the center of recent progress on Artificial Intelligence and are of\ngrowing importance in Cognitive Science and Neuroscience since they enable the\ndevelopment of computational models that can deal with a large range of\nvisually realistic stimuli and visual tasks. They have clear limitations but\nthey also have enormous successes. There is also gradual, though incomplete,\nunderstanding of their inner workings. It seems unlikely that Deep Nets in\ntheir current form will be the best long-term solution either for building\ngeneral purpose intelligent machines or for understanding the mind/brain, but\nit is likely that many aspects of them will remain. At present Deep Nets do\nvery well on specific types of visual tasks and on specific benchmarked\ndatasets. But Deep Nets are much less general purpose, flexible, and adaptive\nthan the human visual system. Moreover, methods like Deep Nets may run into\nfundamental difficulties when faced with the enormous complexity of natural\nimages. To illustrate our main points, while keeping the references small, this\npaper is slightly biased towards work from our group."
    },
    "1706.00387": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-06-01",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Shixiang"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lillicrap",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Timothy"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ghahramani",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zoubin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Turner",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Richard E."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sch\u00f6lkopf",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Bernhard"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Levine",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sergey"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient\n  Estimation for Deep Reinforcement Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.RO",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Off-policy model-free deep reinforcement learning methods using previously\ncollected data can improve sample efficiency over on-policy policy gradient\ntechniques. On the other hand, on-policy algorithms are often more stable and\neasier to use. This paper examines, both theoretically and empirically,\napproaches to merging on- and off-policy updates for deep reinforcement\nlearning. Theoretical results show that off-policy updates with a value\nfunction estimator can be interpolated with on-policy policy gradient updates\nwhilst still satisfying performance bounds. Our analysis uses control variate\nmethods to produce a family of policy gradient algorithms, with several\nrecently proposed algorithms being special cases of this family. We then\nprovide an empirical comparison of these techniques with the remaining\nalgorithmic details fixed, and show how different mixing of off-policy gradient\nestimates with on-policy samples contribute to improvements in empirical\nperformance. The final algorithm provides a generalization and unification of\nexisting deep policy gradient techniques, has theoretical guarantees on the\nbias introduced by off-policy updates, and improves on the state-of-the-art\nmodel-free deep RL methods on a number of OpenAI Gym continuous control\nbenchmarks."
    },
    "1802.03753": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-11",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Weisz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Gell\u00e9rt"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Budzianowski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pawe\u0142"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Su",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Pei-Hao"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ga\u0161i\u0107",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Milica"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Sample Efficient Deep Reinforcement Learning for Dialogue Systems with\n  Large Action Spaces",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.CL cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In spoken dialogue systems, we aim to deploy artificial intelligence to build\nautomated dialogue agents that can converse with humans. A part of this effort\nis the policy optimisation task, which attempts to find a policy describing how\nto respond to humans, in the form of a function taking the current state of the\ndialogue and returning the response of the system. In this paper, we\ninvestigate deep reinforcement learning approaches to solve this problem.\nParticular attention is given to actor-critic methods, off-policy reinforcement\nlearning with experience replay, and various methods aimed at reducing the bias\nand variance of estimators. When combined, these methods result in the\npreviously proposed ACER algorithm that gave competitive results in gaming\nenvironments. These environments however are fully observable and have a\nrelatively small action set so in this paper we examine the application of ACER\nto dialogue policy optimisation. We show that this method beats the current\nstate-of-the-art in deep learning approaches for spoken dialogue systems. This\nnot only leads to a more sample efficient algorithm that can train faster, but\nalso allows us to apply the algorithm in more difficult environments than\nbefore. We thus experiment with learning in a very large action space, which\nhas two orders of magnitude more actions than previously considered. We find\nthat ACER trains significantly faster than the current state-of-the-art."
    },
    "1705.05098": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-15",
        "http://arxiv.org/OAI/arXiv/:updated": "2017-05-24",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Poddar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lahari"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hsu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Wynne"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lee",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mong Li"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Quantifying Aspect Bias in Ordinal Ratings using a Bayesian Approach",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Accepted for publication in IJCAI 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "User opinions expressed in the form of ratings can influence an individual's\nview of an item. However, the true quality of an item is often obfuscated by\nuser biases, and it is not obvious from the observed ratings the importance\ndifferent users place on different aspects of an item. We propose a\nprobabilistic modeling of the observed aspect ratings to infer (i) each user's\naspect bias and (ii) latent intrinsic quality of an item. We model multi-aspect\nratings as ordered discrete data and encode the dependency between different\naspects by using a latent Gaussian structure. We handle the\nGaussian-Categorical non-conjugacy using a stick-breaking formulation coupled\nwith P\\'{o}lya-Gamma auxiliary variable augmentation for a simple, fully\nBayesian inference. On two real world datasets, we demonstrate the predictive\nability of our model and its effectiveness in learning explainable user biases\nto provide insights towards a more reliable product quality estimation."
    },
    "1806.07082": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-19",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tikka",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Santtu"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Karvanen",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Juha"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Simplifying Probabilistic Expressions in Causal Inference",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ML cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "This is the version published in JMLR",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Journal of Machine Learning Research (JMLR), 18(36):1-30, 2017",
        "http://arxiv.org/OAI/arXiv/:license": "http://creativecommons.org/licenses/by/4.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Obtaining a non-parametric expression for an interventional distribution is\none of the most fundamental tasks in causal inference. Such an expression can\nbe obtained for an identifiable causal effect by an algorithm or by manual\napplication of do-calculus. Often we are left with a complicated expression\nwhich can lead to biased or inefficient estimates when missing data or\nmeasurement errors are involved. We present an automatic simplification\nalgorithm that seeks to eliminate symbolically unnecessary variables from these\nexpressions by taking advantage of the structure of the underlying graphical\nmodel. Our method is applicable to all causal effect formulas and is readily\navailable in the R package causaleffect."
    },
    "1802.08534": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-02-23",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-04-14",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zheng",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Yan"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Hao",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Jianye"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhang",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Zongzhang"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Weighted Double Deep Multiagent Reinforcement Learning in Stochastic\n  Cooperative Environments",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.MA cs.AI cs.LG",
        "http://arxiv.org/OAI/arXiv/:comments": "8 pages, 7 figures",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Recently, multiagent deep reinforcement learning (DRL) has received\nincreasingly wide attention. Existing multiagent DRL algorithms are inefficient\nwhen facing with the non-stationarity due to agents update their policies\nsimultaneously in stochastic cooperative environments. This paper extends the\nrecently proposed weighted double estimator to the multiagent domain and\npropose a multiagent DRL framework, named weighted double deep Q-network\n(WDDQN). By utilizing the weighted double estimator and the deep neural\nnetwork, WDDQN can not only reduce the bias effectively but also be extended to\nscenarios with raw visual inputs. To achieve efficient cooperation in the\nmultiagent domain, we introduce the lenient reward network and the scheduled\nreplay strategy. Experiments show that the WDDQN outperforms the existing DRL\nand multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms\nof the average reward and the convergence rate in stochastic cooperative\nenvironments."
    },
    "1503.02834": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-03-10",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Dud\u00edk",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Miroslav"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Erhan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Dumitru"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Langford",
                    "http://arxiv.org/OAI/arXiv/:forenames": "John"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Li",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lihong"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Doubly Robust Policy Evaluation and Optimization",
        "http://arxiv.org/OAI/arXiv/:categories": "stat.ME cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Published in at http://dx.doi.org/10.1214/14-STS500 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)",
        "http://arxiv.org/OAI/arXiv/:proxy": "vtex",
        "http://arxiv.org/OAI/arXiv/:report-no": "IMS-STS-STS500",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Statistical Science 2014, Vol. 29, No. 4, 485-511",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1214/14-STS500",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We study sequential decision making in environments where rewards are only\npartially observed, but can be modeled as a function of observed contexts and\nthe chosen action by the decision maker. This setting, known as contextual\nbandits, encompasses a wide variety of applications such as health care,\ncontent recommendation and Internet advertising. A central task is evaluation\nof a new policy given historic data consisting of contexts, actions and\nreceived rewards. The key challenge is that the past data typically does not\nfaithfully represent proportions of actions taken by a new policy. Previous\napproaches rely either on models of rewards or models of the past policy. The\nformer are plagued by a large bias whereas the latter have a large variance. In\nthis work, we leverage the strengths and overcome the weaknesses of the two\napproaches by applying the doubly robust estimation technique to the problems\nof policy evaluation and optimization. We prove that this approach yields\naccurate value estimates when we have either a good (but not necessarily\nconsistent) model of rewards or a good (but not necessarily consistent) model\nof past policy. Extensive empirical comparison demonstrates that the doubly\nrobust estimation uniformly improves over existing techniques, achieving both\nlower variance in value estimation and better policies. As such, we expect the\ndoubly robust approach to become common practice in policy evaluation and\noptimization."
    },
    "1809.04684": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-09-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Chen",
                "http://arxiv.org/OAI/arXiv/:forenames": "Jiahao"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Fair lending needs explainable models for responsible recommendation",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CY stat.AP stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "4 pages, position paper accepted for FATREC 2018 conference at ACM\n  RecSys",
        "http://arxiv.org/OAI/arXiv/:msc-class": "91G40, 68T01",
        "http://arxiv.org/OAI/arXiv/:acm-class": "J.1; I.5.1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The financial services industry has unique explainability and fairness\nchallenges arising from compliance and ethical considerations in credit\ndecisioning. These challenges complicate the use of model machine learning and\nartificial intelligence methods in business decision processes."
    },
    "1806.00069": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-05-31",
        "http://arxiv.org/OAI/arXiv/:updated": "2018-06-04",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Gilpin",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Leilani H."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bau",
                    "http://arxiv.org/OAI/arXiv/:forenames": "David"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yuan",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ben Z."
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bajwa",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ayesha"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Specter",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Michael"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Kagal",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Lalana"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Explaining Explanations: An Approach to Evaluating Interpretability of\n  Machine Learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.LG stat.ML",
        "http://arxiv.org/OAI/arXiv/:comments": "Edited author email",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "There has recently been a surge of work in explanatory artificial\nintelligence (XAI). This research area tackles the important problem that\ncomplex machines and algorithms often cannot provide insights into their\nbehavior and thought processes. XAI allows users and parts of the internal\nsystem to be more transparent, providing explanations of their decisions in\nsome level of detail. These explanations are important to ensure algorithmic\nfairness, identify potential bias/problems in the training data, and to ensure\nthat the algorithms perform as expected. However, explanations produced by\nthese systems is neither standardized nor systematically assessed. In an effort\nto create best practices and identify open challenges, we provide our\ndefinition of explainability and show how it can be used to classify existing\nliterature. We discuss why current approaches to explanatory methods especially\nfor deep neural networks are insufficient. Finally, based on our survey, we\nconclude with suggested future research directions for explanatory artificial\nintelligence."
    },
    "1705.06460": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2017-05-18",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pratama",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mahardhika"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pedrycz",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Witold"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lughofer",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Edwin"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Evolving Ensemble Fuzzy Classifier",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "this paper is currently submitted for possible publication in IEEE",
        "http://arxiv.org/OAI/arXiv/:doi": "10.1109/TFUZZ.2018.2796099",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "The concept of ensemble learning offers a promising avenue in learning from\ndata streams under complex environments because it addresses the bias and\nvariance dilemma better than its single model counterpart and features a\nreconfigurable structure, which is well suited to the given context. While\nvarious extensions of ensemble learning for mining non-stationary data streams\ncan be found in the literature, most of them are crafted under a static base\nclassifier and revisits preceding samples in the sliding window for a\nretraining step. This feature causes computationally prohibitive complexity and\nis not flexible enough to cope with rapidly changing environments. Their\ncomplexities are often demanding because it involves a large collection of\noffline classifiers due to the absence of structural complexities reduction\nmechanisms and lack of an online feature selection mechanism. A novel evolving\nensemble classifier, namely Parsimonious Ensemble pENsemble, is proposed in\nthis paper. pENsemble differs from existing architectures in the fact that it\nis built upon an evolving classifier from data streams, termed Parsimonious\nClassifier pClass. pENsemble is equipped by an ensemble pruning mechanism,\nwhich estimates a localized generalization error of a base classifier. A\ndynamic online feature selection scenario is integrated into the pENsemble.\nThis method allows for dynamic selection and deselection of input features on\nthe fly. pENsemble adopts a dynamic ensemble structure to output a final\nclassification decision where it features a novel drift detection scenario to\ngrow the ensemble structure. The efficacy of the pENsemble has been numerically\ndemonstrated through rigorous numerical studies with dynamic and evolving data\nstreams where it delivers the most encouraging performance in attaining a\ntradeoff between accuracy and complexity."
    },
    "1304.3443": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-03-27",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Zimmer",
                "http://arxiv.org/OAI/arXiv/:forenames": "Alf C."
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "The Estimation of Subjective Probabilities via Categorical Judgments of\n  Uncertainty",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI",
        "http://arxiv.org/OAI/arXiv/:comments": "Appears in Proceedings of the First Conference on Uncertainty in\n  Artificial Intelligence (UAI1985)",
        "http://arxiv.org/OAI/arXiv/:proxy": "auai",
        "http://arxiv.org/OAI/arXiv/:report-no": "UAI-P-1985-PG-217-224",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Theoretically as well as experimentally it is investigated how people\nrepresent their knowledge in order to make decisions or to share their\nknowledge with others. Experiment 1 probes into the ways how people 6ather\ninformation about the frequencies of events and how the requested response\nmode, that is, numerical vs. verbal estimates interferes with this knowledge.\nThe least interference occurs if the subjects are allowed to give verbal\nresponses. From this it is concluded that processing knowledge about\nuncertainty categorically, that is, by means of verbal expressions, imposes\nless mental work load on the decision matter than numerical processing.\nPossibility theory is used as a framework for modeling the individual usage of\nverbal categories for grades of uncertainty. The 'elastic' constraints on the\nverbal expressions for every sing1e subject are determined in Experiment 2 by\nmeans of sequential calibration. In further experiments it is shown that the\nsuperiority of the verbal processing of knowledge about uncertainty guise\ngenerally reduces persistent biases reported in the literature: conservatism\n(Experiment 3) and neg1igence of regression (Experiment 4). The reanalysis of\nHormann's data reveal that in verbal Judgments people exhibit sensitivity for\nbase rates and are not prone to the conjunction fallacy. In a final experiment\n(5) about predictions in a real-life situation it turns out that in a numerical\nforecasting task subjects restricted themselves to those parts of their\nknowledge which are numerical. On the other hand subjects in a verbal\nforecasting task accessed verbally as well as numerically stated knowledge.\nForecasting is structurally related to the estimation of probabilities for rare\nevents insofar as supporting and contradicting arguments have to be evaluated\nand the choice of the final Judgment has to be Justified according to the\nevidence brought forward. In order to assist people in such choice situations a\nformal model for the interactive checking of arguments has been developed. The\nmodel transforms the normal-language quantifiers used in the arguments into\nfuzzy numbers and evaluates the given train of arguments by means of fuzzy\nnumerica1 operations. Ambiguities in the meanings of quantifiers are resolved\ninteractively."
    },
    "1510.03370": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2015-10-12",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garrabrant",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Scott"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bhaskar",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Siddharth"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Demski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Abram"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Garrabrant",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Joanna"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Koleszarik",
                    "http://arxiv.org/OAI/arXiv/:forenames": "George"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Lloyd",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Evan"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Asymptotic Logical Uncertainty and The Benford Test",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI",
        "http://arxiv.org/OAI/arXiv/:report-no": "2015--11",
        "http://arxiv.org/OAI/arXiv/:acm-class": "F.4.1",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We give an algorithm A which assigns probabilities to logical sentences. For\nany simple infinite sequence of sentences whose truth-values appear\nindistinguishable from a biased coin that outputs \"true\" with probability p, we\nhave that the sequence of probabilities that A assigns to these sentences\nconverges to p."
    },
    "1302.6031": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2013-02-25",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": {
                "http://arxiv.org/OAI/arXiv/:keyname": "Such",
                "http://arxiv.org/OAI/arXiv/:forenames": "Ondrej"
            }
        },
        "http://arxiv.org/OAI/arXiv/:title": "Phoneme discrimination using KS algebra I",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.SD cs.AI cs.NE",
        "http://arxiv.org/OAI/arXiv/:acm-class": "I.2.7; I.5.2; I.5.4",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "In our work we define a new algebra of operators as a substitute for fuzzy\nlogic. Its primary purpose is for construction of binary discriminators for\nphonemes based on spectral content. It is optimized for design of\nnon-parametric computational circuits, and makes uses of 4 operations: $\\min$,\n$\\max$, the difference and generalized additively homogenuous means."
    },
    "1810.02897": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-10-05",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Zhu",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Ye"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Ting",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Kai Ming"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Carman",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Mark"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Angelova",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Maia"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "CDF Transform-Shift: An effective way to deal with inhomogeneous density\n  datasets",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.LG cs.AI cs.CV stat.ML",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Many distance-based algorithms exhibit bias towards dense clusters in\ninhomogeneous datasets (i.e., those which contain clusters in both dense and\nsparse regions of the space). For example, density-based clustering algorithms\ntend to join neighbouring dense clusters together into a single group in the\npresence of a sparse cluster; while distance-based anomaly detectors exhibit\ndifficulty in detecting local anomalies which are close to a dense cluster in\ndatasets also containing sparse clusters. In this paper, we propose the CDF\nTransform-Shift (CDF-TS) algorithm which is based on a multi-dimensional\nCumulative Distribution Function (CDF) transformation. It effectively converts\na dataset with clusters of inhomogeneous density to one with clusters of\nhomogeneous density, i.e., the data distribution is converted to one in which\nall locally low/high-density locations become globally low/high-density\nlocations. Thus, after performing the proposed Transform-Shift, a single global\ndensity threshold can be used to separate the data into clusters and their\nsurrounding noise points. Our empirical evaluations show that CDF-TS overcomes\nthe shortcomings of existing density-based clustering and distance-based\nanomaly detection algorithms and significantly improves their performance."
    },
    "1806.10244": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2018-06-26",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Yadav",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Nitin"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Murawski",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Carsten"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Sardina",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Sebastian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Bossaerts",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Peter"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "Phase transition in the knapsack problem",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.AI cs.CC",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "We examine the phase transition phenomenon for the Knapsack problem from both\na computational and a human perspective. We first provide, via an empirical and\na theoretical analysis, a characterization of the phenomenon in terms of two\ninstance properties; normalised capacity and normalised profit. Then, we show\nevidence that average time spent by human decision makers in solving an\ninstance peaks near the phase transition. Given the ubiquity of the Knapsack\nproblem in every-day life, a better understanding of its structure can improve\nour understanding not only of computational techniques but also of human\nbehavior, including the use and development of heuristics and occurrence of\nbiases."
    },
    "1409.8484": {
        "@http://www.w3.org/2001/XMLSchema-instance:schemaLocation": "http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd",
        "@xmlns": {
            "ns0": "http://arxiv.org/OAI/arXiv/",
            "xsi": "http://www.w3.org/2001/XMLSchema-instance"
        },
        "http://arxiv.org/OAI/arXiv/:created": "2014-09-30",
        "http://arxiv.org/OAI/arXiv/:authors": {
            "http://arxiv.org/OAI/arXiv/:author": [
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Napoli",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Christian"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Pappalardo",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Giuseppe"
                },
                {
                    "http://arxiv.org/OAI/arXiv/:keyname": "Tramontana",
                    "http://arxiv.org/OAI/arXiv/:forenames": "Emiliano"
                }
            ]
        },
        "http://arxiv.org/OAI/arXiv/:title": "An agent-driven semantical identifier using radial basis neural networks\n  and reinforcement learning",
        "http://arxiv.org/OAI/arXiv/:categories": "cs.NE cs.AI cs.CL cs.LG cs.MA",
        "http://arxiv.org/OAI/arXiv/:comments": "Published on: Proceedings of the XV Workshop \"Dagli Oggetti agli\n  Agenti\" (WOA 2014), Catania, Italy, Sepember. 25-26, 2014",
        "http://arxiv.org/OAI/arXiv/:msc-class": "68T01, 68T05, 68T10, 68T50, 68U15",
        "http://arxiv.org/OAI/arXiv/:acm-class": "C.2.1; I.2.6; I.2.7",
        "http://arxiv.org/OAI/arXiv/:journal-ref": "Proceedings of the XV Workshop \"Dagli Oggetti agli Agenti\" (WOA\n  2014), on CEUR-WS, volume 1260, ISSN: 1613-073, Catania, Italy, Sepember.\n  25-26, 2014. http://ceur-ws.org/Vol-1260/",
        "http://arxiv.org/OAI/arXiv/:doi": "10.13140/2.1.1446.7843",
        "http://arxiv.org/OAI/arXiv/:license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/",
        "http://arxiv.org/OAI/arXiv/:abstract": "Due to the huge availability of documents in digital form, and the deception\npossibility raise bound to the essence of digital documents and the way they\nare spread, the authorship attribution problem has constantly increased its\nrelevance. Nowadays, authorship attribution,for both information retrieval and\nanalysis, has gained great importance in the context of security, trust and\ncopyright preservation. This work proposes an innovative multi-agent driven\nmachine learning technique that has been developed for authorship attribution.\nBy means of a preprocessing for word-grouping and time-period related analysis\nof the common lexicon, we determine a bias reference level for the recurrence\nfrequency of the words within analysed texts, and then train a Radial Basis\nNeural Networks (RBPNN)-based classifier to identify the correct author. The\nmain advantage of the proposed approach lies in the generality of the semantic\nanalysis, which can be applied to different contexts and lexical domains,\nwithout requiring any modification. Moreover, the proposed system is able to\nincorporate an external input, meant to tune the classifier, and then\nself-adjust by means of continuous learning reinforcement."
    }
}